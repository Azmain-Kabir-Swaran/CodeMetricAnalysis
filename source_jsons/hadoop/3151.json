{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "WebHdfsFileSystem.java",
  "functionName": "toUrl",
  "functionId": "toUrl___op-HttpOpParam.Op(modifiers-final)__fspath-Path(modifiers-final)__parameters-Param__?,?__(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
  "functionStartLine": 614,
  "functionEndLine": 626,
  "numCommitsSeen": 179,
  "timeTaken": 6689,
  "changeHistory": [
    "da0006fe0473e353ee2d489156248a01aa982dfd",
    "3e5e5b028ad7e199d08e524fe7cddeee5db51a6d",
    "1361030e59d7557a2bffac0ea8df116ce2eaae4a",
    "46d29e3d7ee8dc9bb1818b886d9cc5336b1d67a4",
    "39285e6a1978ea5e53bdc1b0aef62421382124a8",
    "6ee0539ede78b640f01c5eac18ded161182a7835",
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
    "122cad6aec5839d8d515c5008425ecb34f2fa56b",
    "bcf89ddc7d52e04725caf104f5958e33d9f51b35",
    "05fd0a706aedfb83222a48e4cd110b1897c4b3c5",
    "97ccd64401569a8cdabc40c5897e34a03ce4bb22",
    "8fa10b184e607a33f59e67bd4b1fbe5a2e683941",
    "9b1f47226b076bf912a922aba293218dcadc7024",
    "bd21ddcb78350b311f271e233038b8ca78a65242",
    "32cad9affe159ff7c6e4c7e31f57174967ef210a",
    "8335995630e2c4288795fa0dfa9b670090a6790b",
    "83a83d3b733fe18541428aaae2c2923318626e49",
    "4dc4e9e63f7385ddd1d64ae1345e0d32a4acb9de",
    "78e3821b819b441d1faf4bc66c659cdeddc6006c",
    "6c3b59505b863f03629da52a1e9b886fe9b496d0"
  ],
  "changeHistoryShort": {
    "da0006fe0473e353ee2d489156248a01aa982dfd": "Ybodychange",
    "3e5e5b028ad7e199d08e524fe7cddeee5db51a6d": "Ybodychange",
    "1361030e59d7557a2bffac0ea8df116ce2eaae4a": "Ybodychange",
    "46d29e3d7ee8dc9bb1818b886d9cc5336b1d67a4": "Ybodychange",
    "39285e6a1978ea5e53bdc1b0aef62421382124a8": "Ybodychange",
    "6ee0539ede78b640f01c5eac18ded161182a7835": "Ybodychange",
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56": "Ybodychange",
    "122cad6aec5839d8d515c5008425ecb34f2fa56b": "Ybodychange",
    "bcf89ddc7d52e04725caf104f5958e33d9f51b35": "Yfilerename",
    "05fd0a706aedfb83222a48e4cd110b1897c4b3c5": "Ybodychange",
    "97ccd64401569a8cdabc40c5897e34a03ce4bb22": "Ybodychange",
    "8fa10b184e607a33f59e67bd4b1fbe5a2e683941": "Ybodychange",
    "9b1f47226b076bf912a922aba293218dcadc7024": "Ybodychange",
    "bd21ddcb78350b311f271e233038b8ca78a65242": "Ybodychange",
    "32cad9affe159ff7c6e4c7e31f57174967ef210a": "Ybodychange",
    "8335995630e2c4288795fa0dfa9b670090a6790b": "Ybodychange",
    "83a83d3b733fe18541428aaae2c2923318626e49": "Ymodifierchange",
    "4dc4e9e63f7385ddd1d64ae1345e0d32a4acb9de": "Ybodychange",
    "78e3821b819b441d1faf4bc66c659cdeddc6006c": "Ybodychange",
    "6c3b59505b863f03629da52a1e9b886fe9b496d0": "Yintroduced"
  },
  "changeHistoryDetails": {
    "da0006fe0473e353ee2d489156248a01aa982dfd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14423. Percent (%) and plus (+) characters no longer work in WebHDFS.\n\nSigned-off-by: Masatake Iwasaki \u003ciwasakims@apache.org\u003e\n",
      "commitDate": "13/08/19 4:39 PM",
      "commitName": "da0006fe0473e353ee2d489156248a01aa982dfd",
      "commitAuthor": "Masatake Iwasaki",
      "commitDateOld": "02/08/19 11:48 AM",
      "commitNameOld": "e7a0b8aa83c1fb933d409c514d2155e986e4e25b",
      "commitAuthorOld": "Erik Krogen",
      "daysBetweenCommits": 11.2,
      "commitsBetweenForRepo": 105,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,49 +1,13 @@\n   URL toUrl(final HttpOpParam.Op op, final Path fspath,\n       final Param\u003c?,?\u003e... parameters) throws IOException {\n     //initialize URI path and query\n \n-    Path encodedFSPath \u003d fspath;\n-    if (fspath !\u003d null) {\n-      URI fspathUri \u003d fspath.toUri();\n-      String fspathUriDecoded \u003d fspathUri.getPath();\n-      boolean pathAlreadyEncoded \u003d false;\n-      try {\n-        fspathUriDecoded \u003d URLDecoder.decode(fspathUri.getPath(), \"UTF-8\");\n-        //below condition check added as part of fixing HDFS-14323 to make\n-        //sure pathAlreadyEncoded is not set in the case the input url does\n-        //not have any encoded sequence already.This will help pulling data\n-        //from 2.x hadoop cluster to 3.x using 3.x distcp client operation\n-        if(!fspathUri.getPath().equals(fspathUriDecoded)) {\n-          pathAlreadyEncoded \u003d true;\n-        }\n-      } catch (IllegalArgumentException ex) {\n-        LOG.trace(\"Cannot decode URL encoded file\", ex);\n-      }\n-      String[] fspathItems \u003d fspathUriDecoded.split(\"/\");\n-\n-      if (fspathItems.length \u003e 0) {\n-        StringBuilder fsPathEncodedItems \u003d new StringBuilder();\n-        for (String fsPathItem : fspathItems) {\n-          fsPathEncodedItems.append(\"/\");\n-          if (fsPathItem.matches(SPECIAL_FILENAME_CHARACTERS_REGEX) ||\n-              pathAlreadyEncoded) {\n-            fsPathEncodedItems.append(URLEncoder.encode(fsPathItem, \"UTF-8\"));\n-          } else {\n-            fsPathEncodedItems.append(fsPathItem);\n-          }\n-        }\n-        encodedFSPath \u003d new Path(fspathUri.getScheme(),\n-                fspathUri.getAuthority(), fsPathEncodedItems.substring(1));\n-      }\n-    }\n-\n     final String path \u003d PATH_PREFIX\n-        + (encodedFSPath \u003d\u003d null ? \"/\" :\n-            makeQualified(encodedFSPath).toUri().getRawPath());\n+        + (fspath \u003d\u003d null? \"/\": makeQualified(fspath).toUri().getRawPath());\n     final String query \u003d op.toQueryString()\n         + Param.toSortedString(\"\u0026\", getAuthParameters(op))\n         + Param.toSortedString(\"\u0026\", parameters);\n     final URL url \u003d getNamenodeURL(path, query);\n     LOG.trace(\"url\u003d{}\", url);\n     return url;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  URL toUrl(final HttpOpParam.Op op, final Path fspath,\n      final Param\u003c?,?\u003e... parameters) throws IOException {\n    //initialize URI path and query\n\n    final String path \u003d PATH_PREFIX\n        + (fspath \u003d\u003d null? \"/\": makeQualified(fspath).toUri().getRawPath());\n    final String query \u003d op.toQueryString()\n        + Param.toSortedString(\"\u0026\", getAuthParameters(op))\n        + Param.toSortedString(\"\u0026\", parameters);\n    final URL url \u003d getNamenodeURL(path, query);\n    LOG.trace(\"url\u003d{}\", url);\n    return url;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "3e5e5b028ad7e199d08e524fe7cddeee5db51a6d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14323. Distcp fails in Hadoop 3.x when 2.x source webhdfs url has special characters in hdfs file path. Contributed by Srinivasu Majeti.\n\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
      "commitDate": "17/05/19 10:20 AM",
      "commitName": "3e5e5b028ad7e199d08e524fe7cddeee5db51a6d",
      "commitAuthor": "Srinivasu Majeti",
      "commitDateOld": "26/03/19 11:27 AM",
      "commitNameOld": "55fb3c32fb48ca26a629d4d5f3f07e2858d09594",
      "commitAuthorOld": "Takanobu Asanuma",
      "daysBetweenCommits": 51.95,
      "commitsBetweenForRepo": 310,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,43 +1,49 @@\n   URL toUrl(final HttpOpParam.Op op, final Path fspath,\n       final Param\u003c?,?\u003e... parameters) throws IOException {\n     //initialize URI path and query\n \n     Path encodedFSPath \u003d fspath;\n     if (fspath !\u003d null) {\n       URI fspathUri \u003d fspath.toUri();\n       String fspathUriDecoded \u003d fspathUri.getPath();\n       boolean pathAlreadyEncoded \u003d false;\n       try {\n         fspathUriDecoded \u003d URLDecoder.decode(fspathUri.getPath(), \"UTF-8\");\n-        pathAlreadyEncoded \u003d true;\n+        //below condition check added as part of fixing HDFS-14323 to make\n+        //sure pathAlreadyEncoded is not set in the case the input url does\n+        //not have any encoded sequence already.This will help pulling data\n+        //from 2.x hadoop cluster to 3.x using 3.x distcp client operation\n+        if(!fspathUri.getPath().equals(fspathUriDecoded)) {\n+          pathAlreadyEncoded \u003d true;\n+        }\n       } catch (IllegalArgumentException ex) {\n         LOG.trace(\"Cannot decode URL encoded file\", ex);\n       }\n       String[] fspathItems \u003d fspathUriDecoded.split(\"/\");\n \n       if (fspathItems.length \u003e 0) {\n         StringBuilder fsPathEncodedItems \u003d new StringBuilder();\n         for (String fsPathItem : fspathItems) {\n           fsPathEncodedItems.append(\"/\");\n           if (fsPathItem.matches(SPECIAL_FILENAME_CHARACTERS_REGEX) ||\n               pathAlreadyEncoded) {\n             fsPathEncodedItems.append(URLEncoder.encode(fsPathItem, \"UTF-8\"));\n           } else {\n             fsPathEncodedItems.append(fsPathItem);\n           }\n         }\n         encodedFSPath \u003d new Path(fspathUri.getScheme(),\n                 fspathUri.getAuthority(), fsPathEncodedItems.substring(1));\n       }\n     }\n \n     final String path \u003d PATH_PREFIX\n         + (encodedFSPath \u003d\u003d null ? \"/\" :\n             makeQualified(encodedFSPath).toUri().getRawPath());\n     final String query \u003d op.toQueryString()\n         + Param.toSortedString(\"\u0026\", getAuthParameters(op))\n         + Param.toSortedString(\"\u0026\", parameters);\n     final URL url \u003d getNamenodeURL(path, query);\n     LOG.trace(\"url\u003d{}\", url);\n     return url;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  URL toUrl(final HttpOpParam.Op op, final Path fspath,\n      final Param\u003c?,?\u003e... parameters) throws IOException {\n    //initialize URI path and query\n\n    Path encodedFSPath \u003d fspath;\n    if (fspath !\u003d null) {\n      URI fspathUri \u003d fspath.toUri();\n      String fspathUriDecoded \u003d fspathUri.getPath();\n      boolean pathAlreadyEncoded \u003d false;\n      try {\n        fspathUriDecoded \u003d URLDecoder.decode(fspathUri.getPath(), \"UTF-8\");\n        //below condition check added as part of fixing HDFS-14323 to make\n        //sure pathAlreadyEncoded is not set in the case the input url does\n        //not have any encoded sequence already.This will help pulling data\n        //from 2.x hadoop cluster to 3.x using 3.x distcp client operation\n        if(!fspathUri.getPath().equals(fspathUriDecoded)) {\n          pathAlreadyEncoded \u003d true;\n        }\n      } catch (IllegalArgumentException ex) {\n        LOG.trace(\"Cannot decode URL encoded file\", ex);\n      }\n      String[] fspathItems \u003d fspathUriDecoded.split(\"/\");\n\n      if (fspathItems.length \u003e 0) {\n        StringBuilder fsPathEncodedItems \u003d new StringBuilder();\n        for (String fsPathItem : fspathItems) {\n          fsPathEncodedItems.append(\"/\");\n          if (fsPathItem.matches(SPECIAL_FILENAME_CHARACTERS_REGEX) ||\n              pathAlreadyEncoded) {\n            fsPathEncodedItems.append(URLEncoder.encode(fsPathItem, \"UTF-8\"));\n          } else {\n            fsPathEncodedItems.append(fsPathItem);\n          }\n        }\n        encodedFSPath \u003d new Path(fspathUri.getScheme(),\n                fspathUri.getAuthority(), fsPathEncodedItems.substring(1));\n      }\n    }\n\n    final String path \u003d PATH_PREFIX\n        + (encodedFSPath \u003d\u003d null ? \"/\" :\n            makeQualified(encodedFSPath).toUri().getRawPath());\n    final String query \u003d op.toQueryString()\n        + Param.toSortedString(\"\u0026\", getAuthParameters(op))\n        + Param.toSortedString(\"\u0026\", parameters);\n    final URL url \u003d getNamenodeURL(path, query);\n    LOG.trace(\"url\u003d{}\", url);\n    return url;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "1361030e59d7557a2bffac0ea8df116ce2eaae4a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13582. Improve backward compatibility for HDFS-13176 (WebHdfs file path gets truncated when having semicolon (;) inside). Contributed by Zsolt Venczel.\n",
      "commitDate": "31/05/18 6:59 AM",
      "commitName": "1361030e59d7557a2bffac0ea8df116ce2eaae4a",
      "commitAuthor": "Sean Mackrory",
      "commitDateOld": "12/03/18 8:41 PM",
      "commitNameOld": "0355ec20ebeb988679c7192c7024bef7a2a3bced",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 79.43,
      "commitsBetweenForRepo": 1204,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,36 +1,43 @@\n   URL toUrl(final HttpOpParam.Op op, final Path fspath,\n       final Param\u003c?,?\u003e... parameters) throws IOException {\n     //initialize URI path and query\n \n     Path encodedFSPath \u003d fspath;\n     if (fspath !\u003d null) {\n       URI fspathUri \u003d fspath.toUri();\n       String fspathUriDecoded \u003d fspathUri.getPath();\n+      boolean pathAlreadyEncoded \u003d false;\n       try {\n         fspathUriDecoded \u003d URLDecoder.decode(fspathUri.getPath(), \"UTF-8\");\n+        pathAlreadyEncoded \u003d true;\n       } catch (IllegalArgumentException ex) {\n         LOG.trace(\"Cannot decode URL encoded file\", ex);\n       }\n       String[] fspathItems \u003d fspathUriDecoded.split(\"/\");\n \n       if (fspathItems.length \u003e 0) {\n         StringBuilder fsPathEncodedItems \u003d new StringBuilder();\n         for (String fsPathItem : fspathItems) {\n           fsPathEncodedItems.append(\"/\");\n-          fsPathEncodedItems.append(URLEncoder.encode(fsPathItem, \"UTF-8\"));\n+          if (fsPathItem.matches(SPECIAL_FILENAME_CHARACTERS_REGEX) ||\n+              pathAlreadyEncoded) {\n+            fsPathEncodedItems.append(URLEncoder.encode(fsPathItem, \"UTF-8\"));\n+          } else {\n+            fsPathEncodedItems.append(fsPathItem);\n+          }\n         }\n         encodedFSPath \u003d new Path(fspathUri.getScheme(),\n                 fspathUri.getAuthority(), fsPathEncodedItems.substring(1));\n       }\n     }\n \n     final String path \u003d PATH_PREFIX\n         + (encodedFSPath \u003d\u003d null ? \"/\" :\n             makeQualified(encodedFSPath).toUri().getRawPath());\n     final String query \u003d op.toQueryString()\n         + Param.toSortedString(\"\u0026\", getAuthParameters(op))\n         + Param.toSortedString(\"\u0026\", parameters);\n     final URL url \u003d getNamenodeURL(path, query);\n     LOG.trace(\"url\u003d{}\", url);\n     return url;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  URL toUrl(final HttpOpParam.Op op, final Path fspath,\n      final Param\u003c?,?\u003e... parameters) throws IOException {\n    //initialize URI path and query\n\n    Path encodedFSPath \u003d fspath;\n    if (fspath !\u003d null) {\n      URI fspathUri \u003d fspath.toUri();\n      String fspathUriDecoded \u003d fspathUri.getPath();\n      boolean pathAlreadyEncoded \u003d false;\n      try {\n        fspathUriDecoded \u003d URLDecoder.decode(fspathUri.getPath(), \"UTF-8\");\n        pathAlreadyEncoded \u003d true;\n      } catch (IllegalArgumentException ex) {\n        LOG.trace(\"Cannot decode URL encoded file\", ex);\n      }\n      String[] fspathItems \u003d fspathUriDecoded.split(\"/\");\n\n      if (fspathItems.length \u003e 0) {\n        StringBuilder fsPathEncodedItems \u003d new StringBuilder();\n        for (String fsPathItem : fspathItems) {\n          fsPathEncodedItems.append(\"/\");\n          if (fsPathItem.matches(SPECIAL_FILENAME_CHARACTERS_REGEX) ||\n              pathAlreadyEncoded) {\n            fsPathEncodedItems.append(URLEncoder.encode(fsPathItem, \"UTF-8\"));\n          } else {\n            fsPathEncodedItems.append(fsPathItem);\n          }\n        }\n        encodedFSPath \u003d new Path(fspathUri.getScheme(),\n                fspathUri.getAuthority(), fsPathEncodedItems.substring(1));\n      }\n    }\n\n    final String path \u003d PATH_PREFIX\n        + (encodedFSPath \u003d\u003d null ? \"/\" :\n            makeQualified(encodedFSPath).toUri().getRawPath());\n    final String query \u003d op.toQueryString()\n        + Param.toSortedString(\"\u0026\", getAuthParameters(op))\n        + Param.toSortedString(\"\u0026\", parameters);\n    final URL url \u003d getNamenodeURL(path, query);\n    LOG.trace(\"url\u003d{}\", url);\n    return url;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "46d29e3d7ee8dc9bb1818b886d9cc5336b1d67a4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13176. WebHdfs file path gets truncated when having semicolon (;) inside. Contributed by Zsolt Venczel.\n",
      "commitDate": "07/03/18 12:33 PM",
      "commitName": "46d29e3d7ee8dc9bb1818b886d9cc5336b1d67a4",
      "commitAuthor": "Sean Mackrory",
      "commitDateOld": "23/02/18 7:35 PM",
      "commitNameOld": "1e84e46f1621fe694f806bfc41d3b2a06c9500b6",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 11.71,
      "commitsBetweenForRepo": 80,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,36 @@\n   URL toUrl(final HttpOpParam.Op op, final Path fspath,\n       final Param\u003c?,?\u003e... parameters) throws IOException {\n     //initialize URI path and query\n+\n+    Path encodedFSPath \u003d fspath;\n+    if (fspath !\u003d null) {\n+      URI fspathUri \u003d fspath.toUri();\n+      String fspathUriDecoded \u003d fspathUri.getPath();\n+      try {\n+        fspathUriDecoded \u003d URLDecoder.decode(fspathUri.getPath(), \"UTF-8\");\n+      } catch (IllegalArgumentException ex) {\n+        LOG.trace(\"Cannot decode URL encoded file\", ex);\n+      }\n+      String[] fspathItems \u003d fspathUriDecoded.split(\"/\");\n+\n+      if (fspathItems.length \u003e 0) {\n+        StringBuilder fsPathEncodedItems \u003d new StringBuilder();\n+        for (String fsPathItem : fspathItems) {\n+          fsPathEncodedItems.append(\"/\");\n+          fsPathEncodedItems.append(URLEncoder.encode(fsPathItem, \"UTF-8\"));\n+        }\n+        encodedFSPath \u003d new Path(fspathUri.getScheme(),\n+                fspathUri.getAuthority(), fsPathEncodedItems.substring(1));\n+      }\n+    }\n+\n     final String path \u003d PATH_PREFIX\n-        + (fspath \u003d\u003d null? \"/\": makeQualified(fspath).toUri().getRawPath());\n+        + (encodedFSPath \u003d\u003d null ? \"/\" :\n+            makeQualified(encodedFSPath).toUri().getRawPath());\n     final String query \u003d op.toQueryString()\n         + Param.toSortedString(\"\u0026\", getAuthParameters(op))\n         + Param.toSortedString(\"\u0026\", parameters);\n     final URL url \u003d getNamenodeURL(path, query);\n     LOG.trace(\"url\u003d{}\", url);\n     return url;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  URL toUrl(final HttpOpParam.Op op, final Path fspath,\n      final Param\u003c?,?\u003e... parameters) throws IOException {\n    //initialize URI path and query\n\n    Path encodedFSPath \u003d fspath;\n    if (fspath !\u003d null) {\n      URI fspathUri \u003d fspath.toUri();\n      String fspathUriDecoded \u003d fspathUri.getPath();\n      try {\n        fspathUriDecoded \u003d URLDecoder.decode(fspathUri.getPath(), \"UTF-8\");\n      } catch (IllegalArgumentException ex) {\n        LOG.trace(\"Cannot decode URL encoded file\", ex);\n      }\n      String[] fspathItems \u003d fspathUriDecoded.split(\"/\");\n\n      if (fspathItems.length \u003e 0) {\n        StringBuilder fsPathEncodedItems \u003d new StringBuilder();\n        for (String fsPathItem : fspathItems) {\n          fsPathEncodedItems.append(\"/\");\n          fsPathEncodedItems.append(URLEncoder.encode(fsPathItem, \"UTF-8\"));\n        }\n        encodedFSPath \u003d new Path(fspathUri.getScheme(),\n                fspathUri.getAuthority(), fsPathEncodedItems.substring(1));\n      }\n    }\n\n    final String path \u003d PATH_PREFIX\n        + (encodedFSPath \u003d\u003d null ? \"/\" :\n            makeQualified(encodedFSPath).toUri().getRawPath());\n    final String query \u003d op.toQueryString()\n        + Param.toSortedString(\"\u0026\", getAuthParameters(op))\n        + Param.toSortedString(\"\u0026\", parameters);\n    final URL url \u003d getNamenodeURL(path, query);\n    LOG.trace(\"url\u003d{}\", url);\n    return url;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "39285e6a1978ea5e53bdc1b0aef62421382124a8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8971. Remove guards when calling LOG.debug() and LOG.trace() in client package. Contributed by Mingliang Liu.\n",
      "commitDate": "29/09/15 5:52 PM",
      "commitName": "39285e6a1978ea5e53bdc1b0aef62421382124a8",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "29/09/15 5:51 PM",
      "commitNameOld": "6ee0539ede78b640f01c5eac18ded161182a7835",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,12 @@\n   URL toUrl(final HttpOpParam.Op op, final Path fspath,\n       final Param\u003c?,?\u003e... parameters) throws IOException {\n     //initialize URI path and query\n     final String path \u003d PATH_PREFIX\n         + (fspath \u003d\u003d null? \"/\": makeQualified(fspath).toUri().getRawPath());\n     final String query \u003d op.toQueryString()\n         + Param.toSortedString(\"\u0026\", getAuthParameters(op))\n         + Param.toSortedString(\"\u0026\", parameters);\n     final URL url \u003d getNamenodeURL(path, query);\n-    if (LOG.isTraceEnabled()) {\n-      LOG.trace(\"url\u003d{}\", url);\n-    }\n+    LOG.trace(\"url\u003d{}\", url);\n     return url;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  URL toUrl(final HttpOpParam.Op op, final Path fspath,\n      final Param\u003c?,?\u003e... parameters) throws IOException {\n    //initialize URI path and query\n    final String path \u003d PATH_PREFIX\n        + (fspath \u003d\u003d null? \"/\": makeQualified(fspath).toUri().getRawPath());\n    final String query \u003d op.toQueryString()\n        + Param.toSortedString(\"\u0026\", getAuthParameters(op))\n        + Param.toSortedString(\"\u0026\", parameters);\n    final URL url \u003d getNamenodeURL(path, query);\n    LOG.trace(\"url\u003d{}\", url);\n    return url;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "6ee0539ede78b640f01c5eac18ded161182a7835": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-9170. Move libhdfs / fuse-dfs / libwebhdfs to hdfs-client. Contributed by Haohui Mai.\"\n\nThis reverts commit d5a9a3daa0224249221ffa7b8bd5751ab2feca56.\n",
      "commitDate": "29/09/15 5:51 PM",
      "commitName": "6ee0539ede78b640f01c5eac18ded161182a7835",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "29/09/15 5:48 PM",
      "commitNameOld": "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,14 @@\n   URL toUrl(final HttpOpParam.Op op, final Path fspath,\n       final Param\u003c?,?\u003e... parameters) throws IOException {\n     //initialize URI path and query\n     final String path \u003d PATH_PREFIX\n         + (fspath \u003d\u003d null? \"/\": makeQualified(fspath).toUri().getRawPath());\n     final String query \u003d op.toQueryString()\n         + Param.toSortedString(\"\u0026\", getAuthParameters(op))\n         + Param.toSortedString(\"\u0026\", parameters);\n     final URL url \u003d getNamenodeURL(path, query);\n-    LOG.trace(\"url\u003d{}\", url);\n+    if (LOG.isTraceEnabled()) {\n+      LOG.trace(\"url\u003d{}\", url);\n+    }\n     return url;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  URL toUrl(final HttpOpParam.Op op, final Path fspath,\n      final Param\u003c?,?\u003e... parameters) throws IOException {\n    //initialize URI path and query\n    final String path \u003d PATH_PREFIX\n        + (fspath \u003d\u003d null? \"/\": makeQualified(fspath).toUri().getRawPath());\n    final String query \u003d op.toQueryString()\n        + Param.toSortedString(\"\u0026\", getAuthParameters(op))\n        + Param.toSortedString(\"\u0026\", parameters);\n    final URL url \u003d getNamenodeURL(path, query);\n    if (LOG.isTraceEnabled()) {\n      LOG.trace(\"url\u003d{}\", url);\n    }\n    return url;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9170. Move libhdfs / fuse-dfs / libwebhdfs to hdfs-client. Contributed by Haohui Mai.\n",
      "commitDate": "29/09/15 5:48 PM",
      "commitName": "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "28/09/15 3:31 PM",
      "commitNameOld": "3abbdc929bde05f8819f5410cef1eaeb8940203f",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 1.09,
      "commitsBetweenForRepo": 13,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,12 @@\n   URL toUrl(final HttpOpParam.Op op, final Path fspath,\n       final Param\u003c?,?\u003e... parameters) throws IOException {\n     //initialize URI path and query\n     final String path \u003d PATH_PREFIX\n         + (fspath \u003d\u003d null? \"/\": makeQualified(fspath).toUri().getRawPath());\n     final String query \u003d op.toQueryString()\n         + Param.toSortedString(\"\u0026\", getAuthParameters(op))\n         + Param.toSortedString(\"\u0026\", parameters);\n     final URL url \u003d getNamenodeURL(path, query);\n-    if (LOG.isTraceEnabled()) {\n-      LOG.trace(\"url\u003d{}\", url);\n-    }\n+    LOG.trace(\"url\u003d{}\", url);\n     return url;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  URL toUrl(final HttpOpParam.Op op, final Path fspath,\n      final Param\u003c?,?\u003e... parameters) throws IOException {\n    //initialize URI path and query\n    final String path \u003d PATH_PREFIX\n        + (fspath \u003d\u003d null? \"/\": makeQualified(fspath).toUri().getRawPath());\n    final String query \u003d op.toQueryString()\n        + Param.toSortedString(\"\u0026\", getAuthParameters(op))\n        + Param.toSortedString(\"\u0026\", parameters);\n    final URL url \u003d getNamenodeURL(path, query);\n    LOG.trace(\"url\u003d{}\", url);\n    return url;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "122cad6aec5839d8d515c5008425ecb34f2fa56b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6564. Use slf4j instead of common-logging in hdfs-client. Contributed by Rakesh R.\n",
      "commitDate": "23/06/15 11:41 AM",
      "commitName": "122cad6aec5839d8d515c5008425ecb34f2fa56b",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "22/06/15 4:30 PM",
      "commitNameOld": "fac4e04dd359a7ff31f286d664fb06f019ec0b58",
      "commitAuthorOld": "Jakob Homan",
      "daysBetweenCommits": 0.8,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,14 @@\n   URL toUrl(final HttpOpParam.Op op, final Path fspath,\n       final Param\u003c?,?\u003e... parameters) throws IOException {\n     //initialize URI path and query\n     final String path \u003d PATH_PREFIX\n         + (fspath \u003d\u003d null? \"/\": makeQualified(fspath).toUri().getRawPath());\n     final String query \u003d op.toQueryString()\n         + Param.toSortedString(\"\u0026\", getAuthParameters(op))\n         + Param.toSortedString(\"\u0026\", parameters);\n     final URL url \u003d getNamenodeURL(path, query);\n     if (LOG.isTraceEnabled()) {\n-      LOG.trace(\"url\u003d\" + url);\n+      LOG.trace(\"url\u003d{}\", url);\n     }\n     return url;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  URL toUrl(final HttpOpParam.Op op, final Path fspath,\n      final Param\u003c?,?\u003e... parameters) throws IOException {\n    //initialize URI path and query\n    final String path \u003d PATH_PREFIX\n        + (fspath \u003d\u003d null? \"/\": makeQualified(fspath).toUri().getRawPath());\n    final String query \u003d op.toQueryString()\n        + Param.toSortedString(\"\u0026\", getAuthParameters(op))\n        + Param.toSortedString(\"\u0026\", parameters);\n    final URL url \u003d getNamenodeURL(path, query);\n    if (LOG.isTraceEnabled()) {\n      LOG.trace(\"url\u003d{}\", url);\n    }\n    return url;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "bcf89ddc7d52e04725caf104f5958e33d9f51b35": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8052. Move WebHdfsFileSystem into hadoop-hdfs-client. Contributed by Haohui Mai.\n",
      "commitDate": "23/04/15 5:33 PM",
      "commitName": "bcf89ddc7d52e04725caf104f5958e33d9f51b35",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "23/04/15 4:40 PM",
      "commitNameOld": "0b3f8957a87ada1a275c9904b211fdbdcefafb02",
      "commitAuthorOld": "Xuan",
      "daysBetweenCommits": 0.04,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  URL toUrl(final HttpOpParam.Op op, final Path fspath,\n      final Param\u003c?,?\u003e... parameters) throws IOException {\n    //initialize URI path and query\n    final String path \u003d PATH_PREFIX\n        + (fspath \u003d\u003d null? \"/\": makeQualified(fspath).toUri().getRawPath());\n    final String query \u003d op.toQueryString()\n        + Param.toSortedString(\"\u0026\", getAuthParameters(op))\n        + Param.toSortedString(\"\u0026\", parameters);\n    final URL url \u003d getNamenodeURL(path, query);\n    if (LOG.isTraceEnabled()) {\n      LOG.trace(\"url\u003d\" + url);\n    }\n    return url;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java"
      }
    },
    "05fd0a706aedfb83222a48e4cd110b1897c4b3c5": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4943. WebHdfsFileSystem does not work when original file path has encoded chars.  Contributed by Jerry He\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1498962 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/07/13 7:58 AM",
      "commitName": "05fd0a706aedfb83222a48e4cd110b1897c4b3c5",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "14/05/13 7:23 PM",
      "commitNameOld": "f7af4a014c0ad11e146b7cdc8e5436d4f81cd8f8",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 48.52,
      "commitsBetweenForRepo": 295,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,14 @@\n   URL toUrl(final HttpOpParam.Op op, final Path fspath,\n       final Param\u003c?,?\u003e... parameters) throws IOException {\n     //initialize URI path and query\n     final String path \u003d PATH_PREFIX\n-        + (fspath \u003d\u003d null? \"/\": makeQualified(fspath).toUri().getPath());\n+        + (fspath \u003d\u003d null? \"/\": makeQualified(fspath).toUri().getRawPath());\n     final String query \u003d op.toQueryString()\n         + Param.toSortedString(\"\u0026\", getAuthParameters(op))\n         + Param.toSortedString(\"\u0026\", parameters);\n     final URL url \u003d getNamenodeURL(path, query);\n     if (LOG.isTraceEnabled()) {\n       LOG.trace(\"url\u003d\" + url);\n     }\n     return url;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  URL toUrl(final HttpOpParam.Op op, final Path fspath,\n      final Param\u003c?,?\u003e... parameters) throws IOException {\n    //initialize URI path and query\n    final String path \u003d PATH_PREFIX\n        + (fspath \u003d\u003d null? \"/\": makeQualified(fspath).toUri().getRawPath());\n    final String query \u003d op.toQueryString()\n        + Param.toSortedString(\"\u0026\", getAuthParameters(op))\n        + Param.toSortedString(\"\u0026\", parameters);\n    final URL url \u003d getNamenodeURL(path, query);\n    if (LOG.isTraceEnabled()) {\n      LOG.trace(\"url\u003d\" + url);\n    }\n    return url;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "97ccd64401569a8cdabc40c5897e34a03ce4bb22": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4542. Webhdfs doesn\u0027t support secure proxy users. Contributed by Daryn Sharp.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1452978 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "05/03/13 12:17 PM",
      "commitName": "97ccd64401569a8cdabc40c5897e34a03ce4bb22",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "29/01/13 10:51 PM",
      "commitNameOld": "481b6cccf0493cb3f740b119552bede0f7268121",
      "commitAuthorOld": "Konstantin Shvachko",
      "daysBetweenCommits": 34.56,
      "commitsBetweenForRepo": 125,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,14 @@\n   URL toUrl(final HttpOpParam.Op op, final Path fspath,\n       final Param\u003c?,?\u003e... parameters) throws IOException {\n     //initialize URI path and query\n     final String path \u003d PATH_PREFIX\n         + (fspath \u003d\u003d null? \"/\": makeQualified(fspath).toUri().getPath());\n     final String query \u003d op.toQueryString()\n-        + \u0027\u0026\u0027 + new UserParam(ugi)\n+        + Param.toSortedString(\"\u0026\", getAuthParameters(op))\n         + Param.toSortedString(\"\u0026\", parameters);\n-    final URL url;\n-    if (op \u003d\u003d PutOpParam.Op.RENEWDELEGATIONTOKEN\n-        || op \u003d\u003d GetOpParam.Op.GETDELEGATIONTOKEN) {\n-      // Skip adding delegation token for getting or renewing delegation token,\n-      // because these operations require kerberos authentication.\n-      url \u003d getNamenodeURL(path, query);\n-    } else {\n-      url \u003d getNamenodeURL(path, addDt2Query(query));\n-    }\n+    final URL url \u003d getNamenodeURL(path, query);\n     if (LOG.isTraceEnabled()) {\n       LOG.trace(\"url\u003d\" + url);\n     }\n     return url;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  URL toUrl(final HttpOpParam.Op op, final Path fspath,\n      final Param\u003c?,?\u003e... parameters) throws IOException {\n    //initialize URI path and query\n    final String path \u003d PATH_PREFIX\n        + (fspath \u003d\u003d null? \"/\": makeQualified(fspath).toUri().getPath());\n    final String query \u003d op.toQueryString()\n        + Param.toSortedString(\"\u0026\", getAuthParameters(op))\n        + Param.toSortedString(\"\u0026\", parameters);\n    final URL url \u003d getNamenodeURL(path, query);\n    if (LOG.isTraceEnabled()) {\n      LOG.trace(\"url\u003d\" + url);\n    }\n    return url;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "8fa10b184e607a33f59e67bd4b1fbe5a2e683941": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-7967. Need generalized multi-token filesystem support (daryn)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1374271 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/08/12 7:05 AM",
      "commitName": "8fa10b184e607a33f59e67bd4b1fbe5a2e683941",
      "commitAuthor": "Daryn Sharp",
      "commitDateOld": "31/07/12 6:41 PM",
      "commitNameOld": "cb787968c5deac3dd5d10291aae39c36656a1487",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 16.52,
      "commitsBetweenForRepo": 78,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,22 @@\n   URL toUrl(final HttpOpParam.Op op, final Path fspath,\n       final Param\u003c?,?\u003e... parameters) throws IOException {\n     //initialize URI path and query\n     final String path \u003d PATH_PREFIX\n         + (fspath \u003d\u003d null? \"/\": makeQualified(fspath).toUri().getPath());\n     final String query \u003d op.toQueryString()\n         + \u0027\u0026\u0027 + new UserParam(ugi)\n         + Param.toSortedString(\"\u0026\", parameters);\n     final URL url;\n     if (op \u003d\u003d PutOpParam.Op.RENEWDELEGATIONTOKEN\n-        || op \u003d\u003d GetOpParam.Op.GETDELEGATIONTOKEN\n-        || op \u003d\u003d GetOpParam.Op.GETDELEGATIONTOKENS) {\n+        || op \u003d\u003d GetOpParam.Op.GETDELEGATIONTOKEN) {\n       // Skip adding delegation token for getting or renewing delegation token,\n       // because these operations require kerberos authentication.\n       url \u003d getNamenodeURL(path, query);\n     } else {\n       url \u003d getNamenodeURL(path, addDt2Query(query));\n     }\n     if (LOG.isTraceEnabled()) {\n       LOG.trace(\"url\u003d\" + url);\n     }\n     return url;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  URL toUrl(final HttpOpParam.Op op, final Path fspath,\n      final Param\u003c?,?\u003e... parameters) throws IOException {\n    //initialize URI path and query\n    final String path \u003d PATH_PREFIX\n        + (fspath \u003d\u003d null? \"/\": makeQualified(fspath).toUri().getPath());\n    final String query \u003d op.toQueryString()\n        + \u0027\u0026\u0027 + new UserParam(ugi)\n        + Param.toSortedString(\"\u0026\", parameters);\n    final URL url;\n    if (op \u003d\u003d PutOpParam.Op.RENEWDELEGATIONTOKEN\n        || op \u003d\u003d GetOpParam.Op.GETDELEGATIONTOKEN) {\n      // Skip adding delegation token for getting or renewing delegation token,\n      // because these operations require kerberos authentication.\n      url \u003d getNamenodeURL(path, query);\n    } else {\n      url \u003d getNamenodeURL(path, addDt2Query(query));\n    }\n    if (LOG.isTraceEnabled()) {\n      LOG.trace(\"url\u003d\" + url);\n    }\n    return url;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "9b1f47226b076bf912a922aba293218dcadc7024": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2594. Support getDelegationTokens and createSymlink in WebHDFS.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1212299 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/12/11 1:26 AM",
      "commitName": "9b1f47226b076bf912a922aba293218dcadc7024",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "29/11/11 4:25 PM",
      "commitNameOld": "afbc3aa30cd52f85208db97378a05a530c22fcc9",
      "commitAuthorOld": "Alejandro Abdelnur",
      "daysBetweenCommits": 9.38,
      "commitsBetweenForRepo": 50,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,23 @@\n   URL toUrl(final HttpOpParam.Op op, final Path fspath,\n       final Param\u003c?,?\u003e... parameters) throws IOException {\n     //initialize URI path and query\n     final String path \u003d PATH_PREFIX\n         + (fspath \u003d\u003d null? \"/\": makeQualified(fspath).toUri().getPath());\n     final String query \u003d op.toQueryString()\n         + \u0027\u0026\u0027 + new UserParam(ugi)\n         + Param.toSortedString(\"\u0026\", parameters);\n     final URL url;\n-    if (op.equals(PutOpParam.Op.RENEWDELEGATIONTOKEN)\n-        || op.equals(GetOpParam.Op.GETDELEGATIONTOKEN)) {\n+    if (op \u003d\u003d PutOpParam.Op.RENEWDELEGATIONTOKEN\n+        || op \u003d\u003d GetOpParam.Op.GETDELEGATIONTOKEN\n+        || op \u003d\u003d GetOpParam.Op.GETDELEGATIONTOKENS) {\n       // Skip adding delegation token for getting or renewing delegation token,\n       // because these operations require kerberos authentication.\n       url \u003d getNamenodeURL(path, query);\n     } else {\n       url \u003d getNamenodeURL(path, addDt2Query(query));\n     }\n     if (LOG.isTraceEnabled()) {\n       LOG.trace(\"url\u003d\" + url);\n     }\n     return url;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  URL toUrl(final HttpOpParam.Op op, final Path fspath,\n      final Param\u003c?,?\u003e... parameters) throws IOException {\n    //initialize URI path and query\n    final String path \u003d PATH_PREFIX\n        + (fspath \u003d\u003d null? \"/\": makeQualified(fspath).toUri().getPath());\n    final String query \u003d op.toQueryString()\n        + \u0027\u0026\u0027 + new UserParam(ugi)\n        + Param.toSortedString(\"\u0026\", parameters);\n    final URL url;\n    if (op \u003d\u003d PutOpParam.Op.RENEWDELEGATIONTOKEN\n        || op \u003d\u003d GetOpParam.Op.GETDELEGATIONTOKEN\n        || op \u003d\u003d GetOpParam.Op.GETDELEGATIONTOKENS) {\n      // Skip adding delegation token for getting or renewing delegation token,\n      // because these operations require kerberos authentication.\n      url \u003d getNamenodeURL(path, query);\n    } else {\n      url \u003d getNamenodeURL(path, addDt2Query(query));\n    }\n    if (LOG.isTraceEnabled()) {\n      LOG.trace(\"url\u003d\" + url);\n    }\n    return url;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "bd21ddcb78350b311f271e233038b8ca78a65242": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2416. distcp with a webhdfs uri on a secure cluster fails.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1196434 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "01/11/11 7:08 PM",
      "commitName": "bd21ddcb78350b311f271e233038b8ca78a65242",
      "commitAuthor": "Jitendra Nath Pandey",
      "commitDateOld": "31/10/11 1:37 PM",
      "commitNameOld": "32cad9affe159ff7c6e4c7e31f57174967ef210a",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 1.23,
      "commitsBetweenForRepo": 30,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,22 @@\n   URL toUrl(final HttpOpParam.Op op, final Path fspath,\n       final Param\u003c?,?\u003e... parameters) throws IOException {\n     //initialize URI path and query\n     final String path \u003d PATH_PREFIX\n         + (fspath \u003d\u003d null? \"/\": makeQualified(fspath).toUri().getPath());\n     final String query \u003d op.toQueryString()\n         + \u0027\u0026\u0027 + new UserParam(ugi)\n         + Param.toSortedString(\"\u0026\", parameters);\n-    final URL url \u003d getNamenodeURL(path, addDt2Query(query));\n+    final URL url;\n+    if (op.equals(PutOpParam.Op.RENEWDELEGATIONTOKEN)\n+        || op.equals(GetOpParam.Op.GETDELEGATIONTOKEN)) {\n+      // Skip adding delegation token for getting or renewing delegation token,\n+      // because these operations require kerberos authentication.\n+      url \u003d getNamenodeURL(path, query);\n+    } else {\n+      url \u003d getNamenodeURL(path, addDt2Query(query));\n+    }\n     if (LOG.isTraceEnabled()) {\n       LOG.trace(\"url\u003d\" + url);\n     }\n     return url;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  URL toUrl(final HttpOpParam.Op op, final Path fspath,\n      final Param\u003c?,?\u003e... parameters) throws IOException {\n    //initialize URI path and query\n    final String path \u003d PATH_PREFIX\n        + (fspath \u003d\u003d null? \"/\": makeQualified(fspath).toUri().getPath());\n    final String query \u003d op.toQueryString()\n        + \u0027\u0026\u0027 + new UserParam(ugi)\n        + Param.toSortedString(\"\u0026\", parameters);\n    final URL url;\n    if (op.equals(PutOpParam.Op.RENEWDELEGATIONTOKEN)\n        || op.equals(GetOpParam.Op.GETDELEGATIONTOKEN)) {\n      // Skip adding delegation token for getting or renewing delegation token,\n      // because these operations require kerberos authentication.\n      url \u003d getNamenodeURL(path, query);\n    } else {\n      url \u003d getNamenodeURL(path, addDt2Query(query));\n    }\n    if (LOG.isTraceEnabled()) {\n      LOG.trace(\"url\u003d\" + url);\n    }\n    return url;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "32cad9affe159ff7c6e4c7e31f57174967ef210a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2385. Support renew and cancel delegation tokens in webhdfs.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1195656 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "31/10/11 1:37 PM",
      "commitName": "32cad9affe159ff7c6e4c7e31f57174967ef210a",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "27/10/11 4:13 PM",
      "commitNameOld": "8cb0d4b380e0fd4437310c1dd6ef8b8995cc383d",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 3.89,
      "commitsBetweenForRepo": 47,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,14 @@\n   URL toUrl(final HttpOpParam.Op op, final Path fspath,\n       final Param\u003c?,?\u003e... parameters) throws IOException {\n     //initialize URI path and query\n     final String path \u003d PATH_PREFIX\n         + (fspath \u003d\u003d null? \"/\": makeQualified(fspath).toUri().getPath());\n     final String query \u003d op.toQueryString()\n         + \u0027\u0026\u0027 + new UserParam(ugi)\n         + Param.toSortedString(\"\u0026\", parameters);\n-    final URL url \u003d getNamenodeURL(path, addDelegationTokenParam(query));\n+    final URL url \u003d getNamenodeURL(path, addDt2Query(query));\n     if (LOG.isTraceEnabled()) {\n       LOG.trace(\"url\u003d\" + url);\n     }\n     return url;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  URL toUrl(final HttpOpParam.Op op, final Path fspath,\n      final Param\u003c?,?\u003e... parameters) throws IOException {\n    //initialize URI path and query\n    final String path \u003d PATH_PREFIX\n        + (fspath \u003d\u003d null? \"/\": makeQualified(fspath).toUri().getPath());\n    final String query \u003d op.toQueryString()\n        + \u0027\u0026\u0027 + new UserParam(ugi)\n        + Param.toSortedString(\"\u0026\", parameters);\n    final URL url \u003d getNamenodeURL(path, addDt2Query(query));\n    if (LOG.isTraceEnabled()) {\n      LOG.trace(\"url\u003d\" + url);\n    }\n    return url;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "8335995630e2c4288795fa0dfa9b670090a6790b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2501. Add version prefix and root methods to webhdfs.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1189028 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/10/11 10:16 PM",
      "commitName": "8335995630e2c4288795fa0dfa9b670090a6790b",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "20/10/11 5:27 PM",
      "commitNameOld": "7c48130d41a4671dc06a558d82765d0459ad55bf",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 5.2,
      "commitsBetweenForRepo": 36,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,14 @@\n   URL toUrl(final HttpOpParam.Op op, final Path fspath,\n       final Param\u003c?,?\u003e... parameters) throws IOException {\n     //initialize URI path and query\n-    final String path \u003d \"/\" + PATH_PREFIX\n+    final String path \u003d PATH_PREFIX\n         + (fspath \u003d\u003d null? \"/\": makeQualified(fspath).toUri().getPath());\n     final String query \u003d op.toQueryString()\n         + \u0027\u0026\u0027 + new UserParam(ugi)\n         + Param.toSortedString(\"\u0026\", parameters);\n     final URL url \u003d getNamenodeURL(path, addDelegationTokenParam(query));\n     if (LOG.isTraceEnabled()) {\n       LOG.trace(\"url\u003d\" + url);\n     }\n     return url;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  URL toUrl(final HttpOpParam.Op op, final Path fspath,\n      final Param\u003c?,?\u003e... parameters) throws IOException {\n    //initialize URI path and query\n    final String path \u003d PATH_PREFIX\n        + (fspath \u003d\u003d null? \"/\": makeQualified(fspath).toUri().getPath());\n    final String query \u003d op.toQueryString()\n        + \u0027\u0026\u0027 + new UserParam(ugi)\n        + Param.toSortedString(\"\u0026\", parameters);\n    final URL url \u003d getNamenodeURL(path, addDelegationTokenParam(query));\n    if (LOG.isTraceEnabled()) {\n      LOG.trace(\"url\u003d\" + url);\n    }\n    return url;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "83a83d3b733fe18541428aaae2c2923318626e49": {
      "type": "Ymodifierchange",
      "commitMessage": "HDFS-2356.  Support case insensitive query parameter names in webhdfs.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1175113 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/09/11 11:15 PM",
      "commitName": "83a83d3b733fe18541428aaae2c2923318626e49",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "20/09/11 7:56 PM",
      "commitNameOld": "4dc4e9e63f7385ddd1d64ae1345e0d32a4acb9de",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 3.14,
      "commitsBetweenForRepo": 20,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,14 @@\n-  private URL toUrl(final HttpOpParam.Op op, final Path fspath,\n+  URL toUrl(final HttpOpParam.Op op, final Path fspath,\n       final Param\u003c?,?\u003e... parameters) throws IOException {\n     //initialize URI path and query\n     final String path \u003d \"/\" + PATH_PREFIX\n         + (fspath \u003d\u003d null? \"/\": makeQualified(fspath).toUri().getPath());\n     final String query \u003d op.toQueryString()\n         + \u0027\u0026\u0027 + new UserParam(ugi)\n         + Param.toSortedString(\"\u0026\", parameters);\n     final URL url \u003d getNamenodeURL(path, addDelegationTokenParam(query));\n     if (LOG.isTraceEnabled()) {\n       LOG.trace(\"url\u003d\" + url);\n     }\n     return url;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  URL toUrl(final HttpOpParam.Op op, final Path fspath,\n      final Param\u003c?,?\u003e... parameters) throws IOException {\n    //initialize URI path and query\n    final String path \u003d \"/\" + PATH_PREFIX\n        + (fspath \u003d\u003d null? \"/\": makeQualified(fspath).toUri().getPath());\n    final String query \u003d op.toQueryString()\n        + \u0027\u0026\u0027 + new UserParam(ugi)\n        + Param.toSortedString(\"\u0026\", parameters);\n    final URL url \u003d getNamenodeURL(path, addDelegationTokenParam(query));\n    if (LOG.isTraceEnabled()) {\n      LOG.trace(\"url\u003d\" + url);\n    }\n    return url;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {
        "oldValue": "[private]",
        "newValue": "[]"
      }
    },
    "4dc4e9e63f7385ddd1d64ae1345e0d32a4acb9de": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2340. Support getFileBlockLocations and getDelegationToken in webhdfs.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1173468 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/09/11 7:56 PM",
      "commitName": "4dc4e9e63f7385ddd1d64ae1345e0d32a4acb9de",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "16/09/11 8:02 AM",
      "commitNameOld": "78e3821b819b441d1faf4bc66c659cdeddc6006c",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 4.5,
      "commitsBetweenForRepo": 31,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,14 @@\n   private URL toUrl(final HttpOpParam.Op op, final Path fspath,\n       final Param\u003c?,?\u003e... parameters) throws IOException {\n     //initialize URI path and query\n     final String path \u003d \"/\" + PATH_PREFIX\n-        + makeQualified(fspath).toUri().getPath();\n+        + (fspath \u003d\u003d null? \"/\": makeQualified(fspath).toUri().getPath());\n     final String query \u003d op.toQueryString()\n         + \u0027\u0026\u0027 + new UserParam(ugi)\n         + Param.toSortedString(\"\u0026\", parameters);\n     final URL url \u003d getNamenodeURL(path, addDelegationTokenParam(query));\n     if (LOG.isTraceEnabled()) {\n       LOG.trace(\"url\u003d\" + url);\n     }\n     return url;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private URL toUrl(final HttpOpParam.Op op, final Path fspath,\n      final Param\u003c?,?\u003e... parameters) throws IOException {\n    //initialize URI path and query\n    final String path \u003d \"/\" + PATH_PREFIX\n        + (fspath \u003d\u003d null? \"/\": makeQualified(fspath).toUri().getPath());\n    final String query \u003d op.toQueryString()\n        + \u0027\u0026\u0027 + new UserParam(ugi)\n        + Param.toSortedString(\"\u0026\", parameters);\n    final URL url \u003d getNamenodeURL(path, addDelegationTokenParam(query));\n    if (LOG.isTraceEnabled()) {\n      LOG.trace(\"url\u003d\" + url);\n    }\n    return url;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "78e3821b819b441d1faf4bc66c659cdeddc6006c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2318. Provide authentication to webhdfs using SPNEGO and delegation tokens.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1171611 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/09/11 8:02 AM",
      "commitName": "78e3821b819b441d1faf4bc66c659cdeddc6006c",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "15/09/11 1:04 AM",
      "commitNameOld": "be2b0921fa3d1d82fed75bccfceae007d9faaea6",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 1.29,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,14 @@\n   private URL toUrl(final HttpOpParam.Op op, final Path fspath,\n       final Param\u003c?,?\u003e... parameters) throws IOException {\n     //initialize URI path and query\n     final String path \u003d \"/\" + PATH_PREFIX\n         + makeQualified(fspath).toUri().getPath();\n     final String query \u003d op.toQueryString()\n+        + \u0027\u0026\u0027 + new UserParam(ugi)\n         + Param.toSortedString(\"\u0026\", parameters);\n-    final URL url \u003d getNamenodeURL(path, query);\n+    final URL url \u003d getNamenodeURL(path, addDelegationTokenParam(query));\n     if (LOG.isTraceEnabled()) {\n       LOG.trace(\"url\u003d\" + url);\n     }\n     return url;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private URL toUrl(final HttpOpParam.Op op, final Path fspath,\n      final Param\u003c?,?\u003e... parameters) throws IOException {\n    //initialize URI path and query\n    final String path \u003d \"/\" + PATH_PREFIX\n        + makeQualified(fspath).toUri().getPath();\n    final String query \u003d op.toQueryString()\n        + \u0027\u0026\u0027 + new UserParam(ugi)\n        + Param.toSortedString(\"\u0026\", parameters);\n    final URL url \u003d getNamenodeURL(path, addDelegationTokenParam(query));\n    if (LOG.isTraceEnabled()) {\n      LOG.trace(\"url\u003d\" + url);\n    }\n    return url;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "6c3b59505b863f03629da52a1e9b886fe9b496d0": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-2317. Support read access to HDFS in webhdfs.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1170085 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/09/11 1:34 AM",
      "commitName": "6c3b59505b863f03629da52a1e9b886fe9b496d0",
      "commitAuthor": "Tsz-wo Sze",
      "diff": "@@ -0,0 +1,13 @@\n+  private URL toUrl(final HttpOpParam.Op op, final Path fspath,\n+      final Param\u003c?,?\u003e... parameters) throws IOException {\n+    //initialize URI path and query\n+    final String path \u003d \"/\" + PATH_PREFIX\n+        + makeQualified(fspath).toUri().getPath();\n+    final String query \u003d op.toQueryString()\n+        + Param.toSortedString(\"\u0026\", parameters);\n+    final URL url \u003d getNamenodeURL(path, query);\n+    if (LOG.isTraceEnabled()) {\n+      LOG.trace(\"url\u003d\" + url);\n+    }\n+    return url;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private URL toUrl(final HttpOpParam.Op op, final Path fspath,\n      final Param\u003c?,?\u003e... parameters) throws IOException {\n    //initialize URI path and query\n    final String path \u003d \"/\" + PATH_PREFIX\n        + makeQualified(fspath).toUri().getPath();\n    final String query \u003d op.toQueryString()\n        + Param.toSortedString(\"\u0026\", parameters);\n    final URL url \u003d getNamenodeURL(path, query);\n    if (LOG.isTraceEnabled()) {\n      LOG.trace(\"url\u003d\" + url);\n    }\n    return url;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java"
    }
  }
}