{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockManager.java",
  "functionName": "processAllPendingDNMessages",
  "functionId": "processAllPendingDNMessages",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
  "functionStartLine": 3237,
  "functionEndLine": 3248,
  "numCommitsSeen": 477,
  "timeTaken": 14853,
  "changeHistory": [
    "a7f085d6bf499edf23e650a4f7211c53a442da0e",
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de",
    "23b6ed973e1ff5ace1e3a97cded008908e8daa55"
  ],
  "changeHistoryShort": {
    "a7f085d6bf499edf23e650a4f7211c53a442da0e": "Ybodychange",
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de": "Ybodychange",
    "23b6ed973e1ff5ace1e3a97cded008908e8daa55": "Ybodychange"
  },
  "changeHistoryDetails": {
    "a7f085d6bf499edf23e650a4f7211c53a442da0e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11832. Switch leftover logs to slf4j format in BlockManager.java. Contributed by Hui Xu and Chen Liang.\n",
      "commitDate": "29/05/17 1:30 AM",
      "commitName": "a7f085d6bf499edf23e650a4f7211c53a442da0e",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "25/05/17 7:35 AM",
      "commitNameOld": "2e41f8803dd46d1bab16c1b206c71be72ea260a1",
      "commitAuthorOld": "Brahma Reddy Battula",
      "daysBetweenCommits": 3.75,
      "commitsBetweenForRepo": 17,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,12 @@\n   public void processAllPendingDNMessages() throws IOException {\n     assert !shouldPostponeBlocksFromFuture :\n       \"processAllPendingDNMessages() should be called after disabling \" +\n       \"block postponement.\";\n     int count \u003d pendingDNMessages.count();\n     if (count \u003e 0) {\n-      LOG.info(\"Processing \" + count + \" messages from DataNodes \" +\n-          \"that were previously queued during standby state\");\n+      LOG.info(\"Processing {} messages from DataNodes \" +\n+          \"that were previously queued during standby state\", count);\n     }\n     processQueuedMessages(pendingDNMessages.takeAll());\n     assert pendingDNMessages.count() \u003d\u003d 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void processAllPendingDNMessages() throws IOException {\n    assert !shouldPostponeBlocksFromFuture :\n      \"processAllPendingDNMessages() should be called after disabling \" +\n      \"block postponement.\";\n    int count \u003d pendingDNMessages.count();\n    if (count \u003e 0) {\n      LOG.info(\"Processing {} messages from DataNodes \" +\n          \"that were previously queued during standby state\", count);\n    }\n    processQueuedMessages(pendingDNMessages.takeAll());\n    assert pendingDNMessages.count() \u003d\u003d 0;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4122. Cleanup HDFS logs and reduce the size of logged messages. Contributed by Suresh Srinivas.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1403120 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/10/12 4:10 PM",
      "commitName": "cea7bbc630deede93dbe6a1bbda56ad49de4f3de",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "22/10/12 11:30 AM",
      "commitNameOld": "75cdb5bb4965161021df47376cccf058bf413f3b",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 6.19,
      "commitsBetweenForRepo": 35,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,12 @@\n   public void processAllPendingDNMessages() throws IOException {\n     assert !shouldPostponeBlocksFromFuture :\n       \"processAllPendingDNMessages() should be called after disabling \" +\n       \"block postponement.\";\n     int count \u003d pendingDNMessages.count();\n     if (count \u003e 0) {\n       LOG.info(\"Processing \" + count + \" messages from DataNodes \" +\n-          \"that were previously queued during standby state.\");\n+          \"that were previously queued during standby state\");\n     }\n     processQueuedMessages(pendingDNMessages.takeAll());\n     assert pendingDNMessages.count() \u003d\u003d 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void processAllPendingDNMessages() throws IOException {\n    assert !shouldPostponeBlocksFromFuture :\n      \"processAllPendingDNMessages() should be called after disabling \" +\n      \"block postponement.\";\n    int count \u003d pendingDNMessages.count();\n    if (count \u003e 0) {\n      LOG.info(\"Processing \" + count + \" messages from DataNodes \" +\n          \"that were previously queued during standby state\");\n    }\n    processQueuedMessages(pendingDNMessages.takeAll());\n    assert pendingDNMessages.count() \u003d\u003d 0;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "23b6ed973e1ff5ace1e3a97cded008908e8daa55": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3605. Block mistakenly marked corrupt during edit log catchup phase of failover. Contributed by Todd Lipcon and Brahma Reddy Battula.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1363175 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/07/12 4:42 PM",
      "commitName": "23b6ed973e1ff5ace1e3a97cded008908e8daa55",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "16/07/12 2:26 PM",
      "commitNameOld": "527933f4f351a3df5e369c8bb6e2cfc4937e0836",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 2.09,
      "commitsBetweenForRepo": 19,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,12 @@\n   public void processAllPendingDNMessages() throws IOException {\n-    assert !namesystem.isInStandbyState() :\n-      \"processAllPendingDNMessages() should be called after exiting \" +\n-      \"standby state!\";\n+    assert !shouldPostponeBlocksFromFuture :\n+      \"processAllPendingDNMessages() should be called after disabling \" +\n+      \"block postponement.\";\n     int count \u003d pendingDNMessages.count();\n     if (count \u003e 0) {\n       LOG.info(\"Processing \" + count + \" messages from DataNodes \" +\n           \"that were previously queued during standby state.\");\n     }\n     processQueuedMessages(pendingDNMessages.takeAll());\n     assert pendingDNMessages.count() \u003d\u003d 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void processAllPendingDNMessages() throws IOException {\n    assert !shouldPostponeBlocksFromFuture :\n      \"processAllPendingDNMessages() should be called after disabling \" +\n      \"block postponement.\";\n    int count \u003d pendingDNMessages.count();\n    if (count \u003e 0) {\n      LOG.info(\"Processing \" + count + \" messages from DataNodes \" +\n          \"that were previously queued during standby state.\");\n    }\n    processQueuedMessages(pendingDNMessages.takeAll());\n    assert pendingDNMessages.count() \u003d\u003d 0;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    }
  }
}