{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "StoragePolicySatisfier.java",
  "functionName": "run",
  "functionId": "run",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java",
  "functionStartLine": 216,
  "functionEndLine": 345,
  "numCommitsSeen": 47,
  "timeTaken": 16317,
  "changeHistory": [
    "3ac07b720b7839a7fe6c83f4ccfe319b6a892501",
    "66e8f9b31529226309c924226a53dead3e6fcf11",
    "2acc50b826fa8b00f2b09d9546c4b3215b89d46d",
    "75ccc1396b677777cdc0d4992a4af3911f9f88c2",
    "8467ec24fb74f30371d5a13e893fc56309ee9372",
    "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52",
    "5845c36c16c423107183287cce3be9357dad7564",
    "99594b48b8e040ab5a0939d7c3dbcfb34400e6fc",
    "b0cb8d9bb44c963ae686d2b5c1b70bc76b955e10",
    "8d4f74e7339abc77dc0daa162d7bd2814bd79b3d",
    "05d4daf6ba3e5bd40f46e8003ee12fc7c613453d",
    "78420719eb1f138c6f10558befb7bc8ebcc28a54",
    "c561cb316e365ef674784cd6cf0b12c0fbc271a3",
    "5780f0624de2531194bc98eb25a928f7a483b992",
    "00eceed233d6e80d5c7137bf5b5286746ec4d5fb",
    "bfd3f8bd8a9ae2186ec3e4addc71f912ec7b8923",
    "7ea24fc06c081e2ba6f5f66d212abb14b80c9064",
    "5eb24ef7e7b8fb61a5f5b88bae3596b30aaeb60b",
    "0b360b16ab8759e3db606ada3420f4e2f56235f3",
    "6fe6c549e8226b4893f502186f52452dcd9408a2",
    "11a08a7e8f727449f17d1e31855996353b2975fe",
    "9b15f5418dbb49de57922f00858cb6fb0b61826e",
    "6215e35bb633706753a464ad3e8633366e6a10b2",
    "b7bed9f00a25bcad6f9c3543f5a1fb0a1f23b0e9",
    "5179d99b7e1faeac1ce041967480115913d9f795",
    "cd5262aba00aa51b905aaac95e201d4d48f2480d",
    "047526b4c27909f78313e1ed6216de85c6137f14",
    "1438da494424193e330f24edef823bbd60dc37d2"
  ],
  "changeHistoryShort": {
    "3ac07b720b7839a7fe6c83f4ccfe319b6a892501": "Ybodychange",
    "66e8f9b31529226309c924226a53dead3e6fcf11": "Ybodychange",
    "2acc50b826fa8b00f2b09d9546c4b3215b89d46d": "Ybodychange",
    "75ccc1396b677777cdc0d4992a4af3911f9f88c2": "Ybodychange",
    "8467ec24fb74f30371d5a13e893fc56309ee9372": "Ybodychange",
    "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52": "Ybodychange",
    "5845c36c16c423107183287cce3be9357dad7564": "Ybodychange",
    "99594b48b8e040ab5a0939d7c3dbcfb34400e6fc": "Ybodychange",
    "b0cb8d9bb44c963ae686d2b5c1b70bc76b955e10": "Ybodychange",
    "8d4f74e7339abc77dc0daa162d7bd2814bd79b3d": "Ybodychange",
    "05d4daf6ba3e5bd40f46e8003ee12fc7c613453d": "Ybodychange",
    "78420719eb1f138c6f10558befb7bc8ebcc28a54": "Ymultichange(Yfilerename,Ybodychange)",
    "c561cb316e365ef674784cd6cf0b12c0fbc271a3": "Ybodychange",
    "5780f0624de2531194bc98eb25a928f7a483b992": "Ybodychange",
    "00eceed233d6e80d5c7137bf5b5286746ec4d5fb": "Ybodychange",
    "bfd3f8bd8a9ae2186ec3e4addc71f912ec7b8923": "Ybodychange",
    "7ea24fc06c081e2ba6f5f66d212abb14b80c9064": "Ybodychange",
    "5eb24ef7e7b8fb61a5f5b88bae3596b30aaeb60b": "Ybodychange",
    "0b360b16ab8759e3db606ada3420f4e2f56235f3": "Ybodychange",
    "6fe6c549e8226b4893f502186f52452dcd9408a2": "Ybodychange",
    "11a08a7e8f727449f17d1e31855996353b2975fe": "Ybodychange",
    "9b15f5418dbb49de57922f00858cb6fb0b61826e": "Ybodychange",
    "6215e35bb633706753a464ad3e8633366e6a10b2": "Ybodychange",
    "b7bed9f00a25bcad6f9c3543f5a1fb0a1f23b0e9": "Ybodychange",
    "5179d99b7e1faeac1ce041967480115913d9f795": "Ybodychange",
    "cd5262aba00aa51b905aaac95e201d4d48f2480d": "Ybodychange",
    "047526b4c27909f78313e1ed6216de85c6137f14": "Ybodychange",
    "1438da494424193e330f24edef823bbd60dc37d2": "Yintroduced"
  },
  "changeHistoryDetails": {
    "3ac07b720b7839a7fe6c83f4ccfe319b6a892501": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13808: [SPS]: Remove unwanted FSNamesystem #isFileOpenedForWrite() and #getFileInfo() function. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "3ac07b720b7839a7fe6c83f4ccfe319b6a892501",
      "commitAuthor": "Uma Maheswara Rao Gangumalla",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "39ed3a66dbb01383ed16b141183fc48bfd2e613d",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,128 +1,130 @@\n   public void run() {\n     while (isRunning) {\n       // Check if dependent service is running\n       if (!ctxt.isRunning()) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Upstream service is down, skipping the sps work.\");\n         }\n         continue;\n       }\n+      ItemInfo itemInfo \u003d null;\n       try {\n-        ItemInfo itemInfo \u003d null;\n         boolean retryItem \u003d false;\n         if (!ctxt.isInSafeMode()) {\n           itemInfo \u003d storageMovementNeeded.get();\n           if (itemInfo !\u003d null) {\n             if(itemInfo.getRetryCount() \u003e\u003d blockMovementMaxRetry){\n               LOG.info(\"Failed to satisfy the policy after \"\n                   + blockMovementMaxRetry + \" retries. Removing inode \"\n                   + itemInfo.getFile() + \" from the queue\");\n               storageMovementNeeded.removeItemTrackInfo(itemInfo, false);\n               continue;\n             }\n             long trackId \u003d itemInfo.getFile();\n             BlocksMovingAnalysis status \u003d null;\n             BlockStoragePolicy existingStoragePolicy;\n             // TODO: presently, context internally acquire the lock\n             // and returns the result. Need to discuss to move the lock outside?\n             HdfsFileStatus fileStatus \u003d ctxt.getFileInfo(trackId);\n             // Check path existence.\n             if (fileStatus \u003d\u003d null || fileStatus.isDir()) {\n               // File doesn\u0027t exists (maybe got deleted) or its a directory,\n               // just remove trackId from the queue\n               storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n             } else {\n               byte existingStoragePolicyID \u003d fileStatus.getStoragePolicy();\n               existingStoragePolicy \u003d ctxt\n                   .getStoragePolicy(existingStoragePolicyID);\n \n               HdfsLocatedFileStatus file \u003d (HdfsLocatedFileStatus) fileStatus;\n               status \u003d analyseBlocksStorageMovementsAndAssignToDN(file,\n                   existingStoragePolicy);\n               switch (status.status) {\n               // Just add to monitor, so it will be retried after timeout\n               case ANALYSIS_SKIPPED_FOR_RETRY:\n                 // Just add to monitor, so it will be tracked for report and\n                 // be removed on storage movement attempt finished report.\n               case BLOCKS_TARGETS_PAIRED:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Block analysis status:{} for the file id:{}.\"\n                       + \" Adding to attempt monitor queue for the storage \"\n                       + \"movement attempt finished report\",\n                       status.status, fileStatus.getFileId());\n                 }\n                 this.storageMovementsMonitor.add(itemInfo.getStartPath(),\n                     itemInfo.getFile(), monotonicNow(), status.assignedBlocks,\n                     itemInfo.getRetryCount());\n                 break;\n               case NO_BLOCKS_TARGETS_PAIRED:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Adding trackID:{} for the file id:{} back to\"\n                       + \" retry queue as none of the blocks found its eligible\"\n                       + \" targets.\", trackId, fileStatus.getFileId());\n                 }\n                 retryItem \u003d true;\n                 break;\n               case FEW_LOW_REDUNDANCY_BLOCKS:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Adding trackID:{} for the file id:{} back to \"\n                       + \"retry queue as some of the blocks are low redundant.\",\n                       trackId, fileStatus.getFileId());\n                 }\n                 retryItem \u003d true;\n                 break;\n               case BLOCKS_FAILED_TO_MOVE:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Adding trackID:{} for the file id:{} back to \"\n                       + \"retry queue as some of the blocks movement failed.\",\n                       trackId, fileStatus.getFileId());\n                 }\n                 retryItem \u003d true;\n                 break;\n               // Just clean Xattrs\n               case BLOCKS_TARGET_PAIRING_SKIPPED:\n               case BLOCKS_ALREADY_SATISFIED:\n               default:\n                 LOG.info(\"Block analysis status:{} for the file id:{}.\"\n                     + \" So, Cleaning up the Xattrs.\", status.status,\n                     fileStatus.getFileId());\n                 storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n                 break;\n               }\n             }\n           }\n         } else {\n           LOG.info(\"Namenode is in safemode. It will retry again.\");\n           Thread.sleep(3000);\n         }\n         int numLiveDn \u003d ctxt.getNumLiveDataNodes();\n         if (storageMovementNeeded.size() \u003d\u003d 0\n             || blockCount \u003e (numLiveDn * spsWorkMultiplier)) {\n           Thread.sleep(3000);\n           blockCount \u003d 0L;\n         }\n         if (retryItem) {\n-          // itemInfo.increRetryCount();\n           this.storageMovementNeeded.add(itemInfo);\n         }\n       } catch (IOException e) {\n         LOG.error(\"Exception during StoragePolicySatisfier execution - \"\n             + \"will continue next cycle\", e);\n+        // Since it could not finish this item in previous iteration due to IOE,\n+        // just try again.\n+        this.storageMovementNeeded.add(itemInfo);\n       } catch (Throwable t) {\n         synchronized (this) {\n           if (isRunning) {\n             isRunning \u003d false;\n             if (t instanceof InterruptedException) {\n               LOG.info(\"Stopping StoragePolicySatisfier.\", t);\n             } else {\n               LOG.error(\"StoragePolicySatisfier thread received \"\n                   + \"runtime exception.\", t);\n             }\n             // Stopping monitor thread and clearing queues as well\n             this.clearQueues();\n             this.storageMovementsMonitor.stopGracefully();\n           }\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run() {\n    while (isRunning) {\n      // Check if dependent service is running\n      if (!ctxt.isRunning()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Upstream service is down, skipping the sps work.\");\n        }\n        continue;\n      }\n      ItemInfo itemInfo \u003d null;\n      try {\n        boolean retryItem \u003d false;\n        if (!ctxt.isInSafeMode()) {\n          itemInfo \u003d storageMovementNeeded.get();\n          if (itemInfo !\u003d null) {\n            if(itemInfo.getRetryCount() \u003e\u003d blockMovementMaxRetry){\n              LOG.info(\"Failed to satisfy the policy after \"\n                  + blockMovementMaxRetry + \" retries. Removing inode \"\n                  + itemInfo.getFile() + \" from the queue\");\n              storageMovementNeeded.removeItemTrackInfo(itemInfo, false);\n              continue;\n            }\n            long trackId \u003d itemInfo.getFile();\n            BlocksMovingAnalysis status \u003d null;\n            BlockStoragePolicy existingStoragePolicy;\n            // TODO: presently, context internally acquire the lock\n            // and returns the result. Need to discuss to move the lock outside?\n            HdfsFileStatus fileStatus \u003d ctxt.getFileInfo(trackId);\n            // Check path existence.\n            if (fileStatus \u003d\u003d null || fileStatus.isDir()) {\n              // File doesn\u0027t exists (maybe got deleted) or its a directory,\n              // just remove trackId from the queue\n              storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n            } else {\n              byte existingStoragePolicyID \u003d fileStatus.getStoragePolicy();\n              existingStoragePolicy \u003d ctxt\n                  .getStoragePolicy(existingStoragePolicyID);\n\n              HdfsLocatedFileStatus file \u003d (HdfsLocatedFileStatus) fileStatus;\n              status \u003d analyseBlocksStorageMovementsAndAssignToDN(file,\n                  existingStoragePolicy);\n              switch (status.status) {\n              // Just add to monitor, so it will be retried after timeout\n              case ANALYSIS_SKIPPED_FOR_RETRY:\n                // Just add to monitor, so it will be tracked for report and\n                // be removed on storage movement attempt finished report.\n              case BLOCKS_TARGETS_PAIRED:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Block analysis status:{} for the file id:{}.\"\n                      + \" Adding to attempt monitor queue for the storage \"\n                      + \"movement attempt finished report\",\n                      status.status, fileStatus.getFileId());\n                }\n                this.storageMovementsMonitor.add(itemInfo.getStartPath(),\n                    itemInfo.getFile(), monotonicNow(), status.assignedBlocks,\n                    itemInfo.getRetryCount());\n                break;\n              case NO_BLOCKS_TARGETS_PAIRED:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID:{} for the file id:{} back to\"\n                      + \" retry queue as none of the blocks found its eligible\"\n                      + \" targets.\", trackId, fileStatus.getFileId());\n                }\n                retryItem \u003d true;\n                break;\n              case FEW_LOW_REDUNDANCY_BLOCKS:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID:{} for the file id:{} back to \"\n                      + \"retry queue as some of the blocks are low redundant.\",\n                      trackId, fileStatus.getFileId());\n                }\n                retryItem \u003d true;\n                break;\n              case BLOCKS_FAILED_TO_MOVE:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID:{} for the file id:{} back to \"\n                      + \"retry queue as some of the blocks movement failed.\",\n                      trackId, fileStatus.getFileId());\n                }\n                retryItem \u003d true;\n                break;\n              // Just clean Xattrs\n              case BLOCKS_TARGET_PAIRING_SKIPPED:\n              case BLOCKS_ALREADY_SATISFIED:\n              default:\n                LOG.info(\"Block analysis status:{} for the file id:{}.\"\n                    + \" So, Cleaning up the Xattrs.\", status.status,\n                    fileStatus.getFileId());\n                storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n                break;\n              }\n            }\n          }\n        } else {\n          LOG.info(\"Namenode is in safemode. It will retry again.\");\n          Thread.sleep(3000);\n        }\n        int numLiveDn \u003d ctxt.getNumLiveDataNodes();\n        if (storageMovementNeeded.size() \u003d\u003d 0\n            || blockCount \u003e (numLiveDn * spsWorkMultiplier)) {\n          Thread.sleep(3000);\n          blockCount \u003d 0L;\n        }\n        if (retryItem) {\n          this.storageMovementNeeded.add(itemInfo);\n        }\n      } catch (IOException e) {\n        LOG.error(\"Exception during StoragePolicySatisfier execution - \"\n            + \"will continue next cycle\", e);\n        // Since it could not finish this item in previous iteration due to IOE,\n        // just try again.\n        this.storageMovementNeeded.add(itemInfo);\n      } catch (Throwable t) {\n        synchronized (this) {\n          if (isRunning) {\n            isRunning \u003d false;\n            if (t instanceof InterruptedException) {\n              LOG.info(\"Stopping StoragePolicySatisfier.\", t);\n            } else {\n              LOG.error(\"StoragePolicySatisfier thread received \"\n                  + \"runtime exception.\", t);\n            }\n            // Stopping monitor thread and clearing queues as well\n            this.clearQueues();\n            this.storageMovementsMonitor.stopGracefully();\n          }\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java",
      "extendedDetails": {}
    },
    "66e8f9b31529226309c924226a53dead3e6fcf11": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13381 : [SPS]: Use DFSUtilClient#makePathFromFileId() to prepare satisfier file path. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "66e8f9b31529226309c924226a53dead3e6fcf11",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "2acc50b826fa8b00f2b09d9546c4b3215b89d46d",
      "commitAuthorOld": "Rakesh Radhakrishnan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,128 +1,128 @@\n   public void run() {\n     while (isRunning) {\n       // Check if dependent service is running\n       if (!ctxt.isRunning()) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Upstream service is down, skipping the sps work.\");\n         }\n         continue;\n       }\n       try {\n-        ItemInfo\u003cT\u003e itemInfo \u003d null;\n+        ItemInfo itemInfo \u003d null;\n         boolean retryItem \u003d false;\n         if (!ctxt.isInSafeMode()) {\n           itemInfo \u003d storageMovementNeeded.get();\n           if (itemInfo !\u003d null) {\n             if(itemInfo.getRetryCount() \u003e\u003d blockMovementMaxRetry){\n               LOG.info(\"Failed to satisfy the policy after \"\n                   + blockMovementMaxRetry + \" retries. Removing inode \"\n                   + itemInfo.getFile() + \" from the queue\");\n               storageMovementNeeded.removeItemTrackInfo(itemInfo, false);\n               continue;\n             }\n-            T trackId \u003d itemInfo.getFile();\n+            long trackId \u003d itemInfo.getFile();\n             BlocksMovingAnalysis status \u003d null;\n             BlockStoragePolicy existingStoragePolicy;\n             // TODO: presently, context internally acquire the lock\n             // and returns the result. Need to discuss to move the lock outside?\n             HdfsFileStatus fileStatus \u003d ctxt.getFileInfo(trackId);\n             // Check path existence.\n             if (fileStatus \u003d\u003d null || fileStatus.isDir()) {\n               // File doesn\u0027t exists (maybe got deleted) or its a directory,\n               // just remove trackId from the queue\n               storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n             } else {\n               byte existingStoragePolicyID \u003d fileStatus.getStoragePolicy();\n               existingStoragePolicy \u003d ctxt\n                   .getStoragePolicy(existingStoragePolicyID);\n \n               HdfsLocatedFileStatus file \u003d (HdfsLocatedFileStatus) fileStatus;\n               status \u003d analyseBlocksStorageMovementsAndAssignToDN(file,\n                   existingStoragePolicy);\n               switch (status.status) {\n               // Just add to monitor, so it will be retried after timeout\n               case ANALYSIS_SKIPPED_FOR_RETRY:\n                 // Just add to monitor, so it will be tracked for report and\n                 // be removed on storage movement attempt finished report.\n               case BLOCKS_TARGETS_PAIRED:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Block analysis status:{} for the file id:{}.\"\n                       + \" Adding to attempt monitor queue for the storage \"\n                       + \"movement attempt finished report\",\n                       status.status, fileStatus.getFileId());\n                 }\n                 this.storageMovementsMonitor.add(itemInfo.getStartPath(),\n                     itemInfo.getFile(), monotonicNow(), status.assignedBlocks,\n                     itemInfo.getRetryCount());\n                 break;\n               case NO_BLOCKS_TARGETS_PAIRED:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Adding trackID:{} for the file id:{} back to\"\n                       + \" retry queue as none of the blocks found its eligible\"\n                       + \" targets.\", trackId, fileStatus.getFileId());\n                 }\n                 retryItem \u003d true;\n                 break;\n               case FEW_LOW_REDUNDANCY_BLOCKS:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Adding trackID:{} for the file id:{} back to \"\n                       + \"retry queue as some of the blocks are low redundant.\",\n                       trackId, fileStatus.getFileId());\n                 }\n                 retryItem \u003d true;\n                 break;\n               case BLOCKS_FAILED_TO_MOVE:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Adding trackID:{} for the file id:{} back to \"\n                       + \"retry queue as some of the blocks movement failed.\",\n                       trackId, fileStatus.getFileId());\n                 }\n                 retryItem \u003d true;\n                 break;\n               // Just clean Xattrs\n               case BLOCKS_TARGET_PAIRING_SKIPPED:\n               case BLOCKS_ALREADY_SATISFIED:\n               default:\n                 LOG.info(\"Block analysis status:{} for the file id:{}.\"\n                     + \" So, Cleaning up the Xattrs.\", status.status,\n                     fileStatus.getFileId());\n                 storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n                 break;\n               }\n             }\n           }\n         } else {\n           LOG.info(\"Namenode is in safemode. It will retry again.\");\n           Thread.sleep(3000);\n         }\n         int numLiveDn \u003d ctxt.getNumLiveDataNodes();\n         if (storageMovementNeeded.size() \u003d\u003d 0\n             || blockCount \u003e (numLiveDn * spsWorkMultiplier)) {\n           Thread.sleep(3000);\n           blockCount \u003d 0L;\n         }\n         if (retryItem) {\n-          itemInfo.increRetryCount();\n+          // itemInfo.increRetryCount();\n           this.storageMovementNeeded.add(itemInfo);\n         }\n       } catch (IOException e) {\n         LOG.error(\"Exception during StoragePolicySatisfier execution - \"\n             + \"will continue next cycle\", e);\n       } catch (Throwable t) {\n         synchronized (this) {\n           if (isRunning) {\n             isRunning \u003d false;\n             if (t instanceof InterruptedException) {\n               LOG.info(\"Stopping StoragePolicySatisfier.\", t);\n             } else {\n               LOG.error(\"StoragePolicySatisfier thread received \"\n                   + \"runtime exception.\", t);\n             }\n             // Stopping monitor thread and clearing queues as well\n             this.clearQueues();\n             this.storageMovementsMonitor.stopGracefully();\n           }\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run() {\n    while (isRunning) {\n      // Check if dependent service is running\n      if (!ctxt.isRunning()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Upstream service is down, skipping the sps work.\");\n        }\n        continue;\n      }\n      try {\n        ItemInfo itemInfo \u003d null;\n        boolean retryItem \u003d false;\n        if (!ctxt.isInSafeMode()) {\n          itemInfo \u003d storageMovementNeeded.get();\n          if (itemInfo !\u003d null) {\n            if(itemInfo.getRetryCount() \u003e\u003d blockMovementMaxRetry){\n              LOG.info(\"Failed to satisfy the policy after \"\n                  + blockMovementMaxRetry + \" retries. Removing inode \"\n                  + itemInfo.getFile() + \" from the queue\");\n              storageMovementNeeded.removeItemTrackInfo(itemInfo, false);\n              continue;\n            }\n            long trackId \u003d itemInfo.getFile();\n            BlocksMovingAnalysis status \u003d null;\n            BlockStoragePolicy existingStoragePolicy;\n            // TODO: presently, context internally acquire the lock\n            // and returns the result. Need to discuss to move the lock outside?\n            HdfsFileStatus fileStatus \u003d ctxt.getFileInfo(trackId);\n            // Check path existence.\n            if (fileStatus \u003d\u003d null || fileStatus.isDir()) {\n              // File doesn\u0027t exists (maybe got deleted) or its a directory,\n              // just remove trackId from the queue\n              storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n            } else {\n              byte existingStoragePolicyID \u003d fileStatus.getStoragePolicy();\n              existingStoragePolicy \u003d ctxt\n                  .getStoragePolicy(existingStoragePolicyID);\n\n              HdfsLocatedFileStatus file \u003d (HdfsLocatedFileStatus) fileStatus;\n              status \u003d analyseBlocksStorageMovementsAndAssignToDN(file,\n                  existingStoragePolicy);\n              switch (status.status) {\n              // Just add to monitor, so it will be retried after timeout\n              case ANALYSIS_SKIPPED_FOR_RETRY:\n                // Just add to monitor, so it will be tracked for report and\n                // be removed on storage movement attempt finished report.\n              case BLOCKS_TARGETS_PAIRED:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Block analysis status:{} for the file id:{}.\"\n                      + \" Adding to attempt monitor queue for the storage \"\n                      + \"movement attempt finished report\",\n                      status.status, fileStatus.getFileId());\n                }\n                this.storageMovementsMonitor.add(itemInfo.getStartPath(),\n                    itemInfo.getFile(), monotonicNow(), status.assignedBlocks,\n                    itemInfo.getRetryCount());\n                break;\n              case NO_BLOCKS_TARGETS_PAIRED:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID:{} for the file id:{} back to\"\n                      + \" retry queue as none of the blocks found its eligible\"\n                      + \" targets.\", trackId, fileStatus.getFileId());\n                }\n                retryItem \u003d true;\n                break;\n              case FEW_LOW_REDUNDANCY_BLOCKS:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID:{} for the file id:{} back to \"\n                      + \"retry queue as some of the blocks are low redundant.\",\n                      trackId, fileStatus.getFileId());\n                }\n                retryItem \u003d true;\n                break;\n              case BLOCKS_FAILED_TO_MOVE:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID:{} for the file id:{} back to \"\n                      + \"retry queue as some of the blocks movement failed.\",\n                      trackId, fileStatus.getFileId());\n                }\n                retryItem \u003d true;\n                break;\n              // Just clean Xattrs\n              case BLOCKS_TARGET_PAIRING_SKIPPED:\n              case BLOCKS_ALREADY_SATISFIED:\n              default:\n                LOG.info(\"Block analysis status:{} for the file id:{}.\"\n                    + \" So, Cleaning up the Xattrs.\", status.status,\n                    fileStatus.getFileId());\n                storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n                break;\n              }\n            }\n          }\n        } else {\n          LOG.info(\"Namenode is in safemode. It will retry again.\");\n          Thread.sleep(3000);\n        }\n        int numLiveDn \u003d ctxt.getNumLiveDataNodes();\n        if (storageMovementNeeded.size() \u003d\u003d 0\n            || blockCount \u003e (numLiveDn * spsWorkMultiplier)) {\n          Thread.sleep(3000);\n          blockCount \u003d 0L;\n        }\n        if (retryItem) {\n          // itemInfo.increRetryCount();\n          this.storageMovementNeeded.add(itemInfo);\n        }\n      } catch (IOException e) {\n        LOG.error(\"Exception during StoragePolicySatisfier execution - \"\n            + \"will continue next cycle\", e);\n      } catch (Throwable t) {\n        synchronized (this) {\n          if (isRunning) {\n            isRunning \u003d false;\n            if (t instanceof InterruptedException) {\n              LOG.info(\"Stopping StoragePolicySatisfier.\", t);\n            } else {\n              LOG.error(\"StoragePolicySatisfier thread received \"\n                  + \"runtime exception.\", t);\n            }\n            // Stopping monitor thread and clearing queues as well\n            this.clearQueues();\n            this.storageMovementsMonitor.stopGracefully();\n          }\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java",
      "extendedDetails": {}
    },
    "2acc50b826fa8b00f2b09d9546c4b3215b89d46d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13165: [SPS]: Collects successfully moved block details via IBR. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "2acc50b826fa8b00f2b09d9546c4b3215b89d46d",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "75ccc1396b677777cdc0d4992a4af3911f9f88c2",
      "commitAuthorOld": "Surendra Singh Lilhore",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,128 +1,128 @@\n   public void run() {\n     while (isRunning) {\n       // Check if dependent service is running\n       if (!ctxt.isRunning()) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Upstream service is down, skipping the sps work.\");\n         }\n         continue;\n       }\n       try {\n         ItemInfo\u003cT\u003e itemInfo \u003d null;\n         boolean retryItem \u003d false;\n         if (!ctxt.isInSafeMode()) {\n           itemInfo \u003d storageMovementNeeded.get();\n           if (itemInfo !\u003d null) {\n             if(itemInfo.getRetryCount() \u003e\u003d blockMovementMaxRetry){\n               LOG.info(\"Failed to satisfy the policy after \"\n                   + blockMovementMaxRetry + \" retries. Removing inode \"\n                   + itemInfo.getFile() + \" from the queue\");\n               storageMovementNeeded.removeItemTrackInfo(itemInfo, false);\n               continue;\n             }\n             T trackId \u003d itemInfo.getFile();\n             BlocksMovingAnalysis status \u003d null;\n             BlockStoragePolicy existingStoragePolicy;\n             // TODO: presently, context internally acquire the lock\n             // and returns the result. Need to discuss to move the lock outside?\n             HdfsFileStatus fileStatus \u003d ctxt.getFileInfo(trackId);\n             // Check path existence.\n             if (fileStatus \u003d\u003d null || fileStatus.isDir()) {\n               // File doesn\u0027t exists (maybe got deleted) or its a directory,\n               // just remove trackId from the queue\n               storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n             } else {\n               byte existingStoragePolicyID \u003d fileStatus.getStoragePolicy();\n               existingStoragePolicy \u003d ctxt\n                   .getStoragePolicy(existingStoragePolicyID);\n \n               HdfsLocatedFileStatus file \u003d (HdfsLocatedFileStatus) fileStatus;\n               status \u003d analyseBlocksStorageMovementsAndAssignToDN(file,\n                   existingStoragePolicy);\n               switch (status.status) {\n               // Just add to monitor, so it will be retried after timeout\n               case ANALYSIS_SKIPPED_FOR_RETRY:\n                 // Just add to monitor, so it will be tracked for report and\n                 // be removed on storage movement attempt finished report.\n               case BLOCKS_TARGETS_PAIRED:\n                 if (LOG.isDebugEnabled()) {\n-                  LOG.debug(\"Block analysis status:{} for the file path:{}.\"\n+                  LOG.debug(\"Block analysis status:{} for the file id:{}.\"\n                       + \" Adding to attempt monitor queue for the storage \"\n                       + \"movement attempt finished report\",\n-                      status.status, fileStatus.getPath());\n+                      status.status, fileStatus.getFileId());\n                 }\n-                this.storageMovementsMonitor.add(new AttemptedItemInfo\u003cT\u003e(\n-                    itemInfo.getStartPath(), itemInfo.getFile(), monotonicNow(),\n-                    status.assignedBlocks, itemInfo.getRetryCount()));\n+                this.storageMovementsMonitor.add(itemInfo.getStartPath(),\n+                    itemInfo.getFile(), monotonicNow(), status.assignedBlocks,\n+                    itemInfo.getRetryCount());\n                 break;\n               case NO_BLOCKS_TARGETS_PAIRED:\n                 if (LOG.isDebugEnabled()) {\n-                  LOG.debug(\"Adding trackID:{} for the file path:{} back to\"\n+                  LOG.debug(\"Adding trackID:{} for the file id:{} back to\"\n                       + \" retry queue as none of the blocks found its eligible\"\n-                      + \" targets.\", trackId, fileStatus.getPath());\n+                      + \" targets.\", trackId, fileStatus.getFileId());\n                 }\n                 retryItem \u003d true;\n                 break;\n               case FEW_LOW_REDUNDANCY_BLOCKS:\n                 if (LOG.isDebugEnabled()) {\n-                  LOG.debug(\"Adding trackID:{} for the file path:{} back to \"\n+                  LOG.debug(\"Adding trackID:{} for the file id:{} back to \"\n                       + \"retry queue as some of the blocks are low redundant.\",\n-                      trackId, fileStatus.getPath());\n+                      trackId, fileStatus.getFileId());\n                 }\n                 retryItem \u003d true;\n                 break;\n               case BLOCKS_FAILED_TO_MOVE:\n                 if (LOG.isDebugEnabled()) {\n-                  LOG.debug(\"Adding trackID:{} for the file path:{} back to \"\n+                  LOG.debug(\"Adding trackID:{} for the file id:{} back to \"\n                       + \"retry queue as some of the blocks movement failed.\",\n-                      trackId, fileStatus.getPath());\n+                      trackId, fileStatus.getFileId());\n                 }\n                 retryItem \u003d true;\n                 break;\n               // Just clean Xattrs\n               case BLOCKS_TARGET_PAIRING_SKIPPED:\n               case BLOCKS_ALREADY_SATISFIED:\n               default:\n-                LOG.info(\"Block analysis status:{} for the file path:{}.\"\n+                LOG.info(\"Block analysis status:{} for the file id:{}.\"\n                     + \" So, Cleaning up the Xattrs.\", status.status,\n-                    fileStatus.getPath());\n+                    fileStatus.getFileId());\n                 storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n                 break;\n               }\n             }\n           }\n         } else {\n           LOG.info(\"Namenode is in safemode. It will retry again.\");\n           Thread.sleep(3000);\n         }\n         int numLiveDn \u003d ctxt.getNumLiveDataNodes();\n         if (storageMovementNeeded.size() \u003d\u003d 0\n             || blockCount \u003e (numLiveDn * spsWorkMultiplier)) {\n           Thread.sleep(3000);\n           blockCount \u003d 0L;\n         }\n         if (retryItem) {\n           itemInfo.increRetryCount();\n           this.storageMovementNeeded.add(itemInfo);\n         }\n       } catch (IOException e) {\n         LOG.error(\"Exception during StoragePolicySatisfier execution - \"\n             + \"will continue next cycle\", e);\n       } catch (Throwable t) {\n         synchronized (this) {\n           if (isRunning) {\n             isRunning \u003d false;\n             if (t instanceof InterruptedException) {\n               LOG.info(\"Stopping StoragePolicySatisfier.\", t);\n             } else {\n               LOG.error(\"StoragePolicySatisfier thread received \"\n                   + \"runtime exception.\", t);\n             }\n             // Stopping monitor thread and clearing queues as well\n             this.clearQueues();\n             this.storageMovementsMonitor.stopGracefully();\n           }\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run() {\n    while (isRunning) {\n      // Check if dependent service is running\n      if (!ctxt.isRunning()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Upstream service is down, skipping the sps work.\");\n        }\n        continue;\n      }\n      try {\n        ItemInfo\u003cT\u003e itemInfo \u003d null;\n        boolean retryItem \u003d false;\n        if (!ctxt.isInSafeMode()) {\n          itemInfo \u003d storageMovementNeeded.get();\n          if (itemInfo !\u003d null) {\n            if(itemInfo.getRetryCount() \u003e\u003d blockMovementMaxRetry){\n              LOG.info(\"Failed to satisfy the policy after \"\n                  + blockMovementMaxRetry + \" retries. Removing inode \"\n                  + itemInfo.getFile() + \" from the queue\");\n              storageMovementNeeded.removeItemTrackInfo(itemInfo, false);\n              continue;\n            }\n            T trackId \u003d itemInfo.getFile();\n            BlocksMovingAnalysis status \u003d null;\n            BlockStoragePolicy existingStoragePolicy;\n            // TODO: presently, context internally acquire the lock\n            // and returns the result. Need to discuss to move the lock outside?\n            HdfsFileStatus fileStatus \u003d ctxt.getFileInfo(trackId);\n            // Check path existence.\n            if (fileStatus \u003d\u003d null || fileStatus.isDir()) {\n              // File doesn\u0027t exists (maybe got deleted) or its a directory,\n              // just remove trackId from the queue\n              storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n            } else {\n              byte existingStoragePolicyID \u003d fileStatus.getStoragePolicy();\n              existingStoragePolicy \u003d ctxt\n                  .getStoragePolicy(existingStoragePolicyID);\n\n              HdfsLocatedFileStatus file \u003d (HdfsLocatedFileStatus) fileStatus;\n              status \u003d analyseBlocksStorageMovementsAndAssignToDN(file,\n                  existingStoragePolicy);\n              switch (status.status) {\n              // Just add to monitor, so it will be retried after timeout\n              case ANALYSIS_SKIPPED_FOR_RETRY:\n                // Just add to monitor, so it will be tracked for report and\n                // be removed on storage movement attempt finished report.\n              case BLOCKS_TARGETS_PAIRED:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Block analysis status:{} for the file id:{}.\"\n                      + \" Adding to attempt monitor queue for the storage \"\n                      + \"movement attempt finished report\",\n                      status.status, fileStatus.getFileId());\n                }\n                this.storageMovementsMonitor.add(itemInfo.getStartPath(),\n                    itemInfo.getFile(), monotonicNow(), status.assignedBlocks,\n                    itemInfo.getRetryCount());\n                break;\n              case NO_BLOCKS_TARGETS_PAIRED:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID:{} for the file id:{} back to\"\n                      + \" retry queue as none of the blocks found its eligible\"\n                      + \" targets.\", trackId, fileStatus.getFileId());\n                }\n                retryItem \u003d true;\n                break;\n              case FEW_LOW_REDUNDANCY_BLOCKS:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID:{} for the file id:{} back to \"\n                      + \"retry queue as some of the blocks are low redundant.\",\n                      trackId, fileStatus.getFileId());\n                }\n                retryItem \u003d true;\n                break;\n              case BLOCKS_FAILED_TO_MOVE:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID:{} for the file id:{} back to \"\n                      + \"retry queue as some of the blocks movement failed.\",\n                      trackId, fileStatus.getFileId());\n                }\n                retryItem \u003d true;\n                break;\n              // Just clean Xattrs\n              case BLOCKS_TARGET_PAIRING_SKIPPED:\n              case BLOCKS_ALREADY_SATISFIED:\n              default:\n                LOG.info(\"Block analysis status:{} for the file id:{}.\"\n                    + \" So, Cleaning up the Xattrs.\", status.status,\n                    fileStatus.getFileId());\n                storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n                break;\n              }\n            }\n          }\n        } else {\n          LOG.info(\"Namenode is in safemode. It will retry again.\");\n          Thread.sleep(3000);\n        }\n        int numLiveDn \u003d ctxt.getNumLiveDataNodes();\n        if (storageMovementNeeded.size() \u003d\u003d 0\n            || blockCount \u003e (numLiveDn * spsWorkMultiplier)) {\n          Thread.sleep(3000);\n          blockCount \u003d 0L;\n        }\n        if (retryItem) {\n          itemInfo.increRetryCount();\n          this.storageMovementNeeded.add(itemInfo);\n        }\n      } catch (IOException e) {\n        LOG.error(\"Exception during StoragePolicySatisfier execution - \"\n            + \"will continue next cycle\", e);\n      } catch (Throwable t) {\n        synchronized (this) {\n          if (isRunning) {\n            isRunning \u003d false;\n            if (t instanceof InterruptedException) {\n              LOG.info(\"Stopping StoragePolicySatisfier.\", t);\n            } else {\n              LOG.error(\"StoragePolicySatisfier thread received \"\n                  + \"runtime exception.\", t);\n            }\n            // Stopping monitor thread and clearing queues as well\n            this.clearQueues();\n            this.storageMovementsMonitor.stopGracefully();\n          }\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java",
      "extendedDetails": {}
    },
    "75ccc1396b677777cdc0d4992a4af3911f9f88c2": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13166: [SPS]: Implement caching mechanism to keep LIVE datanodes to minimize costly getLiveDatanodeStorageReport() calls. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "75ccc1396b677777cdc0d4992a4af3911f9f88c2",
      "commitAuthor": "Surendra Singh Lilhore",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "8467ec24fb74f30371d5a13e893fc56309ee9372",
      "commitAuthorOld": "Rakesh Radhakrishnan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,130 +1,128 @@\n   public void run() {\n     while (isRunning) {\n       // Check if dependent service is running\n       if (!ctxt.isRunning()) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Upstream service is down, skipping the sps work.\");\n         }\n         continue;\n       }\n       try {\n         ItemInfo\u003cT\u003e itemInfo \u003d null;\n         boolean retryItem \u003d false;\n         if (!ctxt.isInSafeMode()) {\n           itemInfo \u003d storageMovementNeeded.get();\n           if (itemInfo !\u003d null) {\n             if(itemInfo.getRetryCount() \u003e\u003d blockMovementMaxRetry){\n               LOG.info(\"Failed to satisfy the policy after \"\n                   + blockMovementMaxRetry + \" retries. Removing inode \"\n                   + itemInfo.getFile() + \" from the queue\");\n               storageMovementNeeded.removeItemTrackInfo(itemInfo, false);\n               continue;\n             }\n             T trackId \u003d itemInfo.getFile();\n             BlocksMovingAnalysis status \u003d null;\n-            DatanodeStorageReport[] liveDnReports;\n             BlockStoragePolicy existingStoragePolicy;\n             // TODO: presently, context internally acquire the lock\n             // and returns the result. Need to discuss to move the lock outside?\n             HdfsFileStatus fileStatus \u003d ctxt.getFileInfo(trackId);\n             // Check path existence.\n             if (fileStatus \u003d\u003d null || fileStatus.isDir()) {\n               // File doesn\u0027t exists (maybe got deleted) or its a directory,\n               // just remove trackId from the queue\n               storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n             } else {\n-              liveDnReports \u003d ctxt.getLiveDatanodeStorageReport();\n               byte existingStoragePolicyID \u003d fileStatus.getStoragePolicy();\n               existingStoragePolicy \u003d ctxt\n                   .getStoragePolicy(existingStoragePolicyID);\n \n               HdfsLocatedFileStatus file \u003d (HdfsLocatedFileStatus) fileStatus;\n               status \u003d analyseBlocksStorageMovementsAndAssignToDN(file,\n-                  existingStoragePolicy, liveDnReports);\n+                  existingStoragePolicy);\n               switch (status.status) {\n               // Just add to monitor, so it will be retried after timeout\n               case ANALYSIS_SKIPPED_FOR_RETRY:\n                 // Just add to monitor, so it will be tracked for report and\n                 // be removed on storage movement attempt finished report.\n               case BLOCKS_TARGETS_PAIRED:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Block analysis status:{} for the file path:{}.\"\n                       + \" Adding to attempt monitor queue for the storage \"\n                       + \"movement attempt finished report\",\n                       status.status, fileStatus.getPath());\n                 }\n                 this.storageMovementsMonitor.add(new AttemptedItemInfo\u003cT\u003e(\n                     itemInfo.getStartPath(), itemInfo.getFile(), monotonicNow(),\n                     status.assignedBlocks, itemInfo.getRetryCount()));\n                 break;\n               case NO_BLOCKS_TARGETS_PAIRED:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Adding trackID:{} for the file path:{} back to\"\n                       + \" retry queue as none of the blocks found its eligible\"\n                       + \" targets.\", trackId, fileStatus.getPath());\n                 }\n                 retryItem \u003d true;\n                 break;\n               case FEW_LOW_REDUNDANCY_BLOCKS:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Adding trackID:{} for the file path:{} back to \"\n                       + \"retry queue as some of the blocks are low redundant.\",\n                       trackId, fileStatus.getPath());\n                 }\n                 retryItem \u003d true;\n                 break;\n               case BLOCKS_FAILED_TO_MOVE:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Adding trackID:{} for the file path:{} back to \"\n                       + \"retry queue as some of the blocks movement failed.\",\n                       trackId, fileStatus.getPath());\n                 }\n                 retryItem \u003d true;\n                 break;\n               // Just clean Xattrs\n               case BLOCKS_TARGET_PAIRING_SKIPPED:\n               case BLOCKS_ALREADY_SATISFIED:\n               default:\n                 LOG.info(\"Block analysis status:{} for the file path:{}.\"\n                     + \" So, Cleaning up the Xattrs.\", status.status,\n                     fileStatus.getPath());\n                 storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n                 break;\n               }\n             }\n           }\n         } else {\n           LOG.info(\"Namenode is in safemode. It will retry again.\");\n           Thread.sleep(3000);\n         }\n         int numLiveDn \u003d ctxt.getNumLiveDataNodes();\n         if (storageMovementNeeded.size() \u003d\u003d 0\n             || blockCount \u003e (numLiveDn * spsWorkMultiplier)) {\n           Thread.sleep(3000);\n           blockCount \u003d 0L;\n         }\n         if (retryItem) {\n           itemInfo.increRetryCount();\n           this.storageMovementNeeded.add(itemInfo);\n         }\n       } catch (IOException e) {\n         LOG.error(\"Exception during StoragePolicySatisfier execution - \"\n             + \"will continue next cycle\", e);\n       } catch (Throwable t) {\n         synchronized (this) {\n           if (isRunning) {\n             isRunning \u003d false;\n             if (t instanceof InterruptedException) {\n               LOG.info(\"Stopping StoragePolicySatisfier.\", t);\n             } else {\n               LOG.error(\"StoragePolicySatisfier thread received \"\n                   + \"runtime exception.\", t);\n             }\n             // Stopping monitor thread and clearing queues as well\n             this.clearQueues();\n             this.storageMovementsMonitor.stopGracefully();\n           }\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run() {\n    while (isRunning) {\n      // Check if dependent service is running\n      if (!ctxt.isRunning()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Upstream service is down, skipping the sps work.\");\n        }\n        continue;\n      }\n      try {\n        ItemInfo\u003cT\u003e itemInfo \u003d null;\n        boolean retryItem \u003d false;\n        if (!ctxt.isInSafeMode()) {\n          itemInfo \u003d storageMovementNeeded.get();\n          if (itemInfo !\u003d null) {\n            if(itemInfo.getRetryCount() \u003e\u003d blockMovementMaxRetry){\n              LOG.info(\"Failed to satisfy the policy after \"\n                  + blockMovementMaxRetry + \" retries. Removing inode \"\n                  + itemInfo.getFile() + \" from the queue\");\n              storageMovementNeeded.removeItemTrackInfo(itemInfo, false);\n              continue;\n            }\n            T trackId \u003d itemInfo.getFile();\n            BlocksMovingAnalysis status \u003d null;\n            BlockStoragePolicy existingStoragePolicy;\n            // TODO: presently, context internally acquire the lock\n            // and returns the result. Need to discuss to move the lock outside?\n            HdfsFileStatus fileStatus \u003d ctxt.getFileInfo(trackId);\n            // Check path existence.\n            if (fileStatus \u003d\u003d null || fileStatus.isDir()) {\n              // File doesn\u0027t exists (maybe got deleted) or its a directory,\n              // just remove trackId from the queue\n              storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n            } else {\n              byte existingStoragePolicyID \u003d fileStatus.getStoragePolicy();\n              existingStoragePolicy \u003d ctxt\n                  .getStoragePolicy(existingStoragePolicyID);\n\n              HdfsLocatedFileStatus file \u003d (HdfsLocatedFileStatus) fileStatus;\n              status \u003d analyseBlocksStorageMovementsAndAssignToDN(file,\n                  existingStoragePolicy);\n              switch (status.status) {\n              // Just add to monitor, so it will be retried after timeout\n              case ANALYSIS_SKIPPED_FOR_RETRY:\n                // Just add to monitor, so it will be tracked for report and\n                // be removed on storage movement attempt finished report.\n              case BLOCKS_TARGETS_PAIRED:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Block analysis status:{} for the file path:{}.\"\n                      + \" Adding to attempt monitor queue for the storage \"\n                      + \"movement attempt finished report\",\n                      status.status, fileStatus.getPath());\n                }\n                this.storageMovementsMonitor.add(new AttemptedItemInfo\u003cT\u003e(\n                    itemInfo.getStartPath(), itemInfo.getFile(), monotonicNow(),\n                    status.assignedBlocks, itemInfo.getRetryCount()));\n                break;\n              case NO_BLOCKS_TARGETS_PAIRED:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID:{} for the file path:{} back to\"\n                      + \" retry queue as none of the blocks found its eligible\"\n                      + \" targets.\", trackId, fileStatus.getPath());\n                }\n                retryItem \u003d true;\n                break;\n              case FEW_LOW_REDUNDANCY_BLOCKS:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID:{} for the file path:{} back to \"\n                      + \"retry queue as some of the blocks are low redundant.\",\n                      trackId, fileStatus.getPath());\n                }\n                retryItem \u003d true;\n                break;\n              case BLOCKS_FAILED_TO_MOVE:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID:{} for the file path:{} back to \"\n                      + \"retry queue as some of the blocks movement failed.\",\n                      trackId, fileStatus.getPath());\n                }\n                retryItem \u003d true;\n                break;\n              // Just clean Xattrs\n              case BLOCKS_TARGET_PAIRING_SKIPPED:\n              case BLOCKS_ALREADY_SATISFIED:\n              default:\n                LOG.info(\"Block analysis status:{} for the file path:{}.\"\n                    + \" So, Cleaning up the Xattrs.\", status.status,\n                    fileStatus.getPath());\n                storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n                break;\n              }\n            }\n          }\n        } else {\n          LOG.info(\"Namenode is in safemode. It will retry again.\");\n          Thread.sleep(3000);\n        }\n        int numLiveDn \u003d ctxt.getNumLiveDataNodes();\n        if (storageMovementNeeded.size() \u003d\u003d 0\n            || blockCount \u003e (numLiveDn * spsWorkMultiplier)) {\n          Thread.sleep(3000);\n          blockCount \u003d 0L;\n        }\n        if (retryItem) {\n          itemInfo.increRetryCount();\n          this.storageMovementNeeded.add(itemInfo);\n        }\n      } catch (IOException e) {\n        LOG.error(\"Exception during StoragePolicySatisfier execution - \"\n            + \"will continue next cycle\", e);\n      } catch (Throwable t) {\n        synchronized (this) {\n          if (isRunning) {\n            isRunning \u003d false;\n            if (t instanceof InterruptedException) {\n              LOG.info(\"Stopping StoragePolicySatisfier.\", t);\n            } else {\n              LOG.error(\"StoragePolicySatisfier thread received \"\n                  + \"runtime exception.\", t);\n            }\n            // Stopping monitor thread and clearing queues as well\n            this.clearQueues();\n            this.storageMovementsMonitor.stopGracefully();\n          }\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java",
      "extendedDetails": {}
    },
    "8467ec24fb74f30371d5a13e893fc56309ee9372": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13110: [SPS]: Reduce the number of APIs in NamenodeProtocol used by external satisfier. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "8467ec24fb74f30371d5a13e893fc56309ee9372",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,128 +1,130 @@\n   public void run() {\n     while (isRunning) {\n       // Check if dependent service is running\n       if (!ctxt.isRunning()) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Upstream service is down, skipping the sps work.\");\n         }\n         continue;\n       }\n       try {\n+        ItemInfo\u003cT\u003e itemInfo \u003d null;\n+        boolean retryItem \u003d false;\n         if (!ctxt.isInSafeMode()) {\n-          ItemInfo itemInfo \u003d storageMovementNeeded.get();\n+          itemInfo \u003d storageMovementNeeded.get();\n           if (itemInfo !\u003d null) {\n             if(itemInfo.getRetryCount() \u003e\u003d blockMovementMaxRetry){\n               LOG.info(\"Failed to satisfy the policy after \"\n                   + blockMovementMaxRetry + \" retries. Removing inode \"\n-                  + itemInfo.getFileId() + \" from the queue\");\n+                  + itemInfo.getFile() + \" from the queue\");\n               storageMovementNeeded.removeItemTrackInfo(itemInfo, false);\n               continue;\n             }\n-            long trackId \u003d itemInfo.getFileId();\n+            T trackId \u003d itemInfo.getFile();\n             BlocksMovingAnalysis status \u003d null;\n             DatanodeStorageReport[] liveDnReports;\n             BlockStoragePolicy existingStoragePolicy;\n             // TODO: presently, context internally acquire the lock\n             // and returns the result. Need to discuss to move the lock outside?\n-            boolean hasLowRedundancyBlocks \u003d ctxt\n-                .hasLowRedundancyBlocks(trackId);\n             HdfsFileStatus fileStatus \u003d ctxt.getFileInfo(trackId);\n             // Check path existence.\n             if (fileStatus \u003d\u003d null || fileStatus.isDir()) {\n               // File doesn\u0027t exists (maybe got deleted) or its a directory,\n               // just remove trackId from the queue\n               storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n             } else {\n               liveDnReports \u003d ctxt.getLiveDatanodeStorageReport();\n               byte existingStoragePolicyID \u003d fileStatus.getStoragePolicy();\n               existingStoragePolicy \u003d ctxt\n                   .getStoragePolicy(existingStoragePolicyID);\n \n               HdfsLocatedFileStatus file \u003d (HdfsLocatedFileStatus) fileStatus;\n               status \u003d analyseBlocksStorageMovementsAndAssignToDN(file,\n-                  hasLowRedundancyBlocks, existingStoragePolicy, liveDnReports);\n+                  existingStoragePolicy, liveDnReports);\n               switch (status.status) {\n               // Just add to monitor, so it will be retried after timeout\n               case ANALYSIS_SKIPPED_FOR_RETRY:\n                 // Just add to monitor, so it will be tracked for report and\n                 // be removed on storage movement attempt finished report.\n               case BLOCKS_TARGETS_PAIRED:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Block analysis status:{} for the file path:{}.\"\n                       + \" Adding to attempt monitor queue for the storage \"\n                       + \"movement attempt finished report\",\n                       status.status, fileStatus.getPath());\n                 }\n-                this.storageMovementsMonitor.add(new AttemptedItemInfo(itemInfo\n-                    .getStartId(), itemInfo.getFileId(), monotonicNow(),\n+                this.storageMovementsMonitor.add(new AttemptedItemInfo\u003cT\u003e(\n+                    itemInfo.getStartPath(), itemInfo.getFile(), monotonicNow(),\n                     status.assignedBlocks, itemInfo.getRetryCount()));\n                 break;\n               case NO_BLOCKS_TARGETS_PAIRED:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Adding trackID:{} for the file path:{} back to\"\n                       + \" retry queue as none of the blocks found its eligible\"\n                       + \" targets.\", trackId, fileStatus.getPath());\n                 }\n-                itemInfo.increRetryCount();\n-                this.storageMovementNeeded.add(itemInfo);\n+                retryItem \u003d true;\n                 break;\n               case FEW_LOW_REDUNDANCY_BLOCKS:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Adding trackID:{} for the file path:{} back to \"\n                       + \"retry queue as some of the blocks are low redundant.\",\n                       trackId, fileStatus.getPath());\n                 }\n-                itemInfo.increRetryCount();\n-                this.storageMovementNeeded.add(itemInfo);\n+                retryItem \u003d true;\n                 break;\n               case BLOCKS_FAILED_TO_MOVE:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Adding trackID:{} for the file path:{} back to \"\n                       + \"retry queue as some of the blocks movement failed.\",\n                       trackId, fileStatus.getPath());\n                 }\n-                this.storageMovementNeeded.add(itemInfo);\n+                retryItem \u003d true;\n                 break;\n               // Just clean Xattrs\n               case BLOCKS_TARGET_PAIRING_SKIPPED:\n               case BLOCKS_ALREADY_SATISFIED:\n               default:\n                 LOG.info(\"Block analysis status:{} for the file path:{}.\"\n                     + \" So, Cleaning up the Xattrs.\", status.status,\n                     fileStatus.getPath());\n                 storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n                 break;\n               }\n             }\n           }\n         } else {\n           LOG.info(\"Namenode is in safemode. It will retry again.\");\n           Thread.sleep(3000);\n         }\n         int numLiveDn \u003d ctxt.getNumLiveDataNodes();\n         if (storageMovementNeeded.size() \u003d\u003d 0\n             || blockCount \u003e (numLiveDn * spsWorkMultiplier)) {\n           Thread.sleep(3000);\n           blockCount \u003d 0L;\n         }\n+        if (retryItem) {\n+          itemInfo.increRetryCount();\n+          this.storageMovementNeeded.add(itemInfo);\n+        }\n       } catch (IOException e) {\n         LOG.error(\"Exception during StoragePolicySatisfier execution - \"\n             + \"will continue next cycle\", e);\n       } catch (Throwable t) {\n         synchronized (this) {\n           if (isRunning) {\n             isRunning \u003d false;\n             if (t instanceof InterruptedException) {\n               LOG.info(\"Stopping StoragePolicySatisfier.\", t);\n             } else {\n               LOG.error(\"StoragePolicySatisfier thread received \"\n                   + \"runtime exception.\", t);\n             }\n             // Stopping monitor thread and clearing queues as well\n             this.clearQueues();\n             this.storageMovementsMonitor.stopGracefully();\n           }\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run() {\n    while (isRunning) {\n      // Check if dependent service is running\n      if (!ctxt.isRunning()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Upstream service is down, skipping the sps work.\");\n        }\n        continue;\n      }\n      try {\n        ItemInfo\u003cT\u003e itemInfo \u003d null;\n        boolean retryItem \u003d false;\n        if (!ctxt.isInSafeMode()) {\n          itemInfo \u003d storageMovementNeeded.get();\n          if (itemInfo !\u003d null) {\n            if(itemInfo.getRetryCount() \u003e\u003d blockMovementMaxRetry){\n              LOG.info(\"Failed to satisfy the policy after \"\n                  + blockMovementMaxRetry + \" retries. Removing inode \"\n                  + itemInfo.getFile() + \" from the queue\");\n              storageMovementNeeded.removeItemTrackInfo(itemInfo, false);\n              continue;\n            }\n            T trackId \u003d itemInfo.getFile();\n            BlocksMovingAnalysis status \u003d null;\n            DatanodeStorageReport[] liveDnReports;\n            BlockStoragePolicy existingStoragePolicy;\n            // TODO: presently, context internally acquire the lock\n            // and returns the result. Need to discuss to move the lock outside?\n            HdfsFileStatus fileStatus \u003d ctxt.getFileInfo(trackId);\n            // Check path existence.\n            if (fileStatus \u003d\u003d null || fileStatus.isDir()) {\n              // File doesn\u0027t exists (maybe got deleted) or its a directory,\n              // just remove trackId from the queue\n              storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n            } else {\n              liveDnReports \u003d ctxt.getLiveDatanodeStorageReport();\n              byte existingStoragePolicyID \u003d fileStatus.getStoragePolicy();\n              existingStoragePolicy \u003d ctxt\n                  .getStoragePolicy(existingStoragePolicyID);\n\n              HdfsLocatedFileStatus file \u003d (HdfsLocatedFileStatus) fileStatus;\n              status \u003d analyseBlocksStorageMovementsAndAssignToDN(file,\n                  existingStoragePolicy, liveDnReports);\n              switch (status.status) {\n              // Just add to monitor, so it will be retried after timeout\n              case ANALYSIS_SKIPPED_FOR_RETRY:\n                // Just add to monitor, so it will be tracked for report and\n                // be removed on storage movement attempt finished report.\n              case BLOCKS_TARGETS_PAIRED:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Block analysis status:{} for the file path:{}.\"\n                      + \" Adding to attempt monitor queue for the storage \"\n                      + \"movement attempt finished report\",\n                      status.status, fileStatus.getPath());\n                }\n                this.storageMovementsMonitor.add(new AttemptedItemInfo\u003cT\u003e(\n                    itemInfo.getStartPath(), itemInfo.getFile(), monotonicNow(),\n                    status.assignedBlocks, itemInfo.getRetryCount()));\n                break;\n              case NO_BLOCKS_TARGETS_PAIRED:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID:{} for the file path:{} back to\"\n                      + \" retry queue as none of the blocks found its eligible\"\n                      + \" targets.\", trackId, fileStatus.getPath());\n                }\n                retryItem \u003d true;\n                break;\n              case FEW_LOW_REDUNDANCY_BLOCKS:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID:{} for the file path:{} back to \"\n                      + \"retry queue as some of the blocks are low redundant.\",\n                      trackId, fileStatus.getPath());\n                }\n                retryItem \u003d true;\n                break;\n              case BLOCKS_FAILED_TO_MOVE:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID:{} for the file path:{} back to \"\n                      + \"retry queue as some of the blocks movement failed.\",\n                      trackId, fileStatus.getPath());\n                }\n                retryItem \u003d true;\n                break;\n              // Just clean Xattrs\n              case BLOCKS_TARGET_PAIRING_SKIPPED:\n              case BLOCKS_ALREADY_SATISFIED:\n              default:\n                LOG.info(\"Block analysis status:{} for the file path:{}.\"\n                    + \" So, Cleaning up the Xattrs.\", status.status,\n                    fileStatus.getPath());\n                storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n                break;\n              }\n            }\n          }\n        } else {\n          LOG.info(\"Namenode is in safemode. It will retry again.\");\n          Thread.sleep(3000);\n        }\n        int numLiveDn \u003d ctxt.getNumLiveDataNodes();\n        if (storageMovementNeeded.size() \u003d\u003d 0\n            || blockCount \u003e (numLiveDn * spsWorkMultiplier)) {\n          Thread.sleep(3000);\n          blockCount \u003d 0L;\n        }\n        if (retryItem) {\n          itemInfo.increRetryCount();\n          this.storageMovementNeeded.add(itemInfo);\n        }\n      } catch (IOException e) {\n        LOG.error(\"Exception during StoragePolicySatisfier execution - \"\n            + \"will continue next cycle\", e);\n      } catch (Throwable t) {\n        synchronized (this) {\n          if (isRunning) {\n            isRunning \u003d false;\n            if (t instanceof InterruptedException) {\n              LOG.info(\"Stopping StoragePolicySatisfier.\", t);\n            } else {\n              LOG.error(\"StoragePolicySatisfier thread received \"\n                  + \"runtime exception.\", t);\n            }\n            // Stopping monitor thread and clearing queues as well\n            this.clearQueues();\n            this.storageMovementsMonitor.stopGracefully();\n          }\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java",
      "extendedDetails": {}
    },
    "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13097: [SPS]: Fix the branch review comments(Part1). Contributed by Surendra Singh.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "d3de4fb2a084cbadab8ef91f11aa7732d3b0f308",
      "commitAuthorOld": "Surendra Singh Lilhore",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,112 +1,128 @@\n   public void run() {\n     while (isRunning) {\n       // Check if dependent service is running\n       if (!ctxt.isRunning()) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Upstream service is down, skipping the sps work.\");\n         }\n         continue;\n       }\n       try {\n         if (!ctxt.isInSafeMode()) {\n           ItemInfo itemInfo \u003d storageMovementNeeded.get();\n           if (itemInfo !\u003d null) {\n             if(itemInfo.getRetryCount() \u003e\u003d blockMovementMaxRetry){\n               LOG.info(\"Failed to satisfy the policy after \"\n                   + blockMovementMaxRetry + \" retries. Removing inode \"\n                   + itemInfo.getFileId() + \" from the queue\");\n               storageMovementNeeded.removeItemTrackInfo(itemInfo, false);\n               continue;\n             }\n             long trackId \u003d itemInfo.getFileId();\n             BlocksMovingAnalysis status \u003d null;\n             DatanodeStorageReport[] liveDnReports;\n             BlockStoragePolicy existingStoragePolicy;\n             // TODO: presently, context internally acquire the lock\n             // and returns the result. Need to discuss to move the lock outside?\n             boolean hasLowRedundancyBlocks \u003d ctxt\n                 .hasLowRedundancyBlocks(trackId);\n             HdfsFileStatus fileStatus \u003d ctxt.getFileInfo(trackId);\n             // Check path existence.\n             if (fileStatus \u003d\u003d null || fileStatus.isDir()) {\n               // File doesn\u0027t exists (maybe got deleted) or its a directory,\n               // just remove trackId from the queue\n               storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n             } else {\n               liveDnReports \u003d ctxt.getLiveDatanodeStorageReport();\n               byte existingStoragePolicyID \u003d fileStatus.getStoragePolicy();\n               existingStoragePolicy \u003d ctxt\n                   .getStoragePolicy(existingStoragePolicyID);\n \n               HdfsLocatedFileStatus file \u003d (HdfsLocatedFileStatus) fileStatus;\n               status \u003d analyseBlocksStorageMovementsAndAssignToDN(file,\n                   hasLowRedundancyBlocks, existingStoragePolicy, liveDnReports);\n               switch (status.status) {\n               // Just add to monitor, so it will be retried after timeout\n               case ANALYSIS_SKIPPED_FOR_RETRY:\n                 // Just add to monitor, so it will be tracked for report and\n                 // be removed on storage movement attempt finished report.\n               case BLOCKS_TARGETS_PAIRED:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Block analysis status:{} for the file path:{}.\"\n                       + \" Adding to attempt monitor queue for the storage \"\n                       + \"movement attempt finished report\",\n                       status.status, fileStatus.getPath());\n                 }\n                 this.storageMovementsMonitor.add(new AttemptedItemInfo(itemInfo\n                     .getStartId(), itemInfo.getFileId(), monotonicNow(),\n                     status.assignedBlocks, itemInfo.getRetryCount()));\n                 break;\n               case NO_BLOCKS_TARGETS_PAIRED:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Adding trackID:{} for the file path:{} back to\"\n                       + \" retry queue as none of the blocks found its eligible\"\n                       + \" targets.\", trackId, fileStatus.getPath());\n                 }\n                 itemInfo.increRetryCount();\n                 this.storageMovementNeeded.add(itemInfo);\n                 break;\n               case FEW_LOW_REDUNDANCY_BLOCKS:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Adding trackID:{} for the file path:{} back to \"\n                       + \"retry queue as some of the blocks are low redundant.\",\n                       trackId, fileStatus.getPath());\n                 }\n                 itemInfo.increRetryCount();\n                 this.storageMovementNeeded.add(itemInfo);\n                 break;\n               case BLOCKS_FAILED_TO_MOVE:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Adding trackID:{} for the file path:{} back to \"\n                       + \"retry queue as some of the blocks movement failed.\",\n                       trackId, fileStatus.getPath());\n                 }\n                 this.storageMovementNeeded.add(itemInfo);\n                 break;\n               // Just clean Xattrs\n               case BLOCKS_TARGET_PAIRING_SKIPPED:\n               case BLOCKS_ALREADY_SATISFIED:\n               default:\n                 LOG.info(\"Block analysis status:{} for the file path:{}.\"\n                     + \" So, Cleaning up the Xattrs.\", status.status,\n                     fileStatus.getPath());\n                 storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n                 break;\n               }\n             }\n           }\n         } else {\n           LOG.info(\"Namenode is in safemode. It will retry again.\");\n           Thread.sleep(3000);\n         }\n         int numLiveDn \u003d ctxt.getNumLiveDataNodes();\n         if (storageMovementNeeded.size() \u003d\u003d 0\n             || blockCount \u003e (numLiveDn * spsWorkMultiplier)) {\n           Thread.sleep(3000);\n           blockCount \u003d 0L;\n         }\n+      } catch (IOException e) {\n+        LOG.error(\"Exception during StoragePolicySatisfier execution - \"\n+            + \"will continue next cycle\", e);\n       } catch (Throwable t) {\n-        handleException(t);\n+        synchronized (this) {\n+          if (isRunning) {\n+            isRunning \u003d false;\n+            if (t instanceof InterruptedException) {\n+              LOG.info(\"Stopping StoragePolicySatisfier.\", t);\n+            } else {\n+              LOG.error(\"StoragePolicySatisfier thread received \"\n+                  + \"runtime exception.\", t);\n+            }\n+            // Stopping monitor thread and clearing queues as well\n+            this.clearQueues();\n+            this.storageMovementsMonitor.stopGracefully();\n+          }\n+        }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run() {\n    while (isRunning) {\n      // Check if dependent service is running\n      if (!ctxt.isRunning()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Upstream service is down, skipping the sps work.\");\n        }\n        continue;\n      }\n      try {\n        if (!ctxt.isInSafeMode()) {\n          ItemInfo itemInfo \u003d storageMovementNeeded.get();\n          if (itemInfo !\u003d null) {\n            if(itemInfo.getRetryCount() \u003e\u003d blockMovementMaxRetry){\n              LOG.info(\"Failed to satisfy the policy after \"\n                  + blockMovementMaxRetry + \" retries. Removing inode \"\n                  + itemInfo.getFileId() + \" from the queue\");\n              storageMovementNeeded.removeItemTrackInfo(itemInfo, false);\n              continue;\n            }\n            long trackId \u003d itemInfo.getFileId();\n            BlocksMovingAnalysis status \u003d null;\n            DatanodeStorageReport[] liveDnReports;\n            BlockStoragePolicy existingStoragePolicy;\n            // TODO: presently, context internally acquire the lock\n            // and returns the result. Need to discuss to move the lock outside?\n            boolean hasLowRedundancyBlocks \u003d ctxt\n                .hasLowRedundancyBlocks(trackId);\n            HdfsFileStatus fileStatus \u003d ctxt.getFileInfo(trackId);\n            // Check path existence.\n            if (fileStatus \u003d\u003d null || fileStatus.isDir()) {\n              // File doesn\u0027t exists (maybe got deleted) or its a directory,\n              // just remove trackId from the queue\n              storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n            } else {\n              liveDnReports \u003d ctxt.getLiveDatanodeStorageReport();\n              byte existingStoragePolicyID \u003d fileStatus.getStoragePolicy();\n              existingStoragePolicy \u003d ctxt\n                  .getStoragePolicy(existingStoragePolicyID);\n\n              HdfsLocatedFileStatus file \u003d (HdfsLocatedFileStatus) fileStatus;\n              status \u003d analyseBlocksStorageMovementsAndAssignToDN(file,\n                  hasLowRedundancyBlocks, existingStoragePolicy, liveDnReports);\n              switch (status.status) {\n              // Just add to monitor, so it will be retried after timeout\n              case ANALYSIS_SKIPPED_FOR_RETRY:\n                // Just add to monitor, so it will be tracked for report and\n                // be removed on storage movement attempt finished report.\n              case BLOCKS_TARGETS_PAIRED:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Block analysis status:{} for the file path:{}.\"\n                      + \" Adding to attempt monitor queue for the storage \"\n                      + \"movement attempt finished report\",\n                      status.status, fileStatus.getPath());\n                }\n                this.storageMovementsMonitor.add(new AttemptedItemInfo(itemInfo\n                    .getStartId(), itemInfo.getFileId(), monotonicNow(),\n                    status.assignedBlocks, itemInfo.getRetryCount()));\n                break;\n              case NO_BLOCKS_TARGETS_PAIRED:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID:{} for the file path:{} back to\"\n                      + \" retry queue as none of the blocks found its eligible\"\n                      + \" targets.\", trackId, fileStatus.getPath());\n                }\n                itemInfo.increRetryCount();\n                this.storageMovementNeeded.add(itemInfo);\n                break;\n              case FEW_LOW_REDUNDANCY_BLOCKS:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID:{} for the file path:{} back to \"\n                      + \"retry queue as some of the blocks are low redundant.\",\n                      trackId, fileStatus.getPath());\n                }\n                itemInfo.increRetryCount();\n                this.storageMovementNeeded.add(itemInfo);\n                break;\n              case BLOCKS_FAILED_TO_MOVE:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID:{} for the file path:{} back to \"\n                      + \"retry queue as some of the blocks movement failed.\",\n                      trackId, fileStatus.getPath());\n                }\n                this.storageMovementNeeded.add(itemInfo);\n                break;\n              // Just clean Xattrs\n              case BLOCKS_TARGET_PAIRING_SKIPPED:\n              case BLOCKS_ALREADY_SATISFIED:\n              default:\n                LOG.info(\"Block analysis status:{} for the file path:{}.\"\n                    + \" So, Cleaning up the Xattrs.\", status.status,\n                    fileStatus.getPath());\n                storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n                break;\n              }\n            }\n          }\n        } else {\n          LOG.info(\"Namenode is in safemode. It will retry again.\");\n          Thread.sleep(3000);\n        }\n        int numLiveDn \u003d ctxt.getNumLiveDataNodes();\n        if (storageMovementNeeded.size() \u003d\u003d 0\n            || blockCount \u003e (numLiveDn * spsWorkMultiplier)) {\n          Thread.sleep(3000);\n          blockCount \u003d 0L;\n        }\n      } catch (IOException e) {\n        LOG.error(\"Exception during StoragePolicySatisfier execution - \"\n            + \"will continue next cycle\", e);\n      } catch (Throwable t) {\n        synchronized (this) {\n          if (isRunning) {\n            isRunning \u003d false;\n            if (t instanceof InterruptedException) {\n              LOG.info(\"Stopping StoragePolicySatisfier.\", t);\n            } else {\n              LOG.error(\"StoragePolicySatisfier thread received \"\n                  + \"runtime exception.\", t);\n            }\n            // Stopping monitor thread and clearing queues as well\n            this.clearQueues();\n            this.storageMovementsMonitor.stopGracefully();\n          }\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java",
      "extendedDetails": {}
    },
    "5845c36c16c423107183287cce3be9357dad7564": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13050: [SPS]: Create start/stop script to start external SPS process. Contributed by Surendra Singh Lilhore.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "5845c36c16c423107183287cce3be9357dad7564",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "99594b48b8e040ab5a0939d7c3dbcfb34400e6fc",
      "commitAuthorOld": "Surendra Singh Lilhore",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,98 +1,112 @@\n   public void run() {\n-    while (ctxt.isRunning()) {\n+    while (isRunning) {\n+      // Check if dependent service is running\n+      if (!ctxt.isRunning()) {\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"Upstream service is down, skipping the sps work.\");\n+        }\n+        continue;\n+      }\n       try {\n         if (!ctxt.isInSafeMode()) {\n           ItemInfo itemInfo \u003d storageMovementNeeded.get();\n           if (itemInfo !\u003d null) {\n             if(itemInfo.getRetryCount() \u003e\u003d blockMovementMaxRetry){\n               LOG.info(\"Failed to satisfy the policy after \"\n                   + blockMovementMaxRetry + \" retries. Removing inode \"\n                   + itemInfo.getFileId() + \" from the queue\");\n               storageMovementNeeded.removeItemTrackInfo(itemInfo, false);\n               continue;\n             }\n             long trackId \u003d itemInfo.getFileId();\n             BlocksMovingAnalysis status \u003d null;\n             DatanodeStorageReport[] liveDnReports;\n             BlockStoragePolicy existingStoragePolicy;\n             // TODO: presently, context internally acquire the lock\n             // and returns the result. Need to discuss to move the lock outside?\n             boolean hasLowRedundancyBlocks \u003d ctxt\n                 .hasLowRedundancyBlocks(trackId);\n             HdfsFileStatus fileStatus \u003d ctxt.getFileInfo(trackId);\n             // Check path existence.\n             if (fileStatus \u003d\u003d null || fileStatus.isDir()) {\n               // File doesn\u0027t exists (maybe got deleted) or its a directory,\n               // just remove trackId from the queue\n               storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n             } else {\n               liveDnReports \u003d ctxt.getLiveDatanodeStorageReport();\n               byte existingStoragePolicyID \u003d fileStatus.getStoragePolicy();\n               existingStoragePolicy \u003d ctxt\n                   .getStoragePolicy(existingStoragePolicyID);\n \n               HdfsLocatedFileStatus file \u003d (HdfsLocatedFileStatus) fileStatus;\n               status \u003d analyseBlocksStorageMovementsAndAssignToDN(file,\n                   hasLowRedundancyBlocks, existingStoragePolicy, liveDnReports);\n               switch (status.status) {\n               // Just add to monitor, so it will be retried after timeout\n               case ANALYSIS_SKIPPED_FOR_RETRY:\n                 // Just add to monitor, so it will be tracked for report and\n                 // be removed on storage movement attempt finished report.\n               case BLOCKS_TARGETS_PAIRED:\n+                if (LOG.isDebugEnabled()) {\n+                  LOG.debug(\"Block analysis status:{} for the file path:{}.\"\n+                      + \" Adding to attempt monitor queue for the storage \"\n+                      + \"movement attempt finished report\",\n+                      status.status, fileStatus.getPath());\n+                }\n                 this.storageMovementsMonitor.add(new AttemptedItemInfo(itemInfo\n                     .getStartId(), itemInfo.getFileId(), monotonicNow(),\n                     status.assignedBlocks, itemInfo.getRetryCount()));\n                 break;\n               case NO_BLOCKS_TARGETS_PAIRED:\n                 if (LOG.isDebugEnabled()) {\n-                  LOG.debug(\"Adding trackID \" + trackId\n-                      + \" back to retry queue as none of the blocks\"\n-                      + \" found its eligible targets.\");\n+                  LOG.debug(\"Adding trackID:{} for the file path:{} back to\"\n+                      + \" retry queue as none of the blocks found its eligible\"\n+                      + \" targets.\", trackId, fileStatus.getPath());\n                 }\n                 itemInfo.increRetryCount();\n                 this.storageMovementNeeded.add(itemInfo);\n                 break;\n               case FEW_LOW_REDUNDANCY_BLOCKS:\n                 if (LOG.isDebugEnabled()) {\n-                  LOG.debug(\"Adding trackID \" + trackId\n-                      + \" back to retry queue as some of the blocks\"\n-                      + \" are low redundant.\");\n+                  LOG.debug(\"Adding trackID:{} for the file path:{} back to \"\n+                      + \"retry queue as some of the blocks are low redundant.\",\n+                      trackId, fileStatus.getPath());\n                 }\n                 itemInfo.increRetryCount();\n                 this.storageMovementNeeded.add(itemInfo);\n                 break;\n               case BLOCKS_FAILED_TO_MOVE:\n                 if (LOG.isDebugEnabled()) {\n-                  LOG.debug(\"Adding trackID \" + trackId\n-                      + \" back to retry queue as some of the blocks\"\n-                      + \" movement failed.\");\n+                  LOG.debug(\"Adding trackID:{} for the file path:{} back to \"\n+                      + \"retry queue as some of the blocks movement failed.\",\n+                      trackId, fileStatus.getPath());\n                 }\n                 this.storageMovementNeeded.add(itemInfo);\n                 break;\n               // Just clean Xattrs\n               case BLOCKS_TARGET_PAIRING_SKIPPED:\n               case BLOCKS_ALREADY_SATISFIED:\n               default:\n-                LOG.info(\"Block analysis skipped or blocks already satisfied\"\n-                    + \" with storages. So, Cleaning up the Xattrs.\");\n+                LOG.info(\"Block analysis status:{} for the file path:{}.\"\n+                    + \" So, Cleaning up the Xattrs.\", status.status,\n+                    fileStatus.getPath());\n                 storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n                 break;\n               }\n             }\n           }\n         } else {\n           LOG.info(\"Namenode is in safemode. It will retry again.\");\n           Thread.sleep(3000);\n         }\n         int numLiveDn \u003d ctxt.getNumLiveDataNodes();\n         if (storageMovementNeeded.size() \u003d\u003d 0\n             || blockCount \u003e (numLiveDn * spsWorkMultiplier)) {\n           Thread.sleep(3000);\n           blockCount \u003d 0L;\n         }\n       } catch (Throwable t) {\n         handleException(t);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run() {\n    while (isRunning) {\n      // Check if dependent service is running\n      if (!ctxt.isRunning()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Upstream service is down, skipping the sps work.\");\n        }\n        continue;\n      }\n      try {\n        if (!ctxt.isInSafeMode()) {\n          ItemInfo itemInfo \u003d storageMovementNeeded.get();\n          if (itemInfo !\u003d null) {\n            if(itemInfo.getRetryCount() \u003e\u003d blockMovementMaxRetry){\n              LOG.info(\"Failed to satisfy the policy after \"\n                  + blockMovementMaxRetry + \" retries. Removing inode \"\n                  + itemInfo.getFileId() + \" from the queue\");\n              storageMovementNeeded.removeItemTrackInfo(itemInfo, false);\n              continue;\n            }\n            long trackId \u003d itemInfo.getFileId();\n            BlocksMovingAnalysis status \u003d null;\n            DatanodeStorageReport[] liveDnReports;\n            BlockStoragePolicy existingStoragePolicy;\n            // TODO: presently, context internally acquire the lock\n            // and returns the result. Need to discuss to move the lock outside?\n            boolean hasLowRedundancyBlocks \u003d ctxt\n                .hasLowRedundancyBlocks(trackId);\n            HdfsFileStatus fileStatus \u003d ctxt.getFileInfo(trackId);\n            // Check path existence.\n            if (fileStatus \u003d\u003d null || fileStatus.isDir()) {\n              // File doesn\u0027t exists (maybe got deleted) or its a directory,\n              // just remove trackId from the queue\n              storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n            } else {\n              liveDnReports \u003d ctxt.getLiveDatanodeStorageReport();\n              byte existingStoragePolicyID \u003d fileStatus.getStoragePolicy();\n              existingStoragePolicy \u003d ctxt\n                  .getStoragePolicy(existingStoragePolicyID);\n\n              HdfsLocatedFileStatus file \u003d (HdfsLocatedFileStatus) fileStatus;\n              status \u003d analyseBlocksStorageMovementsAndAssignToDN(file,\n                  hasLowRedundancyBlocks, existingStoragePolicy, liveDnReports);\n              switch (status.status) {\n              // Just add to monitor, so it will be retried after timeout\n              case ANALYSIS_SKIPPED_FOR_RETRY:\n                // Just add to monitor, so it will be tracked for report and\n                // be removed on storage movement attempt finished report.\n              case BLOCKS_TARGETS_PAIRED:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Block analysis status:{} for the file path:{}.\"\n                      + \" Adding to attempt monitor queue for the storage \"\n                      + \"movement attempt finished report\",\n                      status.status, fileStatus.getPath());\n                }\n                this.storageMovementsMonitor.add(new AttemptedItemInfo(itemInfo\n                    .getStartId(), itemInfo.getFileId(), monotonicNow(),\n                    status.assignedBlocks, itemInfo.getRetryCount()));\n                break;\n              case NO_BLOCKS_TARGETS_PAIRED:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID:{} for the file path:{} back to\"\n                      + \" retry queue as none of the blocks found its eligible\"\n                      + \" targets.\", trackId, fileStatus.getPath());\n                }\n                itemInfo.increRetryCount();\n                this.storageMovementNeeded.add(itemInfo);\n                break;\n              case FEW_LOW_REDUNDANCY_BLOCKS:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID:{} for the file path:{} back to \"\n                      + \"retry queue as some of the blocks are low redundant.\",\n                      trackId, fileStatus.getPath());\n                }\n                itemInfo.increRetryCount();\n                this.storageMovementNeeded.add(itemInfo);\n                break;\n              case BLOCKS_FAILED_TO_MOVE:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID:{} for the file path:{} back to \"\n                      + \"retry queue as some of the blocks movement failed.\",\n                      trackId, fileStatus.getPath());\n                }\n                this.storageMovementNeeded.add(itemInfo);\n                break;\n              // Just clean Xattrs\n              case BLOCKS_TARGET_PAIRING_SKIPPED:\n              case BLOCKS_ALREADY_SATISFIED:\n              default:\n                LOG.info(\"Block analysis status:{} for the file path:{}.\"\n                    + \" So, Cleaning up the Xattrs.\", status.status,\n                    fileStatus.getPath());\n                storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n                break;\n              }\n            }\n          }\n        } else {\n          LOG.info(\"Namenode is in safemode. It will retry again.\");\n          Thread.sleep(3000);\n        }\n        int numLiveDn \u003d ctxt.getNumLiveDataNodes();\n        if (storageMovementNeeded.size() \u003d\u003d 0\n            || blockCount \u003e (numLiveDn * spsWorkMultiplier)) {\n          Thread.sleep(3000);\n          blockCount \u003d 0L;\n        }\n      } catch (Throwable t) {\n        handleException(t);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java",
      "extendedDetails": {}
    },
    "99594b48b8e040ab5a0939d7c3dbcfb34400e6fc": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13075. [SPS]: Provide External Context implementation. Contributed by Uma Maheswara Rao G.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "99594b48b8e040ab5a0939d7c3dbcfb34400e6fc",
      "commitAuthor": "Surendra Singh Lilhore",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "3b83110d5ed582b9f913ecf3f62ce410535f8fca",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,95 +1,98 @@\n   public void run() {\n     while (ctxt.isRunning()) {\n       try {\n         if (!ctxt.isInSafeMode()) {\n           ItemInfo itemInfo \u003d storageMovementNeeded.get();\n           if (itemInfo !\u003d null) {\n             if(itemInfo.getRetryCount() \u003e\u003d blockMovementMaxRetry){\n               LOG.info(\"Failed to satisfy the policy after \"\n                   + blockMovementMaxRetry + \" retries. Removing inode \"\n                   + itemInfo.getFileId() + \" from the queue\");\n               storageMovementNeeded.removeItemTrackInfo(itemInfo, false);\n               continue;\n             }\n             long trackId \u003d itemInfo.getFileId();\n             BlocksMovingAnalysis status \u003d null;\n             DatanodeStorageReport[] liveDnReports;\n             BlockStoragePolicy existingStoragePolicy;\n             // TODO: presently, context internally acquire the lock\n             // and returns the result. Need to discuss to move the lock outside?\n             boolean hasLowRedundancyBlocks \u003d ctxt\n                 .hasLowRedundancyBlocks(trackId);\n             HdfsFileStatus fileStatus \u003d ctxt.getFileInfo(trackId);\n             // Check path existence.\n             if (fileStatus \u003d\u003d null || fileStatus.isDir()) {\n               // File doesn\u0027t exists (maybe got deleted) or its a directory,\n               // just remove trackId from the queue\n               storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n             } else {\n               liveDnReports \u003d ctxt.getLiveDatanodeStorageReport();\n               byte existingStoragePolicyID \u003d fileStatus.getStoragePolicy();\n               existingStoragePolicy \u003d ctxt\n                   .getStoragePolicy(existingStoragePolicyID);\n \n               HdfsLocatedFileStatus file \u003d (HdfsLocatedFileStatus) fileStatus;\n               status \u003d analyseBlocksStorageMovementsAndAssignToDN(file,\n                   hasLowRedundancyBlocks, existingStoragePolicy, liveDnReports);\n               switch (status.status) {\n               // Just add to monitor, so it will be retried after timeout\n               case ANALYSIS_SKIPPED_FOR_RETRY:\n                 // Just add to monitor, so it will be tracked for report and\n                 // be removed on storage movement attempt finished report.\n               case BLOCKS_TARGETS_PAIRED:\n                 this.storageMovementsMonitor.add(new AttemptedItemInfo(itemInfo\n                     .getStartId(), itemInfo.getFileId(), monotonicNow(),\n                     status.assignedBlocks, itemInfo.getRetryCount()));\n                 break;\n               case NO_BLOCKS_TARGETS_PAIRED:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Adding trackID \" + trackId\n                       + \" back to retry queue as none of the blocks\"\n                       + \" found its eligible targets.\");\n                 }\n                 itemInfo.increRetryCount();\n                 this.storageMovementNeeded.add(itemInfo);\n                 break;\n               case FEW_LOW_REDUNDANCY_BLOCKS:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Adding trackID \" + trackId\n                       + \" back to retry queue as some of the blocks\"\n                       + \" are low redundant.\");\n                 }\n                 itemInfo.increRetryCount();\n                 this.storageMovementNeeded.add(itemInfo);\n                 break;\n               case BLOCKS_FAILED_TO_MOVE:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Adding trackID \" + trackId\n                       + \" back to retry queue as some of the blocks\"\n                       + \" movement failed.\");\n                 }\n                 this.storageMovementNeeded.add(itemInfo);\n                 break;\n               // Just clean Xattrs\n               case BLOCKS_TARGET_PAIRING_SKIPPED:\n               case BLOCKS_ALREADY_SATISFIED:\n               default:\n                 LOG.info(\"Block analysis skipped or blocks already satisfied\"\n                     + \" with storages. So, Cleaning up the Xattrs.\");\n                 storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n                 break;\n               }\n             }\n           }\n+        } else {\n+          LOG.info(\"Namenode is in safemode. It will retry again.\");\n+          Thread.sleep(3000);\n         }\n         int numLiveDn \u003d ctxt.getNumLiveDataNodes();\n         if (storageMovementNeeded.size() \u003d\u003d 0\n             || blockCount \u003e (numLiveDn * spsWorkMultiplier)) {\n           Thread.sleep(3000);\n           blockCount \u003d 0L;\n         }\n       } catch (Throwable t) {\n         handleException(t);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run() {\n    while (ctxt.isRunning()) {\n      try {\n        if (!ctxt.isInSafeMode()) {\n          ItemInfo itemInfo \u003d storageMovementNeeded.get();\n          if (itemInfo !\u003d null) {\n            if(itemInfo.getRetryCount() \u003e\u003d blockMovementMaxRetry){\n              LOG.info(\"Failed to satisfy the policy after \"\n                  + blockMovementMaxRetry + \" retries. Removing inode \"\n                  + itemInfo.getFileId() + \" from the queue\");\n              storageMovementNeeded.removeItemTrackInfo(itemInfo, false);\n              continue;\n            }\n            long trackId \u003d itemInfo.getFileId();\n            BlocksMovingAnalysis status \u003d null;\n            DatanodeStorageReport[] liveDnReports;\n            BlockStoragePolicy existingStoragePolicy;\n            // TODO: presently, context internally acquire the lock\n            // and returns the result. Need to discuss to move the lock outside?\n            boolean hasLowRedundancyBlocks \u003d ctxt\n                .hasLowRedundancyBlocks(trackId);\n            HdfsFileStatus fileStatus \u003d ctxt.getFileInfo(trackId);\n            // Check path existence.\n            if (fileStatus \u003d\u003d null || fileStatus.isDir()) {\n              // File doesn\u0027t exists (maybe got deleted) or its a directory,\n              // just remove trackId from the queue\n              storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n            } else {\n              liveDnReports \u003d ctxt.getLiveDatanodeStorageReport();\n              byte existingStoragePolicyID \u003d fileStatus.getStoragePolicy();\n              existingStoragePolicy \u003d ctxt\n                  .getStoragePolicy(existingStoragePolicyID);\n\n              HdfsLocatedFileStatus file \u003d (HdfsLocatedFileStatus) fileStatus;\n              status \u003d analyseBlocksStorageMovementsAndAssignToDN(file,\n                  hasLowRedundancyBlocks, existingStoragePolicy, liveDnReports);\n              switch (status.status) {\n              // Just add to monitor, so it will be retried after timeout\n              case ANALYSIS_SKIPPED_FOR_RETRY:\n                // Just add to monitor, so it will be tracked for report and\n                // be removed on storage movement attempt finished report.\n              case BLOCKS_TARGETS_PAIRED:\n                this.storageMovementsMonitor.add(new AttemptedItemInfo(itemInfo\n                    .getStartId(), itemInfo.getFileId(), monotonicNow(),\n                    status.assignedBlocks, itemInfo.getRetryCount()));\n                break;\n              case NO_BLOCKS_TARGETS_PAIRED:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID \" + trackId\n                      + \" back to retry queue as none of the blocks\"\n                      + \" found its eligible targets.\");\n                }\n                itemInfo.increRetryCount();\n                this.storageMovementNeeded.add(itemInfo);\n                break;\n              case FEW_LOW_REDUNDANCY_BLOCKS:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID \" + trackId\n                      + \" back to retry queue as some of the blocks\"\n                      + \" are low redundant.\");\n                }\n                itemInfo.increRetryCount();\n                this.storageMovementNeeded.add(itemInfo);\n                break;\n              case BLOCKS_FAILED_TO_MOVE:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID \" + trackId\n                      + \" back to retry queue as some of the blocks\"\n                      + \" movement failed.\");\n                }\n                this.storageMovementNeeded.add(itemInfo);\n                break;\n              // Just clean Xattrs\n              case BLOCKS_TARGET_PAIRING_SKIPPED:\n              case BLOCKS_ALREADY_SATISFIED:\n              default:\n                LOG.info(\"Block analysis skipped or blocks already satisfied\"\n                    + \" with storages. So, Cleaning up the Xattrs.\");\n                storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n                break;\n              }\n            }\n          }\n        } else {\n          LOG.info(\"Namenode is in safemode. It will retry again.\");\n          Thread.sleep(3000);\n        }\n        int numLiveDn \u003d ctxt.getNumLiveDataNodes();\n        if (storageMovementNeeded.size() \u003d\u003d 0\n            || blockCount \u003e (numLiveDn * spsWorkMultiplier)) {\n          Thread.sleep(3000);\n          blockCount \u003d 0L;\n        }\n      } catch (Throwable t) {\n        handleException(t);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java",
      "extendedDetails": {}
    },
    "b0cb8d9bb44c963ae686d2b5c1b70bc76b955e10": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13033: [SPS]: Implement a mechanism to do file block movements for external SPS. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "b0cb8d9bb44c963ae686d2b5c1b70bc76b955e10",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "3159b39cf8ef704835325263154fb1a1cecc109d",
      "commitAuthorOld": "Rakesh Radhakrishnan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,94 +1,95 @@\n   public void run() {\n     while (ctxt.isRunning()) {\n       try {\n         if (!ctxt.isInSafeMode()) {\n           ItemInfo itemInfo \u003d storageMovementNeeded.get();\n           if (itemInfo !\u003d null) {\n             if(itemInfo.getRetryCount() \u003e\u003d blockMovementMaxRetry){\n               LOG.info(\"Failed to satisfy the policy after \"\n                   + blockMovementMaxRetry + \" retries. Removing inode \"\n                   + itemInfo.getFileId() + \" from the queue\");\n               storageMovementNeeded.removeItemTrackInfo(itemInfo, false);\n               continue;\n             }\n             long trackId \u003d itemInfo.getFileId();\n             BlocksMovingAnalysis status \u003d null;\n             DatanodeStorageReport[] liveDnReports;\n             BlockStoragePolicy existingStoragePolicy;\n             // TODO: presently, context internally acquire the lock\n             // and returns the result. Need to discuss to move the lock outside?\n             boolean hasLowRedundancyBlocks \u003d ctxt\n                 .hasLowRedundancyBlocks(trackId);\n             HdfsFileStatus fileStatus \u003d ctxt.getFileInfo(trackId);\n             // Check path existence.\n             if (fileStatus \u003d\u003d null || fileStatus.isDir()) {\n               // File doesn\u0027t exists (maybe got deleted) or its a directory,\n               // just remove trackId from the queue\n               storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n             } else {\n               liveDnReports \u003d ctxt.getLiveDatanodeStorageReport();\n               byte existingStoragePolicyID \u003d fileStatus.getStoragePolicy();\n               existingStoragePolicy \u003d ctxt\n                   .getStoragePolicy(existingStoragePolicyID);\n \n               HdfsLocatedFileStatus file \u003d (HdfsLocatedFileStatus) fileStatus;\n               status \u003d analyseBlocksStorageMovementsAndAssignToDN(file,\n                   hasLowRedundancyBlocks, existingStoragePolicy, liveDnReports);\n               switch (status.status) {\n               // Just add to monitor, so it will be retried after timeout\n               case ANALYSIS_SKIPPED_FOR_RETRY:\n                 // Just add to monitor, so it will be tracked for report and\n                 // be removed on storage movement attempt finished report.\n               case BLOCKS_TARGETS_PAIRED:\n                 this.storageMovementsMonitor.add(new AttemptedItemInfo(itemInfo\n                     .getStartId(), itemInfo.getFileId(), monotonicNow(),\n                     status.assignedBlocks, itemInfo.getRetryCount()));\n                 break;\n               case NO_BLOCKS_TARGETS_PAIRED:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Adding trackID \" + trackId\n                       + \" back to retry queue as none of the blocks\"\n                       + \" found its eligible targets.\");\n                 }\n                 itemInfo.increRetryCount();\n                 this.storageMovementNeeded.add(itemInfo);\n                 break;\n               case FEW_LOW_REDUNDANCY_BLOCKS:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Adding trackID \" + trackId\n                       + \" back to retry queue as some of the blocks\"\n                       + \" are low redundant.\");\n                 }\n+                itemInfo.increRetryCount();\n                 this.storageMovementNeeded.add(itemInfo);\n                 break;\n               case BLOCKS_FAILED_TO_MOVE:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Adding trackID \" + trackId\n                       + \" back to retry queue as some of the blocks\"\n                       + \" movement failed.\");\n                 }\n                 this.storageMovementNeeded.add(itemInfo);\n                 break;\n               // Just clean Xattrs\n               case BLOCKS_TARGET_PAIRING_SKIPPED:\n               case BLOCKS_ALREADY_SATISFIED:\n               default:\n                 LOG.info(\"Block analysis skipped or blocks already satisfied\"\n                     + \" with storages. So, Cleaning up the Xattrs.\");\n                 storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n                 break;\n               }\n             }\n           }\n         }\n         int numLiveDn \u003d ctxt.getNumLiveDataNodes();\n         if (storageMovementNeeded.size() \u003d\u003d 0\n             || blockCount \u003e (numLiveDn * spsWorkMultiplier)) {\n           Thread.sleep(3000);\n           blockCount \u003d 0L;\n         }\n       } catch (Throwable t) {\n         handleException(t);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run() {\n    while (ctxt.isRunning()) {\n      try {\n        if (!ctxt.isInSafeMode()) {\n          ItemInfo itemInfo \u003d storageMovementNeeded.get();\n          if (itemInfo !\u003d null) {\n            if(itemInfo.getRetryCount() \u003e\u003d blockMovementMaxRetry){\n              LOG.info(\"Failed to satisfy the policy after \"\n                  + blockMovementMaxRetry + \" retries. Removing inode \"\n                  + itemInfo.getFileId() + \" from the queue\");\n              storageMovementNeeded.removeItemTrackInfo(itemInfo, false);\n              continue;\n            }\n            long trackId \u003d itemInfo.getFileId();\n            BlocksMovingAnalysis status \u003d null;\n            DatanodeStorageReport[] liveDnReports;\n            BlockStoragePolicy existingStoragePolicy;\n            // TODO: presently, context internally acquire the lock\n            // and returns the result. Need to discuss to move the lock outside?\n            boolean hasLowRedundancyBlocks \u003d ctxt\n                .hasLowRedundancyBlocks(trackId);\n            HdfsFileStatus fileStatus \u003d ctxt.getFileInfo(trackId);\n            // Check path existence.\n            if (fileStatus \u003d\u003d null || fileStatus.isDir()) {\n              // File doesn\u0027t exists (maybe got deleted) or its a directory,\n              // just remove trackId from the queue\n              storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n            } else {\n              liveDnReports \u003d ctxt.getLiveDatanodeStorageReport();\n              byte existingStoragePolicyID \u003d fileStatus.getStoragePolicy();\n              existingStoragePolicy \u003d ctxt\n                  .getStoragePolicy(existingStoragePolicyID);\n\n              HdfsLocatedFileStatus file \u003d (HdfsLocatedFileStatus) fileStatus;\n              status \u003d analyseBlocksStorageMovementsAndAssignToDN(file,\n                  hasLowRedundancyBlocks, existingStoragePolicy, liveDnReports);\n              switch (status.status) {\n              // Just add to monitor, so it will be retried after timeout\n              case ANALYSIS_SKIPPED_FOR_RETRY:\n                // Just add to monitor, so it will be tracked for report and\n                // be removed on storage movement attempt finished report.\n              case BLOCKS_TARGETS_PAIRED:\n                this.storageMovementsMonitor.add(new AttemptedItemInfo(itemInfo\n                    .getStartId(), itemInfo.getFileId(), monotonicNow(),\n                    status.assignedBlocks, itemInfo.getRetryCount()));\n                break;\n              case NO_BLOCKS_TARGETS_PAIRED:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID \" + trackId\n                      + \" back to retry queue as none of the blocks\"\n                      + \" found its eligible targets.\");\n                }\n                itemInfo.increRetryCount();\n                this.storageMovementNeeded.add(itemInfo);\n                break;\n              case FEW_LOW_REDUNDANCY_BLOCKS:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID \" + trackId\n                      + \" back to retry queue as some of the blocks\"\n                      + \" are low redundant.\");\n                }\n                itemInfo.increRetryCount();\n                this.storageMovementNeeded.add(itemInfo);\n                break;\n              case BLOCKS_FAILED_TO_MOVE:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID \" + trackId\n                      + \" back to retry queue as some of the blocks\"\n                      + \" movement failed.\");\n                }\n                this.storageMovementNeeded.add(itemInfo);\n                break;\n              // Just clean Xattrs\n              case BLOCKS_TARGET_PAIRING_SKIPPED:\n              case BLOCKS_ALREADY_SATISFIED:\n              default:\n                LOG.info(\"Block analysis skipped or blocks already satisfied\"\n                    + \" with storages. So, Cleaning up the Xattrs.\");\n                storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n                break;\n              }\n            }\n          }\n        }\n        int numLiveDn \u003d ctxt.getNumLiveDataNodes();\n        if (storageMovementNeeded.size() \u003d\u003d 0\n            || blockCount \u003e (numLiveDn * spsWorkMultiplier)) {\n          Thread.sleep(3000);\n          blockCount \u003d 0L;\n        }\n      } catch (Throwable t) {\n        handleException(t);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java",
      "extendedDetails": {}
    },
    "8d4f74e7339abc77dc0daa162d7bd2814bd79b3d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12911. [SPS]: Modularize the SPS code and expose necessary interfaces for external/internal implementations. Contributed by Uma Maheswara Rao G\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "8d4f74e7339abc77dc0daa162d7bd2814bd79b3d",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "05d4daf6ba3e5bd40f46e8003ee12fc7c613453d",
      "commitAuthorOld": "Surendra Singh Lilhore",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,94 +1,94 @@\n   public void run() {\n     while (ctxt.isRunning()) {\n       try {\n         if (!ctxt.isInSafeMode()) {\n           ItemInfo itemInfo \u003d storageMovementNeeded.get();\n           if (itemInfo !\u003d null) {\n             if(itemInfo.getRetryCount() \u003e\u003d blockMovementMaxRetry){\n               LOG.info(\"Failed to satisfy the policy after \"\n                   + blockMovementMaxRetry + \" retries. Removing inode \"\n-                  + itemInfo.getTrackId() + \" from the queue\");\n+                  + itemInfo.getFileId() + \" from the queue\");\n               storageMovementNeeded.removeItemTrackInfo(itemInfo, false);\n               continue;\n             }\n-            long trackId \u003d itemInfo.getTrackId();\n+            long trackId \u003d itemInfo.getFileId();\n             BlocksMovingAnalysis status \u003d null;\n             DatanodeStorageReport[] liveDnReports;\n             BlockStoragePolicy existingStoragePolicy;\n             // TODO: presently, context internally acquire the lock\n             // and returns the result. Need to discuss to move the lock outside?\n             boolean hasLowRedundancyBlocks \u003d ctxt\n                 .hasLowRedundancyBlocks(trackId);\n             HdfsFileStatus fileStatus \u003d ctxt.getFileInfo(trackId);\n             // Check path existence.\n             if (fileStatus \u003d\u003d null || fileStatus.isDir()) {\n               // File doesn\u0027t exists (maybe got deleted) or its a directory,\n               // just remove trackId from the queue\n               storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n             } else {\n               liveDnReports \u003d ctxt.getLiveDatanodeStorageReport();\n               byte existingStoragePolicyID \u003d fileStatus.getStoragePolicy();\n               existingStoragePolicy \u003d ctxt\n                   .getStoragePolicy(existingStoragePolicyID);\n \n               HdfsLocatedFileStatus file \u003d (HdfsLocatedFileStatus) fileStatus;\n               status \u003d analyseBlocksStorageMovementsAndAssignToDN(file,\n                   hasLowRedundancyBlocks, existingStoragePolicy, liveDnReports);\n               switch (status.status) {\n               // Just add to monitor, so it will be retried after timeout\n               case ANALYSIS_SKIPPED_FOR_RETRY:\n                 // Just add to monitor, so it will be tracked for report and\n                 // be removed on storage movement attempt finished report.\n               case BLOCKS_TARGETS_PAIRED:\n                 this.storageMovementsMonitor.add(new AttemptedItemInfo(itemInfo\n-                    .getStartId(), itemInfo.getTrackId(), monotonicNow(),\n+                    .getStartId(), itemInfo.getFileId(), monotonicNow(),\n                     status.assignedBlocks, itemInfo.getRetryCount()));\n                 break;\n               case NO_BLOCKS_TARGETS_PAIRED:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Adding trackID \" + trackId\n                       + \" back to retry queue as none of the blocks\"\n                       + \" found its eligible targets.\");\n                 }\n-                itemInfo.retryCount++;\n+                itemInfo.increRetryCount();\n                 this.storageMovementNeeded.add(itemInfo);\n                 break;\n               case FEW_LOW_REDUNDANCY_BLOCKS:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Adding trackID \" + trackId\n                       + \" back to retry queue as some of the blocks\"\n                       + \" are low redundant.\");\n                 }\n                 this.storageMovementNeeded.add(itemInfo);\n                 break;\n               case BLOCKS_FAILED_TO_MOVE:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Adding trackID \" + trackId\n                       + \" back to retry queue as some of the blocks\"\n                       + \" movement failed.\");\n                 }\n                 this.storageMovementNeeded.add(itemInfo);\n                 break;\n               // Just clean Xattrs\n               case BLOCKS_TARGET_PAIRING_SKIPPED:\n               case BLOCKS_ALREADY_SATISFIED:\n               default:\n                 LOG.info(\"Block analysis skipped or blocks already satisfied\"\n                     + \" with storages. So, Cleaning up the Xattrs.\");\n                 storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n                 break;\n               }\n             }\n           }\n         }\n         int numLiveDn \u003d ctxt.getNumLiveDataNodes();\n         if (storageMovementNeeded.size() \u003d\u003d 0\n             || blockCount \u003e (numLiveDn * spsWorkMultiplier)) {\n           Thread.sleep(3000);\n           blockCount \u003d 0L;\n         }\n       } catch (Throwable t) {\n         handleException(t);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run() {\n    while (ctxt.isRunning()) {\n      try {\n        if (!ctxt.isInSafeMode()) {\n          ItemInfo itemInfo \u003d storageMovementNeeded.get();\n          if (itemInfo !\u003d null) {\n            if(itemInfo.getRetryCount() \u003e\u003d blockMovementMaxRetry){\n              LOG.info(\"Failed to satisfy the policy after \"\n                  + blockMovementMaxRetry + \" retries. Removing inode \"\n                  + itemInfo.getFileId() + \" from the queue\");\n              storageMovementNeeded.removeItemTrackInfo(itemInfo, false);\n              continue;\n            }\n            long trackId \u003d itemInfo.getFileId();\n            BlocksMovingAnalysis status \u003d null;\n            DatanodeStorageReport[] liveDnReports;\n            BlockStoragePolicy existingStoragePolicy;\n            // TODO: presently, context internally acquire the lock\n            // and returns the result. Need to discuss to move the lock outside?\n            boolean hasLowRedundancyBlocks \u003d ctxt\n                .hasLowRedundancyBlocks(trackId);\n            HdfsFileStatus fileStatus \u003d ctxt.getFileInfo(trackId);\n            // Check path existence.\n            if (fileStatus \u003d\u003d null || fileStatus.isDir()) {\n              // File doesn\u0027t exists (maybe got deleted) or its a directory,\n              // just remove trackId from the queue\n              storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n            } else {\n              liveDnReports \u003d ctxt.getLiveDatanodeStorageReport();\n              byte existingStoragePolicyID \u003d fileStatus.getStoragePolicy();\n              existingStoragePolicy \u003d ctxt\n                  .getStoragePolicy(existingStoragePolicyID);\n\n              HdfsLocatedFileStatus file \u003d (HdfsLocatedFileStatus) fileStatus;\n              status \u003d analyseBlocksStorageMovementsAndAssignToDN(file,\n                  hasLowRedundancyBlocks, existingStoragePolicy, liveDnReports);\n              switch (status.status) {\n              // Just add to monitor, so it will be retried after timeout\n              case ANALYSIS_SKIPPED_FOR_RETRY:\n                // Just add to monitor, so it will be tracked for report and\n                // be removed on storage movement attempt finished report.\n              case BLOCKS_TARGETS_PAIRED:\n                this.storageMovementsMonitor.add(new AttemptedItemInfo(itemInfo\n                    .getStartId(), itemInfo.getFileId(), monotonicNow(),\n                    status.assignedBlocks, itemInfo.getRetryCount()));\n                break;\n              case NO_BLOCKS_TARGETS_PAIRED:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID \" + trackId\n                      + \" back to retry queue as none of the blocks\"\n                      + \" found its eligible targets.\");\n                }\n                itemInfo.increRetryCount();\n                this.storageMovementNeeded.add(itemInfo);\n                break;\n              case FEW_LOW_REDUNDANCY_BLOCKS:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID \" + trackId\n                      + \" back to retry queue as some of the blocks\"\n                      + \" are low redundant.\");\n                }\n                this.storageMovementNeeded.add(itemInfo);\n                break;\n              case BLOCKS_FAILED_TO_MOVE:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID \" + trackId\n                      + \" back to retry queue as some of the blocks\"\n                      + \" movement failed.\");\n                }\n                this.storageMovementNeeded.add(itemInfo);\n                break;\n              // Just clean Xattrs\n              case BLOCKS_TARGET_PAIRING_SKIPPED:\n              case BLOCKS_ALREADY_SATISFIED:\n              default:\n                LOG.info(\"Block analysis skipped or blocks already satisfied\"\n                    + \" with storages. So, Cleaning up the Xattrs.\");\n                storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n                break;\n              }\n            }\n          }\n        }\n        int numLiveDn \u003d ctxt.getNumLiveDataNodes();\n        if (storageMovementNeeded.size() \u003d\u003d 0\n            || blockCount \u003e (numLiveDn * spsWorkMultiplier)) {\n          Thread.sleep(3000);\n          blockCount \u003d 0L;\n        }\n      } catch (Throwable t) {\n        handleException(t);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java",
      "extendedDetails": {}
    },
    "05d4daf6ba3e5bd40f46e8003ee12fc7c613453d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12982 : [SPS]: Reduce the locking and cleanup the Namesystem access. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "05d4daf6ba3e5bd40f46e8003ee12fc7c613453d",
      "commitAuthor": "Surendra Singh Lilhore",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "78420719eb1f138c6f10558befb7bc8ebcc28a54",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,83 +1,94 @@\n   public void run() {\n-    while (namesystem.isRunning() \u0026\u0026 isRunning) {\n+    while (ctxt.isRunning()) {\n       try {\n-        if (!namesystem.isInSafeMode()) {\n+        if (!ctxt.isInSafeMode()) {\n           ItemInfo itemInfo \u003d storageMovementNeeded.get();\n           if (itemInfo !\u003d null) {\n             if(itemInfo.getRetryCount() \u003e\u003d blockMovementMaxRetry){\n               LOG.info(\"Failed to satisfy the policy after \"\n                   + blockMovementMaxRetry + \" retries. Removing inode \"\n                   + itemInfo.getTrackId() + \" from the queue\");\n               storageMovementNeeded.removeItemTrackInfo(itemInfo, false);\n               continue;\n             }\n             long trackId \u003d itemInfo.getTrackId();\n-            BlockCollection blockCollection;\n             BlocksMovingAnalysis status \u003d null;\n-            try {\n-              namesystem.readLock();\n-              blockCollection \u003d namesystem.getBlockCollection(trackId);\n-              // Check blockCollectionId existence.\n-              if (blockCollection \u003d\u003d null) {\n-                // File doesn\u0027t exists (maybe got deleted), remove trackId from\n-                // the queue\n-                storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n-              } else {\n-                status \u003d\n-                    analyseBlocksStorageMovementsAndAssignToDN(\n-                        blockCollection);\n-              }\n-            } finally {\n-              namesystem.readUnlock();\n-            }\n-            if (blockCollection !\u003d null) {\n+            DatanodeStorageReport[] liveDnReports;\n+            BlockStoragePolicy existingStoragePolicy;\n+            // TODO: presently, context internally acquire the lock\n+            // and returns the result. Need to discuss to move the lock outside?\n+            boolean hasLowRedundancyBlocks \u003d ctxt\n+                .hasLowRedundancyBlocks(trackId);\n+            HdfsFileStatus fileStatus \u003d ctxt.getFileInfo(trackId);\n+            // Check path existence.\n+            if (fileStatus \u003d\u003d null || fileStatus.isDir()) {\n+              // File doesn\u0027t exists (maybe got deleted) or its a directory,\n+              // just remove trackId from the queue\n+              storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n+            } else {\n+              liveDnReports \u003d ctxt.getLiveDatanodeStorageReport();\n+              byte existingStoragePolicyID \u003d fileStatus.getStoragePolicy();\n+              existingStoragePolicy \u003d ctxt\n+                  .getStoragePolicy(existingStoragePolicyID);\n+\n+              HdfsLocatedFileStatus file \u003d (HdfsLocatedFileStatus) fileStatus;\n+              status \u003d analyseBlocksStorageMovementsAndAssignToDN(file,\n+                  hasLowRedundancyBlocks, existingStoragePolicy, liveDnReports);\n               switch (status.status) {\n               // Just add to monitor, so it will be retried after timeout\n               case ANALYSIS_SKIPPED_FOR_RETRY:\n                 // Just add to monitor, so it will be tracked for report and\n                 // be removed on storage movement attempt finished report.\n               case BLOCKS_TARGETS_PAIRED:\n                 this.storageMovementsMonitor.add(new AttemptedItemInfo(itemInfo\n                     .getStartId(), itemInfo.getTrackId(), monotonicNow(),\n                     status.assignedBlocks, itemInfo.getRetryCount()));\n                 break;\n               case NO_BLOCKS_TARGETS_PAIRED:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Adding trackID \" + trackId\n                       + \" back to retry queue as none of the blocks\"\n                       + \" found its eligible targets.\");\n                 }\n                 itemInfo.retryCount++;\n                 this.storageMovementNeeded.add(itemInfo);\n                 break;\n               case FEW_LOW_REDUNDANCY_BLOCKS:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Adding trackID \" + trackId\n                       + \" back to retry queue as some of the blocks\"\n                       + \" are low redundant.\");\n                 }\n                 this.storageMovementNeeded.add(itemInfo);\n                 break;\n+              case BLOCKS_FAILED_TO_MOVE:\n+                if (LOG.isDebugEnabled()) {\n+                  LOG.debug(\"Adding trackID \" + trackId\n+                      + \" back to retry queue as some of the blocks\"\n+                      + \" movement failed.\");\n+                }\n+                this.storageMovementNeeded.add(itemInfo);\n+                break;\n               // Just clean Xattrs\n               case BLOCKS_TARGET_PAIRING_SKIPPED:\n               case BLOCKS_ALREADY_SATISFIED:\n               default:\n                 LOG.info(\"Block analysis skipped or blocks already satisfied\"\n                     + \" with storages. So, Cleaning up the Xattrs.\");\n                 storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n                 break;\n               }\n             }\n           }\n         }\n         int numLiveDn \u003d ctxt.getNumLiveDataNodes();\n         if (storageMovementNeeded.size() \u003d\u003d 0\n             || blockCount \u003e (numLiveDn * spsWorkMultiplier)) {\n           Thread.sleep(3000);\n           blockCount \u003d 0L;\n         }\n       } catch (Throwable t) {\n         handleException(t);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run() {\n    while (ctxt.isRunning()) {\n      try {\n        if (!ctxt.isInSafeMode()) {\n          ItemInfo itemInfo \u003d storageMovementNeeded.get();\n          if (itemInfo !\u003d null) {\n            if(itemInfo.getRetryCount() \u003e\u003d blockMovementMaxRetry){\n              LOG.info(\"Failed to satisfy the policy after \"\n                  + blockMovementMaxRetry + \" retries. Removing inode \"\n                  + itemInfo.getTrackId() + \" from the queue\");\n              storageMovementNeeded.removeItemTrackInfo(itemInfo, false);\n              continue;\n            }\n            long trackId \u003d itemInfo.getTrackId();\n            BlocksMovingAnalysis status \u003d null;\n            DatanodeStorageReport[] liveDnReports;\n            BlockStoragePolicy existingStoragePolicy;\n            // TODO: presently, context internally acquire the lock\n            // and returns the result. Need to discuss to move the lock outside?\n            boolean hasLowRedundancyBlocks \u003d ctxt\n                .hasLowRedundancyBlocks(trackId);\n            HdfsFileStatus fileStatus \u003d ctxt.getFileInfo(trackId);\n            // Check path existence.\n            if (fileStatus \u003d\u003d null || fileStatus.isDir()) {\n              // File doesn\u0027t exists (maybe got deleted) or its a directory,\n              // just remove trackId from the queue\n              storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n            } else {\n              liveDnReports \u003d ctxt.getLiveDatanodeStorageReport();\n              byte existingStoragePolicyID \u003d fileStatus.getStoragePolicy();\n              existingStoragePolicy \u003d ctxt\n                  .getStoragePolicy(existingStoragePolicyID);\n\n              HdfsLocatedFileStatus file \u003d (HdfsLocatedFileStatus) fileStatus;\n              status \u003d analyseBlocksStorageMovementsAndAssignToDN(file,\n                  hasLowRedundancyBlocks, existingStoragePolicy, liveDnReports);\n              switch (status.status) {\n              // Just add to monitor, so it will be retried after timeout\n              case ANALYSIS_SKIPPED_FOR_RETRY:\n                // Just add to monitor, so it will be tracked for report and\n                // be removed on storage movement attempt finished report.\n              case BLOCKS_TARGETS_PAIRED:\n                this.storageMovementsMonitor.add(new AttemptedItemInfo(itemInfo\n                    .getStartId(), itemInfo.getTrackId(), monotonicNow(),\n                    status.assignedBlocks, itemInfo.getRetryCount()));\n                break;\n              case NO_BLOCKS_TARGETS_PAIRED:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID \" + trackId\n                      + \" back to retry queue as none of the blocks\"\n                      + \" found its eligible targets.\");\n                }\n                itemInfo.retryCount++;\n                this.storageMovementNeeded.add(itemInfo);\n                break;\n              case FEW_LOW_REDUNDANCY_BLOCKS:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID \" + trackId\n                      + \" back to retry queue as some of the blocks\"\n                      + \" are low redundant.\");\n                }\n                this.storageMovementNeeded.add(itemInfo);\n                break;\n              case BLOCKS_FAILED_TO_MOVE:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID \" + trackId\n                      + \" back to retry queue as some of the blocks\"\n                      + \" movement failed.\");\n                }\n                this.storageMovementNeeded.add(itemInfo);\n                break;\n              // Just clean Xattrs\n              case BLOCKS_TARGET_PAIRING_SKIPPED:\n              case BLOCKS_ALREADY_SATISFIED:\n              default:\n                LOG.info(\"Block analysis skipped or blocks already satisfied\"\n                    + \" with storages. So, Cleaning up the Xattrs.\");\n                storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n                break;\n              }\n            }\n          }\n        }\n        int numLiveDn \u003d ctxt.getNumLiveDataNodes();\n        if (storageMovementNeeded.size() \u003d\u003d 0\n            || blockCount \u003e (numLiveDn * spsWorkMultiplier)) {\n          Thread.sleep(3000);\n          blockCount \u003d 0L;\n        }\n      } catch (Throwable t) {\n        handleException(t);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java",
      "extendedDetails": {}
    },
    "78420719eb1f138c6f10558befb7bc8ebcc28a54": {
      "type": "Ymultichange(Yfilerename,Ybodychange)",
      "commitMessage": "HDFS-12955: [SPS]: Move SPS classes to a separate package. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "78420719eb1f138c6f10558befb7bc8ebcc28a54",
      "commitAuthor": "Uma Maheswara Rao G",
      "subchanges": [
        {
          "type": "Yfilerename",
          "commitMessage": "HDFS-12955: [SPS]: Move SPS classes to a separate package. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "78420719eb1f138c6f10558befb7bc8ebcc28a54",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "c561cb316e365ef674784cd6cf0b12c0fbc271a3",
          "commitAuthorOld": "Surendra Singh Lilhore",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,84 +1,83 @@\n   public void run() {\n     while (namesystem.isRunning() \u0026\u0026 isRunning) {\n       try {\n         if (!namesystem.isInSafeMode()) {\n           ItemInfo itemInfo \u003d storageMovementNeeded.get();\n           if (itemInfo !\u003d null) {\n             if(itemInfo.getRetryCount() \u003e\u003d blockMovementMaxRetry){\n               LOG.info(\"Failed to satisfy the policy after \"\n                   + blockMovementMaxRetry + \" retries. Removing inode \"\n                   + itemInfo.getTrackId() + \" from the queue\");\n               storageMovementNeeded.removeItemTrackInfo(itemInfo, false);\n               continue;\n             }\n             long trackId \u003d itemInfo.getTrackId();\n             BlockCollection blockCollection;\n             BlocksMovingAnalysis status \u003d null;\n             try {\n               namesystem.readLock();\n               blockCollection \u003d namesystem.getBlockCollection(trackId);\n               // Check blockCollectionId existence.\n               if (blockCollection \u003d\u003d null) {\n                 // File doesn\u0027t exists (maybe got deleted), remove trackId from\n                 // the queue\n                 storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n               } else {\n                 status \u003d\n                     analyseBlocksStorageMovementsAndAssignToDN(\n                         blockCollection);\n               }\n             } finally {\n               namesystem.readUnlock();\n             }\n             if (blockCollection !\u003d null) {\n               switch (status.status) {\n               // Just add to monitor, so it will be retried after timeout\n               case ANALYSIS_SKIPPED_FOR_RETRY:\n                 // Just add to monitor, so it will be tracked for report and\n                 // be removed on storage movement attempt finished report.\n               case BLOCKS_TARGETS_PAIRED:\n                 this.storageMovementsMonitor.add(new AttemptedItemInfo(itemInfo\n                     .getStartId(), itemInfo.getTrackId(), monotonicNow(),\n                     status.assignedBlocks, itemInfo.getRetryCount()));\n                 break;\n               case NO_BLOCKS_TARGETS_PAIRED:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Adding trackID \" + trackId\n                       + \" back to retry queue as none of the blocks\"\n                       + \" found its eligible targets.\");\n                 }\n                 itemInfo.retryCount++;\n                 this.storageMovementNeeded.add(itemInfo);\n                 break;\n               case FEW_LOW_REDUNDANCY_BLOCKS:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Adding trackID \" + trackId\n                       + \" back to retry queue as some of the blocks\"\n                       + \" are low redundant.\");\n                 }\n                 this.storageMovementNeeded.add(itemInfo);\n                 break;\n               // Just clean Xattrs\n               case BLOCKS_TARGET_PAIRING_SKIPPED:\n               case BLOCKS_ALREADY_SATISFIED:\n               default:\n                 LOG.info(\"Block analysis skipped or blocks already satisfied\"\n                     + \" with storages. So, Cleaning up the Xattrs.\");\n                 storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n                 break;\n               }\n             }\n           }\n         }\n-        int numLiveDn \u003d namesystem.getFSDirectory().getBlockManager()\n-            .getDatanodeManager().getNumLiveDataNodes();\n+        int numLiveDn \u003d ctxt.getNumLiveDataNodes();\n         if (storageMovementNeeded.size() \u003d\u003d 0\n             || blockCount \u003e (numLiveDn * spsWorkMultiplier)) {\n           Thread.sleep(3000);\n           blockCount \u003d 0L;\n         }\n       } catch (Throwable t) {\n         handleException(t);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void run() {\n    while (namesystem.isRunning() \u0026\u0026 isRunning) {\n      try {\n        if (!namesystem.isInSafeMode()) {\n          ItemInfo itemInfo \u003d storageMovementNeeded.get();\n          if (itemInfo !\u003d null) {\n            if(itemInfo.getRetryCount() \u003e\u003d blockMovementMaxRetry){\n              LOG.info(\"Failed to satisfy the policy after \"\n                  + blockMovementMaxRetry + \" retries. Removing inode \"\n                  + itemInfo.getTrackId() + \" from the queue\");\n              storageMovementNeeded.removeItemTrackInfo(itemInfo, false);\n              continue;\n            }\n            long trackId \u003d itemInfo.getTrackId();\n            BlockCollection blockCollection;\n            BlocksMovingAnalysis status \u003d null;\n            try {\n              namesystem.readLock();\n              blockCollection \u003d namesystem.getBlockCollection(trackId);\n              // Check blockCollectionId existence.\n              if (blockCollection \u003d\u003d null) {\n                // File doesn\u0027t exists (maybe got deleted), remove trackId from\n                // the queue\n                storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n              } else {\n                status \u003d\n                    analyseBlocksStorageMovementsAndAssignToDN(\n                        blockCollection);\n              }\n            } finally {\n              namesystem.readUnlock();\n            }\n            if (blockCollection !\u003d null) {\n              switch (status.status) {\n              // Just add to monitor, so it will be retried after timeout\n              case ANALYSIS_SKIPPED_FOR_RETRY:\n                // Just add to monitor, so it will be tracked for report and\n                // be removed on storage movement attempt finished report.\n              case BLOCKS_TARGETS_PAIRED:\n                this.storageMovementsMonitor.add(new AttemptedItemInfo(itemInfo\n                    .getStartId(), itemInfo.getTrackId(), monotonicNow(),\n                    status.assignedBlocks, itemInfo.getRetryCount()));\n                break;\n              case NO_BLOCKS_TARGETS_PAIRED:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID \" + trackId\n                      + \" back to retry queue as none of the blocks\"\n                      + \" found its eligible targets.\");\n                }\n                itemInfo.retryCount++;\n                this.storageMovementNeeded.add(itemInfo);\n                break;\n              case FEW_LOW_REDUNDANCY_BLOCKS:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID \" + trackId\n                      + \" back to retry queue as some of the blocks\"\n                      + \" are low redundant.\");\n                }\n                this.storageMovementNeeded.add(itemInfo);\n                break;\n              // Just clean Xattrs\n              case BLOCKS_TARGET_PAIRING_SKIPPED:\n              case BLOCKS_ALREADY_SATISFIED:\n              default:\n                LOG.info(\"Block analysis skipped or blocks already satisfied\"\n                    + \" with storages. So, Cleaning up the Xattrs.\");\n                storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n                break;\n              }\n            }\n          }\n        }\n        int numLiveDn \u003d ctxt.getNumLiveDataNodes();\n        if (storageMovementNeeded.size() \u003d\u003d 0\n            || blockCount \u003e (numLiveDn * spsWorkMultiplier)) {\n          Thread.sleep(3000);\n          blockCount \u003d 0L;\n        }\n      } catch (Throwable t) {\n        handleException(t);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/StoragePolicySatisfier.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-12955: [SPS]: Move SPS classes to a separate package. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "78420719eb1f138c6f10558befb7bc8ebcc28a54",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "c561cb316e365ef674784cd6cf0b12c0fbc271a3",
          "commitAuthorOld": "Surendra Singh Lilhore",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,84 +1,83 @@\n   public void run() {\n     while (namesystem.isRunning() \u0026\u0026 isRunning) {\n       try {\n         if (!namesystem.isInSafeMode()) {\n           ItemInfo itemInfo \u003d storageMovementNeeded.get();\n           if (itemInfo !\u003d null) {\n             if(itemInfo.getRetryCount() \u003e\u003d blockMovementMaxRetry){\n               LOG.info(\"Failed to satisfy the policy after \"\n                   + blockMovementMaxRetry + \" retries. Removing inode \"\n                   + itemInfo.getTrackId() + \" from the queue\");\n               storageMovementNeeded.removeItemTrackInfo(itemInfo, false);\n               continue;\n             }\n             long trackId \u003d itemInfo.getTrackId();\n             BlockCollection blockCollection;\n             BlocksMovingAnalysis status \u003d null;\n             try {\n               namesystem.readLock();\n               blockCollection \u003d namesystem.getBlockCollection(trackId);\n               // Check blockCollectionId existence.\n               if (blockCollection \u003d\u003d null) {\n                 // File doesn\u0027t exists (maybe got deleted), remove trackId from\n                 // the queue\n                 storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n               } else {\n                 status \u003d\n                     analyseBlocksStorageMovementsAndAssignToDN(\n                         blockCollection);\n               }\n             } finally {\n               namesystem.readUnlock();\n             }\n             if (blockCollection !\u003d null) {\n               switch (status.status) {\n               // Just add to monitor, so it will be retried after timeout\n               case ANALYSIS_SKIPPED_FOR_RETRY:\n                 // Just add to monitor, so it will be tracked for report and\n                 // be removed on storage movement attempt finished report.\n               case BLOCKS_TARGETS_PAIRED:\n                 this.storageMovementsMonitor.add(new AttemptedItemInfo(itemInfo\n                     .getStartId(), itemInfo.getTrackId(), monotonicNow(),\n                     status.assignedBlocks, itemInfo.getRetryCount()));\n                 break;\n               case NO_BLOCKS_TARGETS_PAIRED:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Adding trackID \" + trackId\n                       + \" back to retry queue as none of the blocks\"\n                       + \" found its eligible targets.\");\n                 }\n                 itemInfo.retryCount++;\n                 this.storageMovementNeeded.add(itemInfo);\n                 break;\n               case FEW_LOW_REDUNDANCY_BLOCKS:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Adding trackID \" + trackId\n                       + \" back to retry queue as some of the blocks\"\n                       + \" are low redundant.\");\n                 }\n                 this.storageMovementNeeded.add(itemInfo);\n                 break;\n               // Just clean Xattrs\n               case BLOCKS_TARGET_PAIRING_SKIPPED:\n               case BLOCKS_ALREADY_SATISFIED:\n               default:\n                 LOG.info(\"Block analysis skipped or blocks already satisfied\"\n                     + \" with storages. So, Cleaning up the Xattrs.\");\n                 storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n                 break;\n               }\n             }\n           }\n         }\n-        int numLiveDn \u003d namesystem.getFSDirectory().getBlockManager()\n-            .getDatanodeManager().getNumLiveDataNodes();\n+        int numLiveDn \u003d ctxt.getNumLiveDataNodes();\n         if (storageMovementNeeded.size() \u003d\u003d 0\n             || blockCount \u003e (numLiveDn * spsWorkMultiplier)) {\n           Thread.sleep(3000);\n           blockCount \u003d 0L;\n         }\n       } catch (Throwable t) {\n         handleException(t);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void run() {\n    while (namesystem.isRunning() \u0026\u0026 isRunning) {\n      try {\n        if (!namesystem.isInSafeMode()) {\n          ItemInfo itemInfo \u003d storageMovementNeeded.get();\n          if (itemInfo !\u003d null) {\n            if(itemInfo.getRetryCount() \u003e\u003d blockMovementMaxRetry){\n              LOG.info(\"Failed to satisfy the policy after \"\n                  + blockMovementMaxRetry + \" retries. Removing inode \"\n                  + itemInfo.getTrackId() + \" from the queue\");\n              storageMovementNeeded.removeItemTrackInfo(itemInfo, false);\n              continue;\n            }\n            long trackId \u003d itemInfo.getTrackId();\n            BlockCollection blockCollection;\n            BlocksMovingAnalysis status \u003d null;\n            try {\n              namesystem.readLock();\n              blockCollection \u003d namesystem.getBlockCollection(trackId);\n              // Check blockCollectionId existence.\n              if (blockCollection \u003d\u003d null) {\n                // File doesn\u0027t exists (maybe got deleted), remove trackId from\n                // the queue\n                storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n              } else {\n                status \u003d\n                    analyseBlocksStorageMovementsAndAssignToDN(\n                        blockCollection);\n              }\n            } finally {\n              namesystem.readUnlock();\n            }\n            if (blockCollection !\u003d null) {\n              switch (status.status) {\n              // Just add to monitor, so it will be retried after timeout\n              case ANALYSIS_SKIPPED_FOR_RETRY:\n                // Just add to monitor, so it will be tracked for report and\n                // be removed on storage movement attempt finished report.\n              case BLOCKS_TARGETS_PAIRED:\n                this.storageMovementsMonitor.add(new AttemptedItemInfo(itemInfo\n                    .getStartId(), itemInfo.getTrackId(), monotonicNow(),\n                    status.assignedBlocks, itemInfo.getRetryCount()));\n                break;\n              case NO_BLOCKS_TARGETS_PAIRED:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID \" + trackId\n                      + \" back to retry queue as none of the blocks\"\n                      + \" found its eligible targets.\");\n                }\n                itemInfo.retryCount++;\n                this.storageMovementNeeded.add(itemInfo);\n                break;\n              case FEW_LOW_REDUNDANCY_BLOCKS:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID \" + trackId\n                      + \" back to retry queue as some of the blocks\"\n                      + \" are low redundant.\");\n                }\n                this.storageMovementNeeded.add(itemInfo);\n                break;\n              // Just clean Xattrs\n              case BLOCKS_TARGET_PAIRING_SKIPPED:\n              case BLOCKS_ALREADY_SATISFIED:\n              default:\n                LOG.info(\"Block analysis skipped or blocks already satisfied\"\n                    + \" with storages. So, Cleaning up the Xattrs.\");\n                storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n                break;\n              }\n            }\n          }\n        }\n        int numLiveDn \u003d ctxt.getNumLiveDataNodes();\n        if (storageMovementNeeded.size() \u003d\u003d 0\n            || blockCount \u003e (numLiveDn * spsWorkMultiplier)) {\n          Thread.sleep(3000);\n          blockCount \u003d 0L;\n        }\n      } catch (Throwable t) {\n        handleException(t);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java",
          "extendedDetails": {}
        }
      ]
    },
    "c561cb316e365ef674784cd6cf0b12c0fbc271a3": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12106: [SPS]: Improve storage policy satisfier configurations. Contributed by Surendra Singh Lilhore.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "c561cb316e365ef674784cd6cf0b12c0fbc271a3",
      "commitAuthor": "Surendra Singh Lilhore",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "68017e3349e3b71a9c49f2ccea2558231ff8485d",
      "commitAuthorOld": "Rakesh Radhakrishnan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,76 +1,84 @@\n   public void run() {\n     while (namesystem.isRunning() \u0026\u0026 isRunning) {\n       try {\n         if (!namesystem.isInSafeMode()) {\n           ItemInfo itemInfo \u003d storageMovementNeeded.get();\n           if (itemInfo !\u003d null) {\n+            if(itemInfo.getRetryCount() \u003e\u003d blockMovementMaxRetry){\n+              LOG.info(\"Failed to satisfy the policy after \"\n+                  + blockMovementMaxRetry + \" retries. Removing inode \"\n+                  + itemInfo.getTrackId() + \" from the queue\");\n+              storageMovementNeeded.removeItemTrackInfo(itemInfo, false);\n+              continue;\n+            }\n             long trackId \u003d itemInfo.getTrackId();\n             BlockCollection blockCollection;\n             BlocksMovingAnalysis status \u003d null;\n             try {\n               namesystem.readLock();\n               blockCollection \u003d namesystem.getBlockCollection(trackId);\n               // Check blockCollectionId existence.\n               if (blockCollection \u003d\u003d null) {\n                 // File doesn\u0027t exists (maybe got deleted), remove trackId from\n                 // the queue\n-                storageMovementNeeded.removeItemTrackInfo(itemInfo);\n+                storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n               } else {\n                 status \u003d\n                     analyseBlocksStorageMovementsAndAssignToDN(\n                         blockCollection);\n               }\n             } finally {\n               namesystem.readUnlock();\n             }\n             if (blockCollection !\u003d null) {\n               switch (status.status) {\n               // Just add to monitor, so it will be retried after timeout\n               case ANALYSIS_SKIPPED_FOR_RETRY:\n                 // Just add to monitor, so it will be tracked for report and\n                 // be removed on storage movement attempt finished report.\n               case BLOCKS_TARGETS_PAIRED:\n-                this.storageMovementsMonitor.add(new AttemptedItemInfo(\n-                    itemInfo.getStartId(), itemInfo.getTrackId(),\n-                    monotonicNow(), status.assignedBlocks));\n+                this.storageMovementsMonitor.add(new AttemptedItemInfo(itemInfo\n+                    .getStartId(), itemInfo.getTrackId(), monotonicNow(),\n+                    status.assignedBlocks, itemInfo.getRetryCount()));\n                 break;\n               case NO_BLOCKS_TARGETS_PAIRED:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Adding trackID \" + trackId\n                       + \" back to retry queue as none of the blocks\"\n                       + \" found its eligible targets.\");\n                 }\n+                itemInfo.retryCount++;\n                 this.storageMovementNeeded.add(itemInfo);\n                 break;\n               case FEW_LOW_REDUNDANCY_BLOCKS:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Adding trackID \" + trackId\n                       + \" back to retry queue as some of the blocks\"\n                       + \" are low redundant.\");\n                 }\n                 this.storageMovementNeeded.add(itemInfo);\n                 break;\n               // Just clean Xattrs\n               case BLOCKS_TARGET_PAIRING_SKIPPED:\n               case BLOCKS_ALREADY_SATISFIED:\n               default:\n                 LOG.info(\"Block analysis skipped or blocks already satisfied\"\n                     + \" with storages. So, Cleaning up the Xattrs.\");\n-                storageMovementNeeded.removeItemTrackInfo(itemInfo);\n+                storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n                 break;\n               }\n             }\n           }\n         }\n         int numLiveDn \u003d namesystem.getFSDirectory().getBlockManager()\n             .getDatanodeManager().getNumLiveDataNodes();\n         if (storageMovementNeeded.size() \u003d\u003d 0\n             || blockCount \u003e (numLiveDn * spsWorkMultiplier)) {\n           Thread.sleep(3000);\n           blockCount \u003d 0L;\n         }\n       } catch (Throwable t) {\n         handleException(t);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run() {\n    while (namesystem.isRunning() \u0026\u0026 isRunning) {\n      try {\n        if (!namesystem.isInSafeMode()) {\n          ItemInfo itemInfo \u003d storageMovementNeeded.get();\n          if (itemInfo !\u003d null) {\n            if(itemInfo.getRetryCount() \u003e\u003d blockMovementMaxRetry){\n              LOG.info(\"Failed to satisfy the policy after \"\n                  + blockMovementMaxRetry + \" retries. Removing inode \"\n                  + itemInfo.getTrackId() + \" from the queue\");\n              storageMovementNeeded.removeItemTrackInfo(itemInfo, false);\n              continue;\n            }\n            long trackId \u003d itemInfo.getTrackId();\n            BlockCollection blockCollection;\n            BlocksMovingAnalysis status \u003d null;\n            try {\n              namesystem.readLock();\n              blockCollection \u003d namesystem.getBlockCollection(trackId);\n              // Check blockCollectionId existence.\n              if (blockCollection \u003d\u003d null) {\n                // File doesn\u0027t exists (maybe got deleted), remove trackId from\n                // the queue\n                storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n              } else {\n                status \u003d\n                    analyseBlocksStorageMovementsAndAssignToDN(\n                        blockCollection);\n              }\n            } finally {\n              namesystem.readUnlock();\n            }\n            if (blockCollection !\u003d null) {\n              switch (status.status) {\n              // Just add to monitor, so it will be retried after timeout\n              case ANALYSIS_SKIPPED_FOR_RETRY:\n                // Just add to monitor, so it will be tracked for report and\n                // be removed on storage movement attempt finished report.\n              case BLOCKS_TARGETS_PAIRED:\n                this.storageMovementsMonitor.add(new AttemptedItemInfo(itemInfo\n                    .getStartId(), itemInfo.getTrackId(), monotonicNow(),\n                    status.assignedBlocks, itemInfo.getRetryCount()));\n                break;\n              case NO_BLOCKS_TARGETS_PAIRED:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID \" + trackId\n                      + \" back to retry queue as none of the blocks\"\n                      + \" found its eligible targets.\");\n                }\n                itemInfo.retryCount++;\n                this.storageMovementNeeded.add(itemInfo);\n                break;\n              case FEW_LOW_REDUNDANCY_BLOCKS:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID \" + trackId\n                      + \" back to retry queue as some of the blocks\"\n                      + \" are low redundant.\");\n                }\n                this.storageMovementNeeded.add(itemInfo);\n                break;\n              // Just clean Xattrs\n              case BLOCKS_TARGET_PAIRING_SKIPPED:\n              case BLOCKS_ALREADY_SATISFIED:\n              default:\n                LOG.info(\"Block analysis skipped or blocks already satisfied\"\n                    + \" with storages. So, Cleaning up the Xattrs.\");\n                storageMovementNeeded.removeItemTrackInfo(itemInfo, true);\n                break;\n              }\n            }\n          }\n        }\n        int numLiveDn \u003d namesystem.getFSDirectory().getBlockManager()\n            .getDatanodeManager().getNumLiveDataNodes();\n        if (storageMovementNeeded.size() \u003d\u003d 0\n            || blockCount \u003e (numLiveDn * spsWorkMultiplier)) {\n          Thread.sleep(3000);\n          blockCount \u003d 0L;\n        }\n      } catch (Throwable t) {\n        handleException(t);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/StoragePolicySatisfier.java",
      "extendedDetails": {}
    },
    "5780f0624de2531194bc98eb25a928f7a483b992": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12556: [SPS] : Block movement analysis should be done in read lock.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "5780f0624de2531194bc98eb25a928f7a483b992",
      "commitAuthor": "Surendra Singh Lilhore",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "00eceed233d6e80d5c7137bf5b5286746ec4d5fb",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,67 +1,76 @@\n   public void run() {\n     while (namesystem.isRunning() \u0026\u0026 isRunning) {\n       try {\n         if (!namesystem.isInSafeMode()) {\n           ItemInfo itemInfo \u003d storageMovementNeeded.get();\n           if (itemInfo !\u003d null) {\n             long trackId \u003d itemInfo.getTrackId();\n-            BlockCollection blockCollection \u003d\n-                namesystem.getBlockCollection(trackId);\n-            // Check blockCollectionId existence.\n+            BlockCollection blockCollection;\n+            BlocksMovingAnalysis status \u003d null;\n+            try {\n+              namesystem.readLock();\n+              blockCollection \u003d namesystem.getBlockCollection(trackId);\n+              // Check blockCollectionId existence.\n+              if (blockCollection \u003d\u003d null) {\n+                // File doesn\u0027t exists (maybe got deleted), remove trackId from\n+                // the queue\n+                storageMovementNeeded.removeItemTrackInfo(itemInfo);\n+              } else {\n+                status \u003d\n+                    analyseBlocksStorageMovementsAndAssignToDN(\n+                        blockCollection);\n+              }\n+            } finally {\n+              namesystem.readUnlock();\n+            }\n             if (blockCollection !\u003d null) {\n-              BlocksMovingAnalysis status \u003d\n-                  analyseBlocksStorageMovementsAndAssignToDN(blockCollection);\n               switch (status.status) {\n               // Just add to monitor, so it will be retried after timeout\n               case ANALYSIS_SKIPPED_FOR_RETRY:\n                 // Just add to monitor, so it will be tracked for report and\n                 // be removed on storage movement attempt finished report.\n               case BLOCKS_TARGETS_PAIRED:\n                 this.storageMovementsMonitor.add(new AttemptedItemInfo(\n                     itemInfo.getStartId(), itemInfo.getTrackId(),\n                     monotonicNow(), status.assignedBlocks));\n                 break;\n               case NO_BLOCKS_TARGETS_PAIRED:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Adding trackID \" + trackId\n                       + \" back to retry queue as none of the blocks\"\n                       + \" found its eligible targets.\");\n                 }\n                 this.storageMovementNeeded.add(itemInfo);\n                 break;\n               case FEW_LOW_REDUNDANCY_BLOCKS:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Adding trackID \" + trackId\n                       + \" back to retry queue as some of the blocks\"\n                       + \" are low redundant.\");\n                 }\n                 this.storageMovementNeeded.add(itemInfo);\n                 break;\n               // Just clean Xattrs\n               case BLOCKS_TARGET_PAIRING_SKIPPED:\n               case BLOCKS_ALREADY_SATISFIED:\n               default:\n                 LOG.info(\"Block analysis skipped or blocks already satisfied\"\n                     + \" with storages. So, Cleaning up the Xattrs.\");\n                 storageMovementNeeded.removeItemTrackInfo(itemInfo);\n                 break;\n               }\n-            } else {\n-              // File doesn\u0027t exists (maybe got deleted), remove trackId from\n-              // the queue\n-              storageMovementNeeded.removeItemTrackInfo(itemInfo);\n             }\n           }\n         }\n         int numLiveDn \u003d namesystem.getFSDirectory().getBlockManager()\n             .getDatanodeManager().getNumLiveDataNodes();\n         if (storageMovementNeeded.size() \u003d\u003d 0\n             || blockCount \u003e (numLiveDn * spsWorkMultiplier)) {\n           Thread.sleep(3000);\n           blockCount \u003d 0L;\n         }\n       } catch (Throwable t) {\n         handleException(t);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run() {\n    while (namesystem.isRunning() \u0026\u0026 isRunning) {\n      try {\n        if (!namesystem.isInSafeMode()) {\n          ItemInfo itemInfo \u003d storageMovementNeeded.get();\n          if (itemInfo !\u003d null) {\n            long trackId \u003d itemInfo.getTrackId();\n            BlockCollection blockCollection;\n            BlocksMovingAnalysis status \u003d null;\n            try {\n              namesystem.readLock();\n              blockCollection \u003d namesystem.getBlockCollection(trackId);\n              // Check blockCollectionId existence.\n              if (blockCollection \u003d\u003d null) {\n                // File doesn\u0027t exists (maybe got deleted), remove trackId from\n                // the queue\n                storageMovementNeeded.removeItemTrackInfo(itemInfo);\n              } else {\n                status \u003d\n                    analyseBlocksStorageMovementsAndAssignToDN(\n                        blockCollection);\n              }\n            } finally {\n              namesystem.readUnlock();\n            }\n            if (blockCollection !\u003d null) {\n              switch (status.status) {\n              // Just add to monitor, so it will be retried after timeout\n              case ANALYSIS_SKIPPED_FOR_RETRY:\n                // Just add to monitor, so it will be tracked for report and\n                // be removed on storage movement attempt finished report.\n              case BLOCKS_TARGETS_PAIRED:\n                this.storageMovementsMonitor.add(new AttemptedItemInfo(\n                    itemInfo.getStartId(), itemInfo.getTrackId(),\n                    monotonicNow(), status.assignedBlocks));\n                break;\n              case NO_BLOCKS_TARGETS_PAIRED:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID \" + trackId\n                      + \" back to retry queue as none of the blocks\"\n                      + \" found its eligible targets.\");\n                }\n                this.storageMovementNeeded.add(itemInfo);\n                break;\n              case FEW_LOW_REDUNDANCY_BLOCKS:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID \" + trackId\n                      + \" back to retry queue as some of the blocks\"\n                      + \" are low redundant.\");\n                }\n                this.storageMovementNeeded.add(itemInfo);\n                break;\n              // Just clean Xattrs\n              case BLOCKS_TARGET_PAIRING_SKIPPED:\n              case BLOCKS_ALREADY_SATISFIED:\n              default:\n                LOG.info(\"Block analysis skipped or blocks already satisfied\"\n                    + \" with storages. So, Cleaning up the Xattrs.\");\n                storageMovementNeeded.removeItemTrackInfo(itemInfo);\n                break;\n              }\n            }\n          }\n        }\n        int numLiveDn \u003d namesystem.getFSDirectory().getBlockManager()\n            .getDatanodeManager().getNumLiveDataNodes();\n        if (storageMovementNeeded.size() \u003d\u003d 0\n            || blockCount \u003e (numLiveDn * spsWorkMultiplier)) {\n          Thread.sleep(3000);\n          blockCount \u003d 0L;\n        }\n      } catch (Throwable t) {\n        handleException(t);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/StoragePolicySatisfier.java",
      "extendedDetails": {}
    },
    "00eceed233d6e80d5c7137bf5b5286746ec4d5fb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12570: [SPS]: Refactor Co-ordinator datanode logic to track the block storage movements. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "00eceed233d6e80d5c7137bf5b5286746ec4d5fb",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "bfd3f8bd8a9ae2186ec3e4addc71f912ec7b8923",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,63 +1,67 @@\n   public void run() {\n     while (namesystem.isRunning() \u0026\u0026 isRunning) {\n       try {\n         if (!namesystem.isInSafeMode()) {\n           ItemInfo itemInfo \u003d storageMovementNeeded.get();\n           if (itemInfo !\u003d null) {\n             long trackId \u003d itemInfo.getTrackId();\n             BlockCollection blockCollection \u003d\n                 namesystem.getBlockCollection(trackId);\n             // Check blockCollectionId existence.\n             if (blockCollection !\u003d null) {\n-              BlocksMovingAnalysisStatus status \u003d\n+              BlocksMovingAnalysis status \u003d\n                   analyseBlocksStorageMovementsAndAssignToDN(blockCollection);\n-              switch (status) {\n+              switch (status.status) {\n               // Just add to monitor, so it will be retried after timeout\n               case ANALYSIS_SKIPPED_FOR_RETRY:\n-                // Just add to monitor, so it will be tracked for result and\n-                // be removed on successful storage movement result.\n-              case ALL_BLOCKS_TARGETS_PAIRED:\n-                this.storageMovementsMonitor.add(itemInfo, true);\n+                // Just add to monitor, so it will be tracked for report and\n+                // be removed on storage movement attempt finished report.\n+              case BLOCKS_TARGETS_PAIRED:\n+                this.storageMovementsMonitor.add(new AttemptedItemInfo(\n+                    itemInfo.getStartId(), itemInfo.getTrackId(),\n+                    monotonicNow(), status.assignedBlocks));\n                 break;\n-              // Add to monitor with allBlcoksAttemptedToSatisfy flag false, so\n-              // that it will be tracked and still it will be consider for retry\n-              // as analysis was not found targets for storage movement blocks.\n-              case FEW_BLOCKS_TARGETS_PAIRED:\n-                this.storageMovementsMonitor.add(itemInfo, false);\n+              case NO_BLOCKS_TARGETS_PAIRED:\n+                if (LOG.isDebugEnabled()) {\n+                  LOG.debug(\"Adding trackID \" + trackId\n+                      + \" back to retry queue as none of the blocks\"\n+                      + \" found its eligible targets.\");\n+                }\n+                this.storageMovementNeeded.add(itemInfo);\n                 break;\n               case FEW_LOW_REDUNDANCY_BLOCKS:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Adding trackID \" + trackId\n                       + \" back to retry queue as some of the blocks\"\n                       + \" are low redundant.\");\n                 }\n                 this.storageMovementNeeded.add(itemInfo);\n                 break;\n               // Just clean Xattrs\n               case BLOCKS_TARGET_PAIRING_SKIPPED:\n               case BLOCKS_ALREADY_SATISFIED:\n               default:\n                 LOG.info(\"Block analysis skipped or blocks already satisfied\"\n                     + \" with storages. So, Cleaning up the Xattrs.\");\n                 storageMovementNeeded.removeItemTrackInfo(itemInfo);\n                 break;\n               }\n             } else {\n               // File doesn\u0027t exists (maybe got deleted), remove trackId from\n               // the queue\n               storageMovementNeeded.removeItemTrackInfo(itemInfo);\n             }\n           }\n         }\n         int numLiveDn \u003d namesystem.getFSDirectory().getBlockManager()\n             .getDatanodeManager().getNumLiveDataNodes();\n         if (storageMovementNeeded.size() \u003d\u003d 0\n             || blockCount \u003e (numLiveDn * spsWorkMultiplier)) {\n           Thread.sleep(3000);\n           blockCount \u003d 0L;\n         }\n       } catch (Throwable t) {\n         handleException(t);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run() {\n    while (namesystem.isRunning() \u0026\u0026 isRunning) {\n      try {\n        if (!namesystem.isInSafeMode()) {\n          ItemInfo itemInfo \u003d storageMovementNeeded.get();\n          if (itemInfo !\u003d null) {\n            long trackId \u003d itemInfo.getTrackId();\n            BlockCollection blockCollection \u003d\n                namesystem.getBlockCollection(trackId);\n            // Check blockCollectionId existence.\n            if (blockCollection !\u003d null) {\n              BlocksMovingAnalysis status \u003d\n                  analyseBlocksStorageMovementsAndAssignToDN(blockCollection);\n              switch (status.status) {\n              // Just add to monitor, so it will be retried after timeout\n              case ANALYSIS_SKIPPED_FOR_RETRY:\n                // Just add to monitor, so it will be tracked for report and\n                // be removed on storage movement attempt finished report.\n              case BLOCKS_TARGETS_PAIRED:\n                this.storageMovementsMonitor.add(new AttemptedItemInfo(\n                    itemInfo.getStartId(), itemInfo.getTrackId(),\n                    monotonicNow(), status.assignedBlocks));\n                break;\n              case NO_BLOCKS_TARGETS_PAIRED:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID \" + trackId\n                      + \" back to retry queue as none of the blocks\"\n                      + \" found its eligible targets.\");\n                }\n                this.storageMovementNeeded.add(itemInfo);\n                break;\n              case FEW_LOW_REDUNDANCY_BLOCKS:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID \" + trackId\n                      + \" back to retry queue as some of the blocks\"\n                      + \" are low redundant.\");\n                }\n                this.storageMovementNeeded.add(itemInfo);\n                break;\n              // Just clean Xattrs\n              case BLOCKS_TARGET_PAIRING_SKIPPED:\n              case BLOCKS_ALREADY_SATISFIED:\n              default:\n                LOG.info(\"Block analysis skipped or blocks already satisfied\"\n                    + \" with storages. So, Cleaning up the Xattrs.\");\n                storageMovementNeeded.removeItemTrackInfo(itemInfo);\n                break;\n              }\n            } else {\n              // File doesn\u0027t exists (maybe got deleted), remove trackId from\n              // the queue\n              storageMovementNeeded.removeItemTrackInfo(itemInfo);\n            }\n          }\n        }\n        int numLiveDn \u003d namesystem.getFSDirectory().getBlockManager()\n            .getDatanodeManager().getNumLiveDataNodes();\n        if (storageMovementNeeded.size() \u003d\u003d 0\n            || blockCount \u003e (numLiveDn * spsWorkMultiplier)) {\n          Thread.sleep(3000);\n          blockCount \u003d 0L;\n        }\n      } catch (Throwable t) {\n        handleException(t);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/StoragePolicySatisfier.java",
      "extendedDetails": {}
    },
    "bfd3f8bd8a9ae2186ec3e4addc71f912ec7b8923": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12291: [SPS]: Provide a mechanism to recursively iterate and satisfy storage policy of all the files under the given dir. Contributed by Surendra Singh Lilhore.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "bfd3f8bd8a9ae2186ec3e4addc71f912ec7b8923",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "7ea24fc06c081e2ba6f5f66d212abb14b80c9064",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,59 +1,63 @@\n   public void run() {\n     while (namesystem.isRunning() \u0026\u0026 isRunning) {\n       try {\n         if (!namesystem.isInSafeMode()) {\n           ItemInfo itemInfo \u003d storageMovementNeeded.get();\n           if (itemInfo !\u003d null) {\n             long trackId \u003d itemInfo.getTrackId();\n             BlockCollection blockCollection \u003d\n                 namesystem.getBlockCollection(trackId);\n             // Check blockCollectionId existence.\n             if (blockCollection !\u003d null) {\n               BlocksMovingAnalysisStatus status \u003d\n                   analyseBlocksStorageMovementsAndAssignToDN(blockCollection);\n               switch (status) {\n               // Just add to monitor, so it will be retried after timeout\n               case ANALYSIS_SKIPPED_FOR_RETRY:\n                 // Just add to monitor, so it will be tracked for result and\n                 // be removed on successful storage movement result.\n               case ALL_BLOCKS_TARGETS_PAIRED:\n                 this.storageMovementsMonitor.add(itemInfo, true);\n                 break;\n               // Add to monitor with allBlcoksAttemptedToSatisfy flag false, so\n               // that it will be tracked and still it will be consider for retry\n               // as analysis was not found targets for storage movement blocks.\n               case FEW_BLOCKS_TARGETS_PAIRED:\n                 this.storageMovementsMonitor.add(itemInfo, false);\n                 break;\n               case FEW_LOW_REDUNDANCY_BLOCKS:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Adding trackID \" + trackId\n                       + \" back to retry queue as some of the blocks\"\n                       + \" are low redundant.\");\n                 }\n                 this.storageMovementNeeded.add(itemInfo);\n                 break;\n               // Just clean Xattrs\n               case BLOCKS_TARGET_PAIRING_SKIPPED:\n               case BLOCKS_ALREADY_SATISFIED:\n               default:\n                 LOG.info(\"Block analysis skipped or blocks already satisfied\"\n                     + \" with storages. So, Cleaning up the Xattrs.\");\n                 storageMovementNeeded.removeItemTrackInfo(itemInfo);\n                 break;\n               }\n             } else {\n               // File doesn\u0027t exists (maybe got deleted), remove trackId from\n               // the queue\n               storageMovementNeeded.removeItemTrackInfo(itemInfo);\n             }\n           }\n         }\n-        // TODO: We can think to make this as configurable later, how frequently\n-        // we want to check block movements.\n-        Thread.sleep(3000);\n+        int numLiveDn \u003d namesystem.getFSDirectory().getBlockManager()\n+            .getDatanodeManager().getNumLiveDataNodes();\n+        if (storageMovementNeeded.size() \u003d\u003d 0\n+            || blockCount \u003e (numLiveDn * spsWorkMultiplier)) {\n+          Thread.sleep(3000);\n+          blockCount \u003d 0L;\n+        }\n       } catch (Throwable t) {\n         handleException(t);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run() {\n    while (namesystem.isRunning() \u0026\u0026 isRunning) {\n      try {\n        if (!namesystem.isInSafeMode()) {\n          ItemInfo itemInfo \u003d storageMovementNeeded.get();\n          if (itemInfo !\u003d null) {\n            long trackId \u003d itemInfo.getTrackId();\n            BlockCollection blockCollection \u003d\n                namesystem.getBlockCollection(trackId);\n            // Check blockCollectionId existence.\n            if (blockCollection !\u003d null) {\n              BlocksMovingAnalysisStatus status \u003d\n                  analyseBlocksStorageMovementsAndAssignToDN(blockCollection);\n              switch (status) {\n              // Just add to monitor, so it will be retried after timeout\n              case ANALYSIS_SKIPPED_FOR_RETRY:\n                // Just add to monitor, so it will be tracked for result and\n                // be removed on successful storage movement result.\n              case ALL_BLOCKS_TARGETS_PAIRED:\n                this.storageMovementsMonitor.add(itemInfo, true);\n                break;\n              // Add to monitor with allBlcoksAttemptedToSatisfy flag false, so\n              // that it will be tracked and still it will be consider for retry\n              // as analysis was not found targets for storage movement blocks.\n              case FEW_BLOCKS_TARGETS_PAIRED:\n                this.storageMovementsMonitor.add(itemInfo, false);\n                break;\n              case FEW_LOW_REDUNDANCY_BLOCKS:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID \" + trackId\n                      + \" back to retry queue as some of the blocks\"\n                      + \" are low redundant.\");\n                }\n                this.storageMovementNeeded.add(itemInfo);\n                break;\n              // Just clean Xattrs\n              case BLOCKS_TARGET_PAIRING_SKIPPED:\n              case BLOCKS_ALREADY_SATISFIED:\n              default:\n                LOG.info(\"Block analysis skipped or blocks already satisfied\"\n                    + \" with storages. So, Cleaning up the Xattrs.\");\n                storageMovementNeeded.removeItemTrackInfo(itemInfo);\n                break;\n              }\n            } else {\n              // File doesn\u0027t exists (maybe got deleted), remove trackId from\n              // the queue\n              storageMovementNeeded.removeItemTrackInfo(itemInfo);\n            }\n          }\n        }\n        int numLiveDn \u003d namesystem.getFSDirectory().getBlockManager()\n            .getDatanodeManager().getNumLiveDataNodes();\n        if (storageMovementNeeded.size() \u003d\u003d 0\n            || blockCount \u003e (numLiveDn * spsWorkMultiplier)) {\n          Thread.sleep(3000);\n          blockCount \u003d 0L;\n        }\n      } catch (Throwable t) {\n        handleException(t);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/StoragePolicySatisfier.java",
      "extendedDetails": {}
    },
    "7ea24fc06c081e2ba6f5f66d212abb14b80c9064": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12225: [SPS]: Optimize extended attributes for tracking SPS movements. Contributed by Surendra Singh Lilhore.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "7ea24fc06c081e2ba6f5f66d212abb14b80c9064",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "0e820f16af309cc8476edba448dd548686431133",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,54 +1,59 @@\n   public void run() {\n     while (namesystem.isRunning() \u0026\u0026 isRunning) {\n       try {\n         if (!namesystem.isInSafeMode()) {\n-          Long blockCollectionID \u003d storageMovementNeeded.get();\n-          if (blockCollectionID !\u003d null) {\n+          ItemInfo itemInfo \u003d storageMovementNeeded.get();\n+          if (itemInfo !\u003d null) {\n+            long trackId \u003d itemInfo.getTrackId();\n             BlockCollection blockCollection \u003d\n-                namesystem.getBlockCollection(blockCollectionID);\n+                namesystem.getBlockCollection(trackId);\n             // Check blockCollectionId existence.\n             if (blockCollection !\u003d null) {\n               BlocksMovingAnalysisStatus status \u003d\n                   analyseBlocksStorageMovementsAndAssignToDN(blockCollection);\n               switch (status) {\n               // Just add to monitor, so it will be retried after timeout\n               case ANALYSIS_SKIPPED_FOR_RETRY:\n                 // Just add to monitor, so it will be tracked for result and\n                 // be removed on successful storage movement result.\n               case ALL_BLOCKS_TARGETS_PAIRED:\n-                this.storageMovementsMonitor.add(blockCollectionID, true);\n+                this.storageMovementsMonitor.add(itemInfo, true);\n                 break;\n               // Add to monitor with allBlcoksAttemptedToSatisfy flag false, so\n               // that it will be tracked and still it will be consider for retry\n               // as analysis was not found targets for storage movement blocks.\n               case FEW_BLOCKS_TARGETS_PAIRED:\n-                this.storageMovementsMonitor.add(blockCollectionID, false);\n+                this.storageMovementsMonitor.add(itemInfo, false);\n                 break;\n               case FEW_LOW_REDUNDANCY_BLOCKS:\n                 if (LOG.isDebugEnabled()) {\n-                  LOG.debug(\"Adding trackID \" + blockCollectionID\n+                  LOG.debug(\"Adding trackID \" + trackId\n                       + \" back to retry queue as some of the blocks\"\n                       + \" are low redundant.\");\n                 }\n-                this.storageMovementNeeded.add(blockCollectionID);\n+                this.storageMovementNeeded.add(itemInfo);\n                 break;\n               // Just clean Xattrs\n               case BLOCKS_TARGET_PAIRING_SKIPPED:\n               case BLOCKS_ALREADY_SATISFIED:\n               default:\n                 LOG.info(\"Block analysis skipped or blocks already satisfied\"\n                     + \" with storages. So, Cleaning up the Xattrs.\");\n-                postBlkStorageMovementCleanup(blockCollectionID);\n+                storageMovementNeeded.removeItemTrackInfo(itemInfo);\n                 break;\n               }\n+            } else {\n+              // File doesn\u0027t exists (maybe got deleted), remove trackId from\n+              // the queue\n+              storageMovementNeeded.removeItemTrackInfo(itemInfo);\n             }\n           }\n         }\n         // TODO: We can think to make this as configurable later, how frequently\n         // we want to check block movements.\n         Thread.sleep(3000);\n       } catch (Throwable t) {\n         handleException(t);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run() {\n    while (namesystem.isRunning() \u0026\u0026 isRunning) {\n      try {\n        if (!namesystem.isInSafeMode()) {\n          ItemInfo itemInfo \u003d storageMovementNeeded.get();\n          if (itemInfo !\u003d null) {\n            long trackId \u003d itemInfo.getTrackId();\n            BlockCollection blockCollection \u003d\n                namesystem.getBlockCollection(trackId);\n            // Check blockCollectionId existence.\n            if (blockCollection !\u003d null) {\n              BlocksMovingAnalysisStatus status \u003d\n                  analyseBlocksStorageMovementsAndAssignToDN(blockCollection);\n              switch (status) {\n              // Just add to monitor, so it will be retried after timeout\n              case ANALYSIS_SKIPPED_FOR_RETRY:\n                // Just add to monitor, so it will be tracked for result and\n                // be removed on successful storage movement result.\n              case ALL_BLOCKS_TARGETS_PAIRED:\n                this.storageMovementsMonitor.add(itemInfo, true);\n                break;\n              // Add to monitor with allBlcoksAttemptedToSatisfy flag false, so\n              // that it will be tracked and still it will be consider for retry\n              // as analysis was not found targets for storage movement blocks.\n              case FEW_BLOCKS_TARGETS_PAIRED:\n                this.storageMovementsMonitor.add(itemInfo, false);\n                break;\n              case FEW_LOW_REDUNDANCY_BLOCKS:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID \" + trackId\n                      + \" back to retry queue as some of the blocks\"\n                      + \" are low redundant.\");\n                }\n                this.storageMovementNeeded.add(itemInfo);\n                break;\n              // Just clean Xattrs\n              case BLOCKS_TARGET_PAIRING_SKIPPED:\n              case BLOCKS_ALREADY_SATISFIED:\n              default:\n                LOG.info(\"Block analysis skipped or blocks already satisfied\"\n                    + \" with storages. So, Cleaning up the Xattrs.\");\n                storageMovementNeeded.removeItemTrackInfo(itemInfo);\n                break;\n              }\n            } else {\n              // File doesn\u0027t exists (maybe got deleted), remove trackId from\n              // the queue\n              storageMovementNeeded.removeItemTrackInfo(itemInfo);\n            }\n          }\n        }\n        // TODO: We can think to make this as configurable later, how frequently\n        // we want to check block movements.\n        Thread.sleep(3000);\n      } catch (Throwable t) {\n        handleException(t);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/StoragePolicySatisfier.java",
      "extendedDetails": {}
    },
    "5eb24ef7e7b8fb61a5f5b88bae3596b30aaeb60b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11264: [SPS]: Double checks to ensure that SPS/Mover are not running together. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "5eb24ef7e7b8fb61a5f5b88bae3596b30aaeb60b",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "0b360b16ab8759e3db606ada3420f4e2f56235f3",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,84 +1,54 @@\n   public void run() {\n-    boolean isMoverRunning \u003d !checkIfMoverRunning();\n-    synchronized (this) {\n-      isRunning \u003d isMoverRunning;\n-      if (!isRunning) {\n-        // Stopping monitor thread and clearing queues as well\n-        this.clearQueues();\n-        this.storageMovementsMonitor.stopGracefully();\n-        LOG.error(\n-            \"Stopping StoragePolicySatisfier thread \" + \"as Mover ID file \"\n-                + HdfsServerConstants.MOVER_ID_PATH.toString()\n-                + \" been opened. Maybe a Mover instance is running!\");\n-        return;\n-      }\n-    }\n     while (namesystem.isRunning() \u0026\u0026 isRunning) {\n       try {\n         if (!namesystem.isInSafeMode()) {\n           Long blockCollectionID \u003d storageMovementNeeded.get();\n           if (blockCollectionID !\u003d null) {\n             BlockCollection blockCollection \u003d\n                 namesystem.getBlockCollection(blockCollectionID);\n             // Check blockCollectionId existence.\n             if (blockCollection !\u003d null) {\n               BlocksMovingAnalysisStatus status \u003d\n                   analyseBlocksStorageMovementsAndAssignToDN(blockCollection);\n               switch (status) {\n               // Just add to monitor, so it will be retried after timeout\n               case ANALYSIS_SKIPPED_FOR_RETRY:\n                 // Just add to monitor, so it will be tracked for result and\n                 // be removed on successful storage movement result.\n               case ALL_BLOCKS_TARGETS_PAIRED:\n                 this.storageMovementsMonitor.add(blockCollectionID, true);\n                 break;\n               // Add to monitor with allBlcoksAttemptedToSatisfy flag false, so\n               // that it will be tracked and still it will be consider for retry\n               // as analysis was not found targets for storage movement blocks.\n               case FEW_BLOCKS_TARGETS_PAIRED:\n                 this.storageMovementsMonitor.add(blockCollectionID, false);\n                 break;\n               case FEW_LOW_REDUNDANCY_BLOCKS:\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(\"Adding trackID \" + blockCollectionID\n                       + \" back to retry queue as some of the blocks\"\n                       + \" are low redundant.\");\n                 }\n                 this.storageMovementNeeded.add(blockCollectionID);\n                 break;\n               // Just clean Xattrs\n               case BLOCKS_TARGET_PAIRING_SKIPPED:\n               case BLOCKS_ALREADY_SATISFIED:\n               default:\n                 LOG.info(\"Block analysis skipped or blocks already satisfied\"\n                     + \" with storages. So, Cleaning up the Xattrs.\");\n                 postBlkStorageMovementCleanup(blockCollectionID);\n                 break;\n               }\n             }\n           }\n         }\n         // TODO: We can think to make this as configurable later, how frequently\n         // we want to check block movements.\n         Thread.sleep(3000);\n       } catch (Throwable t) {\n-        synchronized (this) {\n-          isRunning \u003d false;\n-          // Stopping monitor thread and clearing queues as well\n-          this.clearQueues();\n-          this.storageMovementsMonitor.stopGracefully();\n-        }\n-        if (!namesystem.isRunning()) {\n-          LOG.info(\"Stopping StoragePolicySatisfier.\");\n-          if (!(t instanceof InterruptedException)) {\n-            LOG.info(\"StoragePolicySatisfier received an exception\"\n-                + \" while shutting down.\", t);\n-          }\n-          break;\n-        }\n-        LOG.error(\"StoragePolicySatisfier thread received runtime exception. \"\n-            + \"Stopping Storage policy satisfier work\", t);\n-        break;\n+        handleException(t);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run() {\n    while (namesystem.isRunning() \u0026\u0026 isRunning) {\n      try {\n        if (!namesystem.isInSafeMode()) {\n          Long blockCollectionID \u003d storageMovementNeeded.get();\n          if (blockCollectionID !\u003d null) {\n            BlockCollection blockCollection \u003d\n                namesystem.getBlockCollection(blockCollectionID);\n            // Check blockCollectionId existence.\n            if (blockCollection !\u003d null) {\n              BlocksMovingAnalysisStatus status \u003d\n                  analyseBlocksStorageMovementsAndAssignToDN(blockCollection);\n              switch (status) {\n              // Just add to monitor, so it will be retried after timeout\n              case ANALYSIS_SKIPPED_FOR_RETRY:\n                // Just add to monitor, so it will be tracked for result and\n                // be removed on successful storage movement result.\n              case ALL_BLOCKS_TARGETS_PAIRED:\n                this.storageMovementsMonitor.add(blockCollectionID, true);\n                break;\n              // Add to monitor with allBlcoksAttemptedToSatisfy flag false, so\n              // that it will be tracked and still it will be consider for retry\n              // as analysis was not found targets for storage movement blocks.\n              case FEW_BLOCKS_TARGETS_PAIRED:\n                this.storageMovementsMonitor.add(blockCollectionID, false);\n                break;\n              case FEW_LOW_REDUNDANCY_BLOCKS:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID \" + blockCollectionID\n                      + \" back to retry queue as some of the blocks\"\n                      + \" are low redundant.\");\n                }\n                this.storageMovementNeeded.add(blockCollectionID);\n                break;\n              // Just clean Xattrs\n              case BLOCKS_TARGET_PAIRING_SKIPPED:\n              case BLOCKS_ALREADY_SATISFIED:\n              default:\n                LOG.info(\"Block analysis skipped or blocks already satisfied\"\n                    + \" with storages. So, Cleaning up the Xattrs.\");\n                postBlkStorageMovementCleanup(blockCollectionID);\n                break;\n              }\n            }\n          }\n        }\n        // TODO: We can think to make this as configurable later, how frequently\n        // we want to check block movements.\n        Thread.sleep(3000);\n      } catch (Throwable t) {\n        handleException(t);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/StoragePolicySatisfier.java",
      "extendedDetails": {}
    },
    "0b360b16ab8759e3db606ada3420f4e2f56235f3": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11965: [SPS]: Should give chance to satisfy the low redundant blocks before removing the xattr. Contributed by Surendra Singh Lilhore.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "0b360b16ab8759e3db606ada3420f4e2f56235f3",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:05 AM",
      "commitNameOld": "20f9c623360d8ec534f8ddb0b993b4363a359e89",
      "commitAuthorOld": "Rakesh Radhakrishnan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,76 +1,84 @@\n   public void run() {\n     boolean isMoverRunning \u003d !checkIfMoverRunning();\n     synchronized (this) {\n       isRunning \u003d isMoverRunning;\n       if (!isRunning) {\n         // Stopping monitor thread and clearing queues as well\n         this.clearQueues();\n         this.storageMovementsMonitor.stopGracefully();\n         LOG.error(\n             \"Stopping StoragePolicySatisfier thread \" + \"as Mover ID file \"\n                 + HdfsServerConstants.MOVER_ID_PATH.toString()\n                 + \" been opened. Maybe a Mover instance is running!\");\n         return;\n       }\n     }\n     while (namesystem.isRunning() \u0026\u0026 isRunning) {\n       try {\n         if (!namesystem.isInSafeMode()) {\n           Long blockCollectionID \u003d storageMovementNeeded.get();\n           if (blockCollectionID !\u003d null) {\n             BlockCollection blockCollection \u003d\n                 namesystem.getBlockCollection(blockCollectionID);\n             // Check blockCollectionId existence.\n             if (blockCollection !\u003d null) {\n               BlocksMovingAnalysisStatus status \u003d\n                   analyseBlocksStorageMovementsAndAssignToDN(blockCollection);\n               switch (status) {\n               // Just add to monitor, so it will be retried after timeout\n               case ANALYSIS_SKIPPED_FOR_RETRY:\n                 // Just add to monitor, so it will be tracked for result and\n                 // be removed on successful storage movement result.\n               case ALL_BLOCKS_TARGETS_PAIRED:\n                 this.storageMovementsMonitor.add(blockCollectionID, true);\n                 break;\n               // Add to monitor with allBlcoksAttemptedToSatisfy flag false, so\n               // that it will be tracked and still it will be consider for retry\n               // as analysis was not found targets for storage movement blocks.\n               case FEW_BLOCKS_TARGETS_PAIRED:\n                 this.storageMovementsMonitor.add(blockCollectionID, false);\n                 break;\n+              case FEW_LOW_REDUNDANCY_BLOCKS:\n+                if (LOG.isDebugEnabled()) {\n+                  LOG.debug(\"Adding trackID \" + blockCollectionID\n+                      + \" back to retry queue as some of the blocks\"\n+                      + \" are low redundant.\");\n+                }\n+                this.storageMovementNeeded.add(blockCollectionID);\n+                break;\n               // Just clean Xattrs\n               case BLOCKS_TARGET_PAIRING_SKIPPED:\n               case BLOCKS_ALREADY_SATISFIED:\n               default:\n                 LOG.info(\"Block analysis skipped or blocks already satisfied\"\n                     + \" with storages. So, Cleaning up the Xattrs.\");\n                 postBlkStorageMovementCleanup(blockCollectionID);\n                 break;\n               }\n             }\n           }\n         }\n         // TODO: We can think to make this as configurable later, how frequently\n         // we want to check block movements.\n         Thread.sleep(3000);\n       } catch (Throwable t) {\n         synchronized (this) {\n           isRunning \u003d false;\n           // Stopping monitor thread and clearing queues as well\n           this.clearQueues();\n           this.storageMovementsMonitor.stopGracefully();\n         }\n         if (!namesystem.isRunning()) {\n           LOG.info(\"Stopping StoragePolicySatisfier.\");\n           if (!(t instanceof InterruptedException)) {\n             LOG.info(\"StoragePolicySatisfier received an exception\"\n                 + \" while shutting down.\", t);\n           }\n           break;\n         }\n         LOG.error(\"StoragePolicySatisfier thread received runtime exception. \"\n             + \"Stopping Storage policy satisfier work\", t);\n         break;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run() {\n    boolean isMoverRunning \u003d !checkIfMoverRunning();\n    synchronized (this) {\n      isRunning \u003d isMoverRunning;\n      if (!isRunning) {\n        // Stopping monitor thread and clearing queues as well\n        this.clearQueues();\n        this.storageMovementsMonitor.stopGracefully();\n        LOG.error(\n            \"Stopping StoragePolicySatisfier thread \" + \"as Mover ID file \"\n                + HdfsServerConstants.MOVER_ID_PATH.toString()\n                + \" been opened. Maybe a Mover instance is running!\");\n        return;\n      }\n    }\n    while (namesystem.isRunning() \u0026\u0026 isRunning) {\n      try {\n        if (!namesystem.isInSafeMode()) {\n          Long blockCollectionID \u003d storageMovementNeeded.get();\n          if (blockCollectionID !\u003d null) {\n            BlockCollection blockCollection \u003d\n                namesystem.getBlockCollection(blockCollectionID);\n            // Check blockCollectionId existence.\n            if (blockCollection !\u003d null) {\n              BlocksMovingAnalysisStatus status \u003d\n                  analyseBlocksStorageMovementsAndAssignToDN(blockCollection);\n              switch (status) {\n              // Just add to monitor, so it will be retried after timeout\n              case ANALYSIS_SKIPPED_FOR_RETRY:\n                // Just add to monitor, so it will be tracked for result and\n                // be removed on successful storage movement result.\n              case ALL_BLOCKS_TARGETS_PAIRED:\n                this.storageMovementsMonitor.add(blockCollectionID, true);\n                break;\n              // Add to monitor with allBlcoksAttemptedToSatisfy flag false, so\n              // that it will be tracked and still it will be consider for retry\n              // as analysis was not found targets for storage movement blocks.\n              case FEW_BLOCKS_TARGETS_PAIRED:\n                this.storageMovementsMonitor.add(blockCollectionID, false);\n                break;\n              case FEW_LOW_REDUNDANCY_BLOCKS:\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"Adding trackID \" + blockCollectionID\n                      + \" back to retry queue as some of the blocks\"\n                      + \" are low redundant.\");\n                }\n                this.storageMovementNeeded.add(blockCollectionID);\n                break;\n              // Just clean Xattrs\n              case BLOCKS_TARGET_PAIRING_SKIPPED:\n              case BLOCKS_ALREADY_SATISFIED:\n              default:\n                LOG.info(\"Block analysis skipped or blocks already satisfied\"\n                    + \" with storages. So, Cleaning up the Xattrs.\");\n                postBlkStorageMovementCleanup(blockCollectionID);\n                break;\n              }\n            }\n          }\n        }\n        // TODO: We can think to make this as configurable later, how frequently\n        // we want to check block movements.\n        Thread.sleep(3000);\n      } catch (Throwable t) {\n        synchronized (this) {\n          isRunning \u003d false;\n          // Stopping monitor thread and clearing queues as well\n          this.clearQueues();\n          this.storageMovementsMonitor.stopGracefully();\n        }\n        if (!namesystem.isRunning()) {\n          LOG.info(\"Stopping StoragePolicySatisfier.\");\n          if (!(t instanceof InterruptedException)) {\n            LOG.info(\"StoragePolicySatisfier received an exception\"\n                + \" while shutting down.\", t);\n          }\n          break;\n        }\n        LOG.error(\"StoragePolicySatisfier thread received runtime exception. \"\n            + \"Stopping Storage policy satisfier work\", t);\n        break;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/StoragePolicySatisfier.java",
      "extendedDetails": {}
    },
    "6fe6c549e8226b4893f502186f52452dcd9408a2": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11572. [SPS]: SPS should clean Xattrs when no blocks required to satisfy for a file. Contributed by Uma Maheswara Rao G\n",
      "commitDate": "12/08/18 3:05 AM",
      "commitName": "6fe6c549e8226b4893f502186f52452dcd9408a2",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "12/08/18 3:05 AM",
      "commitNameOld": "695a402fcad20c711c5d845e0664c43fd6b06286",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,57 +1,76 @@\n   public void run() {\n     boolean isMoverRunning \u003d !checkIfMoverRunning();\n     synchronized (this) {\n       isRunning \u003d isMoverRunning;\n       if (!isRunning) {\n         // Stopping monitor thread and clearing queues as well\n         this.clearQueues();\n         this.storageMovementsMonitor.stopGracefully();\n         LOG.error(\n             \"Stopping StoragePolicySatisfier thread \" + \"as Mover ID file \"\n                 + HdfsServerConstants.MOVER_ID_PATH.toString()\n                 + \" been opened. Maybe a Mover instance is running!\");\n         return;\n       }\n     }\n     while (namesystem.isRunning() \u0026\u0026 isRunning) {\n       try {\n         if (!namesystem.isInSafeMode()) {\n           Long blockCollectionID \u003d storageMovementNeeded.get();\n           if (blockCollectionID !\u003d null) {\n             BlockCollection blockCollection \u003d\n                 namesystem.getBlockCollection(blockCollectionID);\n             // Check blockCollectionId existence.\n             if (blockCollection !\u003d null) {\n-              boolean allBlockLocsAttemptedToSatisfy \u003d\n-                  computeAndAssignStorageMismatchedBlocksToDNs(blockCollection);\n-              this.storageMovementsMonitor\n-                  .add(blockCollectionID, allBlockLocsAttemptedToSatisfy);\n+              BlocksMovingAnalysisStatus status \u003d\n+                  analyseBlocksStorageMovementsAndAssignToDN(blockCollection);\n+              switch (status) {\n+              // Just add to monitor, so it will be retried after timeout\n+              case ANALYSIS_SKIPPED_FOR_RETRY:\n+                // Just add to monitor, so it will be tracked for result and\n+                // be removed on successful storage movement result.\n+              case ALL_BLOCKS_TARGETS_PAIRED:\n+                this.storageMovementsMonitor.add(blockCollectionID, true);\n+                break;\n+              // Add to monitor with allBlcoksAttemptedToSatisfy flag false, so\n+              // that it will be tracked and still it will be consider for retry\n+              // as analysis was not found targets for storage movement blocks.\n+              case FEW_BLOCKS_TARGETS_PAIRED:\n+                this.storageMovementsMonitor.add(blockCollectionID, false);\n+                break;\n+              // Just clean Xattrs\n+              case BLOCKS_TARGET_PAIRING_SKIPPED:\n+              case BLOCKS_ALREADY_SATISFIED:\n+              default:\n+                LOG.info(\"Block analysis skipped or blocks already satisfied\"\n+                    + \" with storages. So, Cleaning up the Xattrs.\");\n+                postBlkStorageMovementCleanup(blockCollectionID);\n+                break;\n+              }\n             }\n           }\n         }\n         // TODO: We can think to make this as configurable later, how frequently\n         // we want to check block movements.\n         Thread.sleep(3000);\n       } catch (Throwable t) {\n         synchronized (this) {\n           isRunning \u003d false;\n           // Stopping monitor thread and clearing queues as well\n           this.clearQueues();\n           this.storageMovementsMonitor.stopGracefully();\n         }\n         if (!namesystem.isRunning()) {\n           LOG.info(\"Stopping StoragePolicySatisfier.\");\n           if (!(t instanceof InterruptedException)) {\n             LOG.info(\"StoragePolicySatisfier received an exception\"\n                 + \" while shutting down.\", t);\n           }\n           break;\n         }\n         LOG.error(\"StoragePolicySatisfier thread received runtime exception. \"\n             + \"Stopping Storage policy satisfier work\", t);\n-        // TODO: Just break for now. Once we implement dynamic start/stop\n-        // option, we can add conditions here when to break/terminate.\n         break;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run() {\n    boolean isMoverRunning \u003d !checkIfMoverRunning();\n    synchronized (this) {\n      isRunning \u003d isMoverRunning;\n      if (!isRunning) {\n        // Stopping monitor thread and clearing queues as well\n        this.clearQueues();\n        this.storageMovementsMonitor.stopGracefully();\n        LOG.error(\n            \"Stopping StoragePolicySatisfier thread \" + \"as Mover ID file \"\n                + HdfsServerConstants.MOVER_ID_PATH.toString()\n                + \" been opened. Maybe a Mover instance is running!\");\n        return;\n      }\n    }\n    while (namesystem.isRunning() \u0026\u0026 isRunning) {\n      try {\n        if (!namesystem.isInSafeMode()) {\n          Long blockCollectionID \u003d storageMovementNeeded.get();\n          if (blockCollectionID !\u003d null) {\n            BlockCollection blockCollection \u003d\n                namesystem.getBlockCollection(blockCollectionID);\n            // Check blockCollectionId existence.\n            if (blockCollection !\u003d null) {\n              BlocksMovingAnalysisStatus status \u003d\n                  analyseBlocksStorageMovementsAndAssignToDN(blockCollection);\n              switch (status) {\n              // Just add to monitor, so it will be retried after timeout\n              case ANALYSIS_SKIPPED_FOR_RETRY:\n                // Just add to monitor, so it will be tracked for result and\n                // be removed on successful storage movement result.\n              case ALL_BLOCKS_TARGETS_PAIRED:\n                this.storageMovementsMonitor.add(blockCollectionID, true);\n                break;\n              // Add to monitor with allBlcoksAttemptedToSatisfy flag false, so\n              // that it will be tracked and still it will be consider for retry\n              // as analysis was not found targets for storage movement blocks.\n              case FEW_BLOCKS_TARGETS_PAIRED:\n                this.storageMovementsMonitor.add(blockCollectionID, false);\n                break;\n              // Just clean Xattrs\n              case BLOCKS_TARGET_PAIRING_SKIPPED:\n              case BLOCKS_ALREADY_SATISFIED:\n              default:\n                LOG.info(\"Block analysis skipped or blocks already satisfied\"\n                    + \" with storages. So, Cleaning up the Xattrs.\");\n                postBlkStorageMovementCleanup(blockCollectionID);\n                break;\n              }\n            }\n          }\n        }\n        // TODO: We can think to make this as configurable later, how frequently\n        // we want to check block movements.\n        Thread.sleep(3000);\n      } catch (Throwable t) {\n        synchronized (this) {\n          isRunning \u003d false;\n          // Stopping monitor thread and clearing queues as well\n          this.clearQueues();\n          this.storageMovementsMonitor.stopGracefully();\n        }\n        if (!namesystem.isRunning()) {\n          LOG.info(\"Stopping StoragePolicySatisfier.\");\n          if (!(t instanceof InterruptedException)) {\n            LOG.info(\"StoragePolicySatisfier received an exception\"\n                + \" while shutting down.\", t);\n          }\n          break;\n        }\n        LOG.error(\"StoragePolicySatisfier thread received runtime exception. \"\n            + \"Stopping Storage policy satisfier work\", t);\n        break;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/StoragePolicySatisfier.java",
      "extendedDetails": {}
    },
    "11a08a7e8f727449f17d1e31855996353b2975fe": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11338: [SPS]: Fix timeout issue in unit tests caused by longger NN down time. Contributed by Wei Zhou and Rakesh R\n",
      "commitDate": "12/08/18 3:05 AM",
      "commitName": "11a08a7e8f727449f17d1e31855996353b2975fe",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:05 AM",
      "commitNameOld": "c00be444634b34eb8d29cdd723397a9a2a6392d6",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,57 +1,57 @@\n   public void run() {\n     boolean isMoverRunning \u003d !checkIfMoverRunning();\n     synchronized (this) {\n       isRunning \u003d isMoverRunning;\n       if (!isRunning) {\n         // Stopping monitor thread and clearing queues as well\n         this.clearQueues();\n-        this.storageMovementsMonitor.stop();\n+        this.storageMovementsMonitor.stopGracefully();\n         LOG.error(\n             \"Stopping StoragePolicySatisfier thread \" + \"as Mover ID file \"\n                 + HdfsServerConstants.MOVER_ID_PATH.toString()\n                 + \" been opened. Maybe a Mover instance is running!\");\n         return;\n       }\n     }\n     while (namesystem.isRunning() \u0026\u0026 isRunning) {\n       try {\n         if (!namesystem.isInSafeMode()) {\n           Long blockCollectionID \u003d storageMovementNeeded.get();\n           if (blockCollectionID !\u003d null) {\n             BlockCollection blockCollection \u003d\n                 namesystem.getBlockCollection(blockCollectionID);\n             // Check blockCollectionId existence.\n             if (blockCollection !\u003d null) {\n               boolean allBlockLocsAttemptedToSatisfy \u003d\n                   computeAndAssignStorageMismatchedBlocksToDNs(blockCollection);\n               this.storageMovementsMonitor\n                   .add(blockCollectionID, allBlockLocsAttemptedToSatisfy);\n             }\n           }\n         }\n         // TODO: We can think to make this as configurable later, how frequently\n         // we want to check block movements.\n         Thread.sleep(3000);\n       } catch (Throwable t) {\n         synchronized (this) {\n           isRunning \u003d false;\n           // Stopping monitor thread and clearing queues as well\n           this.clearQueues();\n-          this.storageMovementsMonitor.stop();\n+          this.storageMovementsMonitor.stopGracefully();\n         }\n         if (!namesystem.isRunning()) {\n           LOG.info(\"Stopping StoragePolicySatisfier.\");\n           if (!(t instanceof InterruptedException)) {\n             LOG.info(\"StoragePolicySatisfier received an exception\"\n                 + \" while shutting down.\", t);\n           }\n           break;\n         }\n         LOG.error(\"StoragePolicySatisfier thread received runtime exception. \"\n             + \"Stopping Storage policy satisfier work\", t);\n         // TODO: Just break for now. Once we implement dynamic start/stop\n         // option, we can add conditions here when to break/terminate.\n         break;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run() {\n    boolean isMoverRunning \u003d !checkIfMoverRunning();\n    synchronized (this) {\n      isRunning \u003d isMoverRunning;\n      if (!isRunning) {\n        // Stopping monitor thread and clearing queues as well\n        this.clearQueues();\n        this.storageMovementsMonitor.stopGracefully();\n        LOG.error(\n            \"Stopping StoragePolicySatisfier thread \" + \"as Mover ID file \"\n                + HdfsServerConstants.MOVER_ID_PATH.toString()\n                + \" been opened. Maybe a Mover instance is running!\");\n        return;\n      }\n    }\n    while (namesystem.isRunning() \u0026\u0026 isRunning) {\n      try {\n        if (!namesystem.isInSafeMode()) {\n          Long blockCollectionID \u003d storageMovementNeeded.get();\n          if (blockCollectionID !\u003d null) {\n            BlockCollection blockCollection \u003d\n                namesystem.getBlockCollection(blockCollectionID);\n            // Check blockCollectionId existence.\n            if (blockCollection !\u003d null) {\n              boolean allBlockLocsAttemptedToSatisfy \u003d\n                  computeAndAssignStorageMismatchedBlocksToDNs(blockCollection);\n              this.storageMovementsMonitor\n                  .add(blockCollectionID, allBlockLocsAttemptedToSatisfy);\n            }\n          }\n        }\n        // TODO: We can think to make this as configurable later, how frequently\n        // we want to check block movements.\n        Thread.sleep(3000);\n      } catch (Throwable t) {\n        synchronized (this) {\n          isRunning \u003d false;\n          // Stopping monitor thread and clearing queues as well\n          this.clearQueues();\n          this.storageMovementsMonitor.stopGracefully();\n        }\n        if (!namesystem.isRunning()) {\n          LOG.info(\"Stopping StoragePolicySatisfier.\");\n          if (!(t instanceof InterruptedException)) {\n            LOG.info(\"StoragePolicySatisfier received an exception\"\n                + \" while shutting down.\", t);\n          }\n          break;\n        }\n        LOG.error(\"StoragePolicySatisfier thread received runtime exception. \"\n            + \"Stopping Storage policy satisfier work\", t);\n        // TODO: Just break for now. Once we implement dynamic start/stop\n        // option, we can add conditions here when to break/terminate.\n        break;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/StoragePolicySatisfier.java",
      "extendedDetails": {}
    },
    "9b15f5418dbb49de57922f00858cb6fb0b61826e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11239: [SPS]: Check Mover file ID lease also to determine whether Mover is running. Contributed by Wei Zhou\n",
      "commitDate": "12/08/18 3:05 AM",
      "commitName": "9b15f5418dbb49de57922f00858cb6fb0b61826e",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "12/08/18 3:05 AM",
      "commitNameOld": "e34331c31d68cb22891db48011db5b36ad178af1",
      "commitAuthorOld": "Rakesh Radhakrishnan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,56 +1,57 @@\n   public void run() {\n     boolean isMoverRunning \u003d !checkIfMoverRunning();\n     synchronized (this) {\n       isRunning \u003d isMoverRunning;\n       if (!isRunning) {\n         // Stopping monitor thread and clearing queues as well\n         this.clearQueues();\n         this.storageMovementsMonitor.stop();\n         LOG.error(\n             \"Stopping StoragePolicySatisfier thread \" + \"as Mover ID file \"\n-                + HdfsServerConstants.MOVER_ID_PATH.toString() + \" exists\");\n+                + HdfsServerConstants.MOVER_ID_PATH.toString()\n+                + \" been opened. Maybe a Mover instance is running!\");\n         return;\n       }\n     }\n     while (namesystem.isRunning() \u0026\u0026 isRunning) {\n       try {\n         if (!namesystem.isInSafeMode()) {\n           Long blockCollectionID \u003d storageMovementNeeded.get();\n           if (blockCollectionID !\u003d null) {\n             BlockCollection blockCollection \u003d\n                 namesystem.getBlockCollection(blockCollectionID);\n             // Check blockCollectionId existence.\n             if (blockCollection !\u003d null) {\n               boolean allBlockLocsAttemptedToSatisfy \u003d\n                   computeAndAssignStorageMismatchedBlocksToDNs(blockCollection);\n               this.storageMovementsMonitor\n                   .add(blockCollectionID, allBlockLocsAttemptedToSatisfy);\n             }\n           }\n         }\n         // TODO: We can think to make this as configurable later, how frequently\n         // we want to check block movements.\n         Thread.sleep(3000);\n       } catch (Throwable t) {\n         synchronized (this) {\n           isRunning \u003d false;\n           // Stopping monitor thread and clearing queues as well\n           this.clearQueues();\n           this.storageMovementsMonitor.stop();\n         }\n         if (!namesystem.isRunning()) {\n           LOG.info(\"Stopping StoragePolicySatisfier.\");\n           if (!(t instanceof InterruptedException)) {\n             LOG.info(\"StoragePolicySatisfier received an exception\"\n                 + \" while shutting down.\", t);\n           }\n           break;\n         }\n         LOG.error(\"StoragePolicySatisfier thread received runtime exception. \"\n             + \"Stopping Storage policy satisfier work\", t);\n         // TODO: Just break for now. Once we implement dynamic start/stop\n         // option, we can add conditions here when to break/terminate.\n         break;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run() {\n    boolean isMoverRunning \u003d !checkIfMoverRunning();\n    synchronized (this) {\n      isRunning \u003d isMoverRunning;\n      if (!isRunning) {\n        // Stopping monitor thread and clearing queues as well\n        this.clearQueues();\n        this.storageMovementsMonitor.stop();\n        LOG.error(\n            \"Stopping StoragePolicySatisfier thread \" + \"as Mover ID file \"\n                + HdfsServerConstants.MOVER_ID_PATH.toString()\n                + \" been opened. Maybe a Mover instance is running!\");\n        return;\n      }\n    }\n    while (namesystem.isRunning() \u0026\u0026 isRunning) {\n      try {\n        if (!namesystem.isInSafeMode()) {\n          Long blockCollectionID \u003d storageMovementNeeded.get();\n          if (blockCollectionID !\u003d null) {\n            BlockCollection blockCollection \u003d\n                namesystem.getBlockCollection(blockCollectionID);\n            // Check blockCollectionId existence.\n            if (blockCollection !\u003d null) {\n              boolean allBlockLocsAttemptedToSatisfy \u003d\n                  computeAndAssignStorageMismatchedBlocksToDNs(blockCollection);\n              this.storageMovementsMonitor\n                  .add(blockCollectionID, allBlockLocsAttemptedToSatisfy);\n            }\n          }\n        }\n        // TODO: We can think to make this as configurable later, how frequently\n        // we want to check block movements.\n        Thread.sleep(3000);\n      } catch (Throwable t) {\n        synchronized (this) {\n          isRunning \u003d false;\n          // Stopping monitor thread and clearing queues as well\n          this.clearQueues();\n          this.storageMovementsMonitor.stop();\n        }\n        if (!namesystem.isRunning()) {\n          LOG.info(\"Stopping StoragePolicySatisfier.\");\n          if (!(t instanceof InterruptedException)) {\n            LOG.info(\"StoragePolicySatisfier received an exception\"\n                + \" while shutting down.\", t);\n          }\n          break;\n        }\n        LOG.error(\"StoragePolicySatisfier thread received runtime exception. \"\n            + \"Stopping Storage policy satisfier work\", t);\n        // TODO: Just break for now. Once we implement dynamic start/stop\n        // option, we can add conditions here when to break/terminate.\n        break;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/StoragePolicySatisfier.java",
      "extendedDetails": {}
    },
    "6215e35bb633706753a464ad3e8633366e6a10b2": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11150: [SPS]: Provide persistence when satisfying storage policy. Contributed by Yuanbo Liu\n",
      "commitDate": "12/08/18 3:05 AM",
      "commitName": "6215e35bb633706753a464ad3e8633366e6a10b2",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:05 AM",
      "commitNameOld": "df2b551e79c9e5d8bdd981c48be52bae5f0d9a82",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,54 +1,56 @@\n   public void run() {\n     boolean isMoverRunning \u003d !checkIfMoverRunning();\n     synchronized (this) {\n       isRunning \u003d isMoverRunning;\n       if (!isRunning) {\n         // Stopping monitor thread and clearing queues as well\n         this.clearQueues();\n         this.storageMovementsMonitor.stop();\n         LOG.error(\n             \"Stopping StoragePolicySatisfier thread \" + \"as Mover ID file \"\n                 + HdfsServerConstants.MOVER_ID_PATH.toString() + \" exists\");\n         return;\n       }\n     }\n     while (namesystem.isRunning() \u0026\u0026 isRunning) {\n       try {\n-        Long blockCollectionID \u003d storageMovementNeeded.get();\n-        if (blockCollectionID !\u003d null) {\n-          BlockCollection blockCollection \u003d\n-              namesystem.getBlockCollection(blockCollectionID);\n-          // Check blockCollectionId existence.\n-          if (blockCollection !\u003d null) {\n-            boolean allBlockLocsAttemptedToSatisfy \u003d\n-                computeAndAssignStorageMismatchedBlocksToDNs(blockCollection);\n-            this.storageMovementsMonitor.add(blockCollectionID,\n-                allBlockLocsAttemptedToSatisfy);\n+        if (!namesystem.isInSafeMode()) {\n+          Long blockCollectionID \u003d storageMovementNeeded.get();\n+          if (blockCollectionID !\u003d null) {\n+            BlockCollection blockCollection \u003d\n+                namesystem.getBlockCollection(blockCollectionID);\n+            // Check blockCollectionId existence.\n+            if (blockCollection !\u003d null) {\n+              boolean allBlockLocsAttemptedToSatisfy \u003d\n+                  computeAndAssignStorageMismatchedBlocksToDNs(blockCollection);\n+              this.storageMovementsMonitor\n+                  .add(blockCollectionID, allBlockLocsAttemptedToSatisfy);\n+            }\n           }\n         }\n         // TODO: We can think to make this as configurable later, how frequently\n         // we want to check block movements.\n         Thread.sleep(3000);\n       } catch (Throwable t) {\n         synchronized (this) {\n           isRunning \u003d false;\n           // Stopping monitor thread and clearing queues as well\n           this.clearQueues();\n           this.storageMovementsMonitor.stop();\n         }\n         if (!namesystem.isRunning()) {\n           LOG.info(\"Stopping StoragePolicySatisfier.\");\n           if (!(t instanceof InterruptedException)) {\n             LOG.info(\"StoragePolicySatisfier received an exception\"\n                 + \" while shutting down.\", t);\n           }\n           break;\n         }\n         LOG.error(\"StoragePolicySatisfier thread received runtime exception. \"\n             + \"Stopping Storage policy satisfier work\", t);\n         // TODO: Just break for now. Once we implement dynamic start/stop\n         // option, we can add conditions here when to break/terminate.\n         break;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run() {\n    boolean isMoverRunning \u003d !checkIfMoverRunning();\n    synchronized (this) {\n      isRunning \u003d isMoverRunning;\n      if (!isRunning) {\n        // Stopping monitor thread and clearing queues as well\n        this.clearQueues();\n        this.storageMovementsMonitor.stop();\n        LOG.error(\n            \"Stopping StoragePolicySatisfier thread \" + \"as Mover ID file \"\n                + HdfsServerConstants.MOVER_ID_PATH.toString() + \" exists\");\n        return;\n      }\n    }\n    while (namesystem.isRunning() \u0026\u0026 isRunning) {\n      try {\n        if (!namesystem.isInSafeMode()) {\n          Long blockCollectionID \u003d storageMovementNeeded.get();\n          if (blockCollectionID !\u003d null) {\n            BlockCollection blockCollection \u003d\n                namesystem.getBlockCollection(blockCollectionID);\n            // Check blockCollectionId existence.\n            if (blockCollection !\u003d null) {\n              boolean allBlockLocsAttemptedToSatisfy \u003d\n                  computeAndAssignStorageMismatchedBlocksToDNs(blockCollection);\n              this.storageMovementsMonitor\n                  .add(blockCollectionID, allBlockLocsAttemptedToSatisfy);\n            }\n          }\n        }\n        // TODO: We can think to make this as configurable later, how frequently\n        // we want to check block movements.\n        Thread.sleep(3000);\n      } catch (Throwable t) {\n        synchronized (this) {\n          isRunning \u003d false;\n          // Stopping monitor thread and clearing queues as well\n          this.clearQueues();\n          this.storageMovementsMonitor.stop();\n        }\n        if (!namesystem.isRunning()) {\n          LOG.info(\"Stopping StoragePolicySatisfier.\");\n          if (!(t instanceof InterruptedException)) {\n            LOG.info(\"StoragePolicySatisfier received an exception\"\n                + \" while shutting down.\", t);\n          }\n          break;\n        }\n        LOG.error(\"StoragePolicySatisfier thread received runtime exception. \"\n            + \"Stopping Storage policy satisfier work\", t);\n        // TODO: Just break for now. Once we implement dynamic start/stop\n        // option, we can add conditions here when to break/terminate.\n        break;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/StoragePolicySatisfier.java",
      "extendedDetails": {}
    },
    "b7bed9f00a25bcad6f9c3543f5a1fb0a1f23b0e9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11248: [SPS]: Handle partial block location movements. Contributed by Rakesh R\n",
      "commitDate": "12/08/18 3:05 AM",
      "commitName": "b7bed9f00a25bcad6f9c3543f5a1fb0a1f23b0e9",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:05 AM",
      "commitNameOld": "5179d99b7e1faeac1ce041967480115913d9f795",
      "commitAuthorOld": "Rakesh Radhakrishnan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,47 +1,54 @@\n   public void run() {\n     boolean isMoverRunning \u003d !checkIfMoverRunning();\n     synchronized (this) {\n       isRunning \u003d isMoverRunning;\n       if (!isRunning) {\n         // Stopping monitor thread and clearing queues as well\n         this.clearQueues();\n         this.storageMovementsMonitor.stop();\n         LOG.error(\n             \"Stopping StoragePolicySatisfier thread \" + \"as Mover ID file \"\n                 + HdfsServerConstants.MOVER_ID_PATH.toString() + \" exists\");\n         return;\n       }\n     }\n     while (namesystem.isRunning() \u0026\u0026 isRunning) {\n       try {\n         Long blockCollectionID \u003d storageMovementNeeded.get();\n         if (blockCollectionID !\u003d null) {\n-          computeAndAssignStorageMismatchedBlocksToDNs(blockCollectionID);\n-          this.storageMovementsMonitor.add(blockCollectionID);\n+          BlockCollection blockCollection \u003d\n+              namesystem.getBlockCollection(blockCollectionID);\n+          // Check blockCollectionId existence.\n+          if (blockCollection !\u003d null) {\n+            boolean allBlockLocsAttemptedToSatisfy \u003d\n+                computeAndAssignStorageMismatchedBlocksToDNs(blockCollection);\n+            this.storageMovementsMonitor.add(blockCollectionID,\n+                allBlockLocsAttemptedToSatisfy);\n+          }\n         }\n         // TODO: We can think to make this as configurable later, how frequently\n         // we want to check block movements.\n         Thread.sleep(3000);\n       } catch (Throwable t) {\n         synchronized (this) {\n           isRunning \u003d false;\n           // Stopping monitor thread and clearing queues as well\n           this.clearQueues();\n           this.storageMovementsMonitor.stop();\n         }\n         if (!namesystem.isRunning()) {\n           LOG.info(\"Stopping StoragePolicySatisfier.\");\n           if (!(t instanceof InterruptedException)) {\n             LOG.info(\"StoragePolicySatisfier received an exception\"\n                 + \" while shutting down.\", t);\n           }\n           break;\n         }\n         LOG.error(\"StoragePolicySatisfier thread received runtime exception. \"\n             + \"Stopping Storage policy satisfier work\", t);\n         // TODO: Just break for now. Once we implement dynamic start/stop\n         // option, we can add conditions here when to break/terminate.\n         break;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run() {\n    boolean isMoverRunning \u003d !checkIfMoverRunning();\n    synchronized (this) {\n      isRunning \u003d isMoverRunning;\n      if (!isRunning) {\n        // Stopping monitor thread and clearing queues as well\n        this.clearQueues();\n        this.storageMovementsMonitor.stop();\n        LOG.error(\n            \"Stopping StoragePolicySatisfier thread \" + \"as Mover ID file \"\n                + HdfsServerConstants.MOVER_ID_PATH.toString() + \" exists\");\n        return;\n      }\n    }\n    while (namesystem.isRunning() \u0026\u0026 isRunning) {\n      try {\n        Long blockCollectionID \u003d storageMovementNeeded.get();\n        if (blockCollectionID !\u003d null) {\n          BlockCollection blockCollection \u003d\n              namesystem.getBlockCollection(blockCollectionID);\n          // Check blockCollectionId existence.\n          if (blockCollection !\u003d null) {\n            boolean allBlockLocsAttemptedToSatisfy \u003d\n                computeAndAssignStorageMismatchedBlocksToDNs(blockCollection);\n            this.storageMovementsMonitor.add(blockCollectionID,\n                allBlockLocsAttemptedToSatisfy);\n          }\n        }\n        // TODO: We can think to make this as configurable later, how frequently\n        // we want to check block movements.\n        Thread.sleep(3000);\n      } catch (Throwable t) {\n        synchronized (this) {\n          isRunning \u003d false;\n          // Stopping monitor thread and clearing queues as well\n          this.clearQueues();\n          this.storageMovementsMonitor.stop();\n        }\n        if (!namesystem.isRunning()) {\n          LOG.info(\"Stopping StoragePolicySatisfier.\");\n          if (!(t instanceof InterruptedException)) {\n            LOG.info(\"StoragePolicySatisfier received an exception\"\n                + \" while shutting down.\", t);\n          }\n          break;\n        }\n        LOG.error(\"StoragePolicySatisfier thread received runtime exception. \"\n            + \"Stopping Storage policy satisfier work\", t);\n        // TODO: Just break for now. Once we implement dynamic start/stop\n        // option, we can add conditions here when to break/terminate.\n        break;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/StoragePolicySatisfier.java",
      "extendedDetails": {}
    },
    "5179d99b7e1faeac1ce041967480115913d9f795": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11123. [SPS] Make storage policy satisfier daemon work on/off dynamically. Contributed by Uma Maheswara Rao G\n",
      "commitDate": "12/08/18 3:05 AM",
      "commitName": "5179d99b7e1faeac1ce041967480115913d9f795",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "12/08/18 3:05 AM",
      "commitNameOld": "cd5262aba00aa51b905aaac95e201d4d48f2480d",
      "commitAuthorOld": "Rakesh Radhakrishnan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,36 +1,47 @@\n   public void run() {\n-    isRunning \u003d !checkIfMoverRunning();\n-    if (!isRunning) {\n-      LOG.error(\"StoragePolicySatisfier thread stopped \"\n-          + \"as Mover ID file \" + HdfsServerConstants.MOVER_ID_PATH.toString()\n-          + \" exists\");\n-      return;\n+    boolean isMoverRunning \u003d !checkIfMoverRunning();\n+    synchronized (this) {\n+      isRunning \u003d isMoverRunning;\n+      if (!isRunning) {\n+        // Stopping monitor thread and clearing queues as well\n+        this.clearQueues();\n+        this.storageMovementsMonitor.stop();\n+        LOG.error(\n+            \"Stopping StoragePolicySatisfier thread \" + \"as Mover ID file \"\n+                + HdfsServerConstants.MOVER_ID_PATH.toString() + \" exists\");\n+        return;\n+      }\n     }\n-    while (namesystem.isRunning()) {\n+    while (namesystem.isRunning() \u0026\u0026 isRunning) {\n       try {\n         Long blockCollectionID \u003d storageMovementNeeded.get();\n         if (blockCollectionID !\u003d null) {\n           computeAndAssignStorageMismatchedBlocksToDNs(blockCollectionID);\n           this.storageMovementsMonitor.add(blockCollectionID);\n         }\n         // TODO: We can think to make this as configurable later, how frequently\n         // we want to check block movements.\n         Thread.sleep(3000);\n       } catch (Throwable t) {\n-        isRunning \u003d false;\n+        synchronized (this) {\n+          isRunning \u003d false;\n+          // Stopping monitor thread and clearing queues as well\n+          this.clearQueues();\n+          this.storageMovementsMonitor.stop();\n+        }\n         if (!namesystem.isRunning()) {\n           LOG.info(\"Stopping StoragePolicySatisfier.\");\n           if (!(t instanceof InterruptedException)) {\n             LOG.info(\"StoragePolicySatisfier received an exception\"\n                 + \" while shutting down.\", t);\n           }\n           break;\n         }\n         LOG.error(\"StoragePolicySatisfier thread received runtime exception. \"\n             + \"Stopping Storage policy satisfier work\", t);\n         // TODO: Just break for now. Once we implement dynamic start/stop\n         // option, we can add conditions here when to break/terminate.\n         break;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run() {\n    boolean isMoverRunning \u003d !checkIfMoverRunning();\n    synchronized (this) {\n      isRunning \u003d isMoverRunning;\n      if (!isRunning) {\n        // Stopping monitor thread and clearing queues as well\n        this.clearQueues();\n        this.storageMovementsMonitor.stop();\n        LOG.error(\n            \"Stopping StoragePolicySatisfier thread \" + \"as Mover ID file \"\n                + HdfsServerConstants.MOVER_ID_PATH.toString() + \" exists\");\n        return;\n      }\n    }\n    while (namesystem.isRunning() \u0026\u0026 isRunning) {\n      try {\n        Long blockCollectionID \u003d storageMovementNeeded.get();\n        if (blockCollectionID !\u003d null) {\n          computeAndAssignStorageMismatchedBlocksToDNs(blockCollectionID);\n          this.storageMovementsMonitor.add(blockCollectionID);\n        }\n        // TODO: We can think to make this as configurable later, how frequently\n        // we want to check block movements.\n        Thread.sleep(3000);\n      } catch (Throwable t) {\n        synchronized (this) {\n          isRunning \u003d false;\n          // Stopping monitor thread and clearing queues as well\n          this.clearQueues();\n          this.storageMovementsMonitor.stop();\n        }\n        if (!namesystem.isRunning()) {\n          LOG.info(\"Stopping StoragePolicySatisfier.\");\n          if (!(t instanceof InterruptedException)) {\n            LOG.info(\"StoragePolicySatisfier received an exception\"\n                + \" while shutting down.\", t);\n          }\n          break;\n        }\n        LOG.error(\"StoragePolicySatisfier thread received runtime exception. \"\n            + \"Stopping Storage policy satisfier work\", t);\n        // TODO: Just break for now. Once we implement dynamic start/stop\n        // option, we can add conditions here when to break/terminate.\n        break;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/StoragePolicySatisfier.java",
      "extendedDetails": {}
    },
    "cd5262aba00aa51b905aaac95e201d4d48f2480d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10885. [SPS]: Mover tool should not be allowed to run when Storage Policy Satisfier is on. Contributed by Wei Zhou\n",
      "commitDate": "12/08/18 3:05 AM",
      "commitName": "cd5262aba00aa51b905aaac95e201d4d48f2480d",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "12/08/18 3:05 AM",
      "commitNameOld": "b07291e176c489c2eec3da1850b790b8ba691a3e",
      "commitAuthorOld": "Rakesh Radhakrishnan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,36 @@\n   public void run() {\n+    isRunning \u003d !checkIfMoverRunning();\n+    if (!isRunning) {\n+      LOG.error(\"StoragePolicySatisfier thread stopped \"\n+          + \"as Mover ID file \" + HdfsServerConstants.MOVER_ID_PATH.toString()\n+          + \" exists\");\n+      return;\n+    }\n     while (namesystem.isRunning()) {\n       try {\n         Long blockCollectionID \u003d storageMovementNeeded.get();\n         if (blockCollectionID !\u003d null) {\n           computeAndAssignStorageMismatchedBlocksToDNs(blockCollectionID);\n           this.storageMovementsMonitor.add(blockCollectionID);\n         }\n         // TODO: We can think to make this as configurable later, how frequently\n         // we want to check block movements.\n         Thread.sleep(3000);\n       } catch (Throwable t) {\n+        isRunning \u003d false;\n         if (!namesystem.isRunning()) {\n           LOG.info(\"Stopping StoragePolicySatisfier.\");\n           if (!(t instanceof InterruptedException)) {\n             LOG.info(\"StoragePolicySatisfier received an exception\"\n                 + \" while shutting down.\", t);\n           }\n           break;\n         }\n         LOG.error(\"StoragePolicySatisfier thread received runtime exception. \"\n             + \"Stopping Storage policy satisfier work\", t);\n         // TODO: Just break for now. Once we implement dynamic start/stop\n         // option, we can add conditions here when to break/terminate.\n         break;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run() {\n    isRunning \u003d !checkIfMoverRunning();\n    if (!isRunning) {\n      LOG.error(\"StoragePolicySatisfier thread stopped \"\n          + \"as Mover ID file \" + HdfsServerConstants.MOVER_ID_PATH.toString()\n          + \" exists\");\n      return;\n    }\n    while (namesystem.isRunning()) {\n      try {\n        Long blockCollectionID \u003d storageMovementNeeded.get();\n        if (blockCollectionID !\u003d null) {\n          computeAndAssignStorageMismatchedBlocksToDNs(blockCollectionID);\n          this.storageMovementsMonitor.add(blockCollectionID);\n        }\n        // TODO: We can think to make this as configurable later, how frequently\n        // we want to check block movements.\n        Thread.sleep(3000);\n      } catch (Throwable t) {\n        isRunning \u003d false;\n        if (!namesystem.isRunning()) {\n          LOG.info(\"Stopping StoragePolicySatisfier.\");\n          if (!(t instanceof InterruptedException)) {\n            LOG.info(\"StoragePolicySatisfier received an exception\"\n                + \" while shutting down.\", t);\n          }\n          break;\n        }\n        LOG.error(\"StoragePolicySatisfier thread received runtime exception. \"\n            + \"Stopping Storage policy satisfier work\", t);\n        // TODO: Just break for now. Once we implement dynamic start/stop\n        // option, we can add conditions here when to break/terminate.\n        break;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/StoragePolicySatisfier.java",
      "extendedDetails": {}
    },
    "047526b4c27909f78313e1ed6216de85c6137f14": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11029. [SPS]:Provide retry mechanism for the blocks which were failed while moving its storage at DNs. Contributed by Uma Maheswara Rao G\n",
      "commitDate": "12/08/18 3:05 AM",
      "commitName": "047526b4c27909f78313e1ed6216de85c6137f14",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "12/08/18 3:05 AM",
      "commitNameOld": "0f2d1ddc2c41c8db800c58cabb150e71804fe23a",
      "commitAuthorOld": "Rakesh Radhakrishnan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,27 +1,28 @@\n   public void run() {\n     while (namesystem.isRunning()) {\n       try {\n         Long blockCollectionID \u003d storageMovementNeeded.get();\n         if (blockCollectionID !\u003d null) {\n           computeAndAssignStorageMismatchedBlocksToDNs(blockCollectionID);\n+          this.storageMovementsMonitor.add(blockCollectionID);\n         }\n         // TODO: We can think to make this as configurable later, how frequently\n         // we want to check block movements.\n         Thread.sleep(3000);\n       } catch (Throwable t) {\n         if (!namesystem.isRunning()) {\n           LOG.info(\"Stopping StoragePolicySatisfier.\");\n           if (!(t instanceof InterruptedException)) {\n             LOG.info(\"StoragePolicySatisfier received an exception\"\n                 + \" while shutting down.\", t);\n           }\n           break;\n         }\n         LOG.error(\"StoragePolicySatisfier thread received runtime exception. \"\n             + \"Stopping Storage policy satisfier work\", t);\n         // TODO: Just break for now. Once we implement dynamic start/stop\n         // option, we can add conditions here when to break/terminate.\n         break;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run() {\n    while (namesystem.isRunning()) {\n      try {\n        Long blockCollectionID \u003d storageMovementNeeded.get();\n        if (blockCollectionID !\u003d null) {\n          computeAndAssignStorageMismatchedBlocksToDNs(blockCollectionID);\n          this.storageMovementsMonitor.add(blockCollectionID);\n        }\n        // TODO: We can think to make this as configurable later, how frequently\n        // we want to check block movements.\n        Thread.sleep(3000);\n      } catch (Throwable t) {\n        if (!namesystem.isRunning()) {\n          LOG.info(\"Stopping StoragePolicySatisfier.\");\n          if (!(t instanceof InterruptedException)) {\n            LOG.info(\"StoragePolicySatisfier received an exception\"\n                + \" while shutting down.\", t);\n          }\n          break;\n        }\n        LOG.error(\"StoragePolicySatisfier thread received runtime exception. \"\n            + \"Stopping Storage policy satisfier work\", t);\n        // TODO: Just break for now. Once we implement dynamic start/stop\n        // option, we can add conditions here when to break/terminate.\n        break;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/StoragePolicySatisfier.java",
      "extendedDetails": {}
    },
    "1438da494424193e330f24edef823bbd60dc37d2": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-10800: [SPS]: Daemon thread in Namenode to find blocks placed in other storage than what the policy specifies. Contributed by Uma Maheswara Rao G\n",
      "commitDate": "12/08/18 3:05 AM",
      "commitName": "1438da494424193e330f24edef823bbd60dc37d2",
      "commitAuthor": "Uma Maheswara Rao G",
      "diff": "@@ -0,0 +1,27 @@\n+  public void run() {\n+    while (namesystem.isRunning()) {\n+      try {\n+        Long blockCollectionID \u003d storageMovementNeeded.get();\n+        if (blockCollectionID !\u003d null) {\n+          computeAndAssignStorageMismatchedBlocksToDNs(blockCollectionID);\n+        }\n+        // TODO: We can think to make this as configurable later, how frequently\n+        // we want to check block movements.\n+        Thread.sleep(3000);\n+      } catch (Throwable t) {\n+        if (!namesystem.isRunning()) {\n+          LOG.info(\"Stopping StoragePolicySatisfier.\");\n+          if (!(t instanceof InterruptedException)) {\n+            LOG.info(\"StoragePolicySatisfier received an exception\"\n+                + \" while shutting down.\", t);\n+          }\n+          break;\n+        }\n+        LOG.error(\"StoragePolicySatisfier thread received runtime exception. \"\n+            + \"Stopping Storage policy satisfier work\", t);\n+        // TODO: Just break for now. Once we implement dynamic start/stop\n+        // option, we can add conditions here when to break/terminate.\n+        break;\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void run() {\n    while (namesystem.isRunning()) {\n      try {\n        Long blockCollectionID \u003d storageMovementNeeded.get();\n        if (blockCollectionID !\u003d null) {\n          computeAndAssignStorageMismatchedBlocksToDNs(blockCollectionID);\n        }\n        // TODO: We can think to make this as configurable later, how frequently\n        // we want to check block movements.\n        Thread.sleep(3000);\n      } catch (Throwable t) {\n        if (!namesystem.isRunning()) {\n          LOG.info(\"Stopping StoragePolicySatisfier.\");\n          if (!(t instanceof InterruptedException)) {\n            LOG.info(\"StoragePolicySatisfier received an exception\"\n                + \" while shutting down.\", t);\n          }\n          break;\n        }\n        LOG.error(\"StoragePolicySatisfier thread received runtime exception. \"\n            + \"Stopping Storage policy satisfier work\", t);\n        // TODO: Just break for now. Once we implement dynamic start/stop\n        // option, we can add conditions here when to break/terminate.\n        break;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/StoragePolicySatisfier.java"
    }
  }
}