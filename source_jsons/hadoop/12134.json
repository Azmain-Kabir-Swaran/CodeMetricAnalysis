{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DataNode.java",
  "functionName": "checkSecureConfig",
  "functionId": "checkSecureConfig___dnConf-DNConf__conf-Configuration__resources-SecureResources",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java",
  "functionStartLine": 1501,
  "functionEndLine": 1549,
  "numCommitsSeen": 358,
  "timeTaken": 2103,
  "changeHistory": [
    "dfcb331ba3516264398121c9f23af3a79c0509cc"
  ],
  "changeHistoryShort": {
    "dfcb331ba3516264398121c9f23af3a79c0509cc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "dfcb331ba3516264398121c9f23af3a79c0509cc": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-13076: [SPS]: Addendum. Resolve conflicts after rebasing branch to trunk. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "dfcb331ba3516264398121c9f23af3a79c0509cc",
      "commitAuthor": "Rakesh Radhakrishnan",
      "diff": "@@ -0,0 +1,49 @@\n+  private static void checkSecureConfig(DNConf dnConf, Configuration conf,\n+      SecureResources resources) throws RuntimeException {\n+    if (!UserGroupInformation.isSecurityEnabled()) {\n+      return;\n+    }\n+\n+    // Abort out of inconsistent state if Kerberos is enabled\n+    // but block access tokens are not enabled.\n+    boolean isEnabled \u003d conf.getBoolean(\n+        DFSConfigKeys.DFS_BLOCK_ACCESS_TOKEN_ENABLE_KEY,\n+        DFSConfigKeys.DFS_BLOCK_ACCESS_TOKEN_ENABLE_DEFAULT);\n+    if (!isEnabled) {\n+      String errMessage \u003d \"Security is enabled but block access tokens \" +\n+          \"(via \" + DFSConfigKeys.DFS_BLOCK_ACCESS_TOKEN_ENABLE_KEY + \") \" +\n+          \"aren\u0027t enabled. This may cause issues \" +\n+          \"when clients attempt to connect to a DataNode. Aborting DataNode\";\n+      throw new RuntimeException(errMessage);\n+    }\n+\n+    if (dnConf.getIgnoreSecurePortsForTesting()) {\n+      return;\n+    }\n+\n+    if (resources !\u003d null) {\n+      final boolean httpSecured \u003d resources.isHttpPortPrivileged()\n+          || DFSUtil.getHttpPolicy(conf) \u003d\u003d HttpConfig.Policy.HTTPS_ONLY;\n+      final boolean rpcSecured \u003d resources.isRpcPortPrivileged()\n+          || resources.isSaslEnabled();\n+\n+      // Allow secure DataNode to startup if:\n+      // 1. Http is secure.\n+      // 2. Rpc is secure\n+      if (rpcSecured \u0026\u0026 httpSecured) {\n+        return;\n+      }\n+    } else {\n+      // Handle cases when SecureDataNodeStarter#getSecureResources is not\n+      // invoked\n+      SaslPropertiesResolver saslPropsResolver \u003d dnConf.getSaslPropsResolver();\n+      if (saslPropsResolver !\u003d null \u0026\u0026\n+          DFSUtil.getHttpPolicy(conf) \u003d\u003d HttpConfig.Policy.HTTPS_ONLY) {\n+        return;\n+      }\n+    }\n+\n+    throw new RuntimeException(\"Cannot start secure DataNode due to incorrect \"\n+        + \"config. See https://cwiki.apache.org/confluence/display/HADOOP/\"\n+        + \"Secure+DataNode for details.\");\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private static void checkSecureConfig(DNConf dnConf, Configuration conf,\n      SecureResources resources) throws RuntimeException {\n    if (!UserGroupInformation.isSecurityEnabled()) {\n      return;\n    }\n\n    // Abort out of inconsistent state if Kerberos is enabled\n    // but block access tokens are not enabled.\n    boolean isEnabled \u003d conf.getBoolean(\n        DFSConfigKeys.DFS_BLOCK_ACCESS_TOKEN_ENABLE_KEY,\n        DFSConfigKeys.DFS_BLOCK_ACCESS_TOKEN_ENABLE_DEFAULT);\n    if (!isEnabled) {\n      String errMessage \u003d \"Security is enabled but block access tokens \" +\n          \"(via \" + DFSConfigKeys.DFS_BLOCK_ACCESS_TOKEN_ENABLE_KEY + \") \" +\n          \"aren\u0027t enabled. This may cause issues \" +\n          \"when clients attempt to connect to a DataNode. Aborting DataNode\";\n      throw new RuntimeException(errMessage);\n    }\n\n    if (dnConf.getIgnoreSecurePortsForTesting()) {\n      return;\n    }\n\n    if (resources !\u003d null) {\n      final boolean httpSecured \u003d resources.isHttpPortPrivileged()\n          || DFSUtil.getHttpPolicy(conf) \u003d\u003d HttpConfig.Policy.HTTPS_ONLY;\n      final boolean rpcSecured \u003d resources.isRpcPortPrivileged()\n          || resources.isSaslEnabled();\n\n      // Allow secure DataNode to startup if:\n      // 1. Http is secure.\n      // 2. Rpc is secure\n      if (rpcSecured \u0026\u0026 httpSecured) {\n        return;\n      }\n    } else {\n      // Handle cases when SecureDataNodeStarter#getSecureResources is not\n      // invoked\n      SaslPropertiesResolver saslPropsResolver \u003d dnConf.getSaslPropsResolver();\n      if (saslPropsResolver !\u003d null \u0026\u0026\n          DFSUtil.getHttpPolicy(conf) \u003d\u003d HttpConfig.Policy.HTTPS_ONLY) {\n        return;\n      }\n    }\n\n    throw new RuntimeException(\"Cannot start secure DataNode due to incorrect \"\n        + \"config. See https://cwiki.apache.org/confluence/display/HADOOP/\"\n        + \"Secure+DataNode for details.\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java"
    }
  }
}