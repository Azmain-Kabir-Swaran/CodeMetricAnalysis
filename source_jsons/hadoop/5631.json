{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "CacheManager.java",
  "functionName": "loadPools",
  "functionId": "loadPools___in-DataInput",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
  "functionStartLine": 1235,
  "functionEndLine": 1248,
  "numCommitsSeen": 56,
  "timeTaken": 2507,
  "changeHistory": [
    "991c453ca3ac141a3f286f74af8401f83c38b230",
    "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
    "b60e18db743b8933d96384942046ea57e725855d",
    "af1ac9a5e8d8d97a855940d853dd59ab4666f6e2"
  ],
  "changeHistoryShort": {
    "991c453ca3ac141a3f286f74af8401f83c38b230": "Ybodychange",
    "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a": "Ymultichange(Ymodifierchange,Ybodychange)",
    "b60e18db743b8933d96384942046ea57e725855d": "Ybodychange",
    "af1ac9a5e8d8d97a855940d853dd59ab4666f6e2": "Yintroduced"
  },
  "changeHistoryDetails": {
    "991c453ca3ac141a3f286f74af8401f83c38b230": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5431. Support cachepool-based limit management in path-based caching. (awang via cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1551651 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/12/13 10:47 AM",
      "commitName": "991c453ca3ac141a3f286f74af8401f83c38b230",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "05/12/13 1:09 PM",
      "commitNameOld": "55e5b0653c34a5f4146ce5a97a5b4a88a976d88a",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 11.9,
      "commitsBetweenForRepo": 67,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,14 @@\n   private void loadPools(DataInput in)\n       throws IOException {\n     StartupProgress prog \u003d NameNode.getStartupProgress();\n     Step step \u003d new Step(StepType.CACHE_POOLS);\n     prog.beginStep(Phase.LOADING_FSIMAGE, step);\n     int numberOfPools \u003d in.readInt();\n     prog.setTotal(Phase.LOADING_FSIMAGE, step, numberOfPools);\n     Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n     for (int i \u003d 0; i \u003c numberOfPools; i++) {\n-      addCachePool(CachePoolInfo.readFrom(in));\n+      addCachePool(FSImageSerialization.readCachePoolInfo(in));\n       counter.increment();\n     }\n     prog.endStep(Phase.LOADING_FSIMAGE, step);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void loadPools(DataInput in)\n      throws IOException {\n    StartupProgress prog \u003d NameNode.getStartupProgress();\n    Step step \u003d new Step(StepType.CACHE_POOLS);\n    prog.beginStep(Phase.LOADING_FSIMAGE, step);\n    int numberOfPools \u003d in.readInt();\n    prog.setTotal(Phase.LOADING_FSIMAGE, step, numberOfPools);\n    Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n    for (int i \u003d 0; i \u003c numberOfPools; i++) {\n      addCachePool(FSImageSerialization.readCachePoolInfo(in));\n      counter.increment();\n    }\n    prog.endStep(Phase.LOADING_FSIMAGE, step);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
      "extendedDetails": {}
    },
    "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-5096. Automatically cache new data added to a cached path (contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1532924 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/10/13 3:15 PM",
      "commitName": "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
      "commitAuthor": "Colin McCabe",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-5096. Automatically cache new data added to a cached path (contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1532924 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "16/10/13 3:15 PM",
          "commitName": "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "14/10/13 3:56 PM",
          "commitNameOld": "efe545b0c219eeba61ac5259aee4d518beb74316",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 1.97,
          "commitsBetweenForRepo": 4,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,15 +1,14 @@\n-  private synchronized void loadPools(DataInput in)\n+  private void loadPools(DataInput in)\n       throws IOException {\n     StartupProgress prog \u003d NameNode.getStartupProgress();\n     Step step \u003d new Step(StepType.CACHE_POOLS);\n     prog.beginStep(Phase.LOADING_FSIMAGE, step);\n     int numberOfPools \u003d in.readInt();\n     prog.setTotal(Phase.LOADING_FSIMAGE, step, numberOfPools);\n     Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n     for (int i \u003d 0; i \u003c numberOfPools; i++) {\n-      CachePoolInfo info \u003d CachePoolInfo.readFrom(in);\n-      unprotectedAddCachePool(info);\n+      addCachePool(CachePoolInfo.readFrom(in));\n       counter.increment();\n     }\n     prog.endStep(Phase.LOADING_FSIMAGE, step);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void loadPools(DataInput in)\n      throws IOException {\n    StartupProgress prog \u003d NameNode.getStartupProgress();\n    Step step \u003d new Step(StepType.CACHE_POOLS);\n    prog.beginStep(Phase.LOADING_FSIMAGE, step);\n    int numberOfPools \u003d in.readInt();\n    prog.setTotal(Phase.LOADING_FSIMAGE, step, numberOfPools);\n    Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n    for (int i \u003d 0; i \u003c numberOfPools; i++) {\n      addCachePool(CachePoolInfo.readFrom(in));\n      counter.increment();\n    }\n    prog.endStep(Phase.LOADING_FSIMAGE, step);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
          "extendedDetails": {
            "oldValue": "[private, synchronized]",
            "newValue": "[private]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5096. Automatically cache new data added to a cached path (contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1532924 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "16/10/13 3:15 PM",
          "commitName": "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "14/10/13 3:56 PM",
          "commitNameOld": "efe545b0c219eeba61ac5259aee4d518beb74316",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 1.97,
          "commitsBetweenForRepo": 4,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,15 +1,14 @@\n-  private synchronized void loadPools(DataInput in)\n+  private void loadPools(DataInput in)\n       throws IOException {\n     StartupProgress prog \u003d NameNode.getStartupProgress();\n     Step step \u003d new Step(StepType.CACHE_POOLS);\n     prog.beginStep(Phase.LOADING_FSIMAGE, step);\n     int numberOfPools \u003d in.readInt();\n     prog.setTotal(Phase.LOADING_FSIMAGE, step, numberOfPools);\n     Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n     for (int i \u003d 0; i \u003c numberOfPools; i++) {\n-      CachePoolInfo info \u003d CachePoolInfo.readFrom(in);\n-      unprotectedAddCachePool(info);\n+      addCachePool(CachePoolInfo.readFrom(in));\n       counter.increment();\n     }\n     prog.endStep(Phase.LOADING_FSIMAGE, step);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void loadPools(DataInput in)\n      throws IOException {\n    StartupProgress prog \u003d NameNode.getStartupProgress();\n    Step step \u003d new Step(StepType.CACHE_POOLS);\n    prog.beginStep(Phase.LOADING_FSIMAGE, step);\n    int numberOfPools \u003d in.readInt();\n    prog.setTotal(Phase.LOADING_FSIMAGE, step, numberOfPools);\n    Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n    for (int i \u003d 0; i \u003c numberOfPools; i++) {\n      addCachePool(CachePoolInfo.readFrom(in));\n      counter.increment();\n    }\n    prog.endStep(Phase.LOADING_FSIMAGE, step);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "b60e18db743b8933d96384942046ea57e725855d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5314.  Do not expose CachePool type in AddCachePoolOp (Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1530073 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/10/13 2:26 PM",
      "commitName": "b60e18db743b8933d96384942046ea57e725855d",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "04/10/13 3:28 PM",
      "commitNameOld": "eb2175db1a99348c80457e3ffda172cc461de8bc",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 2.96,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,15 @@\n   private synchronized void loadPools(DataInput in)\n       throws IOException {\n     StartupProgress prog \u003d NameNode.getStartupProgress();\n     Step step \u003d new Step(StepType.CACHE_POOLS);\n     prog.beginStep(Phase.LOADING_FSIMAGE, step);\n     int numberOfPools \u003d in.readInt();\n     prog.setTotal(Phase.LOADING_FSIMAGE, step, numberOfPools);\n     Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n     for (int i \u003d 0; i \u003c numberOfPools; i++) {\n-      CachePool pool \u003d CachePool.readFrom(in);\n-      unprotectedAddCachePool(pool);\n+      CachePoolInfo info \u003d CachePoolInfo.readFrom(in);\n+      unprotectedAddCachePool(info);\n       counter.increment();\n     }\n     prog.endStep(Phase.LOADING_FSIMAGE, step);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void loadPools(DataInput in)\n      throws IOException {\n    StartupProgress prog \u003d NameNode.getStartupProgress();\n    Step step \u003d new Step(StepType.CACHE_POOLS);\n    prog.beginStep(Phase.LOADING_FSIMAGE, step);\n    int numberOfPools \u003d in.readInt();\n    prog.setTotal(Phase.LOADING_FSIMAGE, step, numberOfPools);\n    Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n    for (int i \u003d 0; i \u003c numberOfPools; i++) {\n      CachePoolInfo info \u003d CachePoolInfo.readFrom(in);\n      unprotectedAddCachePool(info);\n      counter.increment();\n    }\n    prog.endStep(Phase.LOADING_FSIMAGE, step);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
      "extendedDetails": {}
    },
    "af1ac9a5e8d8d97a855940d853dd59ab4666f6e2": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5119. Persist CacheManager state in the edit log. (Contributed by Andrew Wang)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1529238 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/10/13 10:46 AM",
      "commitName": "af1ac9a5e8d8d97a855940d853dd59ab4666f6e2",
      "commitAuthor": "Andrew Wang",
      "diff": "@@ -0,0 +1,15 @@\n+  private synchronized void loadPools(DataInput in)\n+      throws IOException {\n+    StartupProgress prog \u003d NameNode.getStartupProgress();\n+    Step step \u003d new Step(StepType.CACHE_POOLS);\n+    prog.beginStep(Phase.LOADING_FSIMAGE, step);\n+    int numberOfPools \u003d in.readInt();\n+    prog.setTotal(Phase.LOADING_FSIMAGE, step, numberOfPools);\n+    Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n+    for (int i \u003d 0; i \u003c numberOfPools; i++) {\n+      CachePool pool \u003d CachePool.readFrom(in);\n+      unprotectedAddCachePool(pool);\n+      counter.increment();\n+    }\n+    prog.endStep(Phase.LOADING_FSIMAGE, step);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void loadPools(DataInput in)\n      throws IOException {\n    StartupProgress prog \u003d NameNode.getStartupProgress();\n    Step step \u003d new Step(StepType.CACHE_POOLS);\n    prog.beginStep(Phase.LOADING_FSIMAGE, step);\n    int numberOfPools \u003d in.readInt();\n    prog.setTotal(Phase.LOADING_FSIMAGE, step, numberOfPools);\n    Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n    for (int i \u003d 0; i \u003c numberOfPools; i++) {\n      CachePool pool \u003d CachePool.readFrom(in);\n      unprotectedAddCachePool(pool);\n      counter.increment();\n    }\n    prog.endStep(Phase.LOADING_FSIMAGE, step);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java"
    }
  }
}