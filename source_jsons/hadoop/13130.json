{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "CacheReplicationMonitor.java",
  "functionName": "rescanCachedBlockMap",
  "functionId": "rescanCachedBlockMap",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/CacheReplicationMonitor.java",
  "functionStartLine": 492,
  "functionEndLine": 607,
  "numCommitsSeen": 28,
  "timeTaken": 3728,
  "changeHistory": [
    "2ca73445f5c2929d9c2ff4232dca58a63a0570a0",
    "211c78c09073e5b34db309b49d8de939a7a812f5",
    "4928f5473394981829e5ffd4b16ea0801baf5c45",
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177",
    "93e23a99157c30b51752fc49748c3c210745a187",
    "bab90b2222abb41d0e3382a92c2f9a8dc568f0e0",
    "07e4fb1455abc33584fc666ef745abe256ebd7d1",
    "3c591aa442d342bdd4a0c4abe9a43c64d8ef3e65",
    "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a"
  ],
  "changeHistoryShort": {
    "2ca73445f5c2929d9c2ff4232dca58a63a0570a0": "Ybodychange",
    "211c78c09073e5b34db309b49d8de939a7a812f5": "Ybodychange",
    "4928f5473394981829e5ffd4b16ea0801baf5c45": "Ybodychange",
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177": "Ybodychange",
    "93e23a99157c30b51752fc49748c3c210745a187": "Ybodychange",
    "bab90b2222abb41d0e3382a92c2f9a8dc568f0e0": "Ybodychange",
    "07e4fb1455abc33584fc666ef745abe256ebd7d1": "Ybodychange",
    "3c591aa442d342bdd4a0c4abe9a43c64d8ef3e65": "Ybodychange",
    "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a": "Yintroduced"
  },
  "changeHistoryDetails": {
    "2ca73445f5c2929d9c2ff4232dca58a63a0570a0": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10525. Fix NPE in CacheReplicationMonitor#rescanCachedBlockMap (Xiao Chen via cmccabe)\n",
      "commitDate": "15/06/16 10:47 PM",
      "commitName": "2ca73445f5c2929d9c2ff4232dca58a63a0570a0",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "10/05/16 11:15 AM",
      "commitNameOld": "f0252ad2525c90b2b89ae2ff1de12482da2c8ddd",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 36.48,
      "commitsBetweenForRepo": 256,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,108 +1,116 @@\n   private void rescanCachedBlockMap() {\n     // Remove pendingCached blocks that will make DN out-of-capacity.\n     Set\u003cDatanodeDescriptor\u003e datanodes \u003d\n         blockManager.getDatanodeManager().getDatanodes();\n     for (DatanodeDescriptor dn : datanodes) {\n       long remaining \u003d dn.getCacheRemaining();\n       for (Iterator\u003cCachedBlock\u003e it \u003d dn.getPendingCached().iterator();\n            it.hasNext();) {\n         CachedBlock cblock \u003d it.next();\n         BlockInfo blockInfo \u003d blockManager.\n             getStoredBlock(new Block(cblock.getBlockId()));\n+        if (blockInfo \u003d\u003d null) {\n+          // Cannot find this block on the NameNode, skip this block from\n+          // capacity calculation. Later logic will handle this block.\n+          LOG.debug(\"Block {}: cannot be found in block manager and hence\"\n+              + \" skipped from calculation for node {}.\", cblock.getBlockId(),\n+              dn.getDatanodeUuid());\n+          continue;\n+        }\n         if (blockInfo.getNumBytes() \u003e remaining) {\n           LOG.debug(\"Block {}: removing from PENDING_CACHED for node {} \"\n                   + \"because it cannot fit in remaining cache size {}.\",\n               cblock.getBlockId(), dn.getDatanodeUuid(), remaining);\n           it.remove();\n         } else {\n           remaining -\u003d blockInfo.getNumBytes();\n         }\n       }\n     }\n     for (Iterator\u003cCachedBlock\u003e cbIter \u003d cachedBlocks.iterator();\n         cbIter.hasNext(); ) {\n       scannedBlocks++;\n       CachedBlock cblock \u003d cbIter.next();\n       List\u003cDatanodeDescriptor\u003e pendingCached \u003d\n           cblock.getDatanodes(Type.PENDING_CACHED);\n       List\u003cDatanodeDescriptor\u003e cached \u003d\n           cblock.getDatanodes(Type.CACHED);\n       List\u003cDatanodeDescriptor\u003e pendingUncached \u003d\n           cblock.getDatanodes(Type.PENDING_UNCACHED);\n       // Remove nodes from PENDING_UNCACHED if they were actually uncached.\n       for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingUncached.iterator();\n           iter.hasNext(); ) {\n         DatanodeDescriptor datanode \u003d iter.next();\n         if (!cblock.isInList(datanode.getCached())) {\n           LOG.trace(\"Block {}: removing from PENDING_UNCACHED for node {} \"\n               + \"because the DataNode uncached it.\", cblock.getBlockId(),\n               datanode.getDatanodeUuid());\n           datanode.getPendingUncached().remove(cblock);\n           iter.remove();\n         }\n       }\n       BlockInfo blockInfo \u003d blockManager.\n             getStoredBlock(new Block(cblock.getBlockId()));\n       String reason \u003d findReasonForNotCaching(cblock, blockInfo);\n       int neededCached \u003d 0;\n       if (reason !\u003d null) {\n         LOG.trace(\"Block {}: can\u0027t cache block because it is {}\",\n             cblock.getBlockId(), reason);\n       } else {\n         neededCached \u003d cblock.getReplication();\n       }\n       int numCached \u003d cached.size();\n       if (numCached \u003e\u003d neededCached) {\n         // If we have enough replicas, drop all pending cached.\n         for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingCached.iterator();\n             iter.hasNext(); ) {\n           DatanodeDescriptor datanode \u003d iter.next();\n           datanode.getPendingCached().remove(cblock);\n           iter.remove();\n           LOG.trace(\"Block {}: removing from PENDING_CACHED for node {} \"\n                   + \"because we already have {} cached replicas and we only\" +\n                   \" need {}\",\n               cblock.getBlockId(), datanode.getDatanodeUuid(), numCached,\n               neededCached\n           );\n         }\n       }\n       if (numCached \u003c neededCached) {\n         // If we don\u0027t have enough replicas, drop all pending uncached.\n         for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingUncached.iterator();\n             iter.hasNext(); ) {\n           DatanodeDescriptor datanode \u003d iter.next();\n           datanode.getPendingUncached().remove(cblock);\n           iter.remove();\n           LOG.trace(\"Block {}: removing from PENDING_UNCACHED for node {} \"\n                   + \"because we only have {} cached replicas and we need \" +\n                   \"{}\", cblock.getBlockId(), datanode.getDatanodeUuid(),\n               numCached, neededCached\n           );\n         }\n       }\n       int neededUncached \u003d numCached -\n           (pendingUncached.size() + neededCached);\n       if (neededUncached \u003e 0) {\n         addNewPendingUncached(neededUncached, cblock, cached,\n             pendingUncached);\n       } else {\n         int additionalCachedNeeded \u003d neededCached -\n             (numCached + pendingCached.size());\n         if (additionalCachedNeeded \u003e 0) {\n           addNewPendingCached(additionalCachedNeeded, cblock, cached,\n               pendingCached);\n         }\n       }\n       if ((neededCached \u003d\u003d 0) \u0026\u0026\n           pendingUncached.isEmpty() \u0026\u0026\n           pendingCached.isEmpty()) {\n         // we have nothing more to do with this block.\n         LOG.trace(\"Block {}: removing from cachedBlocks, since neededCached \"\n                 + \"\u003d\u003d 0, and pendingUncached and pendingCached are empty.\",\n             cblock.getBlockId()\n         );\n         cbIter.remove();\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void rescanCachedBlockMap() {\n    // Remove pendingCached blocks that will make DN out-of-capacity.\n    Set\u003cDatanodeDescriptor\u003e datanodes \u003d\n        blockManager.getDatanodeManager().getDatanodes();\n    for (DatanodeDescriptor dn : datanodes) {\n      long remaining \u003d dn.getCacheRemaining();\n      for (Iterator\u003cCachedBlock\u003e it \u003d dn.getPendingCached().iterator();\n           it.hasNext();) {\n        CachedBlock cblock \u003d it.next();\n        BlockInfo blockInfo \u003d blockManager.\n            getStoredBlock(new Block(cblock.getBlockId()));\n        if (blockInfo \u003d\u003d null) {\n          // Cannot find this block on the NameNode, skip this block from\n          // capacity calculation. Later logic will handle this block.\n          LOG.debug(\"Block {}: cannot be found in block manager and hence\"\n              + \" skipped from calculation for node {}.\", cblock.getBlockId(),\n              dn.getDatanodeUuid());\n          continue;\n        }\n        if (blockInfo.getNumBytes() \u003e remaining) {\n          LOG.debug(\"Block {}: removing from PENDING_CACHED for node {} \"\n                  + \"because it cannot fit in remaining cache size {}.\",\n              cblock.getBlockId(), dn.getDatanodeUuid(), remaining);\n          it.remove();\n        } else {\n          remaining -\u003d blockInfo.getNumBytes();\n        }\n      }\n    }\n    for (Iterator\u003cCachedBlock\u003e cbIter \u003d cachedBlocks.iterator();\n        cbIter.hasNext(); ) {\n      scannedBlocks++;\n      CachedBlock cblock \u003d cbIter.next();\n      List\u003cDatanodeDescriptor\u003e pendingCached \u003d\n          cblock.getDatanodes(Type.PENDING_CACHED);\n      List\u003cDatanodeDescriptor\u003e cached \u003d\n          cblock.getDatanodes(Type.CACHED);\n      List\u003cDatanodeDescriptor\u003e pendingUncached \u003d\n          cblock.getDatanodes(Type.PENDING_UNCACHED);\n      // Remove nodes from PENDING_UNCACHED if they were actually uncached.\n      for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingUncached.iterator();\n          iter.hasNext(); ) {\n        DatanodeDescriptor datanode \u003d iter.next();\n        if (!cblock.isInList(datanode.getCached())) {\n          LOG.trace(\"Block {}: removing from PENDING_UNCACHED for node {} \"\n              + \"because the DataNode uncached it.\", cblock.getBlockId(),\n              datanode.getDatanodeUuid());\n          datanode.getPendingUncached().remove(cblock);\n          iter.remove();\n        }\n      }\n      BlockInfo blockInfo \u003d blockManager.\n            getStoredBlock(new Block(cblock.getBlockId()));\n      String reason \u003d findReasonForNotCaching(cblock, blockInfo);\n      int neededCached \u003d 0;\n      if (reason !\u003d null) {\n        LOG.trace(\"Block {}: can\u0027t cache block because it is {}\",\n            cblock.getBlockId(), reason);\n      } else {\n        neededCached \u003d cblock.getReplication();\n      }\n      int numCached \u003d cached.size();\n      if (numCached \u003e\u003d neededCached) {\n        // If we have enough replicas, drop all pending cached.\n        for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingCached.iterator();\n            iter.hasNext(); ) {\n          DatanodeDescriptor datanode \u003d iter.next();\n          datanode.getPendingCached().remove(cblock);\n          iter.remove();\n          LOG.trace(\"Block {}: removing from PENDING_CACHED for node {} \"\n                  + \"because we already have {} cached replicas and we only\" +\n                  \" need {}\",\n              cblock.getBlockId(), datanode.getDatanodeUuid(), numCached,\n              neededCached\n          );\n        }\n      }\n      if (numCached \u003c neededCached) {\n        // If we don\u0027t have enough replicas, drop all pending uncached.\n        for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingUncached.iterator();\n            iter.hasNext(); ) {\n          DatanodeDescriptor datanode \u003d iter.next();\n          datanode.getPendingUncached().remove(cblock);\n          iter.remove();\n          LOG.trace(\"Block {}: removing from PENDING_UNCACHED for node {} \"\n                  + \"because we only have {} cached replicas and we need \" +\n                  \"{}\", cblock.getBlockId(), datanode.getDatanodeUuid(),\n              numCached, neededCached\n          );\n        }\n      }\n      int neededUncached \u003d numCached -\n          (pendingUncached.size() + neededCached);\n      if (neededUncached \u003e 0) {\n        addNewPendingUncached(neededUncached, cblock, cached,\n            pendingUncached);\n      } else {\n        int additionalCachedNeeded \u003d neededCached -\n            (numCached + pendingCached.size());\n        if (additionalCachedNeeded \u003e 0) {\n          addNewPendingCached(additionalCachedNeeded, cblock, cached,\n              pendingCached);\n        }\n      }\n      if ((neededCached \u003d\u003d 0) \u0026\u0026\n          pendingUncached.isEmpty() \u0026\u0026\n          pendingCached.isEmpty()) {\n        // we have nothing more to do with this block.\n        LOG.trace(\"Block {}: removing from cachedBlocks, since neededCached \"\n                + \"\u003d\u003d 0, and pendingUncached and pendingCached are empty.\",\n            cblock.getBlockId()\n        );\n        cbIter.remove();\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/CacheReplicationMonitor.java",
      "extendedDetails": {}
    },
    "211c78c09073e5b34db309b49d8de939a7a812f5": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9549. TestCacheDirectives#testExceedsCapacity is flaky (Xiao Chen via cmccabe)\n",
      "commitDate": "23/02/16 12:01 PM",
      "commitName": "211c78c09073e5b34db309b49d8de939a7a812f5",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "29/06/15 12:12 PM",
      "commitNameOld": "2ffd84273ac490724fe7e7825664bb6d09ef0e99",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 239.03,
      "commitsBetweenForRepo": 1612,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,88 +1,108 @@\n   private void rescanCachedBlockMap() {\n+    // Remove pendingCached blocks that will make DN out-of-capacity.\n+    Set\u003cDatanodeDescriptor\u003e datanodes \u003d\n+        blockManager.getDatanodeManager().getDatanodes();\n+    for (DatanodeDescriptor dn : datanodes) {\n+      long remaining \u003d dn.getCacheRemaining();\n+      for (Iterator\u003cCachedBlock\u003e it \u003d dn.getPendingCached().iterator();\n+           it.hasNext();) {\n+        CachedBlock cblock \u003d it.next();\n+        BlockInfo blockInfo \u003d blockManager.\n+            getStoredBlock(new Block(cblock.getBlockId()));\n+        if (blockInfo.getNumBytes() \u003e remaining) {\n+          LOG.debug(\"Block {}: removing from PENDING_CACHED for node {} \"\n+                  + \"because it cannot fit in remaining cache size {}.\",\n+              cblock.getBlockId(), dn.getDatanodeUuid(), remaining);\n+          it.remove();\n+        } else {\n+          remaining -\u003d blockInfo.getNumBytes();\n+        }\n+      }\n+    }\n     for (Iterator\u003cCachedBlock\u003e cbIter \u003d cachedBlocks.iterator();\n         cbIter.hasNext(); ) {\n       scannedBlocks++;\n       CachedBlock cblock \u003d cbIter.next();\n       List\u003cDatanodeDescriptor\u003e pendingCached \u003d\n           cblock.getDatanodes(Type.PENDING_CACHED);\n       List\u003cDatanodeDescriptor\u003e cached \u003d\n           cblock.getDatanodes(Type.CACHED);\n       List\u003cDatanodeDescriptor\u003e pendingUncached \u003d\n           cblock.getDatanodes(Type.PENDING_UNCACHED);\n       // Remove nodes from PENDING_UNCACHED if they were actually uncached.\n       for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingUncached.iterator();\n           iter.hasNext(); ) {\n         DatanodeDescriptor datanode \u003d iter.next();\n         if (!cblock.isInList(datanode.getCached())) {\n           LOG.trace(\"Block {}: removing from PENDING_UNCACHED for node {} \"\n               + \"because the DataNode uncached it.\", cblock.getBlockId(),\n               datanode.getDatanodeUuid());\n           datanode.getPendingUncached().remove(cblock);\n           iter.remove();\n         }\n       }\n       BlockInfo blockInfo \u003d blockManager.\n             getStoredBlock(new Block(cblock.getBlockId()));\n       String reason \u003d findReasonForNotCaching(cblock, blockInfo);\n       int neededCached \u003d 0;\n       if (reason !\u003d null) {\n         LOG.trace(\"Block {}: can\u0027t cache block because it is {}\",\n             cblock.getBlockId(), reason);\n       } else {\n         neededCached \u003d cblock.getReplication();\n       }\n       int numCached \u003d cached.size();\n       if (numCached \u003e\u003d neededCached) {\n         // If we have enough replicas, drop all pending cached.\n         for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingCached.iterator();\n             iter.hasNext(); ) {\n           DatanodeDescriptor datanode \u003d iter.next();\n           datanode.getPendingCached().remove(cblock);\n           iter.remove();\n-          LOG.trace(\"Block {}: removing from PENDING_CACHED for node {}\"\n+          LOG.trace(\"Block {}: removing from PENDING_CACHED for node {} \"\n                   + \"because we already have {} cached replicas and we only\" +\n                   \" need {}\",\n               cblock.getBlockId(), datanode.getDatanodeUuid(), numCached,\n               neededCached\n           );\n         }\n       }\n       if (numCached \u003c neededCached) {\n         // If we don\u0027t have enough replicas, drop all pending uncached.\n         for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingUncached.iterator();\n             iter.hasNext(); ) {\n           DatanodeDescriptor datanode \u003d iter.next();\n           datanode.getPendingUncached().remove(cblock);\n           iter.remove();\n           LOG.trace(\"Block {}: removing from PENDING_UNCACHED for node {} \"\n                   + \"because we only have {} cached replicas and we need \" +\n                   \"{}\", cblock.getBlockId(), datanode.getDatanodeUuid(),\n               numCached, neededCached\n           );\n         }\n       }\n       int neededUncached \u003d numCached -\n           (pendingUncached.size() + neededCached);\n       if (neededUncached \u003e 0) {\n         addNewPendingUncached(neededUncached, cblock, cached,\n             pendingUncached);\n       } else {\n         int additionalCachedNeeded \u003d neededCached -\n             (numCached + pendingCached.size());\n         if (additionalCachedNeeded \u003e 0) {\n           addNewPendingCached(additionalCachedNeeded, cblock, cached,\n               pendingCached);\n         }\n       }\n       if ((neededCached \u003d\u003d 0) \u0026\u0026\n           pendingUncached.isEmpty() \u0026\u0026\n           pendingCached.isEmpty()) {\n         // we have nothing more to do with this block.\n         LOG.trace(\"Block {}: removing from cachedBlocks, since neededCached \"\n                 + \"\u003d\u003d 0, and pendingUncached and pendingCached are empty.\",\n             cblock.getBlockId()\n         );\n         cbIter.remove();\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void rescanCachedBlockMap() {\n    // Remove pendingCached blocks that will make DN out-of-capacity.\n    Set\u003cDatanodeDescriptor\u003e datanodes \u003d\n        blockManager.getDatanodeManager().getDatanodes();\n    for (DatanodeDescriptor dn : datanodes) {\n      long remaining \u003d dn.getCacheRemaining();\n      for (Iterator\u003cCachedBlock\u003e it \u003d dn.getPendingCached().iterator();\n           it.hasNext();) {\n        CachedBlock cblock \u003d it.next();\n        BlockInfo blockInfo \u003d blockManager.\n            getStoredBlock(new Block(cblock.getBlockId()));\n        if (blockInfo.getNumBytes() \u003e remaining) {\n          LOG.debug(\"Block {}: removing from PENDING_CACHED for node {} \"\n                  + \"because it cannot fit in remaining cache size {}.\",\n              cblock.getBlockId(), dn.getDatanodeUuid(), remaining);\n          it.remove();\n        } else {\n          remaining -\u003d blockInfo.getNumBytes();\n        }\n      }\n    }\n    for (Iterator\u003cCachedBlock\u003e cbIter \u003d cachedBlocks.iterator();\n        cbIter.hasNext(); ) {\n      scannedBlocks++;\n      CachedBlock cblock \u003d cbIter.next();\n      List\u003cDatanodeDescriptor\u003e pendingCached \u003d\n          cblock.getDatanodes(Type.PENDING_CACHED);\n      List\u003cDatanodeDescriptor\u003e cached \u003d\n          cblock.getDatanodes(Type.CACHED);\n      List\u003cDatanodeDescriptor\u003e pendingUncached \u003d\n          cblock.getDatanodes(Type.PENDING_UNCACHED);\n      // Remove nodes from PENDING_UNCACHED if they were actually uncached.\n      for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingUncached.iterator();\n          iter.hasNext(); ) {\n        DatanodeDescriptor datanode \u003d iter.next();\n        if (!cblock.isInList(datanode.getCached())) {\n          LOG.trace(\"Block {}: removing from PENDING_UNCACHED for node {} \"\n              + \"because the DataNode uncached it.\", cblock.getBlockId(),\n              datanode.getDatanodeUuid());\n          datanode.getPendingUncached().remove(cblock);\n          iter.remove();\n        }\n      }\n      BlockInfo blockInfo \u003d blockManager.\n            getStoredBlock(new Block(cblock.getBlockId()));\n      String reason \u003d findReasonForNotCaching(cblock, blockInfo);\n      int neededCached \u003d 0;\n      if (reason !\u003d null) {\n        LOG.trace(\"Block {}: can\u0027t cache block because it is {}\",\n            cblock.getBlockId(), reason);\n      } else {\n        neededCached \u003d cblock.getReplication();\n      }\n      int numCached \u003d cached.size();\n      if (numCached \u003e\u003d neededCached) {\n        // If we have enough replicas, drop all pending cached.\n        for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingCached.iterator();\n            iter.hasNext(); ) {\n          DatanodeDescriptor datanode \u003d iter.next();\n          datanode.getPendingCached().remove(cblock);\n          iter.remove();\n          LOG.trace(\"Block {}: removing from PENDING_CACHED for node {} \"\n                  + \"because we already have {} cached replicas and we only\" +\n                  \" need {}\",\n              cblock.getBlockId(), datanode.getDatanodeUuid(), numCached,\n              neededCached\n          );\n        }\n      }\n      if (numCached \u003c neededCached) {\n        // If we don\u0027t have enough replicas, drop all pending uncached.\n        for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingUncached.iterator();\n            iter.hasNext(); ) {\n          DatanodeDescriptor datanode \u003d iter.next();\n          datanode.getPendingUncached().remove(cblock);\n          iter.remove();\n          LOG.trace(\"Block {}: removing from PENDING_UNCACHED for node {} \"\n                  + \"because we only have {} cached replicas and we need \" +\n                  \"{}\", cblock.getBlockId(), datanode.getDatanodeUuid(),\n              numCached, neededCached\n          );\n        }\n      }\n      int neededUncached \u003d numCached -\n          (pendingUncached.size() + neededCached);\n      if (neededUncached \u003e 0) {\n        addNewPendingUncached(neededUncached, cblock, cached,\n            pendingUncached);\n      } else {\n        int additionalCachedNeeded \u003d neededCached -\n            (numCached + pendingCached.size());\n        if (additionalCachedNeeded \u003e 0) {\n          addNewPendingCached(additionalCachedNeeded, cblock, cached,\n              pendingCached);\n        }\n      }\n      if ((neededCached \u003d\u003d 0) \u0026\u0026\n          pendingUncached.isEmpty() \u0026\u0026\n          pendingCached.isEmpty()) {\n        // we have nothing more to do with this block.\n        LOG.trace(\"Block {}: removing from cachedBlocks, since neededCached \"\n                + \"\u003d\u003d 0, and pendingUncached and pendingCached are empty.\",\n            cblock.getBlockId()\n        );\n        cbIter.remove();\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/CacheReplicationMonitor.java",
      "extendedDetails": {}
    },
    "4928f5473394981829e5ffd4b16ea0801baf5c45": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8482. Rename BlockInfoContiguous to BlockInfo. Contributed by Zhe Zhang.\n",
      "commitDate": "27/05/15 3:42 PM",
      "commitName": "4928f5473394981829e5ffd4b16ea0801baf5c45",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "08/02/15 11:51 AM",
      "commitNameOld": "1382ae525c67bf95d8f3a436b547dbc72cfbb177",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 108.12,
      "commitsBetweenForRepo": 1040,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,88 +1,88 @@\n   private void rescanCachedBlockMap() {\n     for (Iterator\u003cCachedBlock\u003e cbIter \u003d cachedBlocks.iterator();\n         cbIter.hasNext(); ) {\n       scannedBlocks++;\n       CachedBlock cblock \u003d cbIter.next();\n       List\u003cDatanodeDescriptor\u003e pendingCached \u003d\n           cblock.getDatanodes(Type.PENDING_CACHED);\n       List\u003cDatanodeDescriptor\u003e cached \u003d\n           cblock.getDatanodes(Type.CACHED);\n       List\u003cDatanodeDescriptor\u003e pendingUncached \u003d\n           cblock.getDatanodes(Type.PENDING_UNCACHED);\n       // Remove nodes from PENDING_UNCACHED if they were actually uncached.\n       for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingUncached.iterator();\n           iter.hasNext(); ) {\n         DatanodeDescriptor datanode \u003d iter.next();\n         if (!cblock.isInList(datanode.getCached())) {\n           LOG.trace(\"Block {}: removing from PENDING_UNCACHED for node {} \"\n               + \"because the DataNode uncached it.\", cblock.getBlockId(),\n               datanode.getDatanodeUuid());\n           datanode.getPendingUncached().remove(cblock);\n           iter.remove();\n         }\n       }\n-      BlockInfoContiguous blockInfo \u003d blockManager.\n+      BlockInfo blockInfo \u003d blockManager.\n             getStoredBlock(new Block(cblock.getBlockId()));\n       String reason \u003d findReasonForNotCaching(cblock, blockInfo);\n       int neededCached \u003d 0;\n       if (reason !\u003d null) {\n         LOG.trace(\"Block {}: can\u0027t cache block because it is {}\",\n             cblock.getBlockId(), reason);\n       } else {\n         neededCached \u003d cblock.getReplication();\n       }\n       int numCached \u003d cached.size();\n       if (numCached \u003e\u003d neededCached) {\n         // If we have enough replicas, drop all pending cached.\n         for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingCached.iterator();\n             iter.hasNext(); ) {\n           DatanodeDescriptor datanode \u003d iter.next();\n           datanode.getPendingCached().remove(cblock);\n           iter.remove();\n           LOG.trace(\"Block {}: removing from PENDING_CACHED for node {}\"\n                   + \"because we already have {} cached replicas and we only\" +\n                   \" need {}\",\n               cblock.getBlockId(), datanode.getDatanodeUuid(), numCached,\n               neededCached\n           );\n         }\n       }\n       if (numCached \u003c neededCached) {\n         // If we don\u0027t have enough replicas, drop all pending uncached.\n         for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingUncached.iterator();\n             iter.hasNext(); ) {\n           DatanodeDescriptor datanode \u003d iter.next();\n           datanode.getPendingUncached().remove(cblock);\n           iter.remove();\n           LOG.trace(\"Block {}: removing from PENDING_UNCACHED for node {} \"\n                   + \"because we only have {} cached replicas and we need \" +\n                   \"{}\", cblock.getBlockId(), datanode.getDatanodeUuid(),\n               numCached, neededCached\n           );\n         }\n       }\n       int neededUncached \u003d numCached -\n           (pendingUncached.size() + neededCached);\n       if (neededUncached \u003e 0) {\n         addNewPendingUncached(neededUncached, cblock, cached,\n             pendingUncached);\n       } else {\n         int additionalCachedNeeded \u003d neededCached -\n             (numCached + pendingCached.size());\n         if (additionalCachedNeeded \u003e 0) {\n           addNewPendingCached(additionalCachedNeeded, cblock, cached,\n               pendingCached);\n         }\n       }\n       if ((neededCached \u003d\u003d 0) \u0026\u0026\n           pendingUncached.isEmpty() \u0026\u0026\n           pendingCached.isEmpty()) {\n         // we have nothing more to do with this block.\n         LOG.trace(\"Block {}: removing from cachedBlocks, since neededCached \"\n                 + \"\u003d\u003d 0, and pendingUncached and pendingCached are empty.\",\n             cblock.getBlockId()\n         );\n         cbIter.remove();\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void rescanCachedBlockMap() {\n    for (Iterator\u003cCachedBlock\u003e cbIter \u003d cachedBlocks.iterator();\n        cbIter.hasNext(); ) {\n      scannedBlocks++;\n      CachedBlock cblock \u003d cbIter.next();\n      List\u003cDatanodeDescriptor\u003e pendingCached \u003d\n          cblock.getDatanodes(Type.PENDING_CACHED);\n      List\u003cDatanodeDescriptor\u003e cached \u003d\n          cblock.getDatanodes(Type.CACHED);\n      List\u003cDatanodeDescriptor\u003e pendingUncached \u003d\n          cblock.getDatanodes(Type.PENDING_UNCACHED);\n      // Remove nodes from PENDING_UNCACHED if they were actually uncached.\n      for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingUncached.iterator();\n          iter.hasNext(); ) {\n        DatanodeDescriptor datanode \u003d iter.next();\n        if (!cblock.isInList(datanode.getCached())) {\n          LOG.trace(\"Block {}: removing from PENDING_UNCACHED for node {} \"\n              + \"because the DataNode uncached it.\", cblock.getBlockId(),\n              datanode.getDatanodeUuid());\n          datanode.getPendingUncached().remove(cblock);\n          iter.remove();\n        }\n      }\n      BlockInfo blockInfo \u003d blockManager.\n            getStoredBlock(new Block(cblock.getBlockId()));\n      String reason \u003d findReasonForNotCaching(cblock, blockInfo);\n      int neededCached \u003d 0;\n      if (reason !\u003d null) {\n        LOG.trace(\"Block {}: can\u0027t cache block because it is {}\",\n            cblock.getBlockId(), reason);\n      } else {\n        neededCached \u003d cblock.getReplication();\n      }\n      int numCached \u003d cached.size();\n      if (numCached \u003e\u003d neededCached) {\n        // If we have enough replicas, drop all pending cached.\n        for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingCached.iterator();\n            iter.hasNext(); ) {\n          DatanodeDescriptor datanode \u003d iter.next();\n          datanode.getPendingCached().remove(cblock);\n          iter.remove();\n          LOG.trace(\"Block {}: removing from PENDING_CACHED for node {}\"\n                  + \"because we already have {} cached replicas and we only\" +\n                  \" need {}\",\n              cblock.getBlockId(), datanode.getDatanodeUuid(), numCached,\n              neededCached\n          );\n        }\n      }\n      if (numCached \u003c neededCached) {\n        // If we don\u0027t have enough replicas, drop all pending uncached.\n        for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingUncached.iterator();\n            iter.hasNext(); ) {\n          DatanodeDescriptor datanode \u003d iter.next();\n          datanode.getPendingUncached().remove(cblock);\n          iter.remove();\n          LOG.trace(\"Block {}: removing from PENDING_UNCACHED for node {} \"\n                  + \"because we only have {} cached replicas and we need \" +\n                  \"{}\", cblock.getBlockId(), datanode.getDatanodeUuid(),\n              numCached, neededCached\n          );\n        }\n      }\n      int neededUncached \u003d numCached -\n          (pendingUncached.size() + neededCached);\n      if (neededUncached \u003e 0) {\n        addNewPendingUncached(neededUncached, cblock, cached,\n            pendingUncached);\n      } else {\n        int additionalCachedNeeded \u003d neededCached -\n            (numCached + pendingCached.size());\n        if (additionalCachedNeeded \u003e 0) {\n          addNewPendingCached(additionalCachedNeeded, cblock, cached,\n              pendingCached);\n        }\n      }\n      if ((neededCached \u003d\u003d 0) \u0026\u0026\n          pendingUncached.isEmpty() \u0026\u0026\n          pendingCached.isEmpty()) {\n        // we have nothing more to do with this block.\n        LOG.trace(\"Block {}: removing from cachedBlocks, since neededCached \"\n                + \"\u003d\u003d 0, and pendingUncached and pendingCached are empty.\",\n            cblock.getBlockId()\n        );\n        cbIter.remove();\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/CacheReplicationMonitor.java",
      "extendedDetails": {}
    },
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7743. Code cleanup of BlockInfo and rename BlockInfo to BlockInfoContiguous. Contributed by Jing Zhao.\n",
      "commitDate": "08/02/15 11:51 AM",
      "commitName": "1382ae525c67bf95d8f3a436b547dbc72cfbb177",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "23/10/14 11:58 PM",
      "commitNameOld": "0942c99eba12f6baf5609c9621cd07b09618a97e",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 107.54,
      "commitsBetweenForRepo": 791,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,88 +1,88 @@\n   private void rescanCachedBlockMap() {\n     for (Iterator\u003cCachedBlock\u003e cbIter \u003d cachedBlocks.iterator();\n         cbIter.hasNext(); ) {\n       scannedBlocks++;\n       CachedBlock cblock \u003d cbIter.next();\n       List\u003cDatanodeDescriptor\u003e pendingCached \u003d\n           cblock.getDatanodes(Type.PENDING_CACHED);\n       List\u003cDatanodeDescriptor\u003e cached \u003d\n           cblock.getDatanodes(Type.CACHED);\n       List\u003cDatanodeDescriptor\u003e pendingUncached \u003d\n           cblock.getDatanodes(Type.PENDING_UNCACHED);\n       // Remove nodes from PENDING_UNCACHED if they were actually uncached.\n       for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingUncached.iterator();\n           iter.hasNext(); ) {\n         DatanodeDescriptor datanode \u003d iter.next();\n         if (!cblock.isInList(datanode.getCached())) {\n           LOG.trace(\"Block {}: removing from PENDING_UNCACHED for node {} \"\n               + \"because the DataNode uncached it.\", cblock.getBlockId(),\n               datanode.getDatanodeUuid());\n           datanode.getPendingUncached().remove(cblock);\n           iter.remove();\n         }\n       }\n-      BlockInfo blockInfo \u003d blockManager.\n+      BlockInfoContiguous blockInfo \u003d blockManager.\n             getStoredBlock(new Block(cblock.getBlockId()));\n       String reason \u003d findReasonForNotCaching(cblock, blockInfo);\n       int neededCached \u003d 0;\n       if (reason !\u003d null) {\n         LOG.trace(\"Block {}: can\u0027t cache block because it is {}\",\n             cblock.getBlockId(), reason);\n       } else {\n         neededCached \u003d cblock.getReplication();\n       }\n       int numCached \u003d cached.size();\n       if (numCached \u003e\u003d neededCached) {\n         // If we have enough replicas, drop all pending cached.\n         for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingCached.iterator();\n             iter.hasNext(); ) {\n           DatanodeDescriptor datanode \u003d iter.next();\n           datanode.getPendingCached().remove(cblock);\n           iter.remove();\n           LOG.trace(\"Block {}: removing from PENDING_CACHED for node {}\"\n                   + \"because we already have {} cached replicas and we only\" +\n                   \" need {}\",\n               cblock.getBlockId(), datanode.getDatanodeUuid(), numCached,\n               neededCached\n           );\n         }\n       }\n       if (numCached \u003c neededCached) {\n         // If we don\u0027t have enough replicas, drop all pending uncached.\n         for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingUncached.iterator();\n             iter.hasNext(); ) {\n           DatanodeDescriptor datanode \u003d iter.next();\n           datanode.getPendingUncached().remove(cblock);\n           iter.remove();\n           LOG.trace(\"Block {}: removing from PENDING_UNCACHED for node {} \"\n                   + \"because we only have {} cached replicas and we need \" +\n                   \"{}\", cblock.getBlockId(), datanode.getDatanodeUuid(),\n               numCached, neededCached\n           );\n         }\n       }\n       int neededUncached \u003d numCached -\n           (pendingUncached.size() + neededCached);\n       if (neededUncached \u003e 0) {\n         addNewPendingUncached(neededUncached, cblock, cached,\n             pendingUncached);\n       } else {\n         int additionalCachedNeeded \u003d neededCached -\n             (numCached + pendingCached.size());\n         if (additionalCachedNeeded \u003e 0) {\n           addNewPendingCached(additionalCachedNeeded, cblock, cached,\n               pendingCached);\n         }\n       }\n       if ((neededCached \u003d\u003d 0) \u0026\u0026\n           pendingUncached.isEmpty() \u0026\u0026\n           pendingCached.isEmpty()) {\n         // we have nothing more to do with this block.\n         LOG.trace(\"Block {}: removing from cachedBlocks, since neededCached \"\n                 + \"\u003d\u003d 0, and pendingUncached and pendingCached are empty.\",\n             cblock.getBlockId()\n         );\n         cbIter.remove();\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void rescanCachedBlockMap() {\n    for (Iterator\u003cCachedBlock\u003e cbIter \u003d cachedBlocks.iterator();\n        cbIter.hasNext(); ) {\n      scannedBlocks++;\n      CachedBlock cblock \u003d cbIter.next();\n      List\u003cDatanodeDescriptor\u003e pendingCached \u003d\n          cblock.getDatanodes(Type.PENDING_CACHED);\n      List\u003cDatanodeDescriptor\u003e cached \u003d\n          cblock.getDatanodes(Type.CACHED);\n      List\u003cDatanodeDescriptor\u003e pendingUncached \u003d\n          cblock.getDatanodes(Type.PENDING_UNCACHED);\n      // Remove nodes from PENDING_UNCACHED if they were actually uncached.\n      for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingUncached.iterator();\n          iter.hasNext(); ) {\n        DatanodeDescriptor datanode \u003d iter.next();\n        if (!cblock.isInList(datanode.getCached())) {\n          LOG.trace(\"Block {}: removing from PENDING_UNCACHED for node {} \"\n              + \"because the DataNode uncached it.\", cblock.getBlockId(),\n              datanode.getDatanodeUuid());\n          datanode.getPendingUncached().remove(cblock);\n          iter.remove();\n        }\n      }\n      BlockInfoContiguous blockInfo \u003d blockManager.\n            getStoredBlock(new Block(cblock.getBlockId()));\n      String reason \u003d findReasonForNotCaching(cblock, blockInfo);\n      int neededCached \u003d 0;\n      if (reason !\u003d null) {\n        LOG.trace(\"Block {}: can\u0027t cache block because it is {}\",\n            cblock.getBlockId(), reason);\n      } else {\n        neededCached \u003d cblock.getReplication();\n      }\n      int numCached \u003d cached.size();\n      if (numCached \u003e\u003d neededCached) {\n        // If we have enough replicas, drop all pending cached.\n        for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingCached.iterator();\n            iter.hasNext(); ) {\n          DatanodeDescriptor datanode \u003d iter.next();\n          datanode.getPendingCached().remove(cblock);\n          iter.remove();\n          LOG.trace(\"Block {}: removing from PENDING_CACHED for node {}\"\n                  + \"because we already have {} cached replicas and we only\" +\n                  \" need {}\",\n              cblock.getBlockId(), datanode.getDatanodeUuid(), numCached,\n              neededCached\n          );\n        }\n      }\n      if (numCached \u003c neededCached) {\n        // If we don\u0027t have enough replicas, drop all pending uncached.\n        for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingUncached.iterator();\n            iter.hasNext(); ) {\n          DatanodeDescriptor datanode \u003d iter.next();\n          datanode.getPendingUncached().remove(cblock);\n          iter.remove();\n          LOG.trace(\"Block {}: removing from PENDING_UNCACHED for node {} \"\n                  + \"because we only have {} cached replicas and we need \" +\n                  \"{}\", cblock.getBlockId(), datanode.getDatanodeUuid(),\n              numCached, neededCached\n          );\n        }\n      }\n      int neededUncached \u003d numCached -\n          (pendingUncached.size() + neededCached);\n      if (neededUncached \u003e 0) {\n        addNewPendingUncached(neededUncached, cblock, cached,\n            pendingUncached);\n      } else {\n        int additionalCachedNeeded \u003d neededCached -\n            (numCached + pendingCached.size());\n        if (additionalCachedNeeded \u003e 0) {\n          addNewPendingCached(additionalCachedNeeded, cblock, cached,\n              pendingCached);\n        }\n      }\n      if ((neededCached \u003d\u003d 0) \u0026\u0026\n          pendingUncached.isEmpty() \u0026\u0026\n          pendingCached.isEmpty()) {\n        // we have nothing more to do with this block.\n        LOG.trace(\"Block {}: removing from cachedBlocks, since neededCached \"\n                + \"\u003d\u003d 0, and pendingUncached and pendingCached are empty.\",\n            cblock.getBlockId()\n        );\n        cbIter.remove();\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/CacheReplicationMonitor.java",
      "extendedDetails": {}
    },
    "93e23a99157c30b51752fc49748c3c210745a187": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6613. Improve logging in caching classes. (wang)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1607697 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/07/14 10:13 AM",
      "commitName": "93e23a99157c30b51752fc49748c3c210745a187",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "10/03/14 11:24 PM",
      "commitNameOld": "bab90b2222abb41d0e3382a92c2f9a8dc568f0e0",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 114.45,
      "commitsBetweenForRepo": 724,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,94 +1,88 @@\n   private void rescanCachedBlockMap() {\n     for (Iterator\u003cCachedBlock\u003e cbIter \u003d cachedBlocks.iterator();\n         cbIter.hasNext(); ) {\n       scannedBlocks++;\n       CachedBlock cblock \u003d cbIter.next();\n       List\u003cDatanodeDescriptor\u003e pendingCached \u003d\n           cblock.getDatanodes(Type.PENDING_CACHED);\n       List\u003cDatanodeDescriptor\u003e cached \u003d\n           cblock.getDatanodes(Type.CACHED);\n       List\u003cDatanodeDescriptor\u003e pendingUncached \u003d\n           cblock.getDatanodes(Type.PENDING_UNCACHED);\n       // Remove nodes from PENDING_UNCACHED if they were actually uncached.\n       for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingUncached.iterator();\n           iter.hasNext(); ) {\n         DatanodeDescriptor datanode \u003d iter.next();\n         if (!cblock.isInList(datanode.getCached())) {\n-          if (LOG.isTraceEnabled()) {\n-            LOG.trace(\"Block \" + cblock.getBlockId() + \": removing from \" +\n-                \"PENDING_UNCACHED for node \" + datanode.getDatanodeUuid() +\n-                \"because the DataNode uncached it.\");\n-          }\n+          LOG.trace(\"Block {}: removing from PENDING_UNCACHED for node {} \"\n+              + \"because the DataNode uncached it.\", cblock.getBlockId(),\n+              datanode.getDatanodeUuid());\n           datanode.getPendingUncached().remove(cblock);\n           iter.remove();\n         }\n       }\n       BlockInfo blockInfo \u003d blockManager.\n             getStoredBlock(new Block(cblock.getBlockId()));\n       String reason \u003d findReasonForNotCaching(cblock, blockInfo);\n       int neededCached \u003d 0;\n       if (reason !\u003d null) {\n-        if (LOG.isTraceEnabled()) {\n-          LOG.trace(\"Block \" + cblock.getBlockId() + \": can\u0027t cache \" +\n-              \"block because it is \" + reason);\n-        }\n+        LOG.trace(\"Block {}: can\u0027t cache block because it is {}\",\n+            cblock.getBlockId(), reason);\n       } else {\n         neededCached \u003d cblock.getReplication();\n       }\n       int numCached \u003d cached.size();\n       if (numCached \u003e\u003d neededCached) {\n         // If we have enough replicas, drop all pending cached.\n         for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingCached.iterator();\n             iter.hasNext(); ) {\n           DatanodeDescriptor datanode \u003d iter.next();\n           datanode.getPendingCached().remove(cblock);\n           iter.remove();\n-          if (LOG.isTraceEnabled()) {\n-            LOG.trace(\"Block \" + cblock.getBlockId() + \": removing from \" +\n-                \"PENDING_CACHED for node \" + datanode.getDatanodeUuid() +\n-                \"because we already have \" + numCached + \" cached \" +\n-                \"replicas and we only need \" + neededCached);\n-          }\n+          LOG.trace(\"Block {}: removing from PENDING_CACHED for node {}\"\n+                  + \"because we already have {} cached replicas and we only\" +\n+                  \" need {}\",\n+              cblock.getBlockId(), datanode.getDatanodeUuid(), numCached,\n+              neededCached\n+          );\n         }\n       }\n       if (numCached \u003c neededCached) {\n         // If we don\u0027t have enough replicas, drop all pending uncached.\n         for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingUncached.iterator();\n             iter.hasNext(); ) {\n           DatanodeDescriptor datanode \u003d iter.next();\n           datanode.getPendingUncached().remove(cblock);\n           iter.remove();\n-          if (LOG.isTraceEnabled()) {\n-            LOG.trace(\"Block \" + cblock.getBlockId() + \": removing from \" +\n-                \"PENDING_UNCACHED for node \" + datanode.getDatanodeUuid() +\n-                \"because we only have \" + numCached + \" cached replicas \" +\n-                \"and we need \" + neededCached);\n-          }\n+          LOG.trace(\"Block {}: removing from PENDING_UNCACHED for node {} \"\n+                  + \"because we only have {} cached replicas and we need \" +\n+                  \"{}\", cblock.getBlockId(), datanode.getDatanodeUuid(),\n+              numCached, neededCached\n+          );\n         }\n       }\n       int neededUncached \u003d numCached -\n           (pendingUncached.size() + neededCached);\n       if (neededUncached \u003e 0) {\n         addNewPendingUncached(neededUncached, cblock, cached,\n             pendingUncached);\n       } else {\n         int additionalCachedNeeded \u003d neededCached -\n             (numCached + pendingCached.size());\n         if (additionalCachedNeeded \u003e 0) {\n           addNewPendingCached(additionalCachedNeeded, cblock, cached,\n               pendingCached);\n         }\n       }\n       if ((neededCached \u003d\u003d 0) \u0026\u0026\n           pendingUncached.isEmpty() \u0026\u0026\n           pendingCached.isEmpty()) {\n         // we have nothing more to do with this block.\n-        if (LOG.isTraceEnabled()) {\n-          LOG.trace(\"Block \" + cblock.getBlockId() + \": removing from \" +\n-              \"cachedBlocks, since neededCached \u003d\u003d 0, and \" +\n-              \"pendingUncached and pendingCached are empty.\");\n-        }\n+        LOG.trace(\"Block {}: removing from cachedBlocks, since neededCached \"\n+                + \"\u003d\u003d 0, and pendingUncached and pendingCached are empty.\",\n+            cblock.getBlockId()\n+        );\n         cbIter.remove();\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void rescanCachedBlockMap() {\n    for (Iterator\u003cCachedBlock\u003e cbIter \u003d cachedBlocks.iterator();\n        cbIter.hasNext(); ) {\n      scannedBlocks++;\n      CachedBlock cblock \u003d cbIter.next();\n      List\u003cDatanodeDescriptor\u003e pendingCached \u003d\n          cblock.getDatanodes(Type.PENDING_CACHED);\n      List\u003cDatanodeDescriptor\u003e cached \u003d\n          cblock.getDatanodes(Type.CACHED);\n      List\u003cDatanodeDescriptor\u003e pendingUncached \u003d\n          cblock.getDatanodes(Type.PENDING_UNCACHED);\n      // Remove nodes from PENDING_UNCACHED if they were actually uncached.\n      for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingUncached.iterator();\n          iter.hasNext(); ) {\n        DatanodeDescriptor datanode \u003d iter.next();\n        if (!cblock.isInList(datanode.getCached())) {\n          LOG.trace(\"Block {}: removing from PENDING_UNCACHED for node {} \"\n              + \"because the DataNode uncached it.\", cblock.getBlockId(),\n              datanode.getDatanodeUuid());\n          datanode.getPendingUncached().remove(cblock);\n          iter.remove();\n        }\n      }\n      BlockInfo blockInfo \u003d blockManager.\n            getStoredBlock(new Block(cblock.getBlockId()));\n      String reason \u003d findReasonForNotCaching(cblock, blockInfo);\n      int neededCached \u003d 0;\n      if (reason !\u003d null) {\n        LOG.trace(\"Block {}: can\u0027t cache block because it is {}\",\n            cblock.getBlockId(), reason);\n      } else {\n        neededCached \u003d cblock.getReplication();\n      }\n      int numCached \u003d cached.size();\n      if (numCached \u003e\u003d neededCached) {\n        // If we have enough replicas, drop all pending cached.\n        for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingCached.iterator();\n            iter.hasNext(); ) {\n          DatanodeDescriptor datanode \u003d iter.next();\n          datanode.getPendingCached().remove(cblock);\n          iter.remove();\n          LOG.trace(\"Block {}: removing from PENDING_CACHED for node {}\"\n                  + \"because we already have {} cached replicas and we only\" +\n                  \" need {}\",\n              cblock.getBlockId(), datanode.getDatanodeUuid(), numCached,\n              neededCached\n          );\n        }\n      }\n      if (numCached \u003c neededCached) {\n        // If we don\u0027t have enough replicas, drop all pending uncached.\n        for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingUncached.iterator();\n            iter.hasNext(); ) {\n          DatanodeDescriptor datanode \u003d iter.next();\n          datanode.getPendingUncached().remove(cblock);\n          iter.remove();\n          LOG.trace(\"Block {}: removing from PENDING_UNCACHED for node {} \"\n                  + \"because we only have {} cached replicas and we need \" +\n                  \"{}\", cblock.getBlockId(), datanode.getDatanodeUuid(),\n              numCached, neededCached\n          );\n        }\n      }\n      int neededUncached \u003d numCached -\n          (pendingUncached.size() + neededCached);\n      if (neededUncached \u003e 0) {\n        addNewPendingUncached(neededUncached, cblock, cached,\n            pendingUncached);\n      } else {\n        int additionalCachedNeeded \u003d neededCached -\n            (numCached + pendingCached.size());\n        if (additionalCachedNeeded \u003e 0) {\n          addNewPendingCached(additionalCachedNeeded, cblock, cached,\n              pendingCached);\n        }\n      }\n      if ((neededCached \u003d\u003d 0) \u0026\u0026\n          pendingUncached.isEmpty() \u0026\u0026\n          pendingCached.isEmpty()) {\n        // we have nothing more to do with this block.\n        LOG.trace(\"Block {}: removing from cachedBlocks, since neededCached \"\n                + \"\u003d\u003d 0, and pendingUncached and pendingCached are empty.\",\n            cblock.getBlockId()\n        );\n        cbIter.remove();\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/CacheReplicationMonitor.java",
      "extendedDetails": {}
    },
    "bab90b2222abb41d0e3382a92c2f9a8dc568f0e0": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6085. Improve CacheReplicationMonitor log messages a bit (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1576194 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/03/14 11:24 PM",
      "commitName": "bab90b2222abb41d0e3382a92c2f9a8dc568f0e0",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "07/01/14 12:52 PM",
      "commitNameOld": "70cff9e2f0c8f78c1dc54a064182971bb2106795",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 62.4,
      "commitsBetweenForRepo": 529,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,71 +1,94 @@\n   private void rescanCachedBlockMap() {\n     for (Iterator\u003cCachedBlock\u003e cbIter \u003d cachedBlocks.iterator();\n         cbIter.hasNext(); ) {\n       scannedBlocks++;\n       CachedBlock cblock \u003d cbIter.next();\n       List\u003cDatanodeDescriptor\u003e pendingCached \u003d\n           cblock.getDatanodes(Type.PENDING_CACHED);\n       List\u003cDatanodeDescriptor\u003e cached \u003d\n           cblock.getDatanodes(Type.CACHED);\n       List\u003cDatanodeDescriptor\u003e pendingUncached \u003d\n           cblock.getDatanodes(Type.PENDING_UNCACHED);\n       // Remove nodes from PENDING_UNCACHED if they were actually uncached.\n       for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingUncached.iterator();\n           iter.hasNext(); ) {\n         DatanodeDescriptor datanode \u003d iter.next();\n         if (!cblock.isInList(datanode.getCached())) {\n+          if (LOG.isTraceEnabled()) {\n+            LOG.trace(\"Block \" + cblock.getBlockId() + \": removing from \" +\n+                \"PENDING_UNCACHED for node \" + datanode.getDatanodeUuid() +\n+                \"because the DataNode uncached it.\");\n+          }\n           datanode.getPendingUncached().remove(cblock);\n           iter.remove();\n         }\n       }\n       BlockInfo blockInfo \u003d blockManager.\n             getStoredBlock(new Block(cblock.getBlockId()));\n       String reason \u003d findReasonForNotCaching(cblock, blockInfo);\n       int neededCached \u003d 0;\n       if (reason !\u003d null) {\n-        if (LOG.isDebugEnabled()) {\n-          LOG.debug(\"not caching \" + cblock + \" because it is \" + reason);\n+        if (LOG.isTraceEnabled()) {\n+          LOG.trace(\"Block \" + cblock.getBlockId() + \": can\u0027t cache \" +\n+              \"block because it is \" + reason);\n         }\n       } else {\n         neededCached \u003d cblock.getReplication();\n       }\n       int numCached \u003d cached.size();\n       if (numCached \u003e\u003d neededCached) {\n         // If we have enough replicas, drop all pending cached.\n         for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingCached.iterator();\n             iter.hasNext(); ) {\n           DatanodeDescriptor datanode \u003d iter.next();\n           datanode.getPendingCached().remove(cblock);\n           iter.remove();\n+          if (LOG.isTraceEnabled()) {\n+            LOG.trace(\"Block \" + cblock.getBlockId() + \": removing from \" +\n+                \"PENDING_CACHED for node \" + datanode.getDatanodeUuid() +\n+                \"because we already have \" + numCached + \" cached \" +\n+                \"replicas and we only need \" + neededCached);\n+          }\n         }\n       }\n       if (numCached \u003c neededCached) {\n         // If we don\u0027t have enough replicas, drop all pending uncached.\n         for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingUncached.iterator();\n             iter.hasNext(); ) {\n           DatanodeDescriptor datanode \u003d iter.next();\n           datanode.getPendingUncached().remove(cblock);\n           iter.remove();\n+          if (LOG.isTraceEnabled()) {\n+            LOG.trace(\"Block \" + cblock.getBlockId() + \": removing from \" +\n+                \"PENDING_UNCACHED for node \" + datanode.getDatanodeUuid() +\n+                \"because we only have \" + numCached + \" cached replicas \" +\n+                \"and we need \" + neededCached);\n+          }\n         }\n       }\n       int neededUncached \u003d numCached -\n           (pendingUncached.size() + neededCached);\n       if (neededUncached \u003e 0) {\n         addNewPendingUncached(neededUncached, cblock, cached,\n             pendingUncached);\n       } else {\n         int additionalCachedNeeded \u003d neededCached -\n             (numCached + pendingCached.size());\n         if (additionalCachedNeeded \u003e 0) {\n           addNewPendingCached(additionalCachedNeeded, cblock, cached,\n               pendingCached);\n         }\n       }\n       if ((neededCached \u003d\u003d 0) \u0026\u0026\n           pendingUncached.isEmpty() \u0026\u0026\n           pendingCached.isEmpty()) {\n         // we have nothing more to do with this block.\n+        if (LOG.isTraceEnabled()) {\n+          LOG.trace(\"Block \" + cblock.getBlockId() + \": removing from \" +\n+              \"cachedBlocks, since neededCached \u003d\u003d 0, and \" +\n+              \"pendingUncached and pendingCached are empty.\");\n+        }\n         cbIter.remove();\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void rescanCachedBlockMap() {\n    for (Iterator\u003cCachedBlock\u003e cbIter \u003d cachedBlocks.iterator();\n        cbIter.hasNext(); ) {\n      scannedBlocks++;\n      CachedBlock cblock \u003d cbIter.next();\n      List\u003cDatanodeDescriptor\u003e pendingCached \u003d\n          cblock.getDatanodes(Type.PENDING_CACHED);\n      List\u003cDatanodeDescriptor\u003e cached \u003d\n          cblock.getDatanodes(Type.CACHED);\n      List\u003cDatanodeDescriptor\u003e pendingUncached \u003d\n          cblock.getDatanodes(Type.PENDING_UNCACHED);\n      // Remove nodes from PENDING_UNCACHED if they were actually uncached.\n      for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingUncached.iterator();\n          iter.hasNext(); ) {\n        DatanodeDescriptor datanode \u003d iter.next();\n        if (!cblock.isInList(datanode.getCached())) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"Block \" + cblock.getBlockId() + \": removing from \" +\n                \"PENDING_UNCACHED for node \" + datanode.getDatanodeUuid() +\n                \"because the DataNode uncached it.\");\n          }\n          datanode.getPendingUncached().remove(cblock);\n          iter.remove();\n        }\n      }\n      BlockInfo blockInfo \u003d blockManager.\n            getStoredBlock(new Block(cblock.getBlockId()));\n      String reason \u003d findReasonForNotCaching(cblock, blockInfo);\n      int neededCached \u003d 0;\n      if (reason !\u003d null) {\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(\"Block \" + cblock.getBlockId() + \": can\u0027t cache \" +\n              \"block because it is \" + reason);\n        }\n      } else {\n        neededCached \u003d cblock.getReplication();\n      }\n      int numCached \u003d cached.size();\n      if (numCached \u003e\u003d neededCached) {\n        // If we have enough replicas, drop all pending cached.\n        for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingCached.iterator();\n            iter.hasNext(); ) {\n          DatanodeDescriptor datanode \u003d iter.next();\n          datanode.getPendingCached().remove(cblock);\n          iter.remove();\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"Block \" + cblock.getBlockId() + \": removing from \" +\n                \"PENDING_CACHED for node \" + datanode.getDatanodeUuid() +\n                \"because we already have \" + numCached + \" cached \" +\n                \"replicas and we only need \" + neededCached);\n          }\n        }\n      }\n      if (numCached \u003c neededCached) {\n        // If we don\u0027t have enough replicas, drop all pending uncached.\n        for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingUncached.iterator();\n            iter.hasNext(); ) {\n          DatanodeDescriptor datanode \u003d iter.next();\n          datanode.getPendingUncached().remove(cblock);\n          iter.remove();\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"Block \" + cblock.getBlockId() + \": removing from \" +\n                \"PENDING_UNCACHED for node \" + datanode.getDatanodeUuid() +\n                \"because we only have \" + numCached + \" cached replicas \" +\n                \"and we need \" + neededCached);\n          }\n        }\n      }\n      int neededUncached \u003d numCached -\n          (pendingUncached.size() + neededCached);\n      if (neededUncached \u003e 0) {\n        addNewPendingUncached(neededUncached, cblock, cached,\n            pendingUncached);\n      } else {\n        int additionalCachedNeeded \u003d neededCached -\n            (numCached + pendingCached.size());\n        if (additionalCachedNeeded \u003e 0) {\n          addNewPendingCached(additionalCachedNeeded, cblock, cached,\n              pendingCached);\n        }\n      }\n      if ((neededCached \u003d\u003d 0) \u0026\u0026\n          pendingUncached.isEmpty() \u0026\u0026\n          pendingCached.isEmpty()) {\n        // we have nothing more to do with this block.\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(\"Block \" + cblock.getBlockId() + \": removing from \" +\n              \"cachedBlocks, since neededCached \u003d\u003d 0, and \" +\n              \"pendingUncached and pendingCached are empty.\");\n        }\n        cbIter.remove();\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/CacheReplicationMonitor.java",
      "extendedDetails": {}
    },
    "07e4fb1455abc33584fc666ef745abe256ebd7d1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5708. The CacheManager throws a NPE in the DataNode logs when processing cache reports that refer to a block not known to the BlockManager. Contributed by Colin Patrick McCabe.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1554594 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "31/12/13 4:01 PM",
      "commitName": "07e4fb1455abc33584fc666ef745abe256ebd7d1",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "20/12/13 3:27 PM",
      "commitNameOld": "b9ae3087c0f83bfeeea47ded8e19932b46fd2350",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 11.02,
      "commitsBetweenForRepo": 22,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,65 +1,71 @@\n   private void rescanCachedBlockMap() {\n     for (Iterator\u003cCachedBlock\u003e cbIter \u003d cachedBlocks.iterator();\n         cbIter.hasNext(); ) {\n       scannedBlocks++;\n       CachedBlock cblock \u003d cbIter.next();\n       List\u003cDatanodeDescriptor\u003e pendingCached \u003d\n           cblock.getDatanodes(Type.PENDING_CACHED);\n       List\u003cDatanodeDescriptor\u003e cached \u003d\n           cblock.getDatanodes(Type.CACHED);\n       List\u003cDatanodeDescriptor\u003e pendingUncached \u003d\n           cblock.getDatanodes(Type.PENDING_UNCACHED);\n       // Remove nodes from PENDING_UNCACHED if they were actually uncached.\n       for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingUncached.iterator();\n           iter.hasNext(); ) {\n         DatanodeDescriptor datanode \u003d iter.next();\n         if (!cblock.isInList(datanode.getCached())) {\n           datanode.getPendingUncached().remove(cblock);\n           iter.remove();\n         }\n       }\n-      // If the block\u0027s mark doesn\u0027t match with the mark of this scan, that\n-      // means that this block couldn\u0027t be reached during this scan.  That means\n-      // it doesn\u0027t need to be cached any more.\n-      int neededCached \u003d (cblock.getMark() !\u003d mark) ?\n-          0 : cblock.getReplication();\n+      BlockInfo blockInfo \u003d blockManager.\n+            getStoredBlock(new Block(cblock.getBlockId()));\n+      String reason \u003d findReasonForNotCaching(cblock, blockInfo);\n+      int neededCached \u003d 0;\n+      if (reason !\u003d null) {\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"not caching \" + cblock + \" because it is \" + reason);\n+        }\n+      } else {\n+        neededCached \u003d cblock.getReplication();\n+      }\n       int numCached \u003d cached.size();\n       if (numCached \u003e\u003d neededCached) {\n         // If we have enough replicas, drop all pending cached.\n         for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingCached.iterator();\n             iter.hasNext(); ) {\n           DatanodeDescriptor datanode \u003d iter.next();\n           datanode.getPendingCached().remove(cblock);\n           iter.remove();\n         }\n       }\n       if (numCached \u003c neededCached) {\n         // If we don\u0027t have enough replicas, drop all pending uncached.\n         for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingUncached.iterator();\n             iter.hasNext(); ) {\n           DatanodeDescriptor datanode \u003d iter.next();\n           datanode.getPendingUncached().remove(cblock);\n           iter.remove();\n         }\n       }\n       int neededUncached \u003d numCached -\n           (pendingUncached.size() + neededCached);\n       if (neededUncached \u003e 0) {\n         addNewPendingUncached(neededUncached, cblock, cached,\n             pendingUncached);\n       } else {\n         int additionalCachedNeeded \u003d neededCached -\n             (numCached + pendingCached.size());\n         if (additionalCachedNeeded \u003e 0) {\n           addNewPendingCached(additionalCachedNeeded, cblock, cached,\n               pendingCached);\n         }\n       }\n       if ((neededCached \u003d\u003d 0) \u0026\u0026\n           pendingUncached.isEmpty() \u0026\u0026\n           pendingCached.isEmpty()) {\n         // we have nothing more to do with this block.\n         cbIter.remove();\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void rescanCachedBlockMap() {\n    for (Iterator\u003cCachedBlock\u003e cbIter \u003d cachedBlocks.iterator();\n        cbIter.hasNext(); ) {\n      scannedBlocks++;\n      CachedBlock cblock \u003d cbIter.next();\n      List\u003cDatanodeDescriptor\u003e pendingCached \u003d\n          cblock.getDatanodes(Type.PENDING_CACHED);\n      List\u003cDatanodeDescriptor\u003e cached \u003d\n          cblock.getDatanodes(Type.CACHED);\n      List\u003cDatanodeDescriptor\u003e pendingUncached \u003d\n          cblock.getDatanodes(Type.PENDING_UNCACHED);\n      // Remove nodes from PENDING_UNCACHED if they were actually uncached.\n      for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingUncached.iterator();\n          iter.hasNext(); ) {\n        DatanodeDescriptor datanode \u003d iter.next();\n        if (!cblock.isInList(datanode.getCached())) {\n          datanode.getPendingUncached().remove(cblock);\n          iter.remove();\n        }\n      }\n      BlockInfo blockInfo \u003d blockManager.\n            getStoredBlock(new Block(cblock.getBlockId()));\n      String reason \u003d findReasonForNotCaching(cblock, blockInfo);\n      int neededCached \u003d 0;\n      if (reason !\u003d null) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"not caching \" + cblock + \" because it is \" + reason);\n        }\n      } else {\n        neededCached \u003d cblock.getReplication();\n      }\n      int numCached \u003d cached.size();\n      if (numCached \u003e\u003d neededCached) {\n        // If we have enough replicas, drop all pending cached.\n        for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingCached.iterator();\n            iter.hasNext(); ) {\n          DatanodeDescriptor datanode \u003d iter.next();\n          datanode.getPendingCached().remove(cblock);\n          iter.remove();\n        }\n      }\n      if (numCached \u003c neededCached) {\n        // If we don\u0027t have enough replicas, drop all pending uncached.\n        for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingUncached.iterator();\n            iter.hasNext(); ) {\n          DatanodeDescriptor datanode \u003d iter.next();\n          datanode.getPendingUncached().remove(cblock);\n          iter.remove();\n        }\n      }\n      int neededUncached \u003d numCached -\n          (pendingUncached.size() + neededCached);\n      if (neededUncached \u003e 0) {\n        addNewPendingUncached(neededUncached, cblock, cached,\n            pendingUncached);\n      } else {\n        int additionalCachedNeeded \u003d neededCached -\n            (numCached + pendingCached.size());\n        if (additionalCachedNeeded \u003e 0) {\n          addNewPendingCached(additionalCachedNeeded, cblock, cached,\n              pendingCached);\n        }\n      }\n      if ((neededCached \u003d\u003d 0) \u0026\u0026\n          pendingUncached.isEmpty() \u0026\u0026\n          pendingCached.isEmpty()) {\n        // we have nothing more to do with this block.\n        cbIter.remove();\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/CacheReplicationMonitor.java",
      "extendedDetails": {}
    },
    "3c591aa442d342bdd4a0c4abe9a43c64d8ef3e65": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5366. recaching improvements (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1541647 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/11/13 10:18 AM",
      "commitName": "3c591aa442d342bdd4a0c4abe9a43c64d8ef3e65",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "16/10/13 3:15 PM",
      "commitNameOld": "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 27.84,
      "commitsBetweenForRepo": 131,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,61 +1,65 @@\n   private void rescanCachedBlockMap() {\n     for (Iterator\u003cCachedBlock\u003e cbIter \u003d cachedBlocks.iterator();\n         cbIter.hasNext(); ) {\n       scannedBlocks++;\n       CachedBlock cblock \u003d cbIter.next();\n       List\u003cDatanodeDescriptor\u003e pendingCached \u003d\n           cblock.getDatanodes(Type.PENDING_CACHED);\n       List\u003cDatanodeDescriptor\u003e cached \u003d\n           cblock.getDatanodes(Type.CACHED);\n       List\u003cDatanodeDescriptor\u003e pendingUncached \u003d\n           cblock.getDatanodes(Type.PENDING_UNCACHED);\n       // Remove nodes from PENDING_UNCACHED if they were actually uncached.\n       for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingUncached.iterator();\n           iter.hasNext(); ) {\n         DatanodeDescriptor datanode \u003d iter.next();\n         if (!cblock.isInList(datanode.getCached())) {\n           datanode.getPendingUncached().remove(cblock);\n           iter.remove();\n         }\n       }\n       // If the block\u0027s mark doesn\u0027t match with the mark of this scan, that\n       // means that this block couldn\u0027t be reached during this scan.  That means\n       // it doesn\u0027t need to be cached any more.\n       int neededCached \u003d (cblock.getMark() !\u003d mark) ?\n           0 : cblock.getReplication();\n       int numCached \u003d cached.size();\n       if (numCached \u003e\u003d neededCached) {\n         // If we have enough replicas, drop all pending cached.\n-        for (DatanodeDescriptor datanode : pendingCached) {\n+        for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingCached.iterator();\n+            iter.hasNext(); ) {\n+          DatanodeDescriptor datanode \u003d iter.next();\n           datanode.getPendingCached().remove(cblock);\n+          iter.remove();\n         }\n-        pendingCached.clear();\n       }\n       if (numCached \u003c neededCached) {\n         // If we don\u0027t have enough replicas, drop all pending uncached.\n-        for (DatanodeDescriptor datanode : pendingUncached) {\n+        for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingUncached.iterator();\n+            iter.hasNext(); ) {\n+          DatanodeDescriptor datanode \u003d iter.next();\n           datanode.getPendingUncached().remove(cblock);\n+          iter.remove();\n         }\n-        pendingUncached.clear();\n       }\n       int neededUncached \u003d numCached -\n           (pendingUncached.size() + neededCached);\n       if (neededUncached \u003e 0) {\n         addNewPendingUncached(neededUncached, cblock, cached,\n             pendingUncached);\n       } else {\n         int additionalCachedNeeded \u003d neededCached -\n             (numCached + pendingCached.size());\n         if (additionalCachedNeeded \u003e 0) {\n           addNewPendingCached(additionalCachedNeeded, cblock, cached,\n               pendingCached);\n         }\n       }\n       if ((neededCached \u003d\u003d 0) \u0026\u0026\n           pendingUncached.isEmpty() \u0026\u0026\n           pendingCached.isEmpty()) {\n         // we have nothing more to do with this block.\n         cbIter.remove();\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void rescanCachedBlockMap() {\n    for (Iterator\u003cCachedBlock\u003e cbIter \u003d cachedBlocks.iterator();\n        cbIter.hasNext(); ) {\n      scannedBlocks++;\n      CachedBlock cblock \u003d cbIter.next();\n      List\u003cDatanodeDescriptor\u003e pendingCached \u003d\n          cblock.getDatanodes(Type.PENDING_CACHED);\n      List\u003cDatanodeDescriptor\u003e cached \u003d\n          cblock.getDatanodes(Type.CACHED);\n      List\u003cDatanodeDescriptor\u003e pendingUncached \u003d\n          cblock.getDatanodes(Type.PENDING_UNCACHED);\n      // Remove nodes from PENDING_UNCACHED if they were actually uncached.\n      for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingUncached.iterator();\n          iter.hasNext(); ) {\n        DatanodeDescriptor datanode \u003d iter.next();\n        if (!cblock.isInList(datanode.getCached())) {\n          datanode.getPendingUncached().remove(cblock);\n          iter.remove();\n        }\n      }\n      // If the block\u0027s mark doesn\u0027t match with the mark of this scan, that\n      // means that this block couldn\u0027t be reached during this scan.  That means\n      // it doesn\u0027t need to be cached any more.\n      int neededCached \u003d (cblock.getMark() !\u003d mark) ?\n          0 : cblock.getReplication();\n      int numCached \u003d cached.size();\n      if (numCached \u003e\u003d neededCached) {\n        // If we have enough replicas, drop all pending cached.\n        for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingCached.iterator();\n            iter.hasNext(); ) {\n          DatanodeDescriptor datanode \u003d iter.next();\n          datanode.getPendingCached().remove(cblock);\n          iter.remove();\n        }\n      }\n      if (numCached \u003c neededCached) {\n        // If we don\u0027t have enough replicas, drop all pending uncached.\n        for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingUncached.iterator();\n            iter.hasNext(); ) {\n          DatanodeDescriptor datanode \u003d iter.next();\n          datanode.getPendingUncached().remove(cblock);\n          iter.remove();\n        }\n      }\n      int neededUncached \u003d numCached -\n          (pendingUncached.size() + neededCached);\n      if (neededUncached \u003e 0) {\n        addNewPendingUncached(neededUncached, cblock, cached,\n            pendingUncached);\n      } else {\n        int additionalCachedNeeded \u003d neededCached -\n            (numCached + pendingCached.size());\n        if (additionalCachedNeeded \u003e 0) {\n          addNewPendingCached(additionalCachedNeeded, cblock, cached,\n              pendingCached);\n        }\n      }\n      if ((neededCached \u003d\u003d 0) \u0026\u0026\n          pendingUncached.isEmpty() \u0026\u0026\n          pendingCached.isEmpty()) {\n        // we have nothing more to do with this block.\n        cbIter.remove();\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/CacheReplicationMonitor.java",
      "extendedDetails": {}
    },
    "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5096. Automatically cache new data added to a cached path (contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1532924 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/10/13 3:15 PM",
      "commitName": "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
      "commitAuthor": "Colin McCabe",
      "diff": "@@ -0,0 +1,61 @@\n+  private void rescanCachedBlockMap() {\n+    for (Iterator\u003cCachedBlock\u003e cbIter \u003d cachedBlocks.iterator();\n+        cbIter.hasNext(); ) {\n+      scannedBlocks++;\n+      CachedBlock cblock \u003d cbIter.next();\n+      List\u003cDatanodeDescriptor\u003e pendingCached \u003d\n+          cblock.getDatanodes(Type.PENDING_CACHED);\n+      List\u003cDatanodeDescriptor\u003e cached \u003d\n+          cblock.getDatanodes(Type.CACHED);\n+      List\u003cDatanodeDescriptor\u003e pendingUncached \u003d\n+          cblock.getDatanodes(Type.PENDING_UNCACHED);\n+      // Remove nodes from PENDING_UNCACHED if they were actually uncached.\n+      for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingUncached.iterator();\n+          iter.hasNext(); ) {\n+        DatanodeDescriptor datanode \u003d iter.next();\n+        if (!cblock.isInList(datanode.getCached())) {\n+          datanode.getPendingUncached().remove(cblock);\n+          iter.remove();\n+        }\n+      }\n+      // If the block\u0027s mark doesn\u0027t match with the mark of this scan, that\n+      // means that this block couldn\u0027t be reached during this scan.  That means\n+      // it doesn\u0027t need to be cached any more.\n+      int neededCached \u003d (cblock.getMark() !\u003d mark) ?\n+          0 : cblock.getReplication();\n+      int numCached \u003d cached.size();\n+      if (numCached \u003e\u003d neededCached) {\n+        // If we have enough replicas, drop all pending cached.\n+        for (DatanodeDescriptor datanode : pendingCached) {\n+          datanode.getPendingCached().remove(cblock);\n+        }\n+        pendingCached.clear();\n+      }\n+      if (numCached \u003c neededCached) {\n+        // If we don\u0027t have enough replicas, drop all pending uncached.\n+        for (DatanodeDescriptor datanode : pendingUncached) {\n+          datanode.getPendingUncached().remove(cblock);\n+        }\n+        pendingUncached.clear();\n+      }\n+      int neededUncached \u003d numCached -\n+          (pendingUncached.size() + neededCached);\n+      if (neededUncached \u003e 0) {\n+        addNewPendingUncached(neededUncached, cblock, cached,\n+            pendingUncached);\n+      } else {\n+        int additionalCachedNeeded \u003d neededCached -\n+            (numCached + pendingCached.size());\n+        if (additionalCachedNeeded \u003e 0) {\n+          addNewPendingCached(additionalCachedNeeded, cblock, cached,\n+              pendingCached);\n+        }\n+      }\n+      if ((neededCached \u003d\u003d 0) \u0026\u0026\n+          pendingUncached.isEmpty() \u0026\u0026\n+          pendingCached.isEmpty()) {\n+        // we have nothing more to do with this block.\n+        cbIter.remove();\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void rescanCachedBlockMap() {\n    for (Iterator\u003cCachedBlock\u003e cbIter \u003d cachedBlocks.iterator();\n        cbIter.hasNext(); ) {\n      scannedBlocks++;\n      CachedBlock cblock \u003d cbIter.next();\n      List\u003cDatanodeDescriptor\u003e pendingCached \u003d\n          cblock.getDatanodes(Type.PENDING_CACHED);\n      List\u003cDatanodeDescriptor\u003e cached \u003d\n          cblock.getDatanodes(Type.CACHED);\n      List\u003cDatanodeDescriptor\u003e pendingUncached \u003d\n          cblock.getDatanodes(Type.PENDING_UNCACHED);\n      // Remove nodes from PENDING_UNCACHED if they were actually uncached.\n      for (Iterator\u003cDatanodeDescriptor\u003e iter \u003d pendingUncached.iterator();\n          iter.hasNext(); ) {\n        DatanodeDescriptor datanode \u003d iter.next();\n        if (!cblock.isInList(datanode.getCached())) {\n          datanode.getPendingUncached().remove(cblock);\n          iter.remove();\n        }\n      }\n      // If the block\u0027s mark doesn\u0027t match with the mark of this scan, that\n      // means that this block couldn\u0027t be reached during this scan.  That means\n      // it doesn\u0027t need to be cached any more.\n      int neededCached \u003d (cblock.getMark() !\u003d mark) ?\n          0 : cblock.getReplication();\n      int numCached \u003d cached.size();\n      if (numCached \u003e\u003d neededCached) {\n        // If we have enough replicas, drop all pending cached.\n        for (DatanodeDescriptor datanode : pendingCached) {\n          datanode.getPendingCached().remove(cblock);\n        }\n        pendingCached.clear();\n      }\n      if (numCached \u003c neededCached) {\n        // If we don\u0027t have enough replicas, drop all pending uncached.\n        for (DatanodeDescriptor datanode : pendingUncached) {\n          datanode.getPendingUncached().remove(cblock);\n        }\n        pendingUncached.clear();\n      }\n      int neededUncached \u003d numCached -\n          (pendingUncached.size() + neededCached);\n      if (neededUncached \u003e 0) {\n        addNewPendingUncached(neededUncached, cblock, cached,\n            pendingUncached);\n      } else {\n        int additionalCachedNeeded \u003d neededCached -\n            (numCached + pendingCached.size());\n        if (additionalCachedNeeded \u003e 0) {\n          addNewPendingCached(additionalCachedNeeded, cblock, cached,\n              pendingCached);\n        }\n      }\n      if ((neededCached \u003d\u003d 0) \u0026\u0026\n          pendingUncached.isEmpty() \u0026\u0026\n          pendingCached.isEmpty()) {\n        // we have nothing more to do with this block.\n        cbIter.remove();\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/CacheReplicationMonitor.java"
    }
  }
}