{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "InternalIterators.java",
  "functionName": "hasNext",
  "functionId": "hasNext",
  "sourceFilePath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/s3guard/InternalIterators.java",
  "functionStartLine": 81,
  "functionEndLine": 83,
  "numCommitsSeen": 1,
  "timeTaken": 1263,
  "changeHistory": [
    "511df1e837b19ccb9271520589452d82d50ac69d"
  ],
  "changeHistoryShort": {
    "511df1e837b19ccb9271520589452d82d50ac69d": "Yintroduced"
  },
  "changeHistoryDetails": {
    "511df1e837b19ccb9271520589452d82d50ac69d": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-16430. S3AFilesystem.delete to incrementally update s3guard with deletions\n\nContributed by Steve Loughran.\n\nThis overlaps the scanning for directory entries with batched calls to S3 DELETE and updates of the S3Guard tables.\nIt also uses S3Guard to list the files to delete, so find newly created files even when S3 listings are not use consistent.\n\nFor path which the client considers S3Guard to be authoritative, we also do a recursive LIST of the store and delete files; this is to find unindexed files and do guarantee that the delete(path, true) call really does delete everything underneath.\n\nChange-Id: Ice2f6e940c506e0b3a78fa534a99721b1698708e\n",
      "commitDate": "05/09/19 6:25 AM",
      "commitName": "511df1e837b19ccb9271520589452d82d50ac69d",
      "commitAuthor": "Steve Loughran",
      "diff": "@@ -0,0 +1,3 @@\n+    public boolean hasNext() {\n+      return source.hasNext();\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    public boolean hasNext() {\n      return source.hasNext();\n    }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/s3guard/InternalIterators.java"
    }
  }
}