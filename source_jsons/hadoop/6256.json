{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSEditLogOp.java",
  "functionName": "readRpcIds",
  "functionId": "readRpcIds___in-DataInputStream__logVersion-int",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
  "functionStartLine": 302,
  "functionEndLine": 309,
  "numCommitsSeen": 100,
  "timeTaken": 4959,
  "changeHistory": [
    "00067895a01c66d53715b50bbcb3605efd6425f2",
    "8c7a7e619699386f9e6991842558d78aa0c8053d"
  ],
  "changeHistoryShort": {
    "00067895a01c66d53715b50bbcb3605efd6425f2": "Ybodychange",
    "8c7a7e619699386f9e6991842558d78aa0c8053d": "Yintroduced"
  },
  "changeHistoryDetails": {
    "00067895a01c66d53715b50bbcb3605efd6425f2": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5754. Split LayoutVerion into NameNodeLayoutVersion and DataNodeLayoutVersion. Contributed by Brandon Li\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1563041 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/01/14 7:21 PM",
      "commitName": "00067895a01c66d53715b50bbcb3605efd6425f2",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "27/01/14 9:35 PM",
      "commitNameOld": "917502ef316447d282304f70d170a4686a4c7834",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 2.91,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,8 +1,8 @@\n   void readRpcIds(DataInputStream in, int logVersion)\n       throws IOException {\n-    if (LayoutVersion.supports(Feature.EDITLOG_SUPPORT_RETRYCACHE,\n-        logVersion)) {\n+    if (NameNodeLayoutVersion.supports(\n+        LayoutVersion.Feature.EDITLOG_SUPPORT_RETRYCACHE, logVersion)) {\n       this.rpcClientId \u003d FSImageSerialization.readBytes(in);\n       this.rpcCallId \u003d FSImageSerialization.readInt(in);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void readRpcIds(DataInputStream in, int logVersion)\n      throws IOException {\n    if (NameNodeLayoutVersion.supports(\n        LayoutVersion.Feature.EDITLOG_SUPPORT_RETRYCACHE, logVersion)) {\n      this.rpcClientId \u003d FSImageSerialization.readBytes(in);\n      this.rpcCallId \u003d FSImageSerialization.readInt(in);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {}
    },
    "8c7a7e619699386f9e6991842558d78aa0c8053d": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5025. Record ClientId and CallId in EditLog to enable rebuilding retry cache in case of HA failover. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1508332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/07/13 12:51 AM",
      "commitName": "8c7a7e619699386f9e6991842558d78aa0c8053d",
      "commitAuthor": "Suresh Srinivas",
      "diff": "@@ -0,0 +1,8 @@\n+  void readRpcIds(DataInputStream in, int logVersion)\n+      throws IOException {\n+    if (LayoutVersion.supports(Feature.EDITLOG_SUPPORT_RETRYCACHE,\n+        logVersion)) {\n+      this.rpcClientId \u003d FSImageSerialization.readBytes(in);\n+      this.rpcCallId \u003d FSImageSerialization.readInt(in);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  void readRpcIds(DataInputStream in, int logVersion)\n      throws IOException {\n    if (LayoutVersion.supports(Feature.EDITLOG_SUPPORT_RETRYCACHE,\n        logVersion)) {\n      this.rpcClientId \u003d FSImageSerialization.readBytes(in);\n      this.rpcCallId \u003d FSImageSerialization.readInt(in);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java"
    }
  }
}