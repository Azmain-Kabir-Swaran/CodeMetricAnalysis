{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "WebHdfsFileSystem.java",
  "functionName": "getFileBlockLocations",
  "functionId": "getFileBlockLocations___p-Path(modifiers-final)__offset-long(modifiers-final)__length-long(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
  "functionStartLine": 1822,
  "functionEndLine": 1836,
  "numCommitsSeen": 179,
  "timeTaken": 6045,
  "changeHistory": [
    "390c2b5df0c4e25a2156d8daefd4670efe82b191",
    "7fcc73fc0d248aae1edbd4e1514c5818f6198928",
    "08a7253bc0eb6c9155457feecb9c5cdc17c3a814",
    "c7ff34f8dcca3a2024230c5383abd9299daa1b20",
    "687233f20d24c29041929dd0a99d963cec54b6df",
    "bcf89ddc7d52e04725caf104f5958e33d9f51b35",
    "ab04ff9efe632b4eca6faca7407ac35e00e6a379",
    "e4ee1d111be15ae6cca2f79be7ca73c204288d2b",
    "6afe3e0d22caa2b0752d52ddf7794c25a66cc9c8",
    "8cb0d4b380e0fd4437310c1dd6ef8b8995cc383d",
    "4dc4e9e63f7385ddd1d64ae1345e0d32a4acb9de"
  ],
  "changeHistoryShort": {
    "390c2b5df0c4e25a2156d8daefd4670efe82b191": "Ybodychange",
    "7fcc73fc0d248aae1edbd4e1514c5818f6198928": "Ybodychange",
    "08a7253bc0eb6c9155457feecb9c5cdc17c3a814": "Ybodychange",
    "c7ff34f8dcca3a2024230c5383abd9299daa1b20": "Ybodychange",
    "687233f20d24c29041929dd0a99d963cec54b6df": "Ybodychange",
    "bcf89ddc7d52e04725caf104f5958e33d9f51b35": "Ymultichange(Yfilerename,Ybodychange)",
    "ab04ff9efe632b4eca6faca7407ac35e00e6a379": "Ybodychange",
    "e4ee1d111be15ae6cca2f79be7ca73c204288d2b": "Ybodychange",
    "6afe3e0d22caa2b0752d52ddf7794c25a66cc9c8": "Ybodychange",
    "8cb0d4b380e0fd4437310c1dd6ef8b8995cc383d": "Ybodychange",
    "4dc4e9e63f7385ddd1d64ae1345e0d32a4acb9de": "Yintroduced"
  },
  "changeHistoryDetails": {
    "390c2b5df0c4e25a2156d8daefd4670efe82b191": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-11156. Add new op GETFILEBLOCKLOCATIONS to WebHDFS REST API. Contributed by Weiwei Yang.\"\n\nThis reverts commit 7fcc73fc0d248aae1edbd4e1514c5818f6198928.\n\n Conflicts:\n\thadoop-hdfs-project/hadoop-hdfs/src/site/markdown/WebHDFS.md\n\thadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHDFS.java\n",
      "commitDate": "14/09/17 3:12 PM",
      "commitName": "390c2b5df0c4e25a2156d8daefd4670efe82b191",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "02/08/17 12:12 PM",
      "commitNameOld": "12e44e7bdaf53d3720a89d32f0cc2717241bd6b2",
      "commitAuthorOld": "Chris Douglas",
      "daysBetweenCommits": 43.12,
      "commitsBetweenForRepo": 390,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,29 +1,15 @@\n   public BlockLocation[] getFileBlockLocations(final Path p,\n       final long offset, final long length) throws IOException {\n     statistics.incrementReadOps(1);\n     storageStatistics.incrementOpCounter(OpType.GET_FILE_BLOCK_LOCATIONS);\n-    BlockLocation[] locations \u003d null;\n-    try {\n-      locations \u003d getFileBlockLocations(\n-          GetOpParam.Op.GETFILEBLOCKLOCATIONS,\n-          p, offset, length);\n-    } catch (RemoteException e) {\n-      // See the error message from ExceptionHandle\n-      if(e.getMessage() !\u003d null \u0026\u0026\n-          e.getMessage().contains(\n-              \"Invalid value for webhdfs parameter\") \u0026\u0026\n-          e.getMessage().contains(\n-              GetOpParam.Op.GETFILEBLOCKLOCATIONS.toString())) {\n-        // Old webhdfs server doesn\u0027t support GETFILEBLOCKLOCATIONS\n-        // operation, fall back to query again using old API\n-        // GET_BLOCK_LOCATIONS.\n-        LOG.info(\"Invalid webhdfs operation parameter \"\n-            + GetOpParam.Op.GETFILEBLOCKLOCATIONS + \". Fallback to use \"\n-            + GetOpParam.Op.GET_BLOCK_LOCATIONS + \" instead.\");\n-        locations \u003d getFileBlockLocations(\n-            GetOpParam.Op.GET_BLOCK_LOCATIONS,\n-            p, offset, length);\n+\n+    final HttpOpParam.Op op \u003d GetOpParam.Op.GET_BLOCK_LOCATIONS;\n+    return new FsPathResponseRunner\u003cBlockLocation[]\u003e(op, p,\n+        new OffsetParam(offset), new LengthParam(length)) {\n+      @Override\n+      BlockLocation[] decodeResponse(Map\u003c?,?\u003e json) throws IOException {\n+        return DFSUtilClient.locatedBlocks2Locations(\n+            JsonUtilClient.toLocatedBlocks(json));\n       }\n-    }\n-    return locations;\n+    }.run();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public BlockLocation[] getFileBlockLocations(final Path p,\n      final long offset, final long length) throws IOException {\n    statistics.incrementReadOps(1);\n    storageStatistics.incrementOpCounter(OpType.GET_FILE_BLOCK_LOCATIONS);\n\n    final HttpOpParam.Op op \u003d GetOpParam.Op.GET_BLOCK_LOCATIONS;\n    return new FsPathResponseRunner\u003cBlockLocation[]\u003e(op, p,\n        new OffsetParam(offset), new LengthParam(length)) {\n      @Override\n      BlockLocation[] decodeResponse(Map\u003c?,?\u003e json) throws IOException {\n        return DFSUtilClient.locatedBlocks2Locations(\n            JsonUtilClient.toLocatedBlocks(json));\n      }\n    }.run();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "7fcc73fc0d248aae1edbd4e1514c5818f6198928": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11156. Add new op GETFILEBLOCKLOCATIONS to WebHDFS REST API. Contributed by Weiwei Yang.\n",
      "commitDate": "03/01/17 9:58 AM",
      "commitName": "7fcc73fc0d248aae1edbd4e1514c5818f6198928",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "03/01/17 5:49 AM",
      "commitNameOld": "b31e1951e044b2c6f6e88a007a8c175941ddd674",
      "commitAuthorOld": "Brahma Reddy Battula",
      "daysBetweenCommits": 0.17,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,29 @@\n   public BlockLocation[] getFileBlockLocations(final Path p,\n       final long offset, final long length) throws IOException {\n     statistics.incrementReadOps(1);\n     storageStatistics.incrementOpCounter(OpType.GET_FILE_BLOCK_LOCATIONS);\n-\n-    final HttpOpParam.Op op \u003d GetOpParam.Op.GET_BLOCK_LOCATIONS;\n-    return new FsPathResponseRunner\u003cBlockLocation[]\u003e(op, p,\n-        new OffsetParam(offset), new LengthParam(length)) {\n-      @Override\n-      BlockLocation[] decodeResponse(Map\u003c?,?\u003e json) throws IOException {\n-        return DFSUtilClient.locatedBlocks2Locations(\n-            JsonUtilClient.toLocatedBlocks(json));\n+    BlockLocation[] locations \u003d null;\n+    try {\n+      locations \u003d getFileBlockLocations(\n+          GetOpParam.Op.GETFILEBLOCKLOCATIONS,\n+          p, offset, length);\n+    } catch (RemoteException e) {\n+      // See the error message from ExceptionHandle\n+      if(e.getMessage() !\u003d null \u0026\u0026\n+          e.getMessage().contains(\n+              \"Invalid value for webhdfs parameter\") \u0026\u0026\n+          e.getMessage().contains(\n+              GetOpParam.Op.GETFILEBLOCKLOCATIONS.toString())) {\n+        // Old webhdfs server doesn\u0027t support GETFILEBLOCKLOCATIONS\n+        // operation, fall back to query again using old API\n+        // GET_BLOCK_LOCATIONS.\n+        LOG.info(\"Invalid webhdfs operation parameter \"\n+            + GetOpParam.Op.GETFILEBLOCKLOCATIONS + \". Fallback to use \"\n+            + GetOpParam.Op.GET_BLOCK_LOCATIONS + \" instead.\");\n+        locations \u003d getFileBlockLocations(\n+            GetOpParam.Op.GET_BLOCK_LOCATIONS,\n+            p, offset, length);\n       }\n-    }.run();\n+    }\n+    return locations;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public BlockLocation[] getFileBlockLocations(final Path p,\n      final long offset, final long length) throws IOException {\n    statistics.incrementReadOps(1);\n    storageStatistics.incrementOpCounter(OpType.GET_FILE_BLOCK_LOCATIONS);\n    BlockLocation[] locations \u003d null;\n    try {\n      locations \u003d getFileBlockLocations(\n          GetOpParam.Op.GETFILEBLOCKLOCATIONS,\n          p, offset, length);\n    } catch (RemoteException e) {\n      // See the error message from ExceptionHandle\n      if(e.getMessage() !\u003d null \u0026\u0026\n          e.getMessage().contains(\n              \"Invalid value for webhdfs parameter\") \u0026\u0026\n          e.getMessage().contains(\n              GetOpParam.Op.GETFILEBLOCKLOCATIONS.toString())) {\n        // Old webhdfs server doesn\u0027t support GETFILEBLOCKLOCATIONS\n        // operation, fall back to query again using old API\n        // GET_BLOCK_LOCATIONS.\n        LOG.info(\"Invalid webhdfs operation parameter \"\n            + GetOpParam.Op.GETFILEBLOCKLOCATIONS + \". Fallback to use \"\n            + GetOpParam.Op.GET_BLOCK_LOCATIONS + \" instead.\");\n        locations \u003d getFileBlockLocations(\n            GetOpParam.Op.GET_BLOCK_LOCATIONS,\n            p, offset, length);\n      }\n    }\n    return locations;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "08a7253bc0eb6c9155457feecb9c5cdc17c3a814": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-11156. Add new op GETFILEBLOCKLOCATIONS to WebHDFS REST API. Contributed by Weiwei Yang\"\n\nThis reverts commit c7ff34f8dcca3a2024230c5383abd9299daa1b20.\n",
      "commitDate": "05/12/16 11:09 PM",
      "commitName": "08a7253bc0eb6c9155457feecb9c5cdc17c3a814",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "02/12/16 11:10 AM",
      "commitNameOld": "c7ff34f8dcca3a2024230c5383abd9299daa1b20",
      "commitAuthorOld": "Mingliang Liu",
      "daysBetweenCommits": 3.5,
      "commitsBetweenForRepo": 18,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,15 @@\n   public BlockLocation[] getFileBlockLocations(final Path p,\n       final long offset, final long length) throws IOException {\n     statistics.incrementReadOps(1);\n     storageStatistics.incrementOpCounter(OpType.GET_FILE_BLOCK_LOCATIONS);\n \n-    final HttpOpParam.Op op \u003d GetOpParam.Op.GETFILEBLOCKLOCATIONS;\n+    final HttpOpParam.Op op \u003d GetOpParam.Op.GET_BLOCK_LOCATIONS;\n     return new FsPathResponseRunner\u003cBlockLocation[]\u003e(op, p,\n         new OffsetParam(offset), new LengthParam(length)) {\n       @Override\n-      @SuppressWarnings(\"unchecked\")\n       BlockLocation[] decodeResponse(Map\u003c?,?\u003e json) throws IOException {\n-        List\u003c?\u003e list \u003d JsonUtilClient.getList(json, \"BlockLocations\");\n-        BlockLocation[] locations \u003d new BlockLocation[list.size()];\n-        for(int i\u003d0; i\u003clocations.length; i++) {\n-          BlockLocation bl \u003d JsonUtilClient.\n-              toBlockLocation((Map\u003cString, Object\u003e) list.get(i));\n-          locations[i] \u003d bl;\n-        }\n-        return locations;\n+        return DFSUtilClient.locatedBlocks2Locations(\n+            JsonUtilClient.toLocatedBlocks(json));\n       }\n     }.run();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public BlockLocation[] getFileBlockLocations(final Path p,\n      final long offset, final long length) throws IOException {\n    statistics.incrementReadOps(1);\n    storageStatistics.incrementOpCounter(OpType.GET_FILE_BLOCK_LOCATIONS);\n\n    final HttpOpParam.Op op \u003d GetOpParam.Op.GET_BLOCK_LOCATIONS;\n    return new FsPathResponseRunner\u003cBlockLocation[]\u003e(op, p,\n        new OffsetParam(offset), new LengthParam(length)) {\n      @Override\n      BlockLocation[] decodeResponse(Map\u003c?,?\u003e json) throws IOException {\n        return DFSUtilClient.locatedBlocks2Locations(\n            JsonUtilClient.toLocatedBlocks(json));\n      }\n    }.run();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "c7ff34f8dcca3a2024230c5383abd9299daa1b20": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11156. Add new op GETFILEBLOCKLOCATIONS to WebHDFS REST API. Contributed by Weiwei Yang\n",
      "commitDate": "02/12/16 11:10 AM",
      "commitName": "c7ff34f8dcca3a2024230c5383abd9299daa1b20",
      "commitAuthor": "Mingliang Liu",
      "commitDateOld": "06/11/16 6:16 PM",
      "commitNameOld": "049e7d27bea13d4254baccf49401daae820b71df",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 25.7,
      "commitsBetweenForRepo": 165,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,22 @@\n   public BlockLocation[] getFileBlockLocations(final Path p,\n       final long offset, final long length) throws IOException {\n     statistics.incrementReadOps(1);\n     storageStatistics.incrementOpCounter(OpType.GET_FILE_BLOCK_LOCATIONS);\n \n-    final HttpOpParam.Op op \u003d GetOpParam.Op.GET_BLOCK_LOCATIONS;\n+    final HttpOpParam.Op op \u003d GetOpParam.Op.GETFILEBLOCKLOCATIONS;\n     return new FsPathResponseRunner\u003cBlockLocation[]\u003e(op, p,\n         new OffsetParam(offset), new LengthParam(length)) {\n       @Override\n+      @SuppressWarnings(\"unchecked\")\n       BlockLocation[] decodeResponse(Map\u003c?,?\u003e json) throws IOException {\n-        return DFSUtilClient.locatedBlocks2Locations(\n-            JsonUtilClient.toLocatedBlocks(json));\n+        List\u003c?\u003e list \u003d JsonUtilClient.getList(json, \"BlockLocations\");\n+        BlockLocation[] locations \u003d new BlockLocation[list.size()];\n+        for(int i\u003d0; i\u003clocations.length; i++) {\n+          BlockLocation bl \u003d JsonUtilClient.\n+              toBlockLocation((Map\u003cString, Object\u003e) list.get(i));\n+          locations[i] \u003d bl;\n+        }\n+        return locations;\n       }\n     }.run();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public BlockLocation[] getFileBlockLocations(final Path p,\n      final long offset, final long length) throws IOException {\n    statistics.incrementReadOps(1);\n    storageStatistics.incrementOpCounter(OpType.GET_FILE_BLOCK_LOCATIONS);\n\n    final HttpOpParam.Op op \u003d GetOpParam.Op.GETFILEBLOCKLOCATIONS;\n    return new FsPathResponseRunner\u003cBlockLocation[]\u003e(op, p,\n        new OffsetParam(offset), new LengthParam(length)) {\n      @Override\n      @SuppressWarnings(\"unchecked\")\n      BlockLocation[] decodeResponse(Map\u003c?,?\u003e json) throws IOException {\n        List\u003c?\u003e list \u003d JsonUtilClient.getList(json, \"BlockLocations\");\n        BlockLocation[] locations \u003d new BlockLocation[list.size()];\n        for(int i\u003d0; i\u003clocations.length; i++) {\n          BlockLocation bl \u003d JsonUtilClient.\n              toBlockLocation((Map\u003cString, Object\u003e) list.get(i));\n          locations[i] \u003d bl;\n        }\n        return locations;\n      }\n    }.run();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "687233f20d24c29041929dd0a99d963cec54b6df": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13065. Add a new interface for retrieving FS and FC Statistics (Mingliang Liu via cmccabe)\n",
      "commitDate": "11/05/16 1:45 PM",
      "commitName": "687233f20d24c29041929dd0a99d963cec54b6df",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "23/04/16 7:37 AM",
      "commitNameOld": "6fcde2e38da04cae3aad6b13cf442af211f71506",
      "commitAuthorOld": "Masatake Iwasaki",
      "daysBetweenCommits": 18.26,
      "commitsBetweenForRepo": 102,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,15 @@\n   public BlockLocation[] getFileBlockLocations(final Path p,\n       final long offset, final long length) throws IOException {\n     statistics.incrementReadOps(1);\n+    storageStatistics.incrementOpCounter(OpType.GET_FILE_BLOCK_LOCATIONS);\n \n     final HttpOpParam.Op op \u003d GetOpParam.Op.GET_BLOCK_LOCATIONS;\n     return new FsPathResponseRunner\u003cBlockLocation[]\u003e(op, p,\n         new OffsetParam(offset), new LengthParam(length)) {\n       @Override\n       BlockLocation[] decodeResponse(Map\u003c?,?\u003e json) throws IOException {\n         return DFSUtilClient.locatedBlocks2Locations(\n             JsonUtilClient.toLocatedBlocks(json));\n       }\n     }.run();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public BlockLocation[] getFileBlockLocations(final Path p,\n      final long offset, final long length) throws IOException {\n    statistics.incrementReadOps(1);\n    storageStatistics.incrementOpCounter(OpType.GET_FILE_BLOCK_LOCATIONS);\n\n    final HttpOpParam.Op op \u003d GetOpParam.Op.GET_BLOCK_LOCATIONS;\n    return new FsPathResponseRunner\u003cBlockLocation[]\u003e(op, p,\n        new OffsetParam(offset), new LengthParam(length)) {\n      @Override\n      BlockLocation[] decodeResponse(Map\u003c?,?\u003e json) throws IOException {\n        return DFSUtilClient.locatedBlocks2Locations(\n            JsonUtilClient.toLocatedBlocks(json));\n      }\n    }.run();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "bcf89ddc7d52e04725caf104f5958e33d9f51b35": {
      "type": "Ymultichange(Yfilerename,Ybodychange)",
      "commitMessage": "HDFS-8052. Move WebHdfsFileSystem into hadoop-hdfs-client. Contributed by Haohui Mai.\n",
      "commitDate": "23/04/15 5:33 PM",
      "commitName": "bcf89ddc7d52e04725caf104f5958e33d9f51b35",
      "commitAuthor": "Haohui Mai",
      "subchanges": [
        {
          "type": "Yfilerename",
          "commitMessage": "HDFS-8052. Move WebHdfsFileSystem into hadoop-hdfs-client. Contributed by Haohui Mai.\n",
          "commitDate": "23/04/15 5:33 PM",
          "commitName": "bcf89ddc7d52e04725caf104f5958e33d9f51b35",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "23/04/15 4:40 PM",
          "commitNameOld": "0b3f8957a87ada1a275c9904b211fdbdcefafb02",
          "commitAuthorOld": "Xuan",
          "daysBetweenCommits": 0.04,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,14 @@\n-  public BlockLocation[] getFileBlockLocations(final Path p, \n+  public BlockLocation[] getFileBlockLocations(final Path p,\n       final long offset, final long length) throws IOException {\n     statistics.incrementReadOps(1);\n \n     final HttpOpParam.Op op \u003d GetOpParam.Op.GET_BLOCK_LOCATIONS;\n     return new FsPathResponseRunner\u003cBlockLocation[]\u003e(op, p,\n         new OffsetParam(offset), new LengthParam(length)) {\n       @Override\n       BlockLocation[] decodeResponse(Map\u003c?,?\u003e json) throws IOException {\n-        return DFSUtil.locatedBlocks2Locations(\n+        return DFSUtilClient.locatedBlocks2Locations(\n             JsonUtilClient.toLocatedBlocks(json));\n       }\n     }.run();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public BlockLocation[] getFileBlockLocations(final Path p,\n      final long offset, final long length) throws IOException {\n    statistics.incrementReadOps(1);\n\n    final HttpOpParam.Op op \u003d GetOpParam.Op.GET_BLOCK_LOCATIONS;\n    return new FsPathResponseRunner\u003cBlockLocation[]\u003e(op, p,\n        new OffsetParam(offset), new LengthParam(length)) {\n      @Override\n      BlockLocation[] decodeResponse(Map\u003c?,?\u003e json) throws IOException {\n        return DFSUtilClient.locatedBlocks2Locations(\n            JsonUtilClient.toLocatedBlocks(json));\n      }\n    }.run();\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-8052. Move WebHdfsFileSystem into hadoop-hdfs-client. Contributed by Haohui Mai.\n",
          "commitDate": "23/04/15 5:33 PM",
          "commitName": "bcf89ddc7d52e04725caf104f5958e33d9f51b35",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "23/04/15 4:40 PM",
          "commitNameOld": "0b3f8957a87ada1a275c9904b211fdbdcefafb02",
          "commitAuthorOld": "Xuan",
          "daysBetweenCommits": 0.04,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,14 @@\n-  public BlockLocation[] getFileBlockLocations(final Path p, \n+  public BlockLocation[] getFileBlockLocations(final Path p,\n       final long offset, final long length) throws IOException {\n     statistics.incrementReadOps(1);\n \n     final HttpOpParam.Op op \u003d GetOpParam.Op.GET_BLOCK_LOCATIONS;\n     return new FsPathResponseRunner\u003cBlockLocation[]\u003e(op, p,\n         new OffsetParam(offset), new LengthParam(length)) {\n       @Override\n       BlockLocation[] decodeResponse(Map\u003c?,?\u003e json) throws IOException {\n-        return DFSUtil.locatedBlocks2Locations(\n+        return DFSUtilClient.locatedBlocks2Locations(\n             JsonUtilClient.toLocatedBlocks(json));\n       }\n     }.run();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public BlockLocation[] getFileBlockLocations(final Path p,\n      final long offset, final long length) throws IOException {\n    statistics.incrementReadOps(1);\n\n    final HttpOpParam.Op op \u003d GetOpParam.Op.GET_BLOCK_LOCATIONS;\n    return new FsPathResponseRunner\u003cBlockLocation[]\u003e(op, p,\n        new OffsetParam(offset), new LengthParam(length)) {\n      @Override\n      BlockLocation[] decodeResponse(Map\u003c?,?\u003e json) throws IOException {\n        return DFSUtilClient.locatedBlocks2Locations(\n            JsonUtilClient.toLocatedBlocks(json));\n      }\n    }.run();\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "ab04ff9efe632b4eca6faca7407ac35e00e6a379": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8080. Separate JSON related routines used by WebHdfsFileSystem to a package local class. Contributed by Haohui Mai.\n",
      "commitDate": "07/04/15 9:30 PM",
      "commitName": "ab04ff9efe632b4eca6faca7407ac35e00e6a379",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "01/04/15 12:54 PM",
      "commitNameOld": "ed72daa5df97669906234e8ac9a406d78136b206",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 6.36,
      "commitsBetweenForRepo": 48,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,14 @@\n   public BlockLocation[] getFileBlockLocations(final Path p, \n       final long offset, final long length) throws IOException {\n     statistics.incrementReadOps(1);\n \n     final HttpOpParam.Op op \u003d GetOpParam.Op.GET_BLOCK_LOCATIONS;\n     return new FsPathResponseRunner\u003cBlockLocation[]\u003e(op, p,\n         new OffsetParam(offset), new LengthParam(length)) {\n       @Override\n       BlockLocation[] decodeResponse(Map\u003c?,?\u003e json) throws IOException {\n         return DFSUtil.locatedBlocks2Locations(\n-            JsonUtil.toLocatedBlocks(json));\n+            JsonUtilClient.toLocatedBlocks(json));\n       }\n     }.run();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public BlockLocation[] getFileBlockLocations(final Path p, \n      final long offset, final long length) throws IOException {\n    statistics.incrementReadOps(1);\n\n    final HttpOpParam.Op op \u003d GetOpParam.Op.GET_BLOCK_LOCATIONS;\n    return new FsPathResponseRunner\u003cBlockLocation[]\u003e(op, p,\n        new OffsetParam(offset), new LengthParam(length)) {\n      @Override\n      BlockLocation[] decodeResponse(Map\u003c?,?\u003e json) throws IOException {\n        return DFSUtil.locatedBlocks2Locations(\n            JsonUtilClient.toLocatedBlocks(json));\n      }\n    }.run();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "e4ee1d111be15ae6cca2f79be7ca73c204288d2b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6305. WebHdfs response decoding may throw RuntimeExceptions (Daryn Sharp via jeagles)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1594273 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/05/14 9:40 AM",
      "commitName": "e4ee1d111be15ae6cca2f79be7ca73c204288d2b",
      "commitAuthor": "Jonathan Turner Eagles",
      "commitDateOld": "13/05/14 9:19 AM",
      "commitNameOld": "33ade356b35223654a077103ed7fbed89f3f2321",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,9 +1,14 @@\n   public BlockLocation[] getFileBlockLocations(final Path p, \n       final long offset, final long length) throws IOException {\n     statistics.incrementReadOps(1);\n \n     final HttpOpParam.Op op \u003d GetOpParam.Op.GET_BLOCK_LOCATIONS;\n-    final Map\u003c?, ?\u003e m \u003d run(op, p, new OffsetParam(offset),\n-        new LengthParam(length));\n-    return DFSUtil.locatedBlocks2Locations(JsonUtil.toLocatedBlocks(m));\n+    return new FsPathResponseRunner\u003cBlockLocation[]\u003e(op, p,\n+        new OffsetParam(offset), new LengthParam(length)) {\n+      @Override\n+      BlockLocation[] decodeResponse(Map\u003c?,?\u003e json) throws IOException {\n+        return DFSUtil.locatedBlocks2Locations(\n+            JsonUtil.toLocatedBlocks(json));\n+      }\n+    }.run();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public BlockLocation[] getFileBlockLocations(final Path p, \n      final long offset, final long length) throws IOException {\n    statistics.incrementReadOps(1);\n\n    final HttpOpParam.Op op \u003d GetOpParam.Op.GET_BLOCK_LOCATIONS;\n    return new FsPathResponseRunner\u003cBlockLocation[]\u003e(op, p,\n        new OffsetParam(offset), new LengthParam(length)) {\n      @Override\n      BlockLocation[] decodeResponse(Map\u003c?,?\u003e json) throws IOException {\n        return DFSUtil.locatedBlocks2Locations(\n            JsonUtil.toLocatedBlocks(json));\n      }\n    }.run();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "6afe3e0d22caa2b0752d52ddf7794c25a66cc9c8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2527. WebHdfs: remove the use of \"Range\" header in Open; use ugi username if renewer parameter is null in GetDelegationToken; response OK when setting replication for non-files; rename GETFILEBLOCKLOCATIONS to GET_BLOCK_LOCATIONS and state that it is a private unstable API; replace isDirectory and isSymlink with enum {FILE, DIRECTORY, SYMLINK} in HdfsFileStatus JSON object. \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1197329 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/11/11 3:34 PM",
      "commitName": "6afe3e0d22caa2b0752d52ddf7794c25a66cc9c8",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "01/11/11 7:08 PM",
      "commitNameOld": "bd21ddcb78350b311f271e233038b8ca78a65242",
      "commitAuthorOld": "Jitendra Nath Pandey",
      "daysBetweenCommits": 1.85,
      "commitsBetweenForRepo": 14,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,9 +1,9 @@\n   public BlockLocation[] getFileBlockLocations(final Path p, \n       final long offset, final long length) throws IOException {\n     statistics.incrementReadOps(1);\n \n-    final HttpOpParam.Op op \u003d GetOpParam.Op.GETFILEBLOCKLOCATIONS;\n+    final HttpOpParam.Op op \u003d GetOpParam.Op.GET_BLOCK_LOCATIONS;\n     final Map\u003c?, ?\u003e m \u003d run(op, p, new OffsetParam(offset),\n         new LengthParam(length));\n     return DFSUtil.locatedBlocks2Locations(JsonUtil.toLocatedBlocks(m));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public BlockLocation[] getFileBlockLocations(final Path p, \n      final long offset, final long length) throws IOException {\n    statistics.incrementReadOps(1);\n\n    final HttpOpParam.Op op \u003d GetOpParam.Op.GET_BLOCK_LOCATIONS;\n    final Map\u003c?, ?\u003e m \u003d run(op, p, new OffsetParam(offset),\n        new LengthParam(length));\n    return DFSUtil.locatedBlocks2Locations(JsonUtil.toLocatedBlocks(m));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "8cb0d4b380e0fd4437310c1dd6ef8b8995cc383d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2432. Webhdfs: response FORBIDDEN when setReplication on non-files; clear umask before creating a flie; throw IllegalArgumentException if setOwner with both owner and group empty; throw FileNotFoundException if getFileStatus on non-existing files; fix bugs in getBlockLocations; and changed getFileChecksum json response root to \"FileChecksum\".\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1190077 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/10/11 4:13 PM",
      "commitName": "8cb0d4b380e0fd4437310c1dd6ef8b8995cc383d",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "25/10/11 10:16 PM",
      "commitNameOld": "8335995630e2c4288795fa0dfa9b670090a6790b",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 1.75,
      "commitsBetweenForRepo": 30,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,9 +1,9 @@\n   public BlockLocation[] getFileBlockLocations(final Path p, \n       final long offset, final long length) throws IOException {\n     statistics.incrementReadOps(1);\n \n     final HttpOpParam.Op op \u003d GetOpParam.Op.GETFILEBLOCKLOCATIONS;\n-    final Map\u003cString, Object\u003e m \u003d run(op, p, new OffsetParam(offset),\n+    final Map\u003c?, ?\u003e m \u003d run(op, p, new OffsetParam(offset),\n         new LengthParam(length));\n     return DFSUtil.locatedBlocks2Locations(JsonUtil.toLocatedBlocks(m));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public BlockLocation[] getFileBlockLocations(final Path p, \n      final long offset, final long length) throws IOException {\n    statistics.incrementReadOps(1);\n\n    final HttpOpParam.Op op \u003d GetOpParam.Op.GETFILEBLOCKLOCATIONS;\n    final Map\u003c?, ?\u003e m \u003d run(op, p, new OffsetParam(offset),\n        new LengthParam(length));\n    return DFSUtil.locatedBlocks2Locations(JsonUtil.toLocatedBlocks(m));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "4dc4e9e63f7385ddd1d64ae1345e0d32a4acb9de": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-2340. Support getFileBlockLocations and getDelegationToken in webhdfs.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1173468 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/09/11 7:56 PM",
      "commitName": "4dc4e9e63f7385ddd1d64ae1345e0d32a4acb9de",
      "commitAuthor": "Tsz-wo Sze",
      "diff": "@@ -0,0 +1,9 @@\n+  public BlockLocation[] getFileBlockLocations(final Path p, \n+      final long offset, final long length) throws IOException {\n+    statistics.incrementReadOps(1);\n+\n+    final HttpOpParam.Op op \u003d GetOpParam.Op.GETFILEBLOCKLOCATIONS;\n+    final Map\u003cString, Object\u003e m \u003d run(op, p, new OffsetParam(offset),\n+        new LengthParam(length));\n+    return DFSUtil.locatedBlocks2Locations(JsonUtil.toLocatedBlocks(m));\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public BlockLocation[] getFileBlockLocations(final Path p, \n      final long offset, final long length) throws IOException {\n    statistics.incrementReadOps(1);\n\n    final HttpOpParam.Op op \u003d GetOpParam.Op.GETFILEBLOCKLOCATIONS;\n    final Map\u003cString, Object\u003e m \u003d run(op, p, new OffsetParam(offset),\n        new LengthParam(length));\n    return DFSUtil.locatedBlocks2Locations(JsonUtil.toLocatedBlocks(m));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java"
    }
  }
}