{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DatanodeAdminBackoffMonitor.java",
  "functionName": "isBlockReplicatedOk",
  "functionId": "isBlockReplicatedOk___datanode-DatanodeDescriptor__block-BlockInfo__scheduleReconStruction-Boolean__suspectBlocks-BlockStats",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminBackoffMonitor.java",
  "functionStartLine": 723,
  "functionEndLine": 786,
  "numCommitsSeen": 1,
  "timeTaken": 900,
  "changeHistory": [
    "c93cb6790e0f1c64efd03d859f907a0522010894"
  ],
  "changeHistoryShort": {
    "c93cb6790e0f1c64efd03d859f907a0522010894": "Yintroduced"
  },
  "changeHistoryDetails": {
    "c93cb6790e0f1c64efd03d859f907a0522010894": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-14854. Create improved decommission monitor implementation. Contributed by Stephen O\u0027Donnell.\n\nReviewed-by: Inigo Goiri \u003cinigoiri@apache.org\u003e\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
      "commitDate": "10/12/19 5:16 PM",
      "commitName": "c93cb6790e0f1c64efd03d859f907a0522010894",
      "commitAuthor": "Stephen O\u0027Donnell",
      "diff": "@@ -0,0 +1,64 @@\n+  private boolean isBlockReplicatedOk(DatanodeDescriptor datanode,\n+      BlockInfo block, Boolean scheduleReconStruction,\n+      BlockStats suspectBlocks) {\n+    if (blockManager.blocksMap.getStoredBlock(block) \u003d\u003d null) {\n+      LOG.trace(\"Removing unknown block {}\", block);\n+      return true;\n+    }\n+\n+    long bcId \u003d block.getBlockCollectionId();\n+    if (bcId \u003d\u003d INodeId.INVALID_INODE_ID) {\n+      // Orphan block, will be invalidated eventually. Skip.\n+      return false;\n+    }\n+\n+    final BlockCollection bc \u003d blockManager.getBlockCollection(block);\n+    final NumberReplicas num \u003d blockManager.countNodes(block);\n+    final int liveReplicas \u003d num.liveReplicas();\n+\n+    // Schedule low redundancy blocks for reconstruction\n+    // if not already pending.\n+    boolean isDecommission \u003d datanode.isDecommissionInProgress();\n+    boolean isMaintenance \u003d datanode.isEnteringMaintenance();\n+\n+    boolean neededReconstruction \u003d isDecommission ?\n+        blockManager.isNeededReconstruction(block, num) :\n+        blockManager.isNeededReconstructionForMaintenance(block, num);\n+    if (neededReconstruction \u0026\u0026 scheduleReconStruction) {\n+      if (!blockManager.neededReconstruction.contains(block) \u0026\u0026\n+          blockManager.pendingReconstruction.getNumReplicas(block) \u003d\u003d 0 \u0026\u0026\n+          blockManager.isPopulatingReplQueues()) {\n+        // Process these blocks only when active NN is out of safe mode.\n+        blockManager.neededReconstruction.add(block,\n+            liveReplicas, num.readOnlyReplicas(),\n+            num.outOfServiceReplicas(),\n+            blockManager.getExpectedRedundancyNum(block));\n+      }\n+    }\n+\n+    if (suspectBlocks !\u003d null) {\n+      // Only if we pass a BlockStats object should we do these\n+      // checks, as they should only be checked when processing PendingRep.\n+      if (bc.isUnderConstruction()) {\n+        INode ucFile \u003d namesystem.getFSDirectory().getInode(bc.getId());\n+        if (!(ucFile instanceof INodeFile) ||\n+            !ucFile.asFile().isUnderConstruction()) {\n+          LOG.warn(\"File {} is not under construction. Skipping add to \" +\n+              \"low redundancy open files!\", ucFile.getLocalName());\n+        } else {\n+          suspectBlocks.addOpenFile(ucFile.getId());\n+        }\n+      }\n+      if ((liveReplicas \u003d\u003d 0) \u0026\u0026 (num.outOfServiceReplicas() \u003e 0)) {\n+        suspectBlocks.incrementOutOfServiceBlocks();\n+      }\n+    }\n+\n+    // Even if the block is without sufficient redundancy,\n+    // it might not block decommission/maintenance if it\n+    // has sufficient redundancy.\n+    if (dnAdmin.isSufficient(block, bc, num, isDecommission, isMaintenance)) {\n+      return true;\n+    }\n+    return false;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean isBlockReplicatedOk(DatanodeDescriptor datanode,\n      BlockInfo block, Boolean scheduleReconStruction,\n      BlockStats suspectBlocks) {\n    if (blockManager.blocksMap.getStoredBlock(block) \u003d\u003d null) {\n      LOG.trace(\"Removing unknown block {}\", block);\n      return true;\n    }\n\n    long bcId \u003d block.getBlockCollectionId();\n    if (bcId \u003d\u003d INodeId.INVALID_INODE_ID) {\n      // Orphan block, will be invalidated eventually. Skip.\n      return false;\n    }\n\n    final BlockCollection bc \u003d blockManager.getBlockCollection(block);\n    final NumberReplicas num \u003d blockManager.countNodes(block);\n    final int liveReplicas \u003d num.liveReplicas();\n\n    // Schedule low redundancy blocks for reconstruction\n    // if not already pending.\n    boolean isDecommission \u003d datanode.isDecommissionInProgress();\n    boolean isMaintenance \u003d datanode.isEnteringMaintenance();\n\n    boolean neededReconstruction \u003d isDecommission ?\n        blockManager.isNeededReconstruction(block, num) :\n        blockManager.isNeededReconstructionForMaintenance(block, num);\n    if (neededReconstruction \u0026\u0026 scheduleReconStruction) {\n      if (!blockManager.neededReconstruction.contains(block) \u0026\u0026\n          blockManager.pendingReconstruction.getNumReplicas(block) \u003d\u003d 0 \u0026\u0026\n          blockManager.isPopulatingReplQueues()) {\n        // Process these blocks only when active NN is out of safe mode.\n        blockManager.neededReconstruction.add(block,\n            liveReplicas, num.readOnlyReplicas(),\n            num.outOfServiceReplicas(),\n            blockManager.getExpectedRedundancyNum(block));\n      }\n    }\n\n    if (suspectBlocks !\u003d null) {\n      // Only if we pass a BlockStats object should we do these\n      // checks, as they should only be checked when processing PendingRep.\n      if (bc.isUnderConstruction()) {\n        INode ucFile \u003d namesystem.getFSDirectory().getInode(bc.getId());\n        if (!(ucFile instanceof INodeFile) ||\n            !ucFile.asFile().isUnderConstruction()) {\n          LOG.warn(\"File {} is not under construction. Skipping add to \" +\n              \"low redundancy open files!\", ucFile.getLocalName());\n        } else {\n          suspectBlocks.addOpenFile(ucFile.getId());\n        }\n      }\n      if ((liveReplicas \u003d\u003d 0) \u0026\u0026 (num.outOfServiceReplicas() \u003e 0)) {\n        suspectBlocks.incrementOutOfServiceBlocks();\n      }\n    }\n\n    // Even if the block is without sufficient redundancy,\n    // it might not block decommission/maintenance if it\n    // has sufficient redundancy.\n    if (dnAdmin.isSufficient(block, bc, num, isDecommission, isMaintenance)) {\n      return true;\n    }\n    return false;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminBackoffMonitor.java"
    }
  }
}