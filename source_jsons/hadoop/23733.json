{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "CachedHistoryStorage.java",
  "functionName": "loadJob",
  "functionId": "loadJob___jobId-JobId",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/CachedHistoryStorage.java",
  "functionStartLine": 169,
  "functionEndLine": 188,
  "numCommitsSeen": 31,
  "timeTaken": 9437,
  "changeHistory": [
    "cff9edd4b514bdcfe22cd49964e3707fb78ab876",
    "0f72da7e281376f4fcbfbf3fb33f5d7fedcdb1aa",
    "a83fb61ac07c0468cbc7a38526e92683883dd932",
    "7d04a96027ad75877b41b7cd8f67455dd13159d7",
    "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f",
    "7475e836dc2bdd29142eaf210262fba354b745ed",
    "68fa208b1cc991dec2577a07b3199a6935a71065",
    "a3e8f6836b489f8f2ddd785ae038df729c85059f",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "7c8fcbecf14b2e24d54ccb276bb684fdbe62b669",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517"
  ],
  "changeHistoryShort": {
    "cff9edd4b514bdcfe22cd49964e3707fb78ab876": "Ybodychange",
    "0f72da7e281376f4fcbfbf3fb33f5d7fedcdb1aa": "Ymultichange(Yparameterchange,Yexceptionschange,Ybodychange)",
    "a83fb61ac07c0468cbc7a38526e92683883dd932": "Ybodychange",
    "7d04a96027ad75877b41b7cd8f67455dd13159d7": "Ymultichange(Yparameterchange,Ybodychange)",
    "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f": "Ymultichange(Ymovefromfile,Ybodychange)",
    "7475e836dc2bdd29142eaf210262fba354b745ed": "Ybodychange",
    "68fa208b1cc991dec2577a07b3199a6935a71065": "Ybodychange",
    "a3e8f6836b489f8f2ddd785ae038df729c85059f": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "7c8fcbecf14b2e24d54ccb276bb684fdbe62b669": "Ybodychange",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yintroduced"
  },
  "changeHistoryDetails": {
    "cff9edd4b514bdcfe22cd49964e3707fb78ab876": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-7015. Possible race condition in JHS if the job is not loaded. Contributed by Peter Bacsko\n",
      "commitDate": "24/01/18 12:44 PM",
      "commitName": "cff9edd4b514bdcfe22cd49964e3707fb78ab876",
      "commitAuthor": "Jason Lowe",
      "commitDateOld": "08/11/17 2:21 AM",
      "commitNameOld": "ffee10b68ef1f2d75c9d0df9140c2a605f826724",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 77.43,
      "commitsBetweenForRepo": 412,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,20 @@\n   private Job loadJob(JobId jobId) throws RuntimeException, IOException {\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"Looking for Job \" + jobId);\n     }\n     HistoryFileInfo fileInfo;\n \n     fileInfo \u003d hsManager.getFileInfo(jobId);\n+\n     if (fileInfo \u003d\u003d null) {\n       throw new HSFileRuntimeException(\"Unable to find job \" + jobId);\n-    } else if (fileInfo.isDeleted()) {\n+    }\n+\n+    fileInfo.waitUntilMoved();\n+\n+    if (fileInfo.isDeleted()) {\n       throw new HSFileRuntimeException(\"Cannot load deleted job \" + jobId);\n     } else {\n       return fileInfo.loadJob();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private Job loadJob(JobId jobId) throws RuntimeException, IOException {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Looking for Job \" + jobId);\n    }\n    HistoryFileInfo fileInfo;\n\n    fileInfo \u003d hsManager.getFileInfo(jobId);\n\n    if (fileInfo \u003d\u003d null) {\n      throw new HSFileRuntimeException(\"Unable to find job \" + jobId);\n    }\n\n    fileInfo.waitUntilMoved();\n\n    if (fileInfo.isDeleted()) {\n      throw new HSFileRuntimeException(\"Cannot load deleted job \" + jobId);\n    } else {\n      return fileInfo.loadJob();\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/CachedHistoryStorage.java",
      "extendedDetails": {}
    },
    "0f72da7e281376f4fcbfbf3fb33f5d7fedcdb1aa": {
      "type": "Ymultichange(Yparameterchange,Yexceptionschange,Ybodychange)",
      "commitMessage": "MAPREDUCE-6622. Add capability to set JHS job cache to a task-based limit (rchiang via rkanter)\n",
      "commitDate": "26/02/16 5:57 PM",
      "commitName": "0f72da7e281376f4fcbfbf3fb33f5d7fedcdb1aa",
      "commitAuthor": "Robert Kanter",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "MAPREDUCE-6622. Add capability to set JHS job cache to a task-based limit (rchiang via rkanter)\n",
          "commitDate": "26/02/16 5:57 PM",
          "commitName": "0f72da7e281376f4fcbfbf3fb33f5d7fedcdb1aa",
          "commitAuthor": "Robert Kanter",
          "commitDateOld": "29/07/13 3:33 PM",
          "commitNameOld": "8bb035509ea195ec03b8295a7abd11ce675a4d85",
          "commitAuthorOld": "Jason Darrell Lowe",
          "daysBetweenCommits": 942.14,
          "commitsBetweenForRepo": 7216,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,16 +1,15 @@\n-  private Job loadJob(HistoryFileInfo fileInfo) {\n-    try {\n-      Job job \u003d fileInfo.loadJob();\n-      if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"Adding \" + job.getID() + \" to loaded job cache\");\n-      }\n-      // We can clobber results here, but that should be OK, because it only\n-      // means that we may have two identical copies of the same job floating\n-      // around for a while.\n-      loadedJobCache.put(job.getID(), job);\n-      return job;\n-    } catch (IOException e) {\n-      throw new YarnRuntimeException(\n-          \"Could not find/load job: \" + fileInfo.getJobId(), e);\n+  private Job loadJob(JobId jobId) throws RuntimeException, IOException {\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"Looking for Job \" + jobId);\n+    }\n+    HistoryFileInfo fileInfo;\n+\n+    fileInfo \u003d hsManager.getFileInfo(jobId);\n+    if (fileInfo \u003d\u003d null) {\n+      throw new HSFileRuntimeException(\"Unable to find job \" + jobId);\n+    } else if (fileInfo.isDeleted()) {\n+      throw new HSFileRuntimeException(\"Cannot load deleted job \" + jobId);\n+    } else {\n+      return fileInfo.loadJob();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private Job loadJob(JobId jobId) throws RuntimeException, IOException {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Looking for Job \" + jobId);\n    }\n    HistoryFileInfo fileInfo;\n\n    fileInfo \u003d hsManager.getFileInfo(jobId);\n    if (fileInfo \u003d\u003d null) {\n      throw new HSFileRuntimeException(\"Unable to find job \" + jobId);\n    } else if (fileInfo.isDeleted()) {\n      throw new HSFileRuntimeException(\"Cannot load deleted job \" + jobId);\n    } else {\n      return fileInfo.loadJob();\n    }\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/CachedHistoryStorage.java",
          "extendedDetails": {
            "oldValue": "[fileInfo-HistoryFileInfo]",
            "newValue": "[jobId-JobId]"
          }
        },
        {
          "type": "Yexceptionschange",
          "commitMessage": "MAPREDUCE-6622. Add capability to set JHS job cache to a task-based limit (rchiang via rkanter)\n",
          "commitDate": "26/02/16 5:57 PM",
          "commitName": "0f72da7e281376f4fcbfbf3fb33f5d7fedcdb1aa",
          "commitAuthor": "Robert Kanter",
          "commitDateOld": "29/07/13 3:33 PM",
          "commitNameOld": "8bb035509ea195ec03b8295a7abd11ce675a4d85",
          "commitAuthorOld": "Jason Darrell Lowe",
          "daysBetweenCommits": 942.14,
          "commitsBetweenForRepo": 7216,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,16 +1,15 @@\n-  private Job loadJob(HistoryFileInfo fileInfo) {\n-    try {\n-      Job job \u003d fileInfo.loadJob();\n-      if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"Adding \" + job.getID() + \" to loaded job cache\");\n-      }\n-      // We can clobber results here, but that should be OK, because it only\n-      // means that we may have two identical copies of the same job floating\n-      // around for a while.\n-      loadedJobCache.put(job.getID(), job);\n-      return job;\n-    } catch (IOException e) {\n-      throw new YarnRuntimeException(\n-          \"Could not find/load job: \" + fileInfo.getJobId(), e);\n+  private Job loadJob(JobId jobId) throws RuntimeException, IOException {\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"Looking for Job \" + jobId);\n+    }\n+    HistoryFileInfo fileInfo;\n+\n+    fileInfo \u003d hsManager.getFileInfo(jobId);\n+    if (fileInfo \u003d\u003d null) {\n+      throw new HSFileRuntimeException(\"Unable to find job \" + jobId);\n+    } else if (fileInfo.isDeleted()) {\n+      throw new HSFileRuntimeException(\"Cannot load deleted job \" + jobId);\n+    } else {\n+      return fileInfo.loadJob();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private Job loadJob(JobId jobId) throws RuntimeException, IOException {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Looking for Job \" + jobId);\n    }\n    HistoryFileInfo fileInfo;\n\n    fileInfo \u003d hsManager.getFileInfo(jobId);\n    if (fileInfo \u003d\u003d null) {\n      throw new HSFileRuntimeException(\"Unable to find job \" + jobId);\n    } else if (fileInfo.isDeleted()) {\n      throw new HSFileRuntimeException(\"Cannot load deleted job \" + jobId);\n    } else {\n      return fileInfo.loadJob();\n    }\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/CachedHistoryStorage.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[RuntimeException, IOException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-6622. Add capability to set JHS job cache to a task-based limit (rchiang via rkanter)\n",
          "commitDate": "26/02/16 5:57 PM",
          "commitName": "0f72da7e281376f4fcbfbf3fb33f5d7fedcdb1aa",
          "commitAuthor": "Robert Kanter",
          "commitDateOld": "29/07/13 3:33 PM",
          "commitNameOld": "8bb035509ea195ec03b8295a7abd11ce675a4d85",
          "commitAuthorOld": "Jason Darrell Lowe",
          "daysBetweenCommits": 942.14,
          "commitsBetweenForRepo": 7216,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,16 +1,15 @@\n-  private Job loadJob(HistoryFileInfo fileInfo) {\n-    try {\n-      Job job \u003d fileInfo.loadJob();\n-      if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"Adding \" + job.getID() + \" to loaded job cache\");\n-      }\n-      // We can clobber results here, but that should be OK, because it only\n-      // means that we may have two identical copies of the same job floating\n-      // around for a while.\n-      loadedJobCache.put(job.getID(), job);\n-      return job;\n-    } catch (IOException e) {\n-      throw new YarnRuntimeException(\n-          \"Could not find/load job: \" + fileInfo.getJobId(), e);\n+  private Job loadJob(JobId jobId) throws RuntimeException, IOException {\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"Looking for Job \" + jobId);\n+    }\n+    HistoryFileInfo fileInfo;\n+\n+    fileInfo \u003d hsManager.getFileInfo(jobId);\n+    if (fileInfo \u003d\u003d null) {\n+      throw new HSFileRuntimeException(\"Unable to find job \" + jobId);\n+    } else if (fileInfo.isDeleted()) {\n+      throw new HSFileRuntimeException(\"Cannot load deleted job \" + jobId);\n+    } else {\n+      return fileInfo.loadJob();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private Job loadJob(JobId jobId) throws RuntimeException, IOException {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Looking for Job \" + jobId);\n    }\n    HistoryFileInfo fileInfo;\n\n    fileInfo \u003d hsManager.getFileInfo(jobId);\n    if (fileInfo \u003d\u003d null) {\n      throw new HSFileRuntimeException(\"Unable to find job \" + jobId);\n    } else if (fileInfo.isDeleted()) {\n      throw new HSFileRuntimeException(\"Cannot load deleted job \" + jobId);\n    } else {\n      return fileInfo.loadJob();\n    }\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/CachedHistoryStorage.java",
          "extendedDetails": {}
        }
      ]
    },
    "a83fb61ac07c0468cbc7a38526e92683883dd932": {
      "type": "Ybodychange",
      "commitMessage": "YARN-635. Renamed YarnRemoteException to YarnException. Contributed by Siddharth Seth.\nMAPREDUCE-5301. Updated MR code to work with YARN-635 changes of renaming YarnRemoteException to YarnException. Contributed by Siddharth Seth\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1489283 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/06/13 9:05 PM",
      "commitName": "a83fb61ac07c0468cbc7a38526e92683883dd932",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "17/04/12 6:59 PM",
      "commitNameOld": "7d04a96027ad75877b41b7cd8f67455dd13159d7",
      "commitAuthorOld": "Siddharth Seth",
      "daysBetweenCommits": 412.09,
      "commitsBetweenForRepo": 2335,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,16 @@\n   private Job loadJob(HistoryFileInfo fileInfo) {\n     try {\n       Job job \u003d fileInfo.loadJob();\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Adding \" + job.getID() + \" to loaded job cache\");\n       }\n       // We can clobber results here, but that should be OK, because it only\n       // means that we may have two identical copies of the same job floating\n       // around for a while.\n       loadedJobCache.put(job.getID(), job);\n       return job;\n     } catch (IOException e) {\n-      throw new YarnException(\n+      throw new YarnRuntimeException(\n           \"Could not find/load job: \" + fileInfo.getJobId(), e);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private Job loadJob(HistoryFileInfo fileInfo) {\n    try {\n      Job job \u003d fileInfo.loadJob();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Adding \" + job.getID() + \" to loaded job cache\");\n      }\n      // We can clobber results here, but that should be OK, because it only\n      // means that we may have two identical copies of the same job floating\n      // around for a while.\n      loadedJobCache.put(job.getID(), job);\n      return job;\n    } catch (IOException e) {\n      throw new YarnRuntimeException(\n          \"Could not find/load job: \" + fileInfo.getJobId(), e);\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/CachedHistoryStorage.java",
      "extendedDetails": {}
    },
    "7d04a96027ad75877b41b7cd8f67455dd13159d7": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "MAPREDUCE-3972. Fix locking and exception issues in JobHistory server. (Contributed by Robert Joseph Evans)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1327354 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/04/12 6:59 PM",
      "commitName": "7d04a96027ad75877b41b7cd8f67455dd13159d7",
      "commitAuthor": "Siddharth Seth",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "MAPREDUCE-3972. Fix locking and exception issues in JobHistory server. (Contributed by Robert Joseph Evans)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1327354 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "17/04/12 6:59 PM",
          "commitName": "7d04a96027ad75877b41b7cd8f67455dd13159d7",
          "commitAuthor": "Siddharth Seth",
          "commitDateOld": "10/04/12 11:11 AM",
          "commitNameOld": "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f",
          "commitAuthorOld": "Thomas Graves",
          "daysBetweenCommits": 7.32,
          "commitsBetweenForRepo": 59,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,13 +1,16 @@\n-  private Job loadJob(MetaInfo metaInfo) {\n+  private Job loadJob(HistoryFileInfo fileInfo) {\n     try {\n-      Job job \u003d hsManager.loadJob(metaInfo);\n+      Job job \u003d fileInfo.loadJob();\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Adding \" + job.getID() + \" to loaded job cache\");\n       }\n+      // We can clobber results here, but that should be OK, because it only\n+      // means that we may have two identical copies of the same job floating\n+      // around for a while.\n       loadedJobCache.put(job.getID(), job);\n       return job;\n     } catch (IOException e) {\n       throw new YarnException(\n-          \"Could not find/load job: \" + metaInfo.getJobId(), e);\n+          \"Could not find/load job: \" + fileInfo.getJobId(), e);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private Job loadJob(HistoryFileInfo fileInfo) {\n    try {\n      Job job \u003d fileInfo.loadJob();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Adding \" + job.getID() + \" to loaded job cache\");\n      }\n      // We can clobber results here, but that should be OK, because it only\n      // means that we may have two identical copies of the same job floating\n      // around for a while.\n      loadedJobCache.put(job.getID(), job);\n      return job;\n    } catch (IOException e) {\n      throw new YarnException(\n          \"Could not find/load job: \" + fileInfo.getJobId(), e);\n    }\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/CachedHistoryStorage.java",
          "extendedDetails": {
            "oldValue": "[metaInfo-MetaInfo]",
            "newValue": "[fileInfo-HistoryFileInfo]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-3972. Fix locking and exception issues in JobHistory server. (Contributed by Robert Joseph Evans)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1327354 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "17/04/12 6:59 PM",
          "commitName": "7d04a96027ad75877b41b7cd8f67455dd13159d7",
          "commitAuthor": "Siddharth Seth",
          "commitDateOld": "10/04/12 11:11 AM",
          "commitNameOld": "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f",
          "commitAuthorOld": "Thomas Graves",
          "daysBetweenCommits": 7.32,
          "commitsBetweenForRepo": 59,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,13 +1,16 @@\n-  private Job loadJob(MetaInfo metaInfo) {\n+  private Job loadJob(HistoryFileInfo fileInfo) {\n     try {\n-      Job job \u003d hsManager.loadJob(metaInfo);\n+      Job job \u003d fileInfo.loadJob();\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Adding \" + job.getID() + \" to loaded job cache\");\n       }\n+      // We can clobber results here, but that should be OK, because it only\n+      // means that we may have two identical copies of the same job floating\n+      // around for a while.\n       loadedJobCache.put(job.getID(), job);\n       return job;\n     } catch (IOException e) {\n       throw new YarnException(\n-          \"Could not find/load job: \" + metaInfo.getJobId(), e);\n+          \"Could not find/load job: \" + fileInfo.getJobId(), e);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private Job loadJob(HistoryFileInfo fileInfo) {\n    try {\n      Job job \u003d fileInfo.loadJob();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Adding \" + job.getID() + \" to loaded job cache\");\n      }\n      // We can clobber results here, but that should be OK, because it only\n      // means that we may have two identical copies of the same job floating\n      // around for a while.\n      loadedJobCache.put(job.getID(), job);\n      return job;\n    } catch (IOException e) {\n      throw new YarnException(\n          \"Could not find/load job: \" + fileInfo.getJobId(), e);\n    }\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/CachedHistoryStorage.java",
          "extendedDetails": {}
        }
      ]
    },
    "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange)",
      "commitMessage": "MAPREDUCE-4059. The history server should have a separate pluggable storage/query interface. (Robert Evans via tgraves).\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1311896 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/04/12 11:11 AM",
      "commitName": "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f",
      "commitAuthor": "Thomas Graves",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "MAPREDUCE-4059. The history server should have a separate pluggable storage/query interface. (Robert Evans via tgraves).\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1311896 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "10/04/12 11:11 AM",
          "commitName": "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f",
          "commitAuthor": "Thomas Graves",
          "commitDateOld": "10/04/12 9:13 AM",
          "commitNameOld": "000859a534f4cc6a57524a676805d8af6ad199de",
          "commitAuthorOld": "Robert Joseph Evans",
          "daysBetweenCommits": 0.08,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,13 @@\n   private Job loadJob(MetaInfo metaInfo) {\n-    synchronized(metaInfo) {\n-      try {\n-        Job job \u003d new CompletedJob(conf, metaInfo.getJobIndexInfo().getJobId(), \n-            metaInfo.getHistoryFile(), false, metaInfo.getJobIndexInfo().getUser(),\n-            metaInfo.getConfFile(), this.aclsMgr);\n-        addToLoadedJobCache(job);\n-        return job;\n-      } catch (IOException e) {\n-        throw new YarnException(\"Could not find/load job: \" + \n-            metaInfo.getJobIndexInfo().getJobId(), e);\n+    try {\n+      Job job \u003d hsManager.loadJob(metaInfo);\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"Adding \" + job.getID() + \" to loaded job cache\");\n       }\n+      loadedJobCache.put(job.getID(), job);\n+      return job;\n+    } catch (IOException e) {\n+      throw new YarnException(\n+          \"Could not find/load job: \" + metaInfo.getJobId(), e);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private Job loadJob(MetaInfo metaInfo) {\n    try {\n      Job job \u003d hsManager.loadJob(metaInfo);\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Adding \" + job.getID() + \" to loaded job cache\");\n      }\n      loadedJobCache.put(job.getID(), job);\n      return job;\n    } catch (IOException e) {\n      throw new YarnException(\n          \"Could not find/load job: \" + metaInfo.getJobId(), e);\n    }\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/CachedHistoryStorage.java",
          "extendedDetails": {
            "oldPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
            "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/CachedHistoryStorage.java",
            "oldMethodName": "loadJob",
            "newMethodName": "loadJob"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-4059. The history server should have a separate pluggable storage/query interface. (Robert Evans via tgraves).\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1311896 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "10/04/12 11:11 AM",
          "commitName": "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f",
          "commitAuthor": "Thomas Graves",
          "commitDateOld": "10/04/12 9:13 AM",
          "commitNameOld": "000859a534f4cc6a57524a676805d8af6ad199de",
          "commitAuthorOld": "Robert Joseph Evans",
          "daysBetweenCommits": 0.08,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,13 @@\n   private Job loadJob(MetaInfo metaInfo) {\n-    synchronized(metaInfo) {\n-      try {\n-        Job job \u003d new CompletedJob(conf, metaInfo.getJobIndexInfo().getJobId(), \n-            metaInfo.getHistoryFile(), false, metaInfo.getJobIndexInfo().getUser(),\n-            metaInfo.getConfFile(), this.aclsMgr);\n-        addToLoadedJobCache(job);\n-        return job;\n-      } catch (IOException e) {\n-        throw new YarnException(\"Could not find/load job: \" + \n-            metaInfo.getJobIndexInfo().getJobId(), e);\n+    try {\n+      Job job \u003d hsManager.loadJob(metaInfo);\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"Adding \" + job.getID() + \" to loaded job cache\");\n       }\n+      loadedJobCache.put(job.getID(), job);\n+      return job;\n+    } catch (IOException e) {\n+      throw new YarnException(\n+          \"Could not find/load job: \" + metaInfo.getJobId(), e);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private Job loadJob(MetaInfo metaInfo) {\n    try {\n      Job job \u003d hsManager.loadJob(metaInfo);\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Adding \" + job.getID() + \" to loaded job cache\");\n      }\n      loadedJobCache.put(job.getID(), job);\n      return job;\n    } catch (IOException e) {\n      throw new YarnException(\n          \"Could not find/load job: \" + metaInfo.getJobId(), e);\n    }\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/CachedHistoryStorage.java",
          "extendedDetails": {}
        }
      ]
    },
    "7475e836dc2bdd29142eaf210262fba354b745ed": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3901. Modified JobHistory records in YARN to lazily load job and task reports so as to improve UI response times. Contributed by Siddarth Seth.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1294417 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/02/12 4:32 PM",
      "commitName": "7475e836dc2bdd29142eaf210262fba354b745ed",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "18/01/12 2:10 PM",
      "commitNameOld": "10325d97329c214bb3899c8535df5a366bc86d2f",
      "commitAuthorOld": "Alejandro Abdelnur",
      "daysBetweenCommits": 40.1,
      "commitsBetweenForRepo": 264,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,14 @@\n   private Job loadJob(MetaInfo metaInfo) {\n     synchronized(metaInfo) {\n       try {\n         Job job \u003d new CompletedJob(conf, metaInfo.getJobIndexInfo().getJobId(), \n-            metaInfo.getHistoryFile(), true, metaInfo.getJobIndexInfo().getUser(),\n+            metaInfo.getHistoryFile(), false, metaInfo.getJobIndexInfo().getUser(),\n             metaInfo.getConfFile(), this.aclsMgr);\n         addToLoadedJobCache(job);\n         return job;\n       } catch (IOException e) {\n         throw new YarnException(\"Could not find/load job: \" + \n             metaInfo.getJobIndexInfo().getJobId(), e);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private Job loadJob(MetaInfo metaInfo) {\n    synchronized(metaInfo) {\n      try {\n        Job job \u003d new CompletedJob(conf, metaInfo.getJobIndexInfo().getJobId(), \n            metaInfo.getHistoryFile(), false, metaInfo.getJobIndexInfo().getUser(),\n            metaInfo.getConfFile(), this.aclsMgr);\n        addToLoadedJobCache(job);\n        return job;\n      } catch (IOException e) {\n        throw new YarnException(\"Could not find/load job: \" + \n            metaInfo.getJobIndexInfo().getJobId(), e);\n      }\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
      "extendedDetails": {}
    },
    "68fa208b1cc991dec2577a07b3199a6935a71065": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3103. Implement Job ACLs for MRAppMaster. (mahadev)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1195761 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "31/10/11 6:51 PM",
      "commitName": "68fa208b1cc991dec2577a07b3199a6935a71065",
      "commitAuthor": "Mahadev Konar",
      "commitDateOld": "16/10/11 12:27 PM",
      "commitNameOld": "68328ae92632afc9cdd6e75b7a8d832723ddbe3b",
      "commitAuthorOld": "Mahadev Konar",
      "daysBetweenCommits": 15.27,
      "commitsBetweenForRepo": 164,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,14 @@\n   private Job loadJob(MetaInfo metaInfo) {\n     synchronized(metaInfo) {\n       try {\n         Job job \u003d new CompletedJob(conf, metaInfo.getJobIndexInfo().getJobId(), \n             metaInfo.getHistoryFile(), true, metaInfo.getJobIndexInfo().getUser(),\n-            metaInfo.getConfFile());\n+            metaInfo.getConfFile(), this.aclsMgr);\n         addToLoadedJobCache(job);\n         return job;\n       } catch (IOException e) {\n         throw new YarnException(\"Could not find/load job: \" + \n             metaInfo.getJobIndexInfo().getJobId(), e);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private Job loadJob(MetaInfo metaInfo) {\n    synchronized(metaInfo) {\n      try {\n        Job job \u003d new CompletedJob(conf, metaInfo.getJobIndexInfo().getJobId(), \n            metaInfo.getHistoryFile(), true, metaInfo.getJobIndexInfo().getUser(),\n            metaInfo.getConfFile(), this.aclsMgr);\n        addToLoadedJobCache(job);\n        return job;\n      } catch (IOException e) {\n        throw new YarnException(\"Could not find/load job: \" + \n            metaInfo.getJobIndexInfo().getJobId(), e);\n      }\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
      "extendedDetails": {}
    },
    "a3e8f6836b489f8f2ddd785ae038df729c85059f": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2676. MR-279: JobHistory Job page needs reformatted. (Robert Evans via mahadev)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1170379 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/09/11 3:55 PM",
      "commitName": "a3e8f6836b489f8f2ddd785ae038df729c85059f",
      "commitAuthor": "Mahadev Konar",
      "commitDateOld": "12/09/11 7:24 AM",
      "commitNameOld": "be32d25c546a7d4f98604e142940c483213b485b",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 1.35,
      "commitsBetweenForRepo": 14,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,14 @@\n   private Job loadJob(MetaInfo metaInfo) {\n     synchronized(metaInfo) {\n       try {\n         Job job \u003d new CompletedJob(conf, metaInfo.getJobIndexInfo().getJobId(), \n-            metaInfo.getHistoryFile(), true, metaInfo.getJobIndexInfo().getUser());\n+            metaInfo.getHistoryFile(), true, metaInfo.getJobIndexInfo().getUser(),\n+            metaInfo.getConfFile());\n         addToLoadedJobCache(job);\n         return job;\n       } catch (IOException e) {\n-        throw new YarnException(\"Could not find/load job: \" + metaInfo.getJobIndexInfo().getJobId(), e);\n+        throw new YarnException(\"Could not find/load job: \" + \n+            metaInfo.getJobIndexInfo().getJobId(), e);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private Job loadJob(MetaInfo metaInfo) {\n    synchronized(metaInfo) {\n      try {\n        Job job \u003d new CompletedJob(conf, metaInfo.getJobIndexInfo().getJobId(), \n            metaInfo.getHistoryFile(), true, metaInfo.getJobIndexInfo().getUser(),\n            metaInfo.getConfFile());\n        addToLoadedJobCache(job);\n        return job;\n      } catch (IOException e) {\n        throw new YarnException(\"Could not find/load job: \" + \n            metaInfo.getJobIndexInfo().getJobId(), e);\n      }\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private Job loadJob(MetaInfo metaInfo) {\n    synchronized(metaInfo) {\n      try {\n        Job job \u003d new CompletedJob(conf, metaInfo.getJobIndexInfo().getJobId(), \n            metaInfo.getHistoryFile(), true, metaInfo.getJobIndexInfo().getUser());\n        addToLoadedJobCache(job);\n        return job;\n      } catch (IOException e) {\n        throw new YarnException(\"Could not find/load job: \" + metaInfo.getJobIndexInfo().getJobId(), e);\n      }\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java"
      }
    },
    "7c8fcbecf14b2e24d54ccb276bb684fdbe62b669": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2701. app/Job.java needs UGI for the user that launched it. (Robert Evans via mahadev)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1160392 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/08/11 12:36 PM",
      "commitName": "7c8fcbecf14b2e24d54ccb276bb684fdbe62b669",
      "commitAuthor": "Mahadev Konar",
      "commitDateOld": "18/08/11 4:07 AM",
      "commitNameOld": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 4.35,
      "commitsBetweenForRepo": 14,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,12 @@\n   private Job loadJob(MetaInfo metaInfo) {\n     synchronized(metaInfo) {\n       try {\n-        Job job \u003d new CompletedJob(conf, metaInfo.getJobIndexInfo().getJobId(), metaInfo.getHistoryFile(), true);\n+        Job job \u003d new CompletedJob(conf, metaInfo.getJobIndexInfo().getJobId(), \n+            metaInfo.getHistoryFile(), true, metaInfo.getJobIndexInfo().getUser());\n         addToLoadedJobCache(job);\n         return job;\n       } catch (IOException e) {\n         throw new YarnException(\"Could not find/load job: \" + metaInfo.getJobIndexInfo().getJobId(), e);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private Job loadJob(MetaInfo metaInfo) {\n    synchronized(metaInfo) {\n      try {\n        Job job \u003d new CompletedJob(conf, metaInfo.getJobIndexInfo().getJobId(), \n            metaInfo.getHistoryFile(), true, metaInfo.getJobIndexInfo().getUser());\n        addToLoadedJobCache(job);\n        return job;\n      } catch (IOException e) {\n        throw new YarnException(\"Could not find/load job: \" + metaInfo.getJobIndexInfo().getJobId(), e);\n      }\n    }\n  }",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
      "extendedDetails": {}
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "diff": "@@ -0,0 +1,11 @@\n+  private Job loadJob(MetaInfo metaInfo) {\n+    synchronized(metaInfo) {\n+      try {\n+        Job job \u003d new CompletedJob(conf, metaInfo.getJobIndexInfo().getJobId(), metaInfo.getHistoryFile(), true);\n+        addToLoadedJobCache(job);\n+        return job;\n+      } catch (IOException e) {\n+        throw new YarnException(\"Could not find/load job: \" + metaInfo.getJobIndexInfo().getJobId(), e);\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private Job loadJob(MetaInfo metaInfo) {\n    synchronized(metaInfo) {\n      try {\n        Job job \u003d new CompletedJob(conf, metaInfo.getJobIndexInfo().getJobId(), metaInfo.getHistoryFile(), true);\n        addToLoadedJobCache(job);\n        return job;\n      } catch (IOException e) {\n        throw new YarnException(\"Could not find/load job: \" + metaInfo.getJobIndexInfo().getJobId(), e);\n      }\n    }\n  }",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java"
    }
  }
}