{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ApplicationMasterService.java",
  "functionName": "allocate",
  "functionId": "allocate___request-AllocateRequest",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
  "functionStartLine": 390,
  "functionEndLine": 473,
  "numCommitsSeen": 119,
  "timeTaken": 17208,
  "changeHistory": [
    "3090922805699b8374a359e92323884a4177dc4e",
    "8736fc39ac3b3de168d2c216f3d1c0edb48fb3f9",
    "3a4e861169dc3da9df0158ba6f44a9bc8576e217",
    "077fcf6a96e420e7f36350931722b8603d010cf1",
    "5496a34c0cb2b1a83cfa6b0aba5a77b05ff2d8f0",
    "ac1e5d4f77e3b9df8dcacb0b1f72eecc27931eb8",
    "a926f895c11cd69cf2117c3b970304f3f1f53d92",
    "283fa33febe043bd7b4fa87546be26c9c5a8f8b5",
    "d6d9cff21b7b6141ed88359652cf22e8973c0661",
    "89e5c44f9e891a3579384c3fa3766937cd4970f1",
    "2188a07e5bea1da26bf679ca0ece26ab596d3438",
    "9b5636408005676ae580f8d929f8e912c27828e7",
    "5252562edf1f65a9c5d502016df8bb92fbe78095",
    "f9da5cdb2b2dd071fd60fc01ea1edf0f79c0819b",
    "89cab1ba5f0671f8ef30dbe7432079c18362b434",
    "6f72f1e6003ab11679bebeb96f27f1f62b3b3e02",
    "f7e051c4310024d4040ad466c34432c72e88b0fc",
    "f489a4ec969f3727d03c8e85d51af1018fc0b2a1",
    "f65eeb412d140a3808bcf99344a9f3a965918f70",
    "18297e09727e4af95140084760ae1267e8fe51c4",
    "c1957fef29b07fea70938e971b30532a1e131fd0",
    "e0233c16ebd06bb3aabeb523cd17259008e243ef",
    "0f3b6900be1a3b2e4624f31f84656f4a32dadce9",
    "f2ea555ac6c06a3f2f6559731f48711fff05d3f1",
    "469ea3dcef6e427d02fd08b859b2789cc25189f9",
    "eeb4acd955802e2a84ea94cecf2e2341b83d5efb",
    "c3f1c30e65cc6a10928299f50801782ecbb4ccb6",
    "faddccc216f4ba5b503a7d21ce699217d75fb400",
    "5fd5c9900cfd299428acbc8dff767273e44647c0",
    "996acc834e969bcb71b3d9808854a259490cb32d",
    "1393581bceda234c88cafec00dbfc0ef2a402e83",
    "8caae1d5a65bf082eef9bd03a50fd5025c290406",
    "48264f1994c8b6002d5f1ac2fea46da28798df2d",
    "ac914f79bc80b152e71e7de5497b73f22824f4a7",
    "85f0efb68f9d1d9ee3466e3939c4fc2f985ccf61",
    "15ce82b9c5087ac5e51f7a43eb57873c3c374ced",
    "243bcd367ff3130d74676280233041f88aca62a5",
    "769a0bd8314cd7317c083a9b74abf47242acb58c",
    "af8514eef297574240652672d048748100c97733",
    "2051fd5ee29e99df6fe79c70b0c7c8c0c1cc131f",
    "978012b9b6b18985fd60ec5b26c38693a6e86f9a",
    "a83fb61ac07c0468cbc7a38526e92683883dd932",
    "505fe2653941e4f36f61edd0fc2f8e750ceb5d8f",
    "9c4f86879cad6d6e19255d4ae8f28b61328bd10b",
    "bc6777dd5bdcbaef09897b506bc6511ae456033d",
    "1bd345d6e3855ab330963efd32e0fac102e61d1a",
    "453926397182078c65a4428eb5de5a90d6af6448",
    "6cd0736cc57849e4f7c5d38a3986432a9717fe39",
    "a124297cf016439ee426d3142627606875b9667a",
    "e1fdf62123625e4ba399af02f8aad500637d29d1",
    "407cfa3b56a0645d64d2d9af305f6ef24307e775",
    "606114d6029758f2be130960b8fc3102457406ba",
    "e7543b944c2b35d0a1ca0a92efeca47ad414ac7a",
    "db8ac0ec3cbec046f9cf32644c16fd2a51dd85a2",
    "817ead65b99f465fc2dfa18072cf23cadf5f05d0",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517"
  ],
  "changeHistoryShort": {
    "3090922805699b8374a359e92323884a4177dc4e": "Ybodychange",
    "8736fc39ac3b3de168d2c216f3d1c0edb48fb3f9": "Ybodychange",
    "3a4e861169dc3da9df0158ba6f44a9bc8576e217": "Ybodychange",
    "077fcf6a96e420e7f36350931722b8603d010cf1": "Ybodychange",
    "5496a34c0cb2b1a83cfa6b0aba5a77b05ff2d8f0": "Ybodychange",
    "ac1e5d4f77e3b9df8dcacb0b1f72eecc27931eb8": "Ybodychange",
    "a926f895c11cd69cf2117c3b970304f3f1f53d92": "Ybodychange",
    "283fa33febe043bd7b4fa87546be26c9c5a8f8b5": "Ybodychange",
    "d6d9cff21b7b6141ed88359652cf22e8973c0661": "Ybodychange",
    "89e5c44f9e891a3579384c3fa3766937cd4970f1": "Ybodychange",
    "2188a07e5bea1da26bf679ca0ece26ab596d3438": "Ybodychange",
    "9b5636408005676ae580f8d929f8e912c27828e7": "Ybodychange",
    "5252562edf1f65a9c5d502016df8bb92fbe78095": "Ybodychange",
    "f9da5cdb2b2dd071fd60fc01ea1edf0f79c0819b": "Ybodychange",
    "89cab1ba5f0671f8ef30dbe7432079c18362b434": "Ybodychange",
    "6f72f1e6003ab11679bebeb96f27f1f62b3b3e02": "Ybodychange",
    "f7e051c4310024d4040ad466c34432c72e88b0fc": "Ybodychange",
    "f489a4ec969f3727d03c8e85d51af1018fc0b2a1": "Ybodychange",
    "f65eeb412d140a3808bcf99344a9f3a965918f70": "Ybodychange",
    "18297e09727e4af95140084760ae1267e8fe51c4": "Ybodychange",
    "c1957fef29b07fea70938e971b30532a1e131fd0": "Ybodychange",
    "e0233c16ebd06bb3aabeb523cd17259008e243ef": "Ybodychange",
    "0f3b6900be1a3b2e4624f31f84656f4a32dadce9": "Ybodychange",
    "f2ea555ac6c06a3f2f6559731f48711fff05d3f1": "Ybodychange",
    "469ea3dcef6e427d02fd08b859b2789cc25189f9": "Ybodychange",
    "eeb4acd955802e2a84ea94cecf2e2341b83d5efb": "Ybodychange",
    "c3f1c30e65cc6a10928299f50801782ecbb4ccb6": "Ybodychange",
    "faddccc216f4ba5b503a7d21ce699217d75fb400": "Ybodychange",
    "5fd5c9900cfd299428acbc8dff767273e44647c0": "Ybodychange",
    "996acc834e969bcb71b3d9808854a259490cb32d": "Ybodychange",
    "1393581bceda234c88cafec00dbfc0ef2a402e83": "Ybodychange",
    "8caae1d5a65bf082eef9bd03a50fd5025c290406": "Ybodychange",
    "48264f1994c8b6002d5f1ac2fea46da28798df2d": "Ybodychange",
    "ac914f79bc80b152e71e7de5497b73f22824f4a7": "Ybodychange",
    "85f0efb68f9d1d9ee3466e3939c4fc2f985ccf61": "Ybodychange",
    "15ce82b9c5087ac5e51f7a43eb57873c3c374ced": "Ybodychange",
    "243bcd367ff3130d74676280233041f88aca62a5": "Ybodychange",
    "769a0bd8314cd7317c083a9b74abf47242acb58c": "Ybodychange",
    "af8514eef297574240652672d048748100c97733": "Ybodychange",
    "2051fd5ee29e99df6fe79c70b0c7c8c0c1cc131f": "Ybodychange",
    "978012b9b6b18985fd60ec5b26c38693a6e86f9a": "Ybodychange",
    "a83fb61ac07c0468cbc7a38526e92683883dd932": "Yexceptionschange",
    "505fe2653941e4f36f61edd0fc2f8e750ceb5d8f": "Ybodychange",
    "9c4f86879cad6d6e19255d4ae8f28b61328bd10b": "Yexceptionschange",
    "bc6777dd5bdcbaef09897b506bc6511ae456033d": "Ybodychange",
    "1bd345d6e3855ab330963efd32e0fac102e61d1a": "Ybodychange",
    "453926397182078c65a4428eb5de5a90d6af6448": "Ybodychange",
    "6cd0736cc57849e4f7c5d38a3986432a9717fe39": "Ybodychange",
    "a124297cf016439ee426d3142627606875b9667a": "Ybodychange",
    "e1fdf62123625e4ba399af02f8aad500637d29d1": "Yfilerename",
    "407cfa3b56a0645d64d2d9af305f6ef24307e775": "Ybodychange",
    "606114d6029758f2be130960b8fc3102457406ba": "Ybodychange",
    "e7543b944c2b35d0a1ca0a92efeca47ad414ac7a": "Ybodychange",
    "db8ac0ec3cbec046f9cf32644c16fd2a51dd85a2": "Ybodychange",
    "817ead65b99f465fc2dfa18072cf23cadf5f05d0": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yintroduced"
  },
  "changeHistoryDetails": {
    "3090922805699b8374a359e92323884a4177dc4e": {
      "type": "Ybodychange",
      "commitMessage": "YARN-8696. [AMRMProxy] FederationInterceptor upgrade: home sub-cluster heartbeat async. Contributed by Botong Huang.\n",
      "commitDate": "24/09/18 11:37 AM",
      "commitName": "3090922805699b8374a359e92323884a4177dc4e",
      "commitAuthor": "Giovanni Matteo Fumarola",
      "commitDateOld": "20/08/18 12:22 PM",
      "commitNameOld": "8736fc39ac3b3de168d2c216f3d1c0edb48fb3f9",
      "commitAuthorOld": "Giovanni Matteo Fumarola",
      "daysBetweenCommits": 34.97,
      "commitsBetweenForRepo": 317,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,83 +1,84 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n     AMRMTokenIdentifier amrmTokenIdentifier \u003d\n         YarnServerSecurityUtils.authorizeRequest();\n \n     ApplicationAttemptId appAttemptId \u003d\n         amrmTokenIdentifier.getApplicationAttemptId();\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n     if (lock \u003d\u003d null) {\n       String message \u003d\n           \"Application attempt \" + appAttemptId\n               + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n       LOG.error(message);\n       throw new ApplicationAttemptNotFoundException(message);\n     }\n     synchronized (lock) {\n       AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n       if (!hasApplicationMasterRegistered(appAttemptId)) {\n         String message \u003d\n             \"AM is not registered for known application attempt: \"\n                 + appAttemptId\n                 + \" or RM had restarted after AM registered. \"\n                 + \" AM should re-register.\";\n         throw new ApplicationMasterNotRegisteredException(message);\n       }\n \n       // Normally request.getResponseId() \u003d\u003d lastResponse.getResponseId()\n-      if (getNextResponseId(request.getResponseId()) \u003d\u003d lastResponse\n-          .getResponseId()) {\n+      if (AMRMClientUtils.getNextResponseId(\n+          request.getResponseId()) \u003d\u003d lastResponse.getResponseId()) {\n         // heartbeat one step old, simply return lastReponse\n         return lastResponse;\n       } else if (request.getResponseId() !\u003d lastResponse.getResponseId()) {\n         throw new InvalidApplicationMasterRequestException(AMRMClientUtils\n             .assembleInvalidResponseIdExceptionMessage(appAttemptId,\n                 lastResponse.getResponseId(), request.getResponseId()));\n       }\n \n       AllocateResponse response \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n       this.amsProcessingChain.allocate(\n           amrmTokenIdentifier.getApplicationAttemptId(), request, response);\n \n       // update AMRMToken if the token is rolled-up\n       MasterKeyData nextMasterKey \u003d\n           this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n \n       if (nextMasterKey !\u003d null\n           \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n           .getKeyId()) {\n         RMApp app \u003d\n             this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n         RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n         RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n         Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n         if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n             appAttemptImpl.getAMRMTokenKeyId()) {\n           LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n               + \" to application: \" + appAttemptId.getApplicationId());\n           amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n               .createAndGetAMRMToken(appAttemptId);\n           appAttemptImpl.setAMRMToken(amrmToken);\n         }\n         response.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n             .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n                 .toString(), amrmToken.getPassword(), amrmToken.getService()\n                 .toString()));\n       }\n \n       /*\n        * As we are updating the response inside the lock object so we don\u0027t\n        * need to worry about unregister call occurring in between (which\n        * removes the lock object).\n        */\n-      response.setResponseId(getNextResponseId(lastResponse.getResponseId()));\n+      response.setResponseId(\n+          AMRMClientUtils.getNextResponseId(lastResponse.getResponseId()));\n       lock.setAllocateResponse(response);\n       return response;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    AMRMTokenIdentifier amrmTokenIdentifier \u003d\n        YarnServerSecurityUtils.authorizeRequest();\n\n    ApplicationAttemptId appAttemptId \u003d\n        amrmTokenIdentifier.getApplicationAttemptId();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n    if (lock \u003d\u003d null) {\n      String message \u003d\n          \"Application attempt \" + appAttemptId\n              + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n      LOG.error(message);\n      throw new ApplicationAttemptNotFoundException(message);\n    }\n    synchronized (lock) {\n      AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n      if (!hasApplicationMasterRegistered(appAttemptId)) {\n        String message \u003d\n            \"AM is not registered for known application attempt: \"\n                + appAttemptId\n                + \" or RM had restarted after AM registered. \"\n                + \" AM should re-register.\";\n        throw new ApplicationMasterNotRegisteredException(message);\n      }\n\n      // Normally request.getResponseId() \u003d\u003d lastResponse.getResponseId()\n      if (AMRMClientUtils.getNextResponseId(\n          request.getResponseId()) \u003d\u003d lastResponse.getResponseId()) {\n        // heartbeat one step old, simply return lastReponse\n        return lastResponse;\n      } else if (request.getResponseId() !\u003d lastResponse.getResponseId()) {\n        throw new InvalidApplicationMasterRequestException(AMRMClientUtils\n            .assembleInvalidResponseIdExceptionMessage(appAttemptId,\n                lastResponse.getResponseId(), request.getResponseId()));\n      }\n\n      AllocateResponse response \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n      this.amsProcessingChain.allocate(\n          amrmTokenIdentifier.getApplicationAttemptId(), request, response);\n\n      // update AMRMToken if the token is rolled-up\n      MasterKeyData nextMasterKey \u003d\n          this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n\n      if (nextMasterKey !\u003d null\n          \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n          .getKeyId()) {\n        RMApp app \u003d\n            this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n        RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n        RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n        Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n        if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n            appAttemptImpl.getAMRMTokenKeyId()) {\n          LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n              + \" to application: \" + appAttemptId.getApplicationId());\n          amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n              .createAndGetAMRMToken(appAttemptId);\n          appAttemptImpl.setAMRMToken(amrmToken);\n        }\n        response.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n            .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n                .toString(), amrmToken.getPassword(), amrmToken.getService()\n                .toString()));\n      }\n\n      /*\n       * As we are updating the response inside the lock object so we don\u0027t\n       * need to worry about unregister call occurring in between (which\n       * removes the lock object).\n       */\n      response.setResponseId(\n          AMRMClientUtils.getNextResponseId(lastResponse.getResponseId()));\n      lock.setAllocateResponse(response);\n      return response;\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "8736fc39ac3b3de168d2c216f3d1c0edb48fb3f9": {
      "type": "Ybodychange",
      "commitMessage": "YARN-8673. [AMRMProxy] More robust responseId resync after an YarnRM master slave switch. Contributed by Botong Huang.\n",
      "commitDate": "20/08/18 12:22 PM",
      "commitName": "8736fc39ac3b3de168d2c216f3d1c0edb48fb3f9",
      "commitAuthor": "Giovanni Matteo Fumarola",
      "commitDateOld": "17/05/18 8:00 PM",
      "commitNameOld": "3159bffce23abf35754da2d7d51de7d8c2631ae3",
      "commitAuthorOld": "Arun Suresh",
      "daysBetweenCommits": 94.68,
      "commitsBetweenForRepo": 697,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,86 +1,83 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n     AMRMTokenIdentifier amrmTokenIdentifier \u003d\n         YarnServerSecurityUtils.authorizeRequest();\n \n     ApplicationAttemptId appAttemptId \u003d\n         amrmTokenIdentifier.getApplicationAttemptId();\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n     if (lock \u003d\u003d null) {\n       String message \u003d\n           \"Application attempt \" + appAttemptId\n               + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n       LOG.error(message);\n       throw new ApplicationAttemptNotFoundException(message);\n     }\n     synchronized (lock) {\n       AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n       if (!hasApplicationMasterRegistered(appAttemptId)) {\n         String message \u003d\n             \"AM is not registered for known application attempt: \"\n                 + appAttemptId\n                 + \" or RM had restarted after AM registered. \"\n                 + \" AM should re-register.\";\n         throw new ApplicationMasterNotRegisteredException(message);\n       }\n \n       // Normally request.getResponseId() \u003d\u003d lastResponse.getResponseId()\n       if (getNextResponseId(request.getResponseId()) \u003d\u003d lastResponse\n           .getResponseId()) {\n         // heartbeat one step old, simply return lastReponse\n         return lastResponse;\n       } else if (request.getResponseId() !\u003d lastResponse.getResponseId()) {\n-        String message \u003d\n-            \"Invalid responseId in AllocateRequest from application attempt: \"\n-                + appAttemptId + \", expect responseId to be \"\n-                + lastResponse.getResponseId() + \", but get \"\n-                + request.getResponseId();\n-        throw new InvalidApplicationMasterRequestException(message);\n+        throw new InvalidApplicationMasterRequestException(AMRMClientUtils\n+            .assembleInvalidResponseIdExceptionMessage(appAttemptId,\n+                lastResponse.getResponseId(), request.getResponseId()));\n       }\n \n       AllocateResponse response \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n       this.amsProcessingChain.allocate(\n           amrmTokenIdentifier.getApplicationAttemptId(), request, response);\n \n       // update AMRMToken if the token is rolled-up\n       MasterKeyData nextMasterKey \u003d\n           this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n \n       if (nextMasterKey !\u003d null\n           \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n           .getKeyId()) {\n         RMApp app \u003d\n             this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n         RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n         RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n         Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n         if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n             appAttemptImpl.getAMRMTokenKeyId()) {\n           LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n               + \" to application: \" + appAttemptId.getApplicationId());\n           amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n               .createAndGetAMRMToken(appAttemptId);\n           appAttemptImpl.setAMRMToken(amrmToken);\n         }\n         response.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n             .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n                 .toString(), amrmToken.getPassword(), amrmToken.getService()\n                 .toString()));\n       }\n \n       /*\n        * As we are updating the response inside the lock object so we don\u0027t\n        * need to worry about unregister call occurring in between (which\n        * removes the lock object).\n        */\n       response.setResponseId(getNextResponseId(lastResponse.getResponseId()));\n       lock.setAllocateResponse(response);\n       return response;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    AMRMTokenIdentifier amrmTokenIdentifier \u003d\n        YarnServerSecurityUtils.authorizeRequest();\n\n    ApplicationAttemptId appAttemptId \u003d\n        amrmTokenIdentifier.getApplicationAttemptId();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n    if (lock \u003d\u003d null) {\n      String message \u003d\n          \"Application attempt \" + appAttemptId\n              + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n      LOG.error(message);\n      throw new ApplicationAttemptNotFoundException(message);\n    }\n    synchronized (lock) {\n      AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n      if (!hasApplicationMasterRegistered(appAttemptId)) {\n        String message \u003d\n            \"AM is not registered for known application attempt: \"\n                + appAttemptId\n                + \" or RM had restarted after AM registered. \"\n                + \" AM should re-register.\";\n        throw new ApplicationMasterNotRegisteredException(message);\n      }\n\n      // Normally request.getResponseId() \u003d\u003d lastResponse.getResponseId()\n      if (getNextResponseId(request.getResponseId()) \u003d\u003d lastResponse\n          .getResponseId()) {\n        // heartbeat one step old, simply return lastReponse\n        return lastResponse;\n      } else if (request.getResponseId() !\u003d lastResponse.getResponseId()) {\n        throw new InvalidApplicationMasterRequestException(AMRMClientUtils\n            .assembleInvalidResponseIdExceptionMessage(appAttemptId,\n                lastResponse.getResponseId(), request.getResponseId()));\n      }\n\n      AllocateResponse response \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n      this.amsProcessingChain.allocate(\n          amrmTokenIdentifier.getApplicationAttemptId(), request, response);\n\n      // update AMRMToken if the token is rolled-up\n      MasterKeyData nextMasterKey \u003d\n          this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n\n      if (nextMasterKey !\u003d null\n          \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n          .getKeyId()) {\n        RMApp app \u003d\n            this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n        RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n        RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n        Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n        if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n            appAttemptImpl.getAMRMTokenKeyId()) {\n          LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n              + \" to application: \" + appAttemptId.getApplicationId());\n          amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n              .createAndGetAMRMToken(appAttemptId);\n          appAttemptImpl.setAMRMToken(amrmToken);\n        }\n        response.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n            .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n                .toString(), amrmToken.getPassword(), amrmToken.getService()\n                .toString()));\n      }\n\n      /*\n       * As we are updating the response inside the lock object so we don\u0027t\n       * need to worry about unregister call occurring in between (which\n       * removes the lock object).\n       */\n      response.setResponseId(getNextResponseId(lastResponse.getResponseId()));\n      lock.setAllocateResponse(response);\n      return response;\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "3a4e861169dc3da9df0158ba6f44a9bc8576e217": {
      "type": "Ybodychange",
      "commitMessage": "YARN-6640. AM heartbeat stuck when responseId overflows MAX_INT. Contributed by Botong Huang\n",
      "commitDate": "25/08/17 7:16 AM",
      "commitName": "3a4e861169dc3da9df0158ba6f44a9bc8576e217",
      "commitAuthor": "Jason Lowe",
      "commitDateOld": "01/08/17 5:28 PM",
      "commitNameOld": "712e97d4cfab15bec4cf4b11cc067b8f85c8bec8",
      "commitAuthorOld": "Subru Krishnan",
      "daysBetweenCommits": 23.57,
      "commitsBetweenForRepo": 149,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,83 +1,86 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n     AMRMTokenIdentifier amrmTokenIdentifier \u003d\n         YarnServerSecurityUtils.authorizeRequest();\n \n     ApplicationAttemptId appAttemptId \u003d\n         amrmTokenIdentifier.getApplicationAttemptId();\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n     if (lock \u003d\u003d null) {\n       String message \u003d\n           \"Application attempt \" + appAttemptId\n               + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n       LOG.error(message);\n       throw new ApplicationAttemptNotFoundException(message);\n     }\n     synchronized (lock) {\n       AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n       if (!hasApplicationMasterRegistered(appAttemptId)) {\n         String message \u003d\n             \"AM is not registered for known application attempt: \"\n                 + appAttemptId\n                 + \" or RM had restarted after AM registered. \"\n                 + \" AM should re-register.\";\n         throw new ApplicationMasterNotRegisteredException(message);\n       }\n \n-      if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n-        /* old heartbeat */\n+      // Normally request.getResponseId() \u003d\u003d lastResponse.getResponseId()\n+      if (getNextResponseId(request.getResponseId()) \u003d\u003d lastResponse\n+          .getResponseId()) {\n+        // heartbeat one step old, simply return lastReponse\n         return lastResponse;\n-      } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n+      } else if (request.getResponseId() !\u003d lastResponse.getResponseId()) {\n         String message \u003d\n             \"Invalid responseId in AllocateRequest from application attempt: \"\n                 + appAttemptId + \", expect responseId to be \"\n-                + (lastResponse.getResponseId() + 1);\n+                + lastResponse.getResponseId() + \", but get \"\n+                + request.getResponseId();\n         throw new InvalidApplicationMasterRequestException(message);\n       }\n \n       AllocateResponse response \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n       this.amsProcessingChain.allocate(\n           amrmTokenIdentifier.getApplicationAttemptId(), request, response);\n \n       // update AMRMToken if the token is rolled-up\n       MasterKeyData nextMasterKey \u003d\n           this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n \n       if (nextMasterKey !\u003d null\n           \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n           .getKeyId()) {\n         RMApp app \u003d\n             this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n         RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n         RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n         Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n         if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n             appAttemptImpl.getAMRMTokenKeyId()) {\n           LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n               + \" to application: \" + appAttemptId.getApplicationId());\n           amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n               .createAndGetAMRMToken(appAttemptId);\n           appAttemptImpl.setAMRMToken(amrmToken);\n         }\n         response.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n             .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n                 .toString(), amrmToken.getPassword(), amrmToken.getService()\n                 .toString()));\n       }\n \n       /*\n        * As we are updating the response inside the lock object so we don\u0027t\n        * need to worry about unregister call occurring in between (which\n        * removes the lock object).\n        */\n-      response.setResponseId(lastResponse.getResponseId() + 1);\n+      response.setResponseId(getNextResponseId(lastResponse.getResponseId()));\n       lock.setAllocateResponse(response);\n       return response;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    AMRMTokenIdentifier amrmTokenIdentifier \u003d\n        YarnServerSecurityUtils.authorizeRequest();\n\n    ApplicationAttemptId appAttemptId \u003d\n        amrmTokenIdentifier.getApplicationAttemptId();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n    if (lock \u003d\u003d null) {\n      String message \u003d\n          \"Application attempt \" + appAttemptId\n              + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n      LOG.error(message);\n      throw new ApplicationAttemptNotFoundException(message);\n    }\n    synchronized (lock) {\n      AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n      if (!hasApplicationMasterRegistered(appAttemptId)) {\n        String message \u003d\n            \"AM is not registered for known application attempt: \"\n                + appAttemptId\n                + \" or RM had restarted after AM registered. \"\n                + \" AM should re-register.\";\n        throw new ApplicationMasterNotRegisteredException(message);\n      }\n\n      // Normally request.getResponseId() \u003d\u003d lastResponse.getResponseId()\n      if (getNextResponseId(request.getResponseId()) \u003d\u003d lastResponse\n          .getResponseId()) {\n        // heartbeat one step old, simply return lastReponse\n        return lastResponse;\n      } else if (request.getResponseId() !\u003d lastResponse.getResponseId()) {\n        String message \u003d\n            \"Invalid responseId in AllocateRequest from application attempt: \"\n                + appAttemptId + \", expect responseId to be \"\n                + lastResponse.getResponseId() + \", but get \"\n                + request.getResponseId();\n        throw new InvalidApplicationMasterRequestException(message);\n      }\n\n      AllocateResponse response \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n      this.amsProcessingChain.allocate(\n          amrmTokenIdentifier.getApplicationAttemptId(), request, response);\n\n      // update AMRMToken if the token is rolled-up\n      MasterKeyData nextMasterKey \u003d\n          this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n\n      if (nextMasterKey !\u003d null\n          \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n          .getKeyId()) {\n        RMApp app \u003d\n            this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n        RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n        RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n        Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n        if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n            appAttemptImpl.getAMRMTokenKeyId()) {\n          LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n              + \" to application: \" + appAttemptId.getApplicationId());\n          amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n              .createAndGetAMRMToken(appAttemptId);\n          appAttemptImpl.setAMRMToken(amrmToken);\n        }\n        response.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n            .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n                .toString(), amrmToken.getPassword(), amrmToken.getService()\n                .toString()));\n      }\n\n      /*\n       * As we are updating the response inside the lock object so we don\u0027t\n       * need to worry about unregister call occurring in between (which\n       * removes the lock object).\n       */\n      response.setResponseId(getNextResponseId(lastResponse.getResponseId()));\n      lock.setAllocateResponse(response);\n      return response;\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "077fcf6a96e420e7f36350931722b8603d010cf1": {
      "type": "Ybodychange",
      "commitMessage": "YARN-6777. Support for ApplicationMasterService processing chain of interceptors. (asuresh)\n",
      "commitDate": "19/07/17 12:26 PM",
      "commitName": "077fcf6a96e420e7f36350931722b8603d010cf1",
      "commitAuthor": "Arun Suresh",
      "commitDateOld": "10/07/17 2:34 PM",
      "commitNameOld": "5496a34c0cb2b1a83cfa6b0aba5a77b05ff2d8f0",
      "commitAuthorOld": "Arun Suresh",
      "daysBetweenCommits": 8.91,
      "commitsBetweenForRepo": 53,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,81 +1,83 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n     AMRMTokenIdentifier amrmTokenIdentifier \u003d\n         YarnServerSecurityUtils.authorizeRequest();\n \n     ApplicationAttemptId appAttemptId \u003d\n         amrmTokenIdentifier.getApplicationAttemptId();\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n     if (lock \u003d\u003d null) {\n       String message \u003d\n           \"Application attempt \" + appAttemptId\n               + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n       LOG.error(message);\n       throw new ApplicationAttemptNotFoundException(message);\n     }\n     synchronized (lock) {\n       AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n       if (!hasApplicationMasterRegistered(appAttemptId)) {\n         String message \u003d\n             \"AM is not registered for known application attempt: \"\n                 + appAttemptId\n                 + \" or RM had restarted after AM registered. \"\n                 + \" AM should re-register.\";\n         throw new ApplicationMasterNotRegisteredException(message);\n       }\n \n       if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n         /* old heartbeat */\n         return lastResponse;\n       } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n         String message \u003d\n             \"Invalid responseId in AllocateRequest from application attempt: \"\n                 + appAttemptId + \", expect responseId to be \"\n                 + (lastResponse.getResponseId() + 1);\n         throw new InvalidApplicationMasterRequestException(message);\n       }\n \n-      AllocateResponse response \u003d this.amsProcessor.allocate(\n-          amrmTokenIdentifier.getApplicationAttemptId(), request);\n+      AllocateResponse response \u003d\n+          recordFactory.newRecordInstance(AllocateResponse.class);\n+      this.amsProcessingChain.allocate(\n+          amrmTokenIdentifier.getApplicationAttemptId(), request, response);\n \n       // update AMRMToken if the token is rolled-up\n       MasterKeyData nextMasterKey \u003d\n           this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n \n       if (nextMasterKey !\u003d null\n           \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n           .getKeyId()) {\n         RMApp app \u003d\n             this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n         RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n         RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n         Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n         if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n             appAttemptImpl.getAMRMTokenKeyId()) {\n           LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n               + \" to application: \" + appAttemptId.getApplicationId());\n           amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n               .createAndGetAMRMToken(appAttemptId);\n           appAttemptImpl.setAMRMToken(amrmToken);\n         }\n         response.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n             .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n                 .toString(), amrmToken.getPassword(), amrmToken.getService()\n                 .toString()));\n       }\n \n       /*\n        * As we are updating the response inside the lock object so we don\u0027t\n        * need to worry about unregister call occurring in between (which\n        * removes the lock object).\n        */\n       response.setResponseId(lastResponse.getResponseId() + 1);\n       lock.setAllocateResponse(response);\n       return response;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    AMRMTokenIdentifier amrmTokenIdentifier \u003d\n        YarnServerSecurityUtils.authorizeRequest();\n\n    ApplicationAttemptId appAttemptId \u003d\n        amrmTokenIdentifier.getApplicationAttemptId();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n    if (lock \u003d\u003d null) {\n      String message \u003d\n          \"Application attempt \" + appAttemptId\n              + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n      LOG.error(message);\n      throw new ApplicationAttemptNotFoundException(message);\n    }\n    synchronized (lock) {\n      AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n      if (!hasApplicationMasterRegistered(appAttemptId)) {\n        String message \u003d\n            \"AM is not registered for known application attempt: \"\n                + appAttemptId\n                + \" or RM had restarted after AM registered. \"\n                + \" AM should re-register.\";\n        throw new ApplicationMasterNotRegisteredException(message);\n      }\n\n      if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n        /* old heartbeat */\n        return lastResponse;\n      } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n        String message \u003d\n            \"Invalid responseId in AllocateRequest from application attempt: \"\n                + appAttemptId + \", expect responseId to be \"\n                + (lastResponse.getResponseId() + 1);\n        throw new InvalidApplicationMasterRequestException(message);\n      }\n\n      AllocateResponse response \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n      this.amsProcessingChain.allocate(\n          amrmTokenIdentifier.getApplicationAttemptId(), request, response);\n\n      // update AMRMToken if the token is rolled-up\n      MasterKeyData nextMasterKey \u003d\n          this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n\n      if (nextMasterKey !\u003d null\n          \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n          .getKeyId()) {\n        RMApp app \u003d\n            this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n        RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n        RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n        Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n        if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n            appAttemptImpl.getAMRMTokenKeyId()) {\n          LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n              + \" to application: \" + appAttemptId.getApplicationId());\n          amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n              .createAndGetAMRMToken(appAttemptId);\n          appAttemptImpl.setAMRMToken(amrmToken);\n        }\n        response.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n            .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n                .toString(), amrmToken.getPassword(), amrmToken.getService()\n                .toString()));\n      }\n\n      /*\n       * As we are updating the response inside the lock object so we don\u0027t\n       * need to worry about unregister call occurring in between (which\n       * removes the lock object).\n       */\n      response.setResponseId(lastResponse.getResponseId() + 1);\n      lock.setAllocateResponse(response);\n      return response;\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "5496a34c0cb2b1a83cfa6b0aba5a77b05ff2d8f0": {
      "type": "Ybodychange",
      "commitMessage": "YARN-6776. Refactor ApplicaitonMasterService to move actual processing logic to a separate class. (asuresh)\n",
      "commitDate": "10/07/17 2:34 PM",
      "commitName": "5496a34c0cb2b1a83cfa6b0aba5a77b05ff2d8f0",
      "commitAuthor": "Arun Suresh",
      "commitDateOld": "01/05/17 7:45 AM",
      "commitNameOld": "30fc5801966feb7f9bdd7d79db75acc595102913",
      "commitAuthorOld": "Naganarasimha",
      "daysBetweenCommits": 70.28,
      "commitsBetweenForRepo": 344,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,83 +1,81 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n     AMRMTokenIdentifier amrmTokenIdentifier \u003d\n         YarnServerSecurityUtils.authorizeRequest();\n \n     ApplicationAttemptId appAttemptId \u003d\n         amrmTokenIdentifier.getApplicationAttemptId();\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n     if (lock \u003d\u003d null) {\n       String message \u003d\n           \"Application attempt \" + appAttemptId\n               + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n       LOG.error(message);\n       throw new ApplicationAttemptNotFoundException(message);\n     }\n     synchronized (lock) {\n       AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n       if (!hasApplicationMasterRegistered(appAttemptId)) {\n         String message \u003d\n             \"AM is not registered for known application attempt: \"\n                 + appAttemptId\n                 + \" or RM had restarted after AM registered. \"\n                 + \" AM should re-register.\";\n         throw new ApplicationMasterNotRegisteredException(message);\n       }\n \n       if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n         /* old heartbeat */\n         return lastResponse;\n       } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n         String message \u003d\n             \"Invalid responseId in AllocateRequest from application attempt: \"\n                 + appAttemptId + \", expect responseId to be \"\n                 + (lastResponse.getResponseId() + 1);\n         throw new InvalidApplicationMasterRequestException(message);\n       }\n \n-      AllocateResponse response \u003d\n-          recordFactory.newRecordInstance(AllocateResponse.class);\n-      allocateInternal(amrmTokenIdentifier.getApplicationAttemptId(),\n-          request, response);\n+      AllocateResponse response \u003d this.amsProcessor.allocate(\n+          amrmTokenIdentifier.getApplicationAttemptId(), request);\n \n       // update AMRMToken if the token is rolled-up\n       MasterKeyData nextMasterKey \u003d\n           this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n \n       if (nextMasterKey !\u003d null\n           \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n           .getKeyId()) {\n         RMApp app \u003d\n             this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n         RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n         RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n         Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n         if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n             appAttemptImpl.getAMRMTokenKeyId()) {\n           LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n               + \" to application: \" + appAttemptId.getApplicationId());\n           amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n               .createAndGetAMRMToken(appAttemptId);\n           appAttemptImpl.setAMRMToken(amrmToken);\n         }\n         response.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n             .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n                 .toString(), amrmToken.getPassword(), amrmToken.getService()\n                 .toString()));\n       }\n \n       /*\n        * As we are updating the response inside the lock object so we don\u0027t\n        * need to worry about unregister call occurring in between (which\n        * removes the lock object).\n        */\n       response.setResponseId(lastResponse.getResponseId() + 1);\n       lock.setAllocateResponse(response);\n       return response;\n-    }    \n+    }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    AMRMTokenIdentifier amrmTokenIdentifier \u003d\n        YarnServerSecurityUtils.authorizeRequest();\n\n    ApplicationAttemptId appAttemptId \u003d\n        amrmTokenIdentifier.getApplicationAttemptId();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n    if (lock \u003d\u003d null) {\n      String message \u003d\n          \"Application attempt \" + appAttemptId\n              + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n      LOG.error(message);\n      throw new ApplicationAttemptNotFoundException(message);\n    }\n    synchronized (lock) {\n      AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n      if (!hasApplicationMasterRegistered(appAttemptId)) {\n        String message \u003d\n            \"AM is not registered for known application attempt: \"\n                + appAttemptId\n                + \" or RM had restarted after AM registered. \"\n                + \" AM should re-register.\";\n        throw new ApplicationMasterNotRegisteredException(message);\n      }\n\n      if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n        /* old heartbeat */\n        return lastResponse;\n      } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n        String message \u003d\n            \"Invalid responseId in AllocateRequest from application attempt: \"\n                + appAttemptId + \", expect responseId to be \"\n                + (lastResponse.getResponseId() + 1);\n        throw new InvalidApplicationMasterRequestException(message);\n      }\n\n      AllocateResponse response \u003d this.amsProcessor.allocate(\n          amrmTokenIdentifier.getApplicationAttemptId(), request);\n\n      // update AMRMToken if the token is rolled-up\n      MasterKeyData nextMasterKey \u003d\n          this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n\n      if (nextMasterKey !\u003d null\n          \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n          .getKeyId()) {\n        RMApp app \u003d\n            this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n        RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n        RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n        Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n        if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n            appAttemptImpl.getAMRMTokenKeyId()) {\n          LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n              + \" to application: \" + appAttemptId.getApplicationId());\n          amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n              .createAndGetAMRMToken(appAttemptId);\n          appAttemptImpl.setAMRMToken(amrmToken);\n        }\n        response.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n            .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n                .toString(), amrmToken.getPassword(), amrmToken.getService()\n                .toString()));\n      }\n\n      /*\n       * As we are updating the response inside the lock object so we don\u0027t\n       * need to worry about unregister call occurring in between (which\n       * removes the lock object).\n       */\n      response.setResponseId(lastResponse.getResponseId() + 1);\n      lock.setAllocateResponse(response);\n      return response;\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "ac1e5d4f77e3b9df8dcacb0b1f72eecc27931eb8": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5938. Refactoring OpportunisticContainerAllocator to use SchedulerRequestKey instead of Priority and other misc fixes (asuresh)\n",
      "commitDate": "27/12/16 12:40 PM",
      "commitName": "ac1e5d4f77e3b9df8dcacb0b1f72eecc27931eb8",
      "commitAuthor": "Arun Suresh",
      "commitDateOld": "22/11/16 1:19 AM",
      "commitNameOld": "a926f895c11cd69cf2117c3b970304f3f1f53d92",
      "commitAuthorOld": "Rohith Sharma K S",
      "daysBetweenCommits": 35.47,
      "commitsBetweenForRepo": 191,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,253 +1,83 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n     AMRMTokenIdentifier amrmTokenIdentifier \u003d\n         YarnServerSecurityUtils.authorizeRequest();\n \n     ApplicationAttemptId appAttemptId \u003d\n         amrmTokenIdentifier.getApplicationAttemptId();\n-    ApplicationId applicationId \u003d appAttemptId.getApplicationId();\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n     if (lock \u003d\u003d null) {\n       String message \u003d\n           \"Application attempt \" + appAttemptId\n               + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n       LOG.error(message);\n       throw new ApplicationAttemptNotFoundException(message);\n     }\n     synchronized (lock) {\n       AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n       if (!hasApplicationMasterRegistered(appAttemptId)) {\n         String message \u003d\n-            \"AM is not registered for known application attempt: \" + appAttemptId\n-                + \" or RM had restarted after AM registered . AM should re-register.\";\n+            \"AM is not registered for known application attempt: \"\n+                + appAttemptId\n+                + \" or RM had restarted after AM registered. \"\n+                + \" AM should re-register.\";\n         throw new ApplicationMasterNotRegisteredException(message);\n       }\n \n       if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n         /* old heartbeat */\n         return lastResponse;\n       } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n         String message \u003d\n             \"Invalid responseId in AllocateRequest from application attempt: \"\n                 + appAttemptId + \", expect responseId to be \"\n                 + (lastResponse.getResponseId() + 1);\n         throw new InvalidApplicationMasterRequestException(message);\n       }\n \n-      //filter illegal progress values\n-      float filteredProgress \u003d request.getProgress();\n-      if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n-        || filteredProgress \u003c 0) {\n-         request.setProgress(0);\n-      } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n-        request.setProgress(1);\n-      }\n-\n-      // Send the status update to the appAttempt.\n-      this.rmContext.getDispatcher().getEventHandler().handle(\n-          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n-              .getProgress()));\n-\n-      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n-      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n-\n-      ResourceBlacklistRequest blacklistRequest \u003d\n-          request.getResourceBlacklistRequest();\n-      List\u003cString\u003e blacklistAdditions \u003d\n-          (blacklistRequest !\u003d null) ?\n-              blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n-      List\u003cString\u003e blacklistRemovals \u003d\n-          (blacklistRequest !\u003d null) ?\n-              blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n-      RMApp app \u003d\n-          this.rmContext.getRMApps().get(applicationId);\n-      \n-      // set label expression for Resource Requests if resourceName\u003dANY \n-      ApplicationSubmissionContext asc \u003d app.getApplicationSubmissionContext();\n-      for (ResourceRequest req : ask) {\n-        if (null \u003d\u003d req.getNodeLabelExpression()\n-            \u0026\u0026 ResourceRequest.ANY.equals(req.getResourceName())) {\n-          req.setNodeLabelExpression(asc.getNodeLabelExpression());\n-        }\n-      }\n-      \n-      Resource maximumCapacity \u003d rScheduler.getMaximumResourceCapability();\n-              \n-      // sanity check\n-      try {\n-        RMServerUtils.normalizeAndValidateRequests(ask,\n-            maximumCapacity, app.getQueue(),\n-            rScheduler, rmContext);\n-      } catch (InvalidResourceRequestException e) {\n-        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n-        throw e;\n-      }\n-      \n-      try {\n-        RMServerUtils.validateBlacklistRequest(blacklistRequest);\n-      }  catch (InvalidResourceBlacklistRequestException e) {\n-        LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n-        throw e;\n-      }\n-\n-      // In the case of work-preserving AM restart, it\u0027s possible for the\n-      // AM to release containers from the earlier attempt.\n-      if (!app.getApplicationSubmissionContext()\n-        .getKeepContainersAcrossApplicationAttempts()) {\n-        try {\n-          RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n-        } catch (InvalidContainerReleaseException e) {\n-          LOG.warn(\"Invalid container release by application \" + appAttemptId,\n-              e);\n-          throw e;\n-        }\n-      }\n-\n-      // Split Update Resource Requests into increase and decrease.\n-      // No Exceptions are thrown here. All update errors are aggregated\n-      // and returned to the AM.\n-      List\u003cUpdateContainerRequest\u003e increaseResourceReqs \u003d new ArrayList\u003c\u003e();\n-      List\u003cUpdateContainerRequest\u003e decreaseResourceReqs \u003d new ArrayList\u003c\u003e();\n-      List\u003cUpdateContainerError\u003e updateContainerErrors \u003d\n-          RMServerUtils.validateAndSplitUpdateResourceRequests(rmContext,\n-              request, maximumCapacity, increaseResourceReqs,\n-              decreaseResourceReqs);\n-\n-      // Send new requests to appAttempt.\n-      Allocation allocation;\n-      RMAppAttemptState state \u003d\n-          app.getRMAppAttempt(appAttemptId).getAppAttemptState();\n-      if (state.equals(RMAppAttemptState.FINAL_SAVING) ||\n-          state.equals(RMAppAttemptState.FINISHING) ||\n-          app.isAppFinalStateStored()) {\n-        LOG.warn(appAttemptId + \" is in \" + state +\n-                 \" state, ignore container allocate request.\");\n-        allocation \u003d EMPTY_ALLOCATION;\n-      } else {\n-        allocation \u003d\n-            this.rScheduler.allocate(appAttemptId, ask, release,\n-                blacklistAdditions, blacklistRemovals,\n-                increaseResourceReqs, decreaseResourceReqs);\n-      }\n-\n-      if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n-        LOG.info(\"blacklist are updated in Scheduler.\" +\n-            \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n-            \"blacklistRemovals: \" + blacklistRemovals);\n-      }\n-      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n-      AllocateResponse allocateResponse \u003d\n+      AllocateResponse response \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n-      if (allocation.getNMTokens() !\u003d null \u0026\u0026\n-          !allocation.getNMTokens().isEmpty()) {\n-        allocateResponse.setNMTokens(allocation.getNMTokens());\n-      }\n-\n-      // Notify the AM of container update errors\n-      if (!updateContainerErrors.isEmpty()) {\n-        allocateResponse.setUpdateErrors(updateContainerErrors);\n-      }\n-      // update the response with the deltas of node status changes\n-      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n-      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n-        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n-        for(RMNode rmNode: updatedNodes) {\n-          SchedulerNodeReport schedulerNodeReport \u003d  \n-              rScheduler.getNodeReport(rmNode.getNodeID());\n-          Resource used \u003d BuilderUtils.newResource(0, 0);\n-          int numContainers \u003d 0;\n-          if (schedulerNodeReport !\u003d null) {\n-            used \u003d schedulerNodeReport.getUsedResource();\n-            numContainers \u003d schedulerNodeReport.getNumContainers();\n-          }\n-          NodeId nodeId \u003d rmNode.getNodeID();\n-          NodeReport report \u003d\n-              BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n-                  rmNode.getHttpAddress(), rmNode.getRackName(), used,\n-                  rmNode.getTotalCapability(), numContainers,\n-                  rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n-                  rmNode.getNodeLabels());\n-\n-          updatedNodeReports.add(report);\n-        }\n-        allocateResponse.setUpdatedNodes(updatedNodeReports);\n-      }\n-\n-      allocateResponse.setAllocatedContainers(allocation.getContainers());\n-      allocateResponse.setCompletedContainersStatuses(appAttempt\n-          .pullJustFinishedContainers());\n-      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n-      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n-      \n-      // Handling increased/decreased containers\n-      List\u003cUpdatedContainer\u003e updatedContainers \u003d new ArrayList\u003c\u003e();\n-      if (allocation.getIncreasedContainers() !\u003d null) {\n-        for (Container c : allocation.getIncreasedContainers()) {\n-          updatedContainers.add(\n-              UpdatedContainer.newInstance(\n-                  ContainerUpdateType.INCREASE_RESOURCE, c));\n-        }\n-      }\n-      if (allocation.getDecreasedContainers() !\u003d null) {\n-        for (Container c : allocation.getDecreasedContainers()) {\n-          updatedContainers.add(\n-              UpdatedContainer.newInstance(\n-                  ContainerUpdateType.DECREASE_RESOURCE, c));\n-        }\n-      }\n-\n-      allocateResponse.setUpdatedContainers(updatedContainers);\n-\n-      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n-\n-      // add collector address for this application\n-      if (YarnConfiguration.timelineServiceV2Enabled(getConfig())) {\n-        allocateResponse.setCollectorAddr(\n-            this.rmContext.getRMApps().get(applicationId).getCollectorAddr());\n-      }\n-\n-      // add preemption to the allocateResponse message (if any)\n-      allocateResponse\n-          .setPreemptionMessage(generatePreemptionMessage(allocation));\n-\n-      // Set application priority\n-      allocateResponse.setApplicationPriority(app\n-          .getApplicationPriority());\n+      allocateInternal(amrmTokenIdentifier.getApplicationAttemptId(),\n+          request, response);\n \n       // update AMRMToken if the token is rolled-up\n       MasterKeyData nextMasterKey \u003d\n           this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n \n       if (nextMasterKey !\u003d null\n           \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n-            .getKeyId()) {\n+          .getKeyId()) {\n+        RMApp app \u003d\n+            this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n+        RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n         RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n         Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n         if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n             appAttemptImpl.getAMRMTokenKeyId()) {\n           LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n-              + \" to application: \" + applicationId);\n+              + \" to application: \" + appAttemptId.getApplicationId());\n           amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n               .createAndGetAMRMToken(appAttemptId);\n           appAttemptImpl.setAMRMToken(amrmToken);\n         }\n-        allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n-          .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n-            .toString(), amrmToken.getPassword(), amrmToken.getService()\n-            .toString()));\n+        response.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n+            .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n+                .toString(), amrmToken.getPassword(), amrmToken.getService()\n+                .toString()));\n       }\n \n       /*\n        * As we are updating the response inside the lock object so we don\u0027t\n        * need to worry about unregister call occurring in between (which\n        * removes the lock object).\n        */\n-      lock.setAllocateResponse(allocateResponse);\n-      return allocateResponse;\n+      response.setResponseId(lastResponse.getResponseId() + 1);\n+      lock.setAllocateResponse(response);\n+      return response;\n     }    \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    AMRMTokenIdentifier amrmTokenIdentifier \u003d\n        YarnServerSecurityUtils.authorizeRequest();\n\n    ApplicationAttemptId appAttemptId \u003d\n        amrmTokenIdentifier.getApplicationAttemptId();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n    if (lock \u003d\u003d null) {\n      String message \u003d\n          \"Application attempt \" + appAttemptId\n              + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n      LOG.error(message);\n      throw new ApplicationAttemptNotFoundException(message);\n    }\n    synchronized (lock) {\n      AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n      if (!hasApplicationMasterRegistered(appAttemptId)) {\n        String message \u003d\n            \"AM is not registered for known application attempt: \"\n                + appAttemptId\n                + \" or RM had restarted after AM registered. \"\n                + \" AM should re-register.\";\n        throw new ApplicationMasterNotRegisteredException(message);\n      }\n\n      if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n        /* old heartbeat */\n        return lastResponse;\n      } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n        String message \u003d\n            \"Invalid responseId in AllocateRequest from application attempt: \"\n                + appAttemptId + \", expect responseId to be \"\n                + (lastResponse.getResponseId() + 1);\n        throw new InvalidApplicationMasterRequestException(message);\n      }\n\n      AllocateResponse response \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n      allocateInternal(amrmTokenIdentifier.getApplicationAttemptId(),\n          request, response);\n\n      // update AMRMToken if the token is rolled-up\n      MasterKeyData nextMasterKey \u003d\n          this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n\n      if (nextMasterKey !\u003d null\n          \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n          .getKeyId()) {\n        RMApp app \u003d\n            this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n        RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n        RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n        Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n        if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n            appAttemptImpl.getAMRMTokenKeyId()) {\n          LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n              + \" to application: \" + appAttemptId.getApplicationId());\n          amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n              .createAndGetAMRMToken(appAttemptId);\n          appAttemptImpl.setAMRMToken(amrmToken);\n        }\n        response.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n            .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n                .toString(), amrmToken.getPassword(), amrmToken.getService()\n                .toString()));\n      }\n\n      /*\n       * As we are updating the response inside the lock object so we don\u0027t\n       * need to worry about unregister call occurring in between (which\n       * removes the lock object).\n       */\n      response.setResponseId(lastResponse.getResponseId() + 1);\n      lock.setAllocateResponse(response);\n      return response;\n    }    \n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "a926f895c11cd69cf2117c3b970304f3f1f53d92": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5865. Retrospect updateApplicationPriority api to handle state store exception in align with YARN-5611. Contributed by Sunil G.\n",
      "commitDate": "22/11/16 1:19 AM",
      "commitName": "a926f895c11cd69cf2117c3b970304f3f1f53d92",
      "commitAuthor": "Rohith Sharma K S",
      "commitDateOld": "09/11/16 12:11 AM",
      "commitNameOld": "283fa33febe043bd7b4fa87546be26c9c5a8f8b5",
      "commitAuthorOld": "Arun Suresh",
      "daysBetweenCommits": 13.05,
      "commitsBetweenForRepo": 78,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,253 +1,253 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n     AMRMTokenIdentifier amrmTokenIdentifier \u003d\n         YarnServerSecurityUtils.authorizeRequest();\n \n     ApplicationAttemptId appAttemptId \u003d\n         amrmTokenIdentifier.getApplicationAttemptId();\n     ApplicationId applicationId \u003d appAttemptId.getApplicationId();\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n     if (lock \u003d\u003d null) {\n       String message \u003d\n           \"Application attempt \" + appAttemptId\n               + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n       LOG.error(message);\n       throw new ApplicationAttemptNotFoundException(message);\n     }\n     synchronized (lock) {\n       AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n       if (!hasApplicationMasterRegistered(appAttemptId)) {\n         String message \u003d\n             \"AM is not registered for known application attempt: \" + appAttemptId\n                 + \" or RM had restarted after AM registered . AM should re-register.\";\n         throw new ApplicationMasterNotRegisteredException(message);\n       }\n \n       if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n         /* old heartbeat */\n         return lastResponse;\n       } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n         String message \u003d\n             \"Invalid responseId in AllocateRequest from application attempt: \"\n                 + appAttemptId + \", expect responseId to be \"\n                 + (lastResponse.getResponseId() + 1);\n         throw new InvalidApplicationMasterRequestException(message);\n       }\n \n       //filter illegal progress values\n       float filteredProgress \u003d request.getProgress();\n       if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n         || filteredProgress \u003c 0) {\n          request.setProgress(0);\n       } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n         request.setProgress(1);\n       }\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n       ResourceBlacklistRequest blacklistRequest \u003d\n           request.getResourceBlacklistRequest();\n       List\u003cString\u003e blacklistAdditions \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n       List\u003cString\u003e blacklistRemovals \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n       RMApp app \u003d\n           this.rmContext.getRMApps().get(applicationId);\n       \n       // set label expression for Resource Requests if resourceName\u003dANY \n       ApplicationSubmissionContext asc \u003d app.getApplicationSubmissionContext();\n       for (ResourceRequest req : ask) {\n         if (null \u003d\u003d req.getNodeLabelExpression()\n             \u0026\u0026 ResourceRequest.ANY.equals(req.getResourceName())) {\n           req.setNodeLabelExpression(asc.getNodeLabelExpression());\n         }\n       }\n       \n       Resource maximumCapacity \u003d rScheduler.getMaximumResourceCapability();\n               \n       // sanity check\n       try {\n         RMServerUtils.normalizeAndValidateRequests(ask,\n             maximumCapacity, app.getQueue(),\n             rScheduler, rmContext);\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       try {\n         RMServerUtils.validateBlacklistRequest(blacklistRequest);\n       }  catch (InvalidResourceBlacklistRequestException e) {\n         LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n         throw e;\n       }\n \n       // In the case of work-preserving AM restart, it\u0027s possible for the\n       // AM to release containers from the earlier attempt.\n       if (!app.getApplicationSubmissionContext()\n         .getKeepContainersAcrossApplicationAttempts()) {\n         try {\n           RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n         } catch (InvalidContainerReleaseException e) {\n           LOG.warn(\"Invalid container release by application \" + appAttemptId,\n               e);\n           throw e;\n         }\n       }\n \n       // Split Update Resource Requests into increase and decrease.\n       // No Exceptions are thrown here. All update errors are aggregated\n       // and returned to the AM.\n       List\u003cUpdateContainerRequest\u003e increaseResourceReqs \u003d new ArrayList\u003c\u003e();\n       List\u003cUpdateContainerRequest\u003e decreaseResourceReqs \u003d new ArrayList\u003c\u003e();\n       List\u003cUpdateContainerError\u003e updateContainerErrors \u003d\n           RMServerUtils.validateAndSplitUpdateResourceRequests(rmContext,\n               request, maximumCapacity, increaseResourceReqs,\n               decreaseResourceReqs);\n \n       // Send new requests to appAttempt.\n       Allocation allocation;\n       RMAppAttemptState state \u003d\n           app.getRMAppAttempt(appAttemptId).getAppAttemptState();\n       if (state.equals(RMAppAttemptState.FINAL_SAVING) ||\n           state.equals(RMAppAttemptState.FINISHING) ||\n           app.isAppFinalStateStored()) {\n         LOG.warn(appAttemptId + \" is in \" + state +\n                  \" state, ignore container allocate request.\");\n         allocation \u003d EMPTY_ALLOCATION;\n       } else {\n         allocation \u003d\n             this.rScheduler.allocate(appAttemptId, ask, release,\n                 blacklistAdditions, blacklistRemovals,\n                 increaseResourceReqs, decreaseResourceReqs);\n       }\n \n       if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n         LOG.info(\"blacklist are updated in Scheduler.\" +\n             \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n             \"blacklistRemovals: \" + blacklistRemovals);\n       }\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n       if (allocation.getNMTokens() !\u003d null \u0026\u0026\n           !allocation.getNMTokens().isEmpty()) {\n         allocateResponse.setNMTokens(allocation.getNMTokens());\n       }\n \n       // Notify the AM of container update errors\n       if (!updateContainerErrors.isEmpty()) {\n         allocateResponse.setUpdateErrors(updateContainerErrors);\n       }\n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeId nodeId \u003d rmNode.getNodeID();\n           NodeReport report \u003d\n               BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n                   rmNode.getHttpAddress(), rmNode.getRackName(), used,\n                   rmNode.getTotalCapability(), numContainers,\n                   rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n                   rmNode.getNodeLabels());\n \n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n       \n       // Handling increased/decreased containers\n       List\u003cUpdatedContainer\u003e updatedContainers \u003d new ArrayList\u003c\u003e();\n       if (allocation.getIncreasedContainers() !\u003d null) {\n         for (Container c : allocation.getIncreasedContainers()) {\n           updatedContainers.add(\n               UpdatedContainer.newInstance(\n                   ContainerUpdateType.INCREASE_RESOURCE, c));\n         }\n       }\n       if (allocation.getDecreasedContainers() !\u003d null) {\n         for (Container c : allocation.getDecreasedContainers()) {\n           updatedContainers.add(\n               UpdatedContainer.newInstance(\n                   ContainerUpdateType.DECREASE_RESOURCE, c));\n         }\n       }\n \n       allocateResponse.setUpdatedContainers(updatedContainers);\n \n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n \n       // add collector address for this application\n       if (YarnConfiguration.timelineServiceV2Enabled(getConfig())) {\n         allocateResponse.setCollectorAddr(\n             this.rmContext.getRMApps().get(applicationId).getCollectorAddr());\n       }\n \n       // add preemption to the allocateResponse message (if any)\n       allocateResponse\n           .setPreemptionMessage(generatePreemptionMessage(allocation));\n \n       // Set application priority\n       allocateResponse.setApplicationPriority(app\n-          .getApplicationSubmissionContext().getPriority());\n+          .getApplicationPriority());\n \n       // update AMRMToken if the token is rolled-up\n       MasterKeyData nextMasterKey \u003d\n           this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n \n       if (nextMasterKey !\u003d null\n           \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n             .getKeyId()) {\n         RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n         Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n         if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n             appAttemptImpl.getAMRMTokenKeyId()) {\n           LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n               + \" to application: \" + applicationId);\n           amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n               .createAndGetAMRMToken(appAttemptId);\n           appAttemptImpl.setAMRMToken(amrmToken);\n         }\n         allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n           .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n             .toString(), amrmToken.getPassword(), amrmToken.getService()\n             .toString()));\n       }\n \n       /*\n        * As we are updating the response inside the lock object so we don\u0027t\n        * need to worry about unregister call occurring in between (which\n        * removes the lock object).\n        */\n       lock.setAllocateResponse(allocateResponse);\n       return allocateResponse;\n     }    \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    AMRMTokenIdentifier amrmTokenIdentifier \u003d\n        YarnServerSecurityUtils.authorizeRequest();\n\n    ApplicationAttemptId appAttemptId \u003d\n        amrmTokenIdentifier.getApplicationAttemptId();\n    ApplicationId applicationId \u003d appAttemptId.getApplicationId();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n    if (lock \u003d\u003d null) {\n      String message \u003d\n          \"Application attempt \" + appAttemptId\n              + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n      LOG.error(message);\n      throw new ApplicationAttemptNotFoundException(message);\n    }\n    synchronized (lock) {\n      AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n      if (!hasApplicationMasterRegistered(appAttemptId)) {\n        String message \u003d\n            \"AM is not registered for known application attempt: \" + appAttemptId\n                + \" or RM had restarted after AM registered . AM should re-register.\";\n        throw new ApplicationMasterNotRegisteredException(message);\n      }\n\n      if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n        /* old heartbeat */\n        return lastResponse;\n      } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n        String message \u003d\n            \"Invalid responseId in AllocateRequest from application attempt: \"\n                + appAttemptId + \", expect responseId to be \"\n                + (lastResponse.getResponseId() + 1);\n        throw new InvalidApplicationMasterRequestException(message);\n      }\n\n      //filter illegal progress values\n      float filteredProgress \u003d request.getProgress();\n      if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n        || filteredProgress \u003c 0) {\n         request.setProgress(0);\n      } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n        request.setProgress(1);\n      }\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      ResourceBlacklistRequest blacklistRequest \u003d\n          request.getResourceBlacklistRequest();\n      List\u003cString\u003e blacklistAdditions \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n      List\u003cString\u003e blacklistRemovals \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n      RMApp app \u003d\n          this.rmContext.getRMApps().get(applicationId);\n      \n      // set label expression for Resource Requests if resourceName\u003dANY \n      ApplicationSubmissionContext asc \u003d app.getApplicationSubmissionContext();\n      for (ResourceRequest req : ask) {\n        if (null \u003d\u003d req.getNodeLabelExpression()\n            \u0026\u0026 ResourceRequest.ANY.equals(req.getResourceName())) {\n          req.setNodeLabelExpression(asc.getNodeLabelExpression());\n        }\n      }\n      \n      Resource maximumCapacity \u003d rScheduler.getMaximumResourceCapability();\n              \n      // sanity check\n      try {\n        RMServerUtils.normalizeAndValidateRequests(ask,\n            maximumCapacity, app.getQueue(),\n            rScheduler, rmContext);\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      try {\n        RMServerUtils.validateBlacklistRequest(blacklistRequest);\n      }  catch (InvalidResourceBlacklistRequestException e) {\n        LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n        throw e;\n      }\n\n      // In the case of work-preserving AM restart, it\u0027s possible for the\n      // AM to release containers from the earlier attempt.\n      if (!app.getApplicationSubmissionContext()\n        .getKeepContainersAcrossApplicationAttempts()) {\n        try {\n          RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n        } catch (InvalidContainerReleaseException e) {\n          LOG.warn(\"Invalid container release by application \" + appAttemptId,\n              e);\n          throw e;\n        }\n      }\n\n      // Split Update Resource Requests into increase and decrease.\n      // No Exceptions are thrown here. All update errors are aggregated\n      // and returned to the AM.\n      List\u003cUpdateContainerRequest\u003e increaseResourceReqs \u003d new ArrayList\u003c\u003e();\n      List\u003cUpdateContainerRequest\u003e decreaseResourceReqs \u003d new ArrayList\u003c\u003e();\n      List\u003cUpdateContainerError\u003e updateContainerErrors \u003d\n          RMServerUtils.validateAndSplitUpdateResourceRequests(rmContext,\n              request, maximumCapacity, increaseResourceReqs,\n              decreaseResourceReqs);\n\n      // Send new requests to appAttempt.\n      Allocation allocation;\n      RMAppAttemptState state \u003d\n          app.getRMAppAttempt(appAttemptId).getAppAttemptState();\n      if (state.equals(RMAppAttemptState.FINAL_SAVING) ||\n          state.equals(RMAppAttemptState.FINISHING) ||\n          app.isAppFinalStateStored()) {\n        LOG.warn(appAttemptId + \" is in \" + state +\n                 \" state, ignore container allocate request.\");\n        allocation \u003d EMPTY_ALLOCATION;\n      } else {\n        allocation \u003d\n            this.rScheduler.allocate(appAttemptId, ask, release,\n                blacklistAdditions, blacklistRemovals,\n                increaseResourceReqs, decreaseResourceReqs);\n      }\n\n      if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n        LOG.info(\"blacklist are updated in Scheduler.\" +\n            \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n            \"blacklistRemovals: \" + blacklistRemovals);\n      }\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n      if (allocation.getNMTokens() !\u003d null \u0026\u0026\n          !allocation.getNMTokens().isEmpty()) {\n        allocateResponse.setNMTokens(allocation.getNMTokens());\n      }\n\n      // Notify the AM of container update errors\n      if (!updateContainerErrors.isEmpty()) {\n        allocateResponse.setUpdateErrors(updateContainerErrors);\n      }\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeId nodeId \u003d rmNode.getNodeID();\n          NodeReport report \u003d\n              BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n                  rmNode.getHttpAddress(), rmNode.getRackName(), used,\n                  rmNode.getTotalCapability(), numContainers,\n                  rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n                  rmNode.getNodeLabels());\n\n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n      \n      // Handling increased/decreased containers\n      List\u003cUpdatedContainer\u003e updatedContainers \u003d new ArrayList\u003c\u003e();\n      if (allocation.getIncreasedContainers() !\u003d null) {\n        for (Container c : allocation.getIncreasedContainers()) {\n          updatedContainers.add(\n              UpdatedContainer.newInstance(\n                  ContainerUpdateType.INCREASE_RESOURCE, c));\n        }\n      }\n      if (allocation.getDecreasedContainers() !\u003d null) {\n        for (Container c : allocation.getDecreasedContainers()) {\n          updatedContainers.add(\n              UpdatedContainer.newInstance(\n                  ContainerUpdateType.DECREASE_RESOURCE, c));\n        }\n      }\n\n      allocateResponse.setUpdatedContainers(updatedContainers);\n\n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n\n      // add collector address for this application\n      if (YarnConfiguration.timelineServiceV2Enabled(getConfig())) {\n        allocateResponse.setCollectorAddr(\n            this.rmContext.getRMApps().get(applicationId).getCollectorAddr());\n      }\n\n      // add preemption to the allocateResponse message (if any)\n      allocateResponse\n          .setPreemptionMessage(generatePreemptionMessage(allocation));\n\n      // Set application priority\n      allocateResponse.setApplicationPriority(app\n          .getApplicationPriority());\n\n      // update AMRMToken if the token is rolled-up\n      MasterKeyData nextMasterKey \u003d\n          this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n\n      if (nextMasterKey !\u003d null\n          \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n            .getKeyId()) {\n        RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n        Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n        if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n            appAttemptImpl.getAMRMTokenKeyId()) {\n          LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n              + \" to application: \" + applicationId);\n          amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n              .createAndGetAMRMToken(appAttemptId);\n          appAttemptImpl.setAMRMToken(amrmToken);\n        }\n        allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n          .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n            .toString(), amrmToken.getPassword(), amrmToken.getService()\n            .toString()));\n      }\n\n      /*\n       * As we are updating the response inside the lock object so we don\u0027t\n       * need to worry about unregister call occurring in between (which\n       * removes the lock object).\n       */\n      lock.setAllocateResponse(allocateResponse);\n      return allocateResponse;\n    }    \n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "283fa33febe043bd7b4fa87546be26c9c5a8f8b5": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5823. Update NMTokens in case of requests with only opportunistic containers. (Konstantinos Karanasos via asuresh)\n",
      "commitDate": "09/11/16 12:11 AM",
      "commitName": "283fa33febe043bd7b4fa87546be26c9c5a8f8b5",
      "commitAuthor": "Arun Suresh",
      "commitDateOld": "30/08/16 3:52 PM",
      "commitNameOld": "d6d9cff21b7b6141ed88359652cf22e8973c0661",
      "commitAuthorOld": "Arun Suresh",
      "daysBetweenCommits": 70.39,
      "commitsBetweenForRepo": 541,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,252 +1,253 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n     AMRMTokenIdentifier amrmTokenIdentifier \u003d\n         YarnServerSecurityUtils.authorizeRequest();\n \n     ApplicationAttemptId appAttemptId \u003d\n         amrmTokenIdentifier.getApplicationAttemptId();\n     ApplicationId applicationId \u003d appAttemptId.getApplicationId();\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n     if (lock \u003d\u003d null) {\n       String message \u003d\n           \"Application attempt \" + appAttemptId\n               + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n       LOG.error(message);\n       throw new ApplicationAttemptNotFoundException(message);\n     }\n     synchronized (lock) {\n       AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n       if (!hasApplicationMasterRegistered(appAttemptId)) {\n         String message \u003d\n             \"AM is not registered for known application attempt: \" + appAttemptId\n                 + \" or RM had restarted after AM registered . AM should re-register.\";\n         throw new ApplicationMasterNotRegisteredException(message);\n       }\n \n       if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n         /* old heartbeat */\n         return lastResponse;\n       } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n         String message \u003d\n             \"Invalid responseId in AllocateRequest from application attempt: \"\n                 + appAttemptId + \", expect responseId to be \"\n                 + (lastResponse.getResponseId() + 1);\n         throw new InvalidApplicationMasterRequestException(message);\n       }\n \n       //filter illegal progress values\n       float filteredProgress \u003d request.getProgress();\n       if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n         || filteredProgress \u003c 0) {\n          request.setProgress(0);\n       } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n         request.setProgress(1);\n       }\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n       ResourceBlacklistRequest blacklistRequest \u003d\n           request.getResourceBlacklistRequest();\n       List\u003cString\u003e blacklistAdditions \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n       List\u003cString\u003e blacklistRemovals \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n       RMApp app \u003d\n           this.rmContext.getRMApps().get(applicationId);\n       \n       // set label expression for Resource Requests if resourceName\u003dANY \n       ApplicationSubmissionContext asc \u003d app.getApplicationSubmissionContext();\n       for (ResourceRequest req : ask) {\n         if (null \u003d\u003d req.getNodeLabelExpression()\n             \u0026\u0026 ResourceRequest.ANY.equals(req.getResourceName())) {\n           req.setNodeLabelExpression(asc.getNodeLabelExpression());\n         }\n       }\n       \n       Resource maximumCapacity \u003d rScheduler.getMaximumResourceCapability();\n               \n       // sanity check\n       try {\n         RMServerUtils.normalizeAndValidateRequests(ask,\n             maximumCapacity, app.getQueue(),\n             rScheduler, rmContext);\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       try {\n         RMServerUtils.validateBlacklistRequest(blacklistRequest);\n       }  catch (InvalidResourceBlacklistRequestException e) {\n         LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n         throw e;\n       }\n \n       // In the case of work-preserving AM restart, it\u0027s possible for the\n       // AM to release containers from the earlier attempt.\n       if (!app.getApplicationSubmissionContext()\n         .getKeepContainersAcrossApplicationAttempts()) {\n         try {\n           RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n         } catch (InvalidContainerReleaseException e) {\n           LOG.warn(\"Invalid container release by application \" + appAttemptId,\n               e);\n           throw e;\n         }\n       }\n \n       // Split Update Resource Requests into increase and decrease.\n       // No Exceptions are thrown here. All update errors are aggregated\n       // and returned to the AM.\n       List\u003cUpdateContainerRequest\u003e increaseResourceReqs \u003d new ArrayList\u003c\u003e();\n       List\u003cUpdateContainerRequest\u003e decreaseResourceReqs \u003d new ArrayList\u003c\u003e();\n       List\u003cUpdateContainerError\u003e updateContainerErrors \u003d\n           RMServerUtils.validateAndSplitUpdateResourceRequests(rmContext,\n               request, maximumCapacity, increaseResourceReqs,\n               decreaseResourceReqs);\n \n       // Send new requests to appAttempt.\n       Allocation allocation;\n       RMAppAttemptState state \u003d\n           app.getRMAppAttempt(appAttemptId).getAppAttemptState();\n       if (state.equals(RMAppAttemptState.FINAL_SAVING) ||\n           state.equals(RMAppAttemptState.FINISHING) ||\n           app.isAppFinalStateStored()) {\n         LOG.warn(appAttemptId + \" is in \" + state +\n                  \" state, ignore container allocate request.\");\n         allocation \u003d EMPTY_ALLOCATION;\n       } else {\n         allocation \u003d\n             this.rScheduler.allocate(appAttemptId, ask, release,\n                 blacklistAdditions, blacklistRemovals,\n                 increaseResourceReqs, decreaseResourceReqs);\n       }\n \n       if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n         LOG.info(\"blacklist are updated in Scheduler.\" +\n             \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n             \"blacklistRemovals: \" + blacklistRemovals);\n       }\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n-      if (!allocation.getContainers().isEmpty()) {\n+      if (allocation.getNMTokens() !\u003d null \u0026\u0026\n+          !allocation.getNMTokens().isEmpty()) {\n         allocateResponse.setNMTokens(allocation.getNMTokens());\n       }\n \n       // Notify the AM of container update errors\n       if (!updateContainerErrors.isEmpty()) {\n         allocateResponse.setUpdateErrors(updateContainerErrors);\n       }\n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeId nodeId \u003d rmNode.getNodeID();\n           NodeReport report \u003d\n               BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n                   rmNode.getHttpAddress(), rmNode.getRackName(), used,\n                   rmNode.getTotalCapability(), numContainers,\n                   rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n                   rmNode.getNodeLabels());\n \n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n       \n       // Handling increased/decreased containers\n       List\u003cUpdatedContainer\u003e updatedContainers \u003d new ArrayList\u003c\u003e();\n       if (allocation.getIncreasedContainers() !\u003d null) {\n         for (Container c : allocation.getIncreasedContainers()) {\n           updatedContainers.add(\n               UpdatedContainer.newInstance(\n                   ContainerUpdateType.INCREASE_RESOURCE, c));\n         }\n       }\n       if (allocation.getDecreasedContainers() !\u003d null) {\n         for (Container c : allocation.getDecreasedContainers()) {\n           updatedContainers.add(\n               UpdatedContainer.newInstance(\n                   ContainerUpdateType.DECREASE_RESOURCE, c));\n         }\n       }\n \n       allocateResponse.setUpdatedContainers(updatedContainers);\n \n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n \n       // add collector address for this application\n       if (YarnConfiguration.timelineServiceV2Enabled(getConfig())) {\n         allocateResponse.setCollectorAddr(\n             this.rmContext.getRMApps().get(applicationId).getCollectorAddr());\n       }\n \n       // add preemption to the allocateResponse message (if any)\n       allocateResponse\n           .setPreemptionMessage(generatePreemptionMessage(allocation));\n \n       // Set application priority\n       allocateResponse.setApplicationPriority(app\n           .getApplicationSubmissionContext().getPriority());\n \n       // update AMRMToken if the token is rolled-up\n       MasterKeyData nextMasterKey \u003d\n           this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n \n       if (nextMasterKey !\u003d null\n           \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n             .getKeyId()) {\n         RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n         Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n         if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n             appAttemptImpl.getAMRMTokenKeyId()) {\n           LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n               + \" to application: \" + applicationId);\n           amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n               .createAndGetAMRMToken(appAttemptId);\n           appAttemptImpl.setAMRMToken(amrmToken);\n         }\n         allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n           .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n             .toString(), amrmToken.getPassword(), amrmToken.getService()\n             .toString()));\n       }\n \n       /*\n        * As we are updating the response inside the lock object so we don\u0027t\n        * need to worry about unregister call occurring in between (which\n        * removes the lock object).\n        */\n       lock.setAllocateResponse(allocateResponse);\n       return allocateResponse;\n     }    \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    AMRMTokenIdentifier amrmTokenIdentifier \u003d\n        YarnServerSecurityUtils.authorizeRequest();\n\n    ApplicationAttemptId appAttemptId \u003d\n        amrmTokenIdentifier.getApplicationAttemptId();\n    ApplicationId applicationId \u003d appAttemptId.getApplicationId();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n    if (lock \u003d\u003d null) {\n      String message \u003d\n          \"Application attempt \" + appAttemptId\n              + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n      LOG.error(message);\n      throw new ApplicationAttemptNotFoundException(message);\n    }\n    synchronized (lock) {\n      AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n      if (!hasApplicationMasterRegistered(appAttemptId)) {\n        String message \u003d\n            \"AM is not registered for known application attempt: \" + appAttemptId\n                + \" or RM had restarted after AM registered . AM should re-register.\";\n        throw new ApplicationMasterNotRegisteredException(message);\n      }\n\n      if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n        /* old heartbeat */\n        return lastResponse;\n      } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n        String message \u003d\n            \"Invalid responseId in AllocateRequest from application attempt: \"\n                + appAttemptId + \", expect responseId to be \"\n                + (lastResponse.getResponseId() + 1);\n        throw new InvalidApplicationMasterRequestException(message);\n      }\n\n      //filter illegal progress values\n      float filteredProgress \u003d request.getProgress();\n      if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n        || filteredProgress \u003c 0) {\n         request.setProgress(0);\n      } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n        request.setProgress(1);\n      }\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      ResourceBlacklistRequest blacklistRequest \u003d\n          request.getResourceBlacklistRequest();\n      List\u003cString\u003e blacklistAdditions \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n      List\u003cString\u003e blacklistRemovals \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n      RMApp app \u003d\n          this.rmContext.getRMApps().get(applicationId);\n      \n      // set label expression for Resource Requests if resourceName\u003dANY \n      ApplicationSubmissionContext asc \u003d app.getApplicationSubmissionContext();\n      for (ResourceRequest req : ask) {\n        if (null \u003d\u003d req.getNodeLabelExpression()\n            \u0026\u0026 ResourceRequest.ANY.equals(req.getResourceName())) {\n          req.setNodeLabelExpression(asc.getNodeLabelExpression());\n        }\n      }\n      \n      Resource maximumCapacity \u003d rScheduler.getMaximumResourceCapability();\n              \n      // sanity check\n      try {\n        RMServerUtils.normalizeAndValidateRequests(ask,\n            maximumCapacity, app.getQueue(),\n            rScheduler, rmContext);\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      try {\n        RMServerUtils.validateBlacklistRequest(blacklistRequest);\n      }  catch (InvalidResourceBlacklistRequestException e) {\n        LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n        throw e;\n      }\n\n      // In the case of work-preserving AM restart, it\u0027s possible for the\n      // AM to release containers from the earlier attempt.\n      if (!app.getApplicationSubmissionContext()\n        .getKeepContainersAcrossApplicationAttempts()) {\n        try {\n          RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n        } catch (InvalidContainerReleaseException e) {\n          LOG.warn(\"Invalid container release by application \" + appAttemptId,\n              e);\n          throw e;\n        }\n      }\n\n      // Split Update Resource Requests into increase and decrease.\n      // No Exceptions are thrown here. All update errors are aggregated\n      // and returned to the AM.\n      List\u003cUpdateContainerRequest\u003e increaseResourceReqs \u003d new ArrayList\u003c\u003e();\n      List\u003cUpdateContainerRequest\u003e decreaseResourceReqs \u003d new ArrayList\u003c\u003e();\n      List\u003cUpdateContainerError\u003e updateContainerErrors \u003d\n          RMServerUtils.validateAndSplitUpdateResourceRequests(rmContext,\n              request, maximumCapacity, increaseResourceReqs,\n              decreaseResourceReqs);\n\n      // Send new requests to appAttempt.\n      Allocation allocation;\n      RMAppAttemptState state \u003d\n          app.getRMAppAttempt(appAttemptId).getAppAttemptState();\n      if (state.equals(RMAppAttemptState.FINAL_SAVING) ||\n          state.equals(RMAppAttemptState.FINISHING) ||\n          app.isAppFinalStateStored()) {\n        LOG.warn(appAttemptId + \" is in \" + state +\n                 \" state, ignore container allocate request.\");\n        allocation \u003d EMPTY_ALLOCATION;\n      } else {\n        allocation \u003d\n            this.rScheduler.allocate(appAttemptId, ask, release,\n                blacklistAdditions, blacklistRemovals,\n                increaseResourceReqs, decreaseResourceReqs);\n      }\n\n      if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n        LOG.info(\"blacklist are updated in Scheduler.\" +\n            \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n            \"blacklistRemovals: \" + blacklistRemovals);\n      }\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n      if (allocation.getNMTokens() !\u003d null \u0026\u0026\n          !allocation.getNMTokens().isEmpty()) {\n        allocateResponse.setNMTokens(allocation.getNMTokens());\n      }\n\n      // Notify the AM of container update errors\n      if (!updateContainerErrors.isEmpty()) {\n        allocateResponse.setUpdateErrors(updateContainerErrors);\n      }\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeId nodeId \u003d rmNode.getNodeID();\n          NodeReport report \u003d\n              BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n                  rmNode.getHttpAddress(), rmNode.getRackName(), used,\n                  rmNode.getTotalCapability(), numContainers,\n                  rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n                  rmNode.getNodeLabels());\n\n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n      \n      // Handling increased/decreased containers\n      List\u003cUpdatedContainer\u003e updatedContainers \u003d new ArrayList\u003c\u003e();\n      if (allocation.getIncreasedContainers() !\u003d null) {\n        for (Container c : allocation.getIncreasedContainers()) {\n          updatedContainers.add(\n              UpdatedContainer.newInstance(\n                  ContainerUpdateType.INCREASE_RESOURCE, c));\n        }\n      }\n      if (allocation.getDecreasedContainers() !\u003d null) {\n        for (Container c : allocation.getDecreasedContainers()) {\n          updatedContainers.add(\n              UpdatedContainer.newInstance(\n                  ContainerUpdateType.DECREASE_RESOURCE, c));\n        }\n      }\n\n      allocateResponse.setUpdatedContainers(updatedContainers);\n\n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n\n      // add collector address for this application\n      if (YarnConfiguration.timelineServiceV2Enabled(getConfig())) {\n        allocateResponse.setCollectorAddr(\n            this.rmContext.getRMApps().get(applicationId).getCollectorAddr());\n      }\n\n      // add preemption to the allocateResponse message (if any)\n      allocateResponse\n          .setPreemptionMessage(generatePreemptionMessage(allocation));\n\n      // Set application priority\n      allocateResponse.setApplicationPriority(app\n          .getApplicationSubmissionContext().getPriority());\n\n      // update AMRMToken if the token is rolled-up\n      MasterKeyData nextMasterKey \u003d\n          this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n\n      if (nextMasterKey !\u003d null\n          \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n            .getKeyId()) {\n        RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n        Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n        if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n            appAttemptImpl.getAMRMTokenKeyId()) {\n          LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n              + \" to application: \" + applicationId);\n          amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n              .createAndGetAMRMToken(appAttemptId);\n          appAttemptImpl.setAMRMToken(amrmToken);\n        }\n        allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n          .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n            .toString(), amrmToken.getPassword(), amrmToken.getService()\n            .toString()));\n      }\n\n      /*\n       * As we are updating the response inside the lock object so we don\u0027t\n       * need to worry about unregister call occurring in between (which\n       * removes the lock object).\n       */\n      lock.setAllocateResponse(allocateResponse);\n      return allocateResponse;\n    }    \n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "d6d9cff21b7b6141ed88359652cf22e8973c0661": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5221. Expose UpdateResourceRequest API to allow AM to request for change in container properties. (asuresh)\n",
      "commitDate": "30/08/16 3:52 PM",
      "commitName": "d6d9cff21b7b6141ed88359652cf22e8973c0661",
      "commitAuthor": "Arun Suresh",
      "commitDateOld": "10/07/16 8:45 AM",
      "commitNameOld": "89e5c44f9e891a3579384c3fa3766937cd4970f1",
      "commitAuthorOld": "Li Lu",
      "daysBetweenCommits": 51.3,
      "commitsBetweenForRepo": 414,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,231 +1,252 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n     AMRMTokenIdentifier amrmTokenIdentifier \u003d\n         YarnServerSecurityUtils.authorizeRequest();\n \n     ApplicationAttemptId appAttemptId \u003d\n         amrmTokenIdentifier.getApplicationAttemptId();\n     ApplicationId applicationId \u003d appAttemptId.getApplicationId();\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n     if (lock \u003d\u003d null) {\n       String message \u003d\n           \"Application attempt \" + appAttemptId\n               + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n       LOG.error(message);\n       throw new ApplicationAttemptNotFoundException(message);\n     }\n     synchronized (lock) {\n       AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n       if (!hasApplicationMasterRegistered(appAttemptId)) {\n         String message \u003d\n             \"AM is not registered for known application attempt: \" + appAttemptId\n                 + \" or RM had restarted after AM registered . AM should re-register.\";\n         throw new ApplicationMasterNotRegisteredException(message);\n       }\n \n       if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n         /* old heartbeat */\n         return lastResponse;\n       } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n         String message \u003d\n             \"Invalid responseId in AllocateRequest from application attempt: \"\n                 + appAttemptId + \", expect responseId to be \"\n                 + (lastResponse.getResponseId() + 1);\n         throw new InvalidApplicationMasterRequestException(message);\n       }\n \n       //filter illegal progress values\n       float filteredProgress \u003d request.getProgress();\n       if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n         || filteredProgress \u003c 0) {\n          request.setProgress(0);\n       } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n         request.setProgress(1);\n       }\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n       ResourceBlacklistRequest blacklistRequest \u003d\n           request.getResourceBlacklistRequest();\n       List\u003cString\u003e blacklistAdditions \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n       List\u003cString\u003e blacklistRemovals \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n       RMApp app \u003d\n           this.rmContext.getRMApps().get(applicationId);\n       \n       // set label expression for Resource Requests if resourceName\u003dANY \n       ApplicationSubmissionContext asc \u003d app.getApplicationSubmissionContext();\n       for (ResourceRequest req : ask) {\n         if (null \u003d\u003d req.getNodeLabelExpression()\n             \u0026\u0026 ResourceRequest.ANY.equals(req.getResourceName())) {\n           req.setNodeLabelExpression(asc.getNodeLabelExpression());\n         }\n       }\n       \n       Resource maximumCapacity \u003d rScheduler.getMaximumResourceCapability();\n               \n       // sanity check\n       try {\n         RMServerUtils.normalizeAndValidateRequests(ask,\n             maximumCapacity, app.getQueue(),\n             rScheduler, rmContext);\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       try {\n         RMServerUtils.validateBlacklistRequest(blacklistRequest);\n       }  catch (InvalidResourceBlacklistRequestException e) {\n         LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n         throw e;\n       }\n \n-      try {\n-        RMServerUtils.increaseDecreaseRequestSanityCheck(rmContext,\n-            request.getIncreaseRequests(), request.getDecreaseRequests(),\n-            maximumCapacity);\n-      } catch (InvalidResourceRequestException e) {\n-        LOG.warn(e);\n-        throw e;\n-      }\n-\n       // In the case of work-preserving AM restart, it\u0027s possible for the\n       // AM to release containers from the earlier attempt.\n       if (!app.getApplicationSubmissionContext()\n         .getKeepContainersAcrossApplicationAttempts()) {\n         try {\n           RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n         } catch (InvalidContainerReleaseException e) {\n-          LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n+          LOG.warn(\"Invalid container release by application \" + appAttemptId,\n+              e);\n           throw e;\n         }\n       }\n \n+      // Split Update Resource Requests into increase and decrease.\n+      // No Exceptions are thrown here. All update errors are aggregated\n+      // and returned to the AM.\n+      List\u003cUpdateContainerRequest\u003e increaseResourceReqs \u003d new ArrayList\u003c\u003e();\n+      List\u003cUpdateContainerRequest\u003e decreaseResourceReqs \u003d new ArrayList\u003c\u003e();\n+      List\u003cUpdateContainerError\u003e updateContainerErrors \u003d\n+          RMServerUtils.validateAndSplitUpdateResourceRequests(rmContext,\n+              request, maximumCapacity, increaseResourceReqs,\n+              decreaseResourceReqs);\n+\n       // Send new requests to appAttempt.\n       Allocation allocation;\n       RMAppAttemptState state \u003d\n           app.getRMAppAttempt(appAttemptId).getAppAttemptState();\n       if (state.equals(RMAppAttemptState.FINAL_SAVING) ||\n           state.equals(RMAppAttemptState.FINISHING) ||\n           app.isAppFinalStateStored()) {\n         LOG.warn(appAttemptId + \" is in \" + state +\n                  \" state, ignore container allocate request.\");\n         allocation \u003d EMPTY_ALLOCATION;\n       } else {\n         allocation \u003d\n             this.rScheduler.allocate(appAttemptId, ask, release,\n                 blacklistAdditions, blacklistRemovals,\n-                request.getIncreaseRequests(), request.getDecreaseRequests());\n+                increaseResourceReqs, decreaseResourceReqs);\n       }\n \n       if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n         LOG.info(\"blacklist are updated in Scheduler.\" +\n             \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n             \"blacklistRemovals: \" + blacklistRemovals);\n       }\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n       if (!allocation.getContainers().isEmpty()) {\n         allocateResponse.setNMTokens(allocation.getNMTokens());\n       }\n \n+      // Notify the AM of container update errors\n+      if (!updateContainerErrors.isEmpty()) {\n+        allocateResponse.setUpdateErrors(updateContainerErrors);\n+      }\n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeId nodeId \u003d rmNode.getNodeID();\n           NodeReport report \u003d\n               BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n                   rmNode.getHttpAddress(), rmNode.getRackName(), used,\n                   rmNode.getTotalCapability(), numContainers,\n                   rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n                   rmNode.getNodeLabels());\n \n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n       \n       // Handling increased/decreased containers\n-      allocateResponse.setIncreasedContainers(allocation.getIncreasedContainers());\n-      allocateResponse.setDecreasedContainers(allocation.getDecreasedContainers());\n+      List\u003cUpdatedContainer\u003e updatedContainers \u003d new ArrayList\u003c\u003e();\n+      if (allocation.getIncreasedContainers() !\u003d null) {\n+        for (Container c : allocation.getIncreasedContainers()) {\n+          updatedContainers.add(\n+              UpdatedContainer.newInstance(\n+                  ContainerUpdateType.INCREASE_RESOURCE, c));\n+        }\n+      }\n+      if (allocation.getDecreasedContainers() !\u003d null) {\n+        for (Container c : allocation.getDecreasedContainers()) {\n+          updatedContainers.add(\n+              UpdatedContainer.newInstance(\n+                  ContainerUpdateType.DECREASE_RESOURCE, c));\n+        }\n+      }\n+\n+      allocateResponse.setUpdatedContainers(updatedContainers);\n \n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n \n       // add collector address for this application\n       if (YarnConfiguration.timelineServiceV2Enabled(getConfig())) {\n         allocateResponse.setCollectorAddr(\n             this.rmContext.getRMApps().get(applicationId).getCollectorAddr());\n       }\n \n       // add preemption to the allocateResponse message (if any)\n       allocateResponse\n           .setPreemptionMessage(generatePreemptionMessage(allocation));\n \n       // Set application priority\n       allocateResponse.setApplicationPriority(app\n           .getApplicationSubmissionContext().getPriority());\n \n       // update AMRMToken if the token is rolled-up\n       MasterKeyData nextMasterKey \u003d\n           this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n \n       if (nextMasterKey !\u003d null\n           \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n             .getKeyId()) {\n         RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n         Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n         if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n             appAttemptImpl.getAMRMTokenKeyId()) {\n           LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n               + \" to application: \" + applicationId);\n           amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n               .createAndGetAMRMToken(appAttemptId);\n           appAttemptImpl.setAMRMToken(amrmToken);\n         }\n         allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n           .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n             .toString(), amrmToken.getPassword(), amrmToken.getService()\n             .toString()));\n       }\n \n       /*\n        * As we are updating the response inside the lock object so we don\u0027t\n        * need to worry about unregister call occurring in between (which\n        * removes the lock object).\n        */\n       lock.setAllocateResponse(allocateResponse);\n       return allocateResponse;\n     }    \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    AMRMTokenIdentifier amrmTokenIdentifier \u003d\n        YarnServerSecurityUtils.authorizeRequest();\n\n    ApplicationAttemptId appAttemptId \u003d\n        amrmTokenIdentifier.getApplicationAttemptId();\n    ApplicationId applicationId \u003d appAttemptId.getApplicationId();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n    if (lock \u003d\u003d null) {\n      String message \u003d\n          \"Application attempt \" + appAttemptId\n              + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n      LOG.error(message);\n      throw new ApplicationAttemptNotFoundException(message);\n    }\n    synchronized (lock) {\n      AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n      if (!hasApplicationMasterRegistered(appAttemptId)) {\n        String message \u003d\n            \"AM is not registered for known application attempt: \" + appAttemptId\n                + \" or RM had restarted after AM registered . AM should re-register.\";\n        throw new ApplicationMasterNotRegisteredException(message);\n      }\n\n      if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n        /* old heartbeat */\n        return lastResponse;\n      } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n        String message \u003d\n            \"Invalid responseId in AllocateRequest from application attempt: \"\n                + appAttemptId + \", expect responseId to be \"\n                + (lastResponse.getResponseId() + 1);\n        throw new InvalidApplicationMasterRequestException(message);\n      }\n\n      //filter illegal progress values\n      float filteredProgress \u003d request.getProgress();\n      if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n        || filteredProgress \u003c 0) {\n         request.setProgress(0);\n      } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n        request.setProgress(1);\n      }\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      ResourceBlacklistRequest blacklistRequest \u003d\n          request.getResourceBlacklistRequest();\n      List\u003cString\u003e blacklistAdditions \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n      List\u003cString\u003e blacklistRemovals \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n      RMApp app \u003d\n          this.rmContext.getRMApps().get(applicationId);\n      \n      // set label expression for Resource Requests if resourceName\u003dANY \n      ApplicationSubmissionContext asc \u003d app.getApplicationSubmissionContext();\n      for (ResourceRequest req : ask) {\n        if (null \u003d\u003d req.getNodeLabelExpression()\n            \u0026\u0026 ResourceRequest.ANY.equals(req.getResourceName())) {\n          req.setNodeLabelExpression(asc.getNodeLabelExpression());\n        }\n      }\n      \n      Resource maximumCapacity \u003d rScheduler.getMaximumResourceCapability();\n              \n      // sanity check\n      try {\n        RMServerUtils.normalizeAndValidateRequests(ask,\n            maximumCapacity, app.getQueue(),\n            rScheduler, rmContext);\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      try {\n        RMServerUtils.validateBlacklistRequest(blacklistRequest);\n      }  catch (InvalidResourceBlacklistRequestException e) {\n        LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n        throw e;\n      }\n\n      // In the case of work-preserving AM restart, it\u0027s possible for the\n      // AM to release containers from the earlier attempt.\n      if (!app.getApplicationSubmissionContext()\n        .getKeepContainersAcrossApplicationAttempts()) {\n        try {\n          RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n        } catch (InvalidContainerReleaseException e) {\n          LOG.warn(\"Invalid container release by application \" + appAttemptId,\n              e);\n          throw e;\n        }\n      }\n\n      // Split Update Resource Requests into increase and decrease.\n      // No Exceptions are thrown here. All update errors are aggregated\n      // and returned to the AM.\n      List\u003cUpdateContainerRequest\u003e increaseResourceReqs \u003d new ArrayList\u003c\u003e();\n      List\u003cUpdateContainerRequest\u003e decreaseResourceReqs \u003d new ArrayList\u003c\u003e();\n      List\u003cUpdateContainerError\u003e updateContainerErrors \u003d\n          RMServerUtils.validateAndSplitUpdateResourceRequests(rmContext,\n              request, maximumCapacity, increaseResourceReqs,\n              decreaseResourceReqs);\n\n      // Send new requests to appAttempt.\n      Allocation allocation;\n      RMAppAttemptState state \u003d\n          app.getRMAppAttempt(appAttemptId).getAppAttemptState();\n      if (state.equals(RMAppAttemptState.FINAL_SAVING) ||\n          state.equals(RMAppAttemptState.FINISHING) ||\n          app.isAppFinalStateStored()) {\n        LOG.warn(appAttemptId + \" is in \" + state +\n                 \" state, ignore container allocate request.\");\n        allocation \u003d EMPTY_ALLOCATION;\n      } else {\n        allocation \u003d\n            this.rScheduler.allocate(appAttemptId, ask, release,\n                blacklistAdditions, blacklistRemovals,\n                increaseResourceReqs, decreaseResourceReqs);\n      }\n\n      if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n        LOG.info(\"blacklist are updated in Scheduler.\" +\n            \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n            \"blacklistRemovals: \" + blacklistRemovals);\n      }\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n      if (!allocation.getContainers().isEmpty()) {\n        allocateResponse.setNMTokens(allocation.getNMTokens());\n      }\n\n      // Notify the AM of container update errors\n      if (!updateContainerErrors.isEmpty()) {\n        allocateResponse.setUpdateErrors(updateContainerErrors);\n      }\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeId nodeId \u003d rmNode.getNodeID();\n          NodeReport report \u003d\n              BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n                  rmNode.getHttpAddress(), rmNode.getRackName(), used,\n                  rmNode.getTotalCapability(), numContainers,\n                  rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n                  rmNode.getNodeLabels());\n\n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n      \n      // Handling increased/decreased containers\n      List\u003cUpdatedContainer\u003e updatedContainers \u003d new ArrayList\u003c\u003e();\n      if (allocation.getIncreasedContainers() !\u003d null) {\n        for (Container c : allocation.getIncreasedContainers()) {\n          updatedContainers.add(\n              UpdatedContainer.newInstance(\n                  ContainerUpdateType.INCREASE_RESOURCE, c));\n        }\n      }\n      if (allocation.getDecreasedContainers() !\u003d null) {\n        for (Container c : allocation.getDecreasedContainers()) {\n          updatedContainers.add(\n              UpdatedContainer.newInstance(\n                  ContainerUpdateType.DECREASE_RESOURCE, c));\n        }\n      }\n\n      allocateResponse.setUpdatedContainers(updatedContainers);\n\n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n\n      // add collector address for this application\n      if (YarnConfiguration.timelineServiceV2Enabled(getConfig())) {\n        allocateResponse.setCollectorAddr(\n            this.rmContext.getRMApps().get(applicationId).getCollectorAddr());\n      }\n\n      // add preemption to the allocateResponse message (if any)\n      allocateResponse\n          .setPreemptionMessage(generatePreemptionMessage(allocation));\n\n      // Set application priority\n      allocateResponse.setApplicationPriority(app\n          .getApplicationSubmissionContext().getPriority());\n\n      // update AMRMToken if the token is rolled-up\n      MasterKeyData nextMasterKey \u003d\n          this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n\n      if (nextMasterKey !\u003d null\n          \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n            .getKeyId()) {\n        RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n        Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n        if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n            appAttemptImpl.getAMRMTokenKeyId()) {\n          LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n              + \" to application: \" + applicationId);\n          amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n              .createAndGetAMRMToken(appAttemptId);\n          appAttemptImpl.setAMRMToken(amrmToken);\n        }\n        allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n          .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n            .toString(), amrmToken.getPassword(), amrmToken.getService()\n            .toString()));\n      }\n\n      /*\n       * As we are updating the response inside the lock object so we don\u0027t\n       * need to worry about unregister call occurring in between (which\n       * removes the lock object).\n       */\n      lock.setAllocateResponse(allocateResponse);\n      return allocateResponse;\n    }    \n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "89e5c44f9e891a3579384c3fa3766937cd4970f1": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4356. Ensure the timeline service v.2 is disabled cleanly and has no\nimpact when it\u0027s turned off. Contributed by Sangjin Lee.\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "89e5c44f9e891a3579384c3fa3766937cd4970f1",
      "commitAuthor": "Li Lu",
      "commitDateOld": "10/07/16 8:45 AM",
      "commitNameOld": "2188a07e5bea1da26bf679ca0ece26ab596d3438",
      "commitAuthorOld": "Junping Du",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 57,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,229 +1,231 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n     AMRMTokenIdentifier amrmTokenIdentifier \u003d\n         YarnServerSecurityUtils.authorizeRequest();\n \n     ApplicationAttemptId appAttemptId \u003d\n         amrmTokenIdentifier.getApplicationAttemptId();\n     ApplicationId applicationId \u003d appAttemptId.getApplicationId();\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n     if (lock \u003d\u003d null) {\n       String message \u003d\n           \"Application attempt \" + appAttemptId\n               + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n       LOG.error(message);\n       throw new ApplicationAttemptNotFoundException(message);\n     }\n     synchronized (lock) {\n       AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n       if (!hasApplicationMasterRegistered(appAttemptId)) {\n         String message \u003d\n             \"AM is not registered for known application attempt: \" + appAttemptId\n                 + \" or RM had restarted after AM registered . AM should re-register.\";\n         throw new ApplicationMasterNotRegisteredException(message);\n       }\n \n       if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n         /* old heartbeat */\n         return lastResponse;\n       } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n         String message \u003d\n             \"Invalid responseId in AllocateRequest from application attempt: \"\n                 + appAttemptId + \", expect responseId to be \"\n                 + (lastResponse.getResponseId() + 1);\n         throw new InvalidApplicationMasterRequestException(message);\n       }\n \n       //filter illegal progress values\n       float filteredProgress \u003d request.getProgress();\n       if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n         || filteredProgress \u003c 0) {\n          request.setProgress(0);\n       } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n         request.setProgress(1);\n       }\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n       ResourceBlacklistRequest blacklistRequest \u003d\n           request.getResourceBlacklistRequest();\n       List\u003cString\u003e blacklistAdditions \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n       List\u003cString\u003e blacklistRemovals \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n       RMApp app \u003d\n           this.rmContext.getRMApps().get(applicationId);\n       \n       // set label expression for Resource Requests if resourceName\u003dANY \n       ApplicationSubmissionContext asc \u003d app.getApplicationSubmissionContext();\n       for (ResourceRequest req : ask) {\n         if (null \u003d\u003d req.getNodeLabelExpression()\n             \u0026\u0026 ResourceRequest.ANY.equals(req.getResourceName())) {\n           req.setNodeLabelExpression(asc.getNodeLabelExpression());\n         }\n       }\n       \n       Resource maximumCapacity \u003d rScheduler.getMaximumResourceCapability();\n               \n       // sanity check\n       try {\n         RMServerUtils.normalizeAndValidateRequests(ask,\n             maximumCapacity, app.getQueue(),\n             rScheduler, rmContext);\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       try {\n         RMServerUtils.validateBlacklistRequest(blacklistRequest);\n       }  catch (InvalidResourceBlacklistRequestException e) {\n         LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n         throw e;\n       }\n \n       try {\n         RMServerUtils.increaseDecreaseRequestSanityCheck(rmContext,\n             request.getIncreaseRequests(), request.getDecreaseRequests(),\n             maximumCapacity);\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(e);\n         throw e;\n       }\n \n       // In the case of work-preserving AM restart, it\u0027s possible for the\n       // AM to release containers from the earlier attempt.\n       if (!app.getApplicationSubmissionContext()\n         .getKeepContainersAcrossApplicationAttempts()) {\n         try {\n           RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n         } catch (InvalidContainerReleaseException e) {\n           LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n           throw e;\n         }\n       }\n \n       // Send new requests to appAttempt.\n       Allocation allocation;\n       RMAppAttemptState state \u003d\n           app.getRMAppAttempt(appAttemptId).getAppAttemptState();\n       if (state.equals(RMAppAttemptState.FINAL_SAVING) ||\n           state.equals(RMAppAttemptState.FINISHING) ||\n           app.isAppFinalStateStored()) {\n         LOG.warn(appAttemptId + \" is in \" + state +\n                  \" state, ignore container allocate request.\");\n         allocation \u003d EMPTY_ALLOCATION;\n       } else {\n         allocation \u003d\n             this.rScheduler.allocate(appAttemptId, ask, release,\n                 blacklistAdditions, blacklistRemovals,\n                 request.getIncreaseRequests(), request.getDecreaseRequests());\n       }\n \n       if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n         LOG.info(\"blacklist are updated in Scheduler.\" +\n             \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n             \"blacklistRemovals: \" + blacklistRemovals);\n       }\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n       if (!allocation.getContainers().isEmpty()) {\n         allocateResponse.setNMTokens(allocation.getNMTokens());\n       }\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeId nodeId \u003d rmNode.getNodeID();\n           NodeReport report \u003d\n               BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n                   rmNode.getHttpAddress(), rmNode.getRackName(), used,\n                   rmNode.getTotalCapability(), numContainers,\n                   rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n                   rmNode.getNodeLabels());\n \n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n       \n       // Handling increased/decreased containers\n       allocateResponse.setIncreasedContainers(allocation.getIncreasedContainers());\n       allocateResponse.setDecreasedContainers(allocation.getDecreasedContainers());\n \n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n \n       // add collector address for this application\n-      allocateResponse.setCollectorAddr(\n-          this.rmContext.getRMApps().get(applicationId).getCollectorAddr());\n+      if (YarnConfiguration.timelineServiceV2Enabled(getConfig())) {\n+        allocateResponse.setCollectorAddr(\n+            this.rmContext.getRMApps().get(applicationId).getCollectorAddr());\n+      }\n \n       // add preemption to the allocateResponse message (if any)\n       allocateResponse\n           .setPreemptionMessage(generatePreemptionMessage(allocation));\n \n       // Set application priority\n       allocateResponse.setApplicationPriority(app\n           .getApplicationSubmissionContext().getPriority());\n \n       // update AMRMToken if the token is rolled-up\n       MasterKeyData nextMasterKey \u003d\n           this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n \n       if (nextMasterKey !\u003d null\n           \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n             .getKeyId()) {\n         RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n         Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n         if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n             appAttemptImpl.getAMRMTokenKeyId()) {\n           LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n               + \" to application: \" + applicationId);\n           amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n               .createAndGetAMRMToken(appAttemptId);\n           appAttemptImpl.setAMRMToken(amrmToken);\n         }\n         allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n           .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n             .toString(), amrmToken.getPassword(), amrmToken.getService()\n             .toString()));\n       }\n \n       /*\n        * As we are updating the response inside the lock object so we don\u0027t\n        * need to worry about unregister call occurring in between (which\n        * removes the lock object).\n        */\n       lock.setAllocateResponse(allocateResponse);\n       return allocateResponse;\n     }    \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    AMRMTokenIdentifier amrmTokenIdentifier \u003d\n        YarnServerSecurityUtils.authorizeRequest();\n\n    ApplicationAttemptId appAttemptId \u003d\n        amrmTokenIdentifier.getApplicationAttemptId();\n    ApplicationId applicationId \u003d appAttemptId.getApplicationId();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n    if (lock \u003d\u003d null) {\n      String message \u003d\n          \"Application attempt \" + appAttemptId\n              + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n      LOG.error(message);\n      throw new ApplicationAttemptNotFoundException(message);\n    }\n    synchronized (lock) {\n      AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n      if (!hasApplicationMasterRegistered(appAttemptId)) {\n        String message \u003d\n            \"AM is not registered for known application attempt: \" + appAttemptId\n                + \" or RM had restarted after AM registered . AM should re-register.\";\n        throw new ApplicationMasterNotRegisteredException(message);\n      }\n\n      if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n        /* old heartbeat */\n        return lastResponse;\n      } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n        String message \u003d\n            \"Invalid responseId in AllocateRequest from application attempt: \"\n                + appAttemptId + \", expect responseId to be \"\n                + (lastResponse.getResponseId() + 1);\n        throw new InvalidApplicationMasterRequestException(message);\n      }\n\n      //filter illegal progress values\n      float filteredProgress \u003d request.getProgress();\n      if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n        || filteredProgress \u003c 0) {\n         request.setProgress(0);\n      } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n        request.setProgress(1);\n      }\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      ResourceBlacklistRequest blacklistRequest \u003d\n          request.getResourceBlacklistRequest();\n      List\u003cString\u003e blacklistAdditions \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n      List\u003cString\u003e blacklistRemovals \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n      RMApp app \u003d\n          this.rmContext.getRMApps().get(applicationId);\n      \n      // set label expression for Resource Requests if resourceName\u003dANY \n      ApplicationSubmissionContext asc \u003d app.getApplicationSubmissionContext();\n      for (ResourceRequest req : ask) {\n        if (null \u003d\u003d req.getNodeLabelExpression()\n            \u0026\u0026 ResourceRequest.ANY.equals(req.getResourceName())) {\n          req.setNodeLabelExpression(asc.getNodeLabelExpression());\n        }\n      }\n      \n      Resource maximumCapacity \u003d rScheduler.getMaximumResourceCapability();\n              \n      // sanity check\n      try {\n        RMServerUtils.normalizeAndValidateRequests(ask,\n            maximumCapacity, app.getQueue(),\n            rScheduler, rmContext);\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      try {\n        RMServerUtils.validateBlacklistRequest(blacklistRequest);\n      }  catch (InvalidResourceBlacklistRequestException e) {\n        LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n        throw e;\n      }\n\n      try {\n        RMServerUtils.increaseDecreaseRequestSanityCheck(rmContext,\n            request.getIncreaseRequests(), request.getDecreaseRequests(),\n            maximumCapacity);\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(e);\n        throw e;\n      }\n\n      // In the case of work-preserving AM restart, it\u0027s possible for the\n      // AM to release containers from the earlier attempt.\n      if (!app.getApplicationSubmissionContext()\n        .getKeepContainersAcrossApplicationAttempts()) {\n        try {\n          RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n        } catch (InvalidContainerReleaseException e) {\n          LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n          throw e;\n        }\n      }\n\n      // Send new requests to appAttempt.\n      Allocation allocation;\n      RMAppAttemptState state \u003d\n          app.getRMAppAttempt(appAttemptId).getAppAttemptState();\n      if (state.equals(RMAppAttemptState.FINAL_SAVING) ||\n          state.equals(RMAppAttemptState.FINISHING) ||\n          app.isAppFinalStateStored()) {\n        LOG.warn(appAttemptId + \" is in \" + state +\n                 \" state, ignore container allocate request.\");\n        allocation \u003d EMPTY_ALLOCATION;\n      } else {\n        allocation \u003d\n            this.rScheduler.allocate(appAttemptId, ask, release,\n                blacklistAdditions, blacklistRemovals,\n                request.getIncreaseRequests(), request.getDecreaseRequests());\n      }\n\n      if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n        LOG.info(\"blacklist are updated in Scheduler.\" +\n            \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n            \"blacklistRemovals: \" + blacklistRemovals);\n      }\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n      if (!allocation.getContainers().isEmpty()) {\n        allocateResponse.setNMTokens(allocation.getNMTokens());\n      }\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeId nodeId \u003d rmNode.getNodeID();\n          NodeReport report \u003d\n              BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n                  rmNode.getHttpAddress(), rmNode.getRackName(), used,\n                  rmNode.getTotalCapability(), numContainers,\n                  rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n                  rmNode.getNodeLabels());\n\n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n      \n      // Handling increased/decreased containers\n      allocateResponse.setIncreasedContainers(allocation.getIncreasedContainers());\n      allocateResponse.setDecreasedContainers(allocation.getDecreasedContainers());\n\n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n\n      // add collector address for this application\n      if (YarnConfiguration.timelineServiceV2Enabled(getConfig())) {\n        allocateResponse.setCollectorAddr(\n            this.rmContext.getRMApps().get(applicationId).getCollectorAddr());\n      }\n\n      // add preemption to the allocateResponse message (if any)\n      allocateResponse\n          .setPreemptionMessage(generatePreemptionMessage(allocation));\n\n      // Set application priority\n      allocateResponse.setApplicationPriority(app\n          .getApplicationSubmissionContext().getPriority());\n\n      // update AMRMToken if the token is rolled-up\n      MasterKeyData nextMasterKey \u003d\n          this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n\n      if (nextMasterKey !\u003d null\n          \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n            .getKeyId()) {\n        RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n        Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n        if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n            appAttemptImpl.getAMRMTokenKeyId()) {\n          LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n              + \" to application: \" + applicationId);\n          amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n              .createAndGetAMRMToken(appAttemptId);\n          appAttemptImpl.setAMRMToken(amrmToken);\n        }\n        allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n          .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n            .toString(), amrmToken.getPassword(), amrmToken.getService()\n            .toString()));\n      }\n\n      /*\n       * As we are updating the response inside the lock object so we don\u0027t\n       * need to worry about unregister call occurring in between (which\n       * removes the lock object).\n       */\n      lock.setAllocateResponse(allocateResponse);\n      return allocateResponse;\n    }    \n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "2188a07e5bea1da26bf679ca0ece26ab596d3438": {
      "type": "Ybodychange",
      "commitMessage": "YARN-3333. Rename TimelineAggregator etc. to TimelineCollector. Contributed by Sangjin Lee\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "2188a07e5bea1da26bf679ca0ece26ab596d3438",
      "commitAuthor": "Junping Du",
      "commitDateOld": "10/07/16 8:45 AM",
      "commitNameOld": "9b5636408005676ae580f8d929f8e912c27828e7",
      "commitAuthorOld": "Zhijie Shen",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,229 +1,229 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n     AMRMTokenIdentifier amrmTokenIdentifier \u003d\n         YarnServerSecurityUtils.authorizeRequest();\n \n     ApplicationAttemptId appAttemptId \u003d\n         amrmTokenIdentifier.getApplicationAttemptId();\n     ApplicationId applicationId \u003d appAttemptId.getApplicationId();\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n     if (lock \u003d\u003d null) {\n       String message \u003d\n           \"Application attempt \" + appAttemptId\n               + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n       LOG.error(message);\n       throw new ApplicationAttemptNotFoundException(message);\n     }\n     synchronized (lock) {\n       AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n       if (!hasApplicationMasterRegistered(appAttemptId)) {\n         String message \u003d\n             \"AM is not registered for known application attempt: \" + appAttemptId\n                 + \" or RM had restarted after AM registered . AM should re-register.\";\n         throw new ApplicationMasterNotRegisteredException(message);\n       }\n \n       if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n         /* old heartbeat */\n         return lastResponse;\n       } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n         String message \u003d\n             \"Invalid responseId in AllocateRequest from application attempt: \"\n                 + appAttemptId + \", expect responseId to be \"\n                 + (lastResponse.getResponseId() + 1);\n         throw new InvalidApplicationMasterRequestException(message);\n       }\n \n       //filter illegal progress values\n       float filteredProgress \u003d request.getProgress();\n       if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n         || filteredProgress \u003c 0) {\n          request.setProgress(0);\n       } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n         request.setProgress(1);\n       }\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n       ResourceBlacklistRequest blacklistRequest \u003d\n           request.getResourceBlacklistRequest();\n       List\u003cString\u003e blacklistAdditions \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n       List\u003cString\u003e blacklistRemovals \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n       RMApp app \u003d\n           this.rmContext.getRMApps().get(applicationId);\n       \n       // set label expression for Resource Requests if resourceName\u003dANY \n       ApplicationSubmissionContext asc \u003d app.getApplicationSubmissionContext();\n       for (ResourceRequest req : ask) {\n         if (null \u003d\u003d req.getNodeLabelExpression()\n             \u0026\u0026 ResourceRequest.ANY.equals(req.getResourceName())) {\n           req.setNodeLabelExpression(asc.getNodeLabelExpression());\n         }\n       }\n       \n       Resource maximumCapacity \u003d rScheduler.getMaximumResourceCapability();\n               \n       // sanity check\n       try {\n         RMServerUtils.normalizeAndValidateRequests(ask,\n             maximumCapacity, app.getQueue(),\n             rScheduler, rmContext);\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       try {\n         RMServerUtils.validateBlacklistRequest(blacklistRequest);\n       }  catch (InvalidResourceBlacklistRequestException e) {\n         LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n         throw e;\n       }\n \n       try {\n         RMServerUtils.increaseDecreaseRequestSanityCheck(rmContext,\n             request.getIncreaseRequests(), request.getDecreaseRequests(),\n             maximumCapacity);\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(e);\n         throw e;\n       }\n \n       // In the case of work-preserving AM restart, it\u0027s possible for the\n       // AM to release containers from the earlier attempt.\n       if (!app.getApplicationSubmissionContext()\n         .getKeepContainersAcrossApplicationAttempts()) {\n         try {\n           RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n         } catch (InvalidContainerReleaseException e) {\n           LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n           throw e;\n         }\n       }\n \n       // Send new requests to appAttempt.\n       Allocation allocation;\n       RMAppAttemptState state \u003d\n           app.getRMAppAttempt(appAttemptId).getAppAttemptState();\n       if (state.equals(RMAppAttemptState.FINAL_SAVING) ||\n           state.equals(RMAppAttemptState.FINISHING) ||\n           app.isAppFinalStateStored()) {\n         LOG.warn(appAttemptId + \" is in \" + state +\n                  \" state, ignore container allocate request.\");\n         allocation \u003d EMPTY_ALLOCATION;\n       } else {\n         allocation \u003d\n             this.rScheduler.allocate(appAttemptId, ask, release,\n                 blacklistAdditions, blacklistRemovals,\n                 request.getIncreaseRequests(), request.getDecreaseRequests());\n       }\n \n       if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n         LOG.info(\"blacklist are updated in Scheduler.\" +\n             \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n             \"blacklistRemovals: \" + blacklistRemovals);\n       }\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n       if (!allocation.getContainers().isEmpty()) {\n         allocateResponse.setNMTokens(allocation.getNMTokens());\n       }\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeId nodeId \u003d rmNode.getNodeID();\n           NodeReport report \u003d\n               BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n                   rmNode.getHttpAddress(), rmNode.getRackName(), used,\n                   rmNode.getTotalCapability(), numContainers,\n                   rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n                   rmNode.getNodeLabels());\n \n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n       \n       // Handling increased/decreased containers\n       allocateResponse.setIncreasedContainers(allocation.getIncreasedContainers());\n       allocateResponse.setDecreasedContainers(allocation.getDecreasedContainers());\n \n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n-      \n-      // add aggregator address for this application\n-      allocateResponse.setAggregatorAddr(\n-          this.rmContext.getRMApps().get(applicationId).getAggregatorAddr());\n+\n+      // add collector address for this application\n+      allocateResponse.setCollectorAddr(\n+          this.rmContext.getRMApps().get(applicationId).getCollectorAddr());\n \n       // add preemption to the allocateResponse message (if any)\n       allocateResponse\n           .setPreemptionMessage(generatePreemptionMessage(allocation));\n \n       // Set application priority\n       allocateResponse.setApplicationPriority(app\n           .getApplicationSubmissionContext().getPriority());\n \n       // update AMRMToken if the token is rolled-up\n       MasterKeyData nextMasterKey \u003d\n           this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n \n       if (nextMasterKey !\u003d null\n           \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n             .getKeyId()) {\n         RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n         Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n         if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n             appAttemptImpl.getAMRMTokenKeyId()) {\n           LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n               + \" to application: \" + applicationId);\n           amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n               .createAndGetAMRMToken(appAttemptId);\n           appAttemptImpl.setAMRMToken(amrmToken);\n         }\n         allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n           .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n             .toString(), amrmToken.getPassword(), amrmToken.getService()\n             .toString()));\n       }\n \n       /*\n        * As we are updating the response inside the lock object so we don\u0027t\n        * need to worry about unregister call occurring in between (which\n        * removes the lock object).\n        */\n       lock.setAllocateResponse(allocateResponse);\n       return allocateResponse;\n     }    \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    AMRMTokenIdentifier amrmTokenIdentifier \u003d\n        YarnServerSecurityUtils.authorizeRequest();\n\n    ApplicationAttemptId appAttemptId \u003d\n        amrmTokenIdentifier.getApplicationAttemptId();\n    ApplicationId applicationId \u003d appAttemptId.getApplicationId();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n    if (lock \u003d\u003d null) {\n      String message \u003d\n          \"Application attempt \" + appAttemptId\n              + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n      LOG.error(message);\n      throw new ApplicationAttemptNotFoundException(message);\n    }\n    synchronized (lock) {\n      AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n      if (!hasApplicationMasterRegistered(appAttemptId)) {\n        String message \u003d\n            \"AM is not registered for known application attempt: \" + appAttemptId\n                + \" or RM had restarted after AM registered . AM should re-register.\";\n        throw new ApplicationMasterNotRegisteredException(message);\n      }\n\n      if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n        /* old heartbeat */\n        return lastResponse;\n      } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n        String message \u003d\n            \"Invalid responseId in AllocateRequest from application attempt: \"\n                + appAttemptId + \", expect responseId to be \"\n                + (lastResponse.getResponseId() + 1);\n        throw new InvalidApplicationMasterRequestException(message);\n      }\n\n      //filter illegal progress values\n      float filteredProgress \u003d request.getProgress();\n      if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n        || filteredProgress \u003c 0) {\n         request.setProgress(0);\n      } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n        request.setProgress(1);\n      }\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      ResourceBlacklistRequest blacklistRequest \u003d\n          request.getResourceBlacklistRequest();\n      List\u003cString\u003e blacklistAdditions \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n      List\u003cString\u003e blacklistRemovals \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n      RMApp app \u003d\n          this.rmContext.getRMApps().get(applicationId);\n      \n      // set label expression for Resource Requests if resourceName\u003dANY \n      ApplicationSubmissionContext asc \u003d app.getApplicationSubmissionContext();\n      for (ResourceRequest req : ask) {\n        if (null \u003d\u003d req.getNodeLabelExpression()\n            \u0026\u0026 ResourceRequest.ANY.equals(req.getResourceName())) {\n          req.setNodeLabelExpression(asc.getNodeLabelExpression());\n        }\n      }\n      \n      Resource maximumCapacity \u003d rScheduler.getMaximumResourceCapability();\n              \n      // sanity check\n      try {\n        RMServerUtils.normalizeAndValidateRequests(ask,\n            maximumCapacity, app.getQueue(),\n            rScheduler, rmContext);\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      try {\n        RMServerUtils.validateBlacklistRequest(blacklistRequest);\n      }  catch (InvalidResourceBlacklistRequestException e) {\n        LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n        throw e;\n      }\n\n      try {\n        RMServerUtils.increaseDecreaseRequestSanityCheck(rmContext,\n            request.getIncreaseRequests(), request.getDecreaseRequests(),\n            maximumCapacity);\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(e);\n        throw e;\n      }\n\n      // In the case of work-preserving AM restart, it\u0027s possible for the\n      // AM to release containers from the earlier attempt.\n      if (!app.getApplicationSubmissionContext()\n        .getKeepContainersAcrossApplicationAttempts()) {\n        try {\n          RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n        } catch (InvalidContainerReleaseException e) {\n          LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n          throw e;\n        }\n      }\n\n      // Send new requests to appAttempt.\n      Allocation allocation;\n      RMAppAttemptState state \u003d\n          app.getRMAppAttempt(appAttemptId).getAppAttemptState();\n      if (state.equals(RMAppAttemptState.FINAL_SAVING) ||\n          state.equals(RMAppAttemptState.FINISHING) ||\n          app.isAppFinalStateStored()) {\n        LOG.warn(appAttemptId + \" is in \" + state +\n                 \" state, ignore container allocate request.\");\n        allocation \u003d EMPTY_ALLOCATION;\n      } else {\n        allocation \u003d\n            this.rScheduler.allocate(appAttemptId, ask, release,\n                blacklistAdditions, blacklistRemovals,\n                request.getIncreaseRequests(), request.getDecreaseRequests());\n      }\n\n      if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n        LOG.info(\"blacklist are updated in Scheduler.\" +\n            \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n            \"blacklistRemovals: \" + blacklistRemovals);\n      }\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n      if (!allocation.getContainers().isEmpty()) {\n        allocateResponse.setNMTokens(allocation.getNMTokens());\n      }\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeId nodeId \u003d rmNode.getNodeID();\n          NodeReport report \u003d\n              BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n                  rmNode.getHttpAddress(), rmNode.getRackName(), used,\n                  rmNode.getTotalCapability(), numContainers,\n                  rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n                  rmNode.getNodeLabels());\n\n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n      \n      // Handling increased/decreased containers\n      allocateResponse.setIncreasedContainers(allocation.getIncreasedContainers());\n      allocateResponse.setDecreasedContainers(allocation.getDecreasedContainers());\n\n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n\n      // add collector address for this application\n      allocateResponse.setCollectorAddr(\n          this.rmContext.getRMApps().get(applicationId).getCollectorAddr());\n\n      // add preemption to the allocateResponse message (if any)\n      allocateResponse\n          .setPreemptionMessage(generatePreemptionMessage(allocation));\n\n      // Set application priority\n      allocateResponse.setApplicationPriority(app\n          .getApplicationSubmissionContext().getPriority());\n\n      // update AMRMToken if the token is rolled-up\n      MasterKeyData nextMasterKey \u003d\n          this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n\n      if (nextMasterKey !\u003d null\n          \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n            .getKeyId()) {\n        RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n        Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n        if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n            appAttemptImpl.getAMRMTokenKeyId()) {\n          LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n              + \" to application: \" + applicationId);\n          amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n              .createAndGetAMRMToken(appAttemptId);\n          appAttemptImpl.setAMRMToken(amrmToken);\n        }\n        allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n          .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n            .toString(), amrmToken.getPassword(), amrmToken.getService()\n            .toString()));\n      }\n\n      /*\n       * As we are updating the response inside the lock object so we don\u0027t\n       * need to worry about unregister call occurring in between (which\n       * removes the lock object).\n       */\n      lock.setAllocateResponse(allocateResponse);\n      return allocateResponse;\n    }    \n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "9b5636408005676ae580f8d929f8e912c27828e7": {
      "type": "Ybodychange",
      "commitMessage": "YARN-3039. Implemented the app-level timeline aggregator discovery service. Contributed by Junping Du.\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "9b5636408005676ae580f8d929f8e912c27828e7",
      "commitAuthor": "Zhijie Shen",
      "commitDateOld": "08/07/16 11:39 AM",
      "commitNameOld": "5252562edf1f65a9c5d502016df8bb92fbe78095",
      "commitAuthorOld": "Varun Saxena",
      "daysBetweenCommits": 1.88,
      "commitsBetweenForRepo": 15,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,225 +1,229 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n     AMRMTokenIdentifier amrmTokenIdentifier \u003d\n         YarnServerSecurityUtils.authorizeRequest();\n \n     ApplicationAttemptId appAttemptId \u003d\n         amrmTokenIdentifier.getApplicationAttemptId();\n     ApplicationId applicationId \u003d appAttemptId.getApplicationId();\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n     if (lock \u003d\u003d null) {\n       String message \u003d\n           \"Application attempt \" + appAttemptId\n               + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n       LOG.error(message);\n       throw new ApplicationAttemptNotFoundException(message);\n     }\n     synchronized (lock) {\n       AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n       if (!hasApplicationMasterRegistered(appAttemptId)) {\n         String message \u003d\n             \"AM is not registered for known application attempt: \" + appAttemptId\n                 + \" or RM had restarted after AM registered . AM should re-register.\";\n         throw new ApplicationMasterNotRegisteredException(message);\n       }\n \n       if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n         /* old heartbeat */\n         return lastResponse;\n       } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n         String message \u003d\n             \"Invalid responseId in AllocateRequest from application attempt: \"\n                 + appAttemptId + \", expect responseId to be \"\n                 + (lastResponse.getResponseId() + 1);\n         throw new InvalidApplicationMasterRequestException(message);\n       }\n \n       //filter illegal progress values\n       float filteredProgress \u003d request.getProgress();\n       if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n         || filteredProgress \u003c 0) {\n          request.setProgress(0);\n       } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n         request.setProgress(1);\n       }\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n       ResourceBlacklistRequest blacklistRequest \u003d\n           request.getResourceBlacklistRequest();\n       List\u003cString\u003e blacklistAdditions \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n       List\u003cString\u003e blacklistRemovals \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n       RMApp app \u003d\n           this.rmContext.getRMApps().get(applicationId);\n       \n       // set label expression for Resource Requests if resourceName\u003dANY \n       ApplicationSubmissionContext asc \u003d app.getApplicationSubmissionContext();\n       for (ResourceRequest req : ask) {\n         if (null \u003d\u003d req.getNodeLabelExpression()\n             \u0026\u0026 ResourceRequest.ANY.equals(req.getResourceName())) {\n           req.setNodeLabelExpression(asc.getNodeLabelExpression());\n         }\n       }\n       \n       Resource maximumCapacity \u003d rScheduler.getMaximumResourceCapability();\n               \n       // sanity check\n       try {\n         RMServerUtils.normalizeAndValidateRequests(ask,\n             maximumCapacity, app.getQueue(),\n             rScheduler, rmContext);\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       try {\n         RMServerUtils.validateBlacklistRequest(blacklistRequest);\n       }  catch (InvalidResourceBlacklistRequestException e) {\n         LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n         throw e;\n       }\n \n       try {\n         RMServerUtils.increaseDecreaseRequestSanityCheck(rmContext,\n             request.getIncreaseRequests(), request.getDecreaseRequests(),\n             maximumCapacity);\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(e);\n         throw e;\n       }\n \n       // In the case of work-preserving AM restart, it\u0027s possible for the\n       // AM to release containers from the earlier attempt.\n       if (!app.getApplicationSubmissionContext()\n         .getKeepContainersAcrossApplicationAttempts()) {\n         try {\n           RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n         } catch (InvalidContainerReleaseException e) {\n           LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n           throw e;\n         }\n       }\n \n       // Send new requests to appAttempt.\n       Allocation allocation;\n       RMAppAttemptState state \u003d\n           app.getRMAppAttempt(appAttemptId).getAppAttemptState();\n       if (state.equals(RMAppAttemptState.FINAL_SAVING) ||\n           state.equals(RMAppAttemptState.FINISHING) ||\n           app.isAppFinalStateStored()) {\n         LOG.warn(appAttemptId + \" is in \" + state +\n                  \" state, ignore container allocate request.\");\n         allocation \u003d EMPTY_ALLOCATION;\n       } else {\n         allocation \u003d\n             this.rScheduler.allocate(appAttemptId, ask, release,\n                 blacklistAdditions, blacklistRemovals,\n                 request.getIncreaseRequests(), request.getDecreaseRequests());\n       }\n \n       if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n         LOG.info(\"blacklist are updated in Scheduler.\" +\n             \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n             \"blacklistRemovals: \" + blacklistRemovals);\n       }\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n       if (!allocation.getContainers().isEmpty()) {\n         allocateResponse.setNMTokens(allocation.getNMTokens());\n       }\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeId nodeId \u003d rmNode.getNodeID();\n           NodeReport report \u003d\n               BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n                   rmNode.getHttpAddress(), rmNode.getRackName(), used,\n                   rmNode.getTotalCapability(), numContainers,\n                   rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n                   rmNode.getNodeLabels());\n \n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n       \n       // Handling increased/decreased containers\n       allocateResponse.setIncreasedContainers(allocation.getIncreasedContainers());\n       allocateResponse.setDecreasedContainers(allocation.getDecreasedContainers());\n \n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n+      \n+      // add aggregator address for this application\n+      allocateResponse.setAggregatorAddr(\n+          this.rmContext.getRMApps().get(applicationId).getAggregatorAddr());\n \n       // add preemption to the allocateResponse message (if any)\n       allocateResponse\n           .setPreemptionMessage(generatePreemptionMessage(allocation));\n \n       // Set application priority\n       allocateResponse.setApplicationPriority(app\n           .getApplicationSubmissionContext().getPriority());\n \n       // update AMRMToken if the token is rolled-up\n       MasterKeyData nextMasterKey \u003d\n           this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n \n       if (nextMasterKey !\u003d null\n           \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n             .getKeyId()) {\n         RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n         Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n         if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n             appAttemptImpl.getAMRMTokenKeyId()) {\n           LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n               + \" to application: \" + applicationId);\n           amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n               .createAndGetAMRMToken(appAttemptId);\n           appAttemptImpl.setAMRMToken(amrmToken);\n         }\n         allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n           .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n             .toString(), amrmToken.getPassword(), amrmToken.getService()\n             .toString()));\n       }\n \n       /*\n        * As we are updating the response inside the lock object so we don\u0027t\n        * need to worry about unregister call occurring in between (which\n        * removes the lock object).\n        */\n       lock.setAllocateResponse(allocateResponse);\n       return allocateResponse;\n     }    \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    AMRMTokenIdentifier amrmTokenIdentifier \u003d\n        YarnServerSecurityUtils.authorizeRequest();\n\n    ApplicationAttemptId appAttemptId \u003d\n        amrmTokenIdentifier.getApplicationAttemptId();\n    ApplicationId applicationId \u003d appAttemptId.getApplicationId();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n    if (lock \u003d\u003d null) {\n      String message \u003d\n          \"Application attempt \" + appAttemptId\n              + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n      LOG.error(message);\n      throw new ApplicationAttemptNotFoundException(message);\n    }\n    synchronized (lock) {\n      AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n      if (!hasApplicationMasterRegistered(appAttemptId)) {\n        String message \u003d\n            \"AM is not registered for known application attempt: \" + appAttemptId\n                + \" or RM had restarted after AM registered . AM should re-register.\";\n        throw new ApplicationMasterNotRegisteredException(message);\n      }\n\n      if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n        /* old heartbeat */\n        return lastResponse;\n      } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n        String message \u003d\n            \"Invalid responseId in AllocateRequest from application attempt: \"\n                + appAttemptId + \", expect responseId to be \"\n                + (lastResponse.getResponseId() + 1);\n        throw new InvalidApplicationMasterRequestException(message);\n      }\n\n      //filter illegal progress values\n      float filteredProgress \u003d request.getProgress();\n      if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n        || filteredProgress \u003c 0) {\n         request.setProgress(0);\n      } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n        request.setProgress(1);\n      }\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      ResourceBlacklistRequest blacklistRequest \u003d\n          request.getResourceBlacklistRequest();\n      List\u003cString\u003e blacklistAdditions \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n      List\u003cString\u003e blacklistRemovals \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n      RMApp app \u003d\n          this.rmContext.getRMApps().get(applicationId);\n      \n      // set label expression for Resource Requests if resourceName\u003dANY \n      ApplicationSubmissionContext asc \u003d app.getApplicationSubmissionContext();\n      for (ResourceRequest req : ask) {\n        if (null \u003d\u003d req.getNodeLabelExpression()\n            \u0026\u0026 ResourceRequest.ANY.equals(req.getResourceName())) {\n          req.setNodeLabelExpression(asc.getNodeLabelExpression());\n        }\n      }\n      \n      Resource maximumCapacity \u003d rScheduler.getMaximumResourceCapability();\n              \n      // sanity check\n      try {\n        RMServerUtils.normalizeAndValidateRequests(ask,\n            maximumCapacity, app.getQueue(),\n            rScheduler, rmContext);\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      try {\n        RMServerUtils.validateBlacklistRequest(blacklistRequest);\n      }  catch (InvalidResourceBlacklistRequestException e) {\n        LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n        throw e;\n      }\n\n      try {\n        RMServerUtils.increaseDecreaseRequestSanityCheck(rmContext,\n            request.getIncreaseRequests(), request.getDecreaseRequests(),\n            maximumCapacity);\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(e);\n        throw e;\n      }\n\n      // In the case of work-preserving AM restart, it\u0027s possible for the\n      // AM to release containers from the earlier attempt.\n      if (!app.getApplicationSubmissionContext()\n        .getKeepContainersAcrossApplicationAttempts()) {\n        try {\n          RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n        } catch (InvalidContainerReleaseException e) {\n          LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n          throw e;\n        }\n      }\n\n      // Send new requests to appAttempt.\n      Allocation allocation;\n      RMAppAttemptState state \u003d\n          app.getRMAppAttempt(appAttemptId).getAppAttemptState();\n      if (state.equals(RMAppAttemptState.FINAL_SAVING) ||\n          state.equals(RMAppAttemptState.FINISHING) ||\n          app.isAppFinalStateStored()) {\n        LOG.warn(appAttemptId + \" is in \" + state +\n                 \" state, ignore container allocate request.\");\n        allocation \u003d EMPTY_ALLOCATION;\n      } else {\n        allocation \u003d\n            this.rScheduler.allocate(appAttemptId, ask, release,\n                blacklistAdditions, blacklistRemovals,\n                request.getIncreaseRequests(), request.getDecreaseRequests());\n      }\n\n      if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n        LOG.info(\"blacklist are updated in Scheduler.\" +\n            \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n            \"blacklistRemovals: \" + blacklistRemovals);\n      }\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n      if (!allocation.getContainers().isEmpty()) {\n        allocateResponse.setNMTokens(allocation.getNMTokens());\n      }\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeId nodeId \u003d rmNode.getNodeID();\n          NodeReport report \u003d\n              BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n                  rmNode.getHttpAddress(), rmNode.getRackName(), used,\n                  rmNode.getTotalCapability(), numContainers,\n                  rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n                  rmNode.getNodeLabels());\n\n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n      \n      // Handling increased/decreased containers\n      allocateResponse.setIncreasedContainers(allocation.getIncreasedContainers());\n      allocateResponse.setDecreasedContainers(allocation.getDecreasedContainers());\n\n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n      \n      // add aggregator address for this application\n      allocateResponse.setAggregatorAddr(\n          this.rmContext.getRMApps().get(applicationId).getAggregatorAddr());\n\n      // add preemption to the allocateResponse message (if any)\n      allocateResponse\n          .setPreemptionMessage(generatePreemptionMessage(allocation));\n\n      // Set application priority\n      allocateResponse.setApplicationPriority(app\n          .getApplicationSubmissionContext().getPriority());\n\n      // update AMRMToken if the token is rolled-up\n      MasterKeyData nextMasterKey \u003d\n          this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n\n      if (nextMasterKey !\u003d null\n          \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n            .getKeyId()) {\n        RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n        Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n        if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n            appAttemptImpl.getAMRMTokenKeyId()) {\n          LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n              + \" to application: \" + applicationId);\n          amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n              .createAndGetAMRMToken(appAttemptId);\n          appAttemptImpl.setAMRMToken(amrmToken);\n        }\n        allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n          .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n            .toString(), amrmToken.getPassword(), amrmToken.getService()\n            .toString()));\n      }\n\n      /*\n       * As we are updating the response inside the lock object so we don\u0027t\n       * need to worry about unregister call occurring in between (which\n       * removes the lock object).\n       */\n      lock.setAllocateResponse(allocateResponse);\n      return allocateResponse;\n    }    \n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "5252562edf1f65a9c5d502016df8bb92fbe78095": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5297. Avoid printing a stack trace when recovering an app after the RM restarts. (Junping Du via Varun Saxena).\n",
      "commitDate": "08/07/16 11:39 AM",
      "commitName": "5252562edf1f65a9c5d502016df8bb92fbe78095",
      "commitAuthor": "Varun Saxena",
      "commitDateOld": "24/04/16 10:38 PM",
      "commitNameOld": "c282a08f3892e2e8ceb58e1e9a411062fbd1fb2b",
      "commitAuthorOld": "Arun Suresh",
      "daysBetweenCommits": 74.54,
      "commitsBetweenForRepo": 504,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,230 +1,225 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n     AMRMTokenIdentifier amrmTokenIdentifier \u003d\n         YarnServerSecurityUtils.authorizeRequest();\n \n     ApplicationAttemptId appAttemptId \u003d\n         amrmTokenIdentifier.getApplicationAttemptId();\n     ApplicationId applicationId \u003d appAttemptId.getApplicationId();\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n     if (lock \u003d\u003d null) {\n       String message \u003d\n           \"Application attempt \" + appAttemptId\n               + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n       LOG.error(message);\n       throw new ApplicationAttemptNotFoundException(message);\n     }\n     synchronized (lock) {\n       AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n       if (!hasApplicationMasterRegistered(appAttemptId)) {\n         String message \u003d\n             \"AM is not registered for known application attempt: \" + appAttemptId\n                 + \" or RM had restarted after AM registered . AM should re-register.\";\n-        LOG.info(message);\n-        RMAuditLogger.logFailure(\n-          this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n-            .getUser(), AuditConstants.AM_ALLOCATE, \"\",\n-          \"ApplicationMasterService\", message, applicationId, appAttemptId);\n         throw new ApplicationMasterNotRegisteredException(message);\n       }\n \n       if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n         /* old heartbeat */\n         return lastResponse;\n       } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n         String message \u003d\n             \"Invalid responseId in AllocateRequest from application attempt: \"\n                 + appAttemptId + \", expect responseId to be \"\n                 + (lastResponse.getResponseId() + 1);\n         throw new InvalidApplicationMasterRequestException(message);\n       }\n \n       //filter illegal progress values\n       float filteredProgress \u003d request.getProgress();\n       if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n         || filteredProgress \u003c 0) {\n          request.setProgress(0);\n       } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n         request.setProgress(1);\n       }\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n       ResourceBlacklistRequest blacklistRequest \u003d\n           request.getResourceBlacklistRequest();\n       List\u003cString\u003e blacklistAdditions \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n       List\u003cString\u003e blacklistRemovals \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n       RMApp app \u003d\n           this.rmContext.getRMApps().get(applicationId);\n       \n       // set label expression for Resource Requests if resourceName\u003dANY \n       ApplicationSubmissionContext asc \u003d app.getApplicationSubmissionContext();\n       for (ResourceRequest req : ask) {\n         if (null \u003d\u003d req.getNodeLabelExpression()\n             \u0026\u0026 ResourceRequest.ANY.equals(req.getResourceName())) {\n           req.setNodeLabelExpression(asc.getNodeLabelExpression());\n         }\n       }\n       \n       Resource maximumCapacity \u003d rScheduler.getMaximumResourceCapability();\n               \n       // sanity check\n       try {\n         RMServerUtils.normalizeAndValidateRequests(ask,\n             maximumCapacity, app.getQueue(),\n             rScheduler, rmContext);\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       try {\n         RMServerUtils.validateBlacklistRequest(blacklistRequest);\n       }  catch (InvalidResourceBlacklistRequestException e) {\n         LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n         throw e;\n       }\n \n       try {\n         RMServerUtils.increaseDecreaseRequestSanityCheck(rmContext,\n             request.getIncreaseRequests(), request.getDecreaseRequests(),\n             maximumCapacity);\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(e);\n         throw e;\n       }\n \n       // In the case of work-preserving AM restart, it\u0027s possible for the\n       // AM to release containers from the earlier attempt.\n       if (!app.getApplicationSubmissionContext()\n         .getKeepContainersAcrossApplicationAttempts()) {\n         try {\n           RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n         } catch (InvalidContainerReleaseException e) {\n           LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n           throw e;\n         }\n       }\n \n       // Send new requests to appAttempt.\n       Allocation allocation;\n       RMAppAttemptState state \u003d\n           app.getRMAppAttempt(appAttemptId).getAppAttemptState();\n       if (state.equals(RMAppAttemptState.FINAL_SAVING) ||\n           state.equals(RMAppAttemptState.FINISHING) ||\n           app.isAppFinalStateStored()) {\n         LOG.warn(appAttemptId + \" is in \" + state +\n                  \" state, ignore container allocate request.\");\n         allocation \u003d EMPTY_ALLOCATION;\n       } else {\n         allocation \u003d\n             this.rScheduler.allocate(appAttemptId, ask, release,\n                 blacklistAdditions, blacklistRemovals,\n                 request.getIncreaseRequests(), request.getDecreaseRequests());\n       }\n \n       if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n         LOG.info(\"blacklist are updated in Scheduler.\" +\n             \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n             \"blacklistRemovals: \" + blacklistRemovals);\n       }\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n       if (!allocation.getContainers().isEmpty()) {\n         allocateResponse.setNMTokens(allocation.getNMTokens());\n       }\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeId nodeId \u003d rmNode.getNodeID();\n           NodeReport report \u003d\n               BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n                   rmNode.getHttpAddress(), rmNode.getRackName(), used,\n                   rmNode.getTotalCapability(), numContainers,\n                   rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n                   rmNode.getNodeLabels());\n \n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n       \n       // Handling increased/decreased containers\n       allocateResponse.setIncreasedContainers(allocation.getIncreasedContainers());\n       allocateResponse.setDecreasedContainers(allocation.getDecreasedContainers());\n \n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n \n       // add preemption to the allocateResponse message (if any)\n       allocateResponse\n           .setPreemptionMessage(generatePreemptionMessage(allocation));\n \n       // Set application priority\n       allocateResponse.setApplicationPriority(app\n           .getApplicationSubmissionContext().getPriority());\n \n       // update AMRMToken if the token is rolled-up\n       MasterKeyData nextMasterKey \u003d\n           this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n \n       if (nextMasterKey !\u003d null\n           \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n             .getKeyId()) {\n         RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n         Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n         if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n             appAttemptImpl.getAMRMTokenKeyId()) {\n           LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n               + \" to application: \" + applicationId);\n           amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n               .createAndGetAMRMToken(appAttemptId);\n           appAttemptImpl.setAMRMToken(amrmToken);\n         }\n         allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n           .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n             .toString(), amrmToken.getPassword(), amrmToken.getService()\n             .toString()));\n       }\n \n       /*\n        * As we are updating the response inside the lock object so we don\u0027t\n        * need to worry about unregister call occurring in between (which\n        * removes the lock object).\n        */\n       lock.setAllocateResponse(allocateResponse);\n       return allocateResponse;\n     }    \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    AMRMTokenIdentifier amrmTokenIdentifier \u003d\n        YarnServerSecurityUtils.authorizeRequest();\n\n    ApplicationAttemptId appAttemptId \u003d\n        amrmTokenIdentifier.getApplicationAttemptId();\n    ApplicationId applicationId \u003d appAttemptId.getApplicationId();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n    if (lock \u003d\u003d null) {\n      String message \u003d\n          \"Application attempt \" + appAttemptId\n              + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n      LOG.error(message);\n      throw new ApplicationAttemptNotFoundException(message);\n    }\n    synchronized (lock) {\n      AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n      if (!hasApplicationMasterRegistered(appAttemptId)) {\n        String message \u003d\n            \"AM is not registered for known application attempt: \" + appAttemptId\n                + \" or RM had restarted after AM registered . AM should re-register.\";\n        throw new ApplicationMasterNotRegisteredException(message);\n      }\n\n      if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n        /* old heartbeat */\n        return lastResponse;\n      } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n        String message \u003d\n            \"Invalid responseId in AllocateRequest from application attempt: \"\n                + appAttemptId + \", expect responseId to be \"\n                + (lastResponse.getResponseId() + 1);\n        throw new InvalidApplicationMasterRequestException(message);\n      }\n\n      //filter illegal progress values\n      float filteredProgress \u003d request.getProgress();\n      if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n        || filteredProgress \u003c 0) {\n         request.setProgress(0);\n      } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n        request.setProgress(1);\n      }\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      ResourceBlacklistRequest blacklistRequest \u003d\n          request.getResourceBlacklistRequest();\n      List\u003cString\u003e blacklistAdditions \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n      List\u003cString\u003e blacklistRemovals \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n      RMApp app \u003d\n          this.rmContext.getRMApps().get(applicationId);\n      \n      // set label expression for Resource Requests if resourceName\u003dANY \n      ApplicationSubmissionContext asc \u003d app.getApplicationSubmissionContext();\n      for (ResourceRequest req : ask) {\n        if (null \u003d\u003d req.getNodeLabelExpression()\n            \u0026\u0026 ResourceRequest.ANY.equals(req.getResourceName())) {\n          req.setNodeLabelExpression(asc.getNodeLabelExpression());\n        }\n      }\n      \n      Resource maximumCapacity \u003d rScheduler.getMaximumResourceCapability();\n              \n      // sanity check\n      try {\n        RMServerUtils.normalizeAndValidateRequests(ask,\n            maximumCapacity, app.getQueue(),\n            rScheduler, rmContext);\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      try {\n        RMServerUtils.validateBlacklistRequest(blacklistRequest);\n      }  catch (InvalidResourceBlacklistRequestException e) {\n        LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n        throw e;\n      }\n\n      try {\n        RMServerUtils.increaseDecreaseRequestSanityCheck(rmContext,\n            request.getIncreaseRequests(), request.getDecreaseRequests(),\n            maximumCapacity);\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(e);\n        throw e;\n      }\n\n      // In the case of work-preserving AM restart, it\u0027s possible for the\n      // AM to release containers from the earlier attempt.\n      if (!app.getApplicationSubmissionContext()\n        .getKeepContainersAcrossApplicationAttempts()) {\n        try {\n          RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n        } catch (InvalidContainerReleaseException e) {\n          LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n          throw e;\n        }\n      }\n\n      // Send new requests to appAttempt.\n      Allocation allocation;\n      RMAppAttemptState state \u003d\n          app.getRMAppAttempt(appAttemptId).getAppAttemptState();\n      if (state.equals(RMAppAttemptState.FINAL_SAVING) ||\n          state.equals(RMAppAttemptState.FINISHING) ||\n          app.isAppFinalStateStored()) {\n        LOG.warn(appAttemptId + \" is in \" + state +\n                 \" state, ignore container allocate request.\");\n        allocation \u003d EMPTY_ALLOCATION;\n      } else {\n        allocation \u003d\n            this.rScheduler.allocate(appAttemptId, ask, release,\n                blacklistAdditions, blacklistRemovals,\n                request.getIncreaseRequests(), request.getDecreaseRequests());\n      }\n\n      if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n        LOG.info(\"blacklist are updated in Scheduler.\" +\n            \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n            \"blacklistRemovals: \" + blacklistRemovals);\n      }\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n      if (!allocation.getContainers().isEmpty()) {\n        allocateResponse.setNMTokens(allocation.getNMTokens());\n      }\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeId nodeId \u003d rmNode.getNodeID();\n          NodeReport report \u003d\n              BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n                  rmNode.getHttpAddress(), rmNode.getRackName(), used,\n                  rmNode.getTotalCapability(), numContainers,\n                  rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n                  rmNode.getNodeLabels());\n\n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n      \n      // Handling increased/decreased containers\n      allocateResponse.setIncreasedContainers(allocation.getIncreasedContainers());\n      allocateResponse.setDecreasedContainers(allocation.getDecreasedContainers());\n\n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n\n      // add preemption to the allocateResponse message (if any)\n      allocateResponse\n          .setPreemptionMessage(generatePreemptionMessage(allocation));\n\n      // Set application priority\n      allocateResponse.setApplicationPriority(app\n          .getApplicationSubmissionContext().getPriority());\n\n      // update AMRMToken if the token is rolled-up\n      MasterKeyData nextMasterKey \u003d\n          this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n\n      if (nextMasterKey !\u003d null\n          \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n            .getKeyId()) {\n        RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n        Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n        if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n            appAttemptImpl.getAMRMTokenKeyId()) {\n          LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n              + \" to application: \" + applicationId);\n          amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n              .createAndGetAMRMToken(appAttemptId);\n          appAttemptImpl.setAMRMToken(amrmToken);\n        }\n        allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n          .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n            .toString(), amrmToken.getPassword(), amrmToken.getService()\n            .toString()));\n      }\n\n      /*\n       * As we are updating the response inside the lock object so we don\u0027t\n       * need to worry about unregister call occurring in between (which\n       * removes the lock object).\n       */\n      lock.setAllocateResponse(allocateResponse);\n      return allocateResponse;\n    }    \n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "f9da5cdb2b2dd071fd60fc01ea1edf0f79c0819b": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4170. AM need to be notified with priority in AllocateResponse. Contributed by Sunil G\n",
      "commitDate": "16/10/15 3:26 PM",
      "commitName": "f9da5cdb2b2dd071fd60fc01ea1edf0f79c0819b",
      "commitAuthor": "Jian He",
      "commitDateOld": "23/09/15 1:29 PM",
      "commitNameOld": "89cab1ba5f0671f8ef30dbe7432079c18362b434",
      "commitAuthorOld": "Jian He",
      "daysBetweenCommits": 23.08,
      "commitsBetweenForRepo": 182,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,226 +1,230 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n     AMRMTokenIdentifier amrmTokenIdentifier \u003d\n         YarnServerSecurityUtils.authorizeRequest();\n \n     ApplicationAttemptId appAttemptId \u003d\n         amrmTokenIdentifier.getApplicationAttemptId();\n     ApplicationId applicationId \u003d appAttemptId.getApplicationId();\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n     if (lock \u003d\u003d null) {\n       String message \u003d\n           \"Application attempt \" + appAttemptId\n               + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n       LOG.error(message);\n       throw new ApplicationAttemptNotFoundException(message);\n     }\n     synchronized (lock) {\n       AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n       if (!hasApplicationMasterRegistered(appAttemptId)) {\n         String message \u003d\n             \"AM is not registered for known application attempt: \" + appAttemptId\n                 + \" or RM had restarted after AM registered . AM should re-register.\";\n         LOG.info(message);\n         RMAuditLogger.logFailure(\n           this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n             .getUser(), AuditConstants.AM_ALLOCATE, \"\",\n           \"ApplicationMasterService\", message, applicationId, appAttemptId);\n         throw new ApplicationMasterNotRegisteredException(message);\n       }\n \n       if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n         /* old heartbeat */\n         return lastResponse;\n       } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n         String message \u003d\n             \"Invalid responseId in AllocateRequest from application attempt: \"\n                 + appAttemptId + \", expect responseId to be \"\n                 + (lastResponse.getResponseId() + 1);\n         throw new InvalidApplicationMasterRequestException(message);\n       }\n \n       //filter illegal progress values\n       float filteredProgress \u003d request.getProgress();\n       if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n         || filteredProgress \u003c 0) {\n          request.setProgress(0);\n       } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n         request.setProgress(1);\n       }\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n       ResourceBlacklistRequest blacklistRequest \u003d\n           request.getResourceBlacklistRequest();\n       List\u003cString\u003e blacklistAdditions \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n       List\u003cString\u003e blacklistRemovals \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n       RMApp app \u003d\n           this.rmContext.getRMApps().get(applicationId);\n       \n       // set label expression for Resource Requests if resourceName\u003dANY \n       ApplicationSubmissionContext asc \u003d app.getApplicationSubmissionContext();\n       for (ResourceRequest req : ask) {\n         if (null \u003d\u003d req.getNodeLabelExpression()\n             \u0026\u0026 ResourceRequest.ANY.equals(req.getResourceName())) {\n           req.setNodeLabelExpression(asc.getNodeLabelExpression());\n         }\n       }\n       \n       Resource maximumCapacity \u003d rScheduler.getMaximumResourceCapability();\n               \n       // sanity check\n       try {\n         RMServerUtils.normalizeAndValidateRequests(ask,\n             maximumCapacity, app.getQueue(),\n             rScheduler, rmContext);\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       try {\n         RMServerUtils.validateBlacklistRequest(blacklistRequest);\n       }  catch (InvalidResourceBlacklistRequestException e) {\n         LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n         throw e;\n       }\n \n       try {\n         RMServerUtils.increaseDecreaseRequestSanityCheck(rmContext,\n             request.getIncreaseRequests(), request.getDecreaseRequests(),\n             maximumCapacity);\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(e);\n         throw e;\n       }\n \n       // In the case of work-preserving AM restart, it\u0027s possible for the\n       // AM to release containers from the earlier attempt.\n       if (!app.getApplicationSubmissionContext()\n         .getKeepContainersAcrossApplicationAttempts()) {\n         try {\n           RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n         } catch (InvalidContainerReleaseException e) {\n           LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n           throw e;\n         }\n       }\n \n       // Send new requests to appAttempt.\n       Allocation allocation;\n       RMAppAttemptState state \u003d\n           app.getRMAppAttempt(appAttemptId).getAppAttemptState();\n       if (state.equals(RMAppAttemptState.FINAL_SAVING) ||\n           state.equals(RMAppAttemptState.FINISHING) ||\n           app.isAppFinalStateStored()) {\n         LOG.warn(appAttemptId + \" is in \" + state +\n                  \" state, ignore container allocate request.\");\n         allocation \u003d EMPTY_ALLOCATION;\n       } else {\n         allocation \u003d\n             this.rScheduler.allocate(appAttemptId, ask, release,\n                 blacklistAdditions, blacklistRemovals,\n                 request.getIncreaseRequests(), request.getDecreaseRequests());\n       }\n \n       if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n         LOG.info(\"blacklist are updated in Scheduler.\" +\n             \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n             \"blacklistRemovals: \" + blacklistRemovals);\n       }\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n       if (!allocation.getContainers().isEmpty()) {\n         allocateResponse.setNMTokens(allocation.getNMTokens());\n       }\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeId nodeId \u003d rmNode.getNodeID();\n           NodeReport report \u003d\n               BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n                   rmNode.getHttpAddress(), rmNode.getRackName(), used,\n                   rmNode.getTotalCapability(), numContainers,\n                   rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n                   rmNode.getNodeLabels());\n \n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n       \n       // Handling increased/decreased containers\n       allocateResponse.setIncreasedContainers(allocation.getIncreasedContainers());\n       allocateResponse.setDecreasedContainers(allocation.getDecreasedContainers());\n \n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n \n       // add preemption to the allocateResponse message (if any)\n       allocateResponse\n           .setPreemptionMessage(generatePreemptionMessage(allocation));\n \n+      // Set application priority\n+      allocateResponse.setApplicationPriority(app\n+          .getApplicationSubmissionContext().getPriority());\n+\n       // update AMRMToken if the token is rolled-up\n       MasterKeyData nextMasterKey \u003d\n           this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n \n       if (nextMasterKey !\u003d null\n           \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n             .getKeyId()) {\n         RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n         Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n         if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n             appAttemptImpl.getAMRMTokenKeyId()) {\n           LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n               + \" to application: \" + applicationId);\n           amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n               .createAndGetAMRMToken(appAttemptId);\n           appAttemptImpl.setAMRMToken(amrmToken);\n         }\n         allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n           .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n             .toString(), amrmToken.getPassword(), amrmToken.getService()\n             .toString()));\n       }\n \n       /*\n        * As we are updating the response inside the lock object so we don\u0027t\n        * need to worry about unregister call occurring in between (which\n        * removes the lock object).\n        */\n       lock.setAllocateResponse(allocateResponse);\n       return allocateResponse;\n     }    \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    AMRMTokenIdentifier amrmTokenIdentifier \u003d\n        YarnServerSecurityUtils.authorizeRequest();\n\n    ApplicationAttemptId appAttemptId \u003d\n        amrmTokenIdentifier.getApplicationAttemptId();\n    ApplicationId applicationId \u003d appAttemptId.getApplicationId();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n    if (lock \u003d\u003d null) {\n      String message \u003d\n          \"Application attempt \" + appAttemptId\n              + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n      LOG.error(message);\n      throw new ApplicationAttemptNotFoundException(message);\n    }\n    synchronized (lock) {\n      AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n      if (!hasApplicationMasterRegistered(appAttemptId)) {\n        String message \u003d\n            \"AM is not registered for known application attempt: \" + appAttemptId\n                + \" or RM had restarted after AM registered . AM should re-register.\";\n        LOG.info(message);\n        RMAuditLogger.logFailure(\n          this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n            .getUser(), AuditConstants.AM_ALLOCATE, \"\",\n          \"ApplicationMasterService\", message, applicationId, appAttemptId);\n        throw new ApplicationMasterNotRegisteredException(message);\n      }\n\n      if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n        /* old heartbeat */\n        return lastResponse;\n      } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n        String message \u003d\n            \"Invalid responseId in AllocateRequest from application attempt: \"\n                + appAttemptId + \", expect responseId to be \"\n                + (lastResponse.getResponseId() + 1);\n        throw new InvalidApplicationMasterRequestException(message);\n      }\n\n      //filter illegal progress values\n      float filteredProgress \u003d request.getProgress();\n      if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n        || filteredProgress \u003c 0) {\n         request.setProgress(0);\n      } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n        request.setProgress(1);\n      }\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      ResourceBlacklistRequest blacklistRequest \u003d\n          request.getResourceBlacklistRequest();\n      List\u003cString\u003e blacklistAdditions \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n      List\u003cString\u003e blacklistRemovals \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n      RMApp app \u003d\n          this.rmContext.getRMApps().get(applicationId);\n      \n      // set label expression for Resource Requests if resourceName\u003dANY \n      ApplicationSubmissionContext asc \u003d app.getApplicationSubmissionContext();\n      for (ResourceRequest req : ask) {\n        if (null \u003d\u003d req.getNodeLabelExpression()\n            \u0026\u0026 ResourceRequest.ANY.equals(req.getResourceName())) {\n          req.setNodeLabelExpression(asc.getNodeLabelExpression());\n        }\n      }\n      \n      Resource maximumCapacity \u003d rScheduler.getMaximumResourceCapability();\n              \n      // sanity check\n      try {\n        RMServerUtils.normalizeAndValidateRequests(ask,\n            maximumCapacity, app.getQueue(),\n            rScheduler, rmContext);\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      try {\n        RMServerUtils.validateBlacklistRequest(blacklistRequest);\n      }  catch (InvalidResourceBlacklistRequestException e) {\n        LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n        throw e;\n      }\n\n      try {\n        RMServerUtils.increaseDecreaseRequestSanityCheck(rmContext,\n            request.getIncreaseRequests(), request.getDecreaseRequests(),\n            maximumCapacity);\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(e);\n        throw e;\n      }\n\n      // In the case of work-preserving AM restart, it\u0027s possible for the\n      // AM to release containers from the earlier attempt.\n      if (!app.getApplicationSubmissionContext()\n        .getKeepContainersAcrossApplicationAttempts()) {\n        try {\n          RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n        } catch (InvalidContainerReleaseException e) {\n          LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n          throw e;\n        }\n      }\n\n      // Send new requests to appAttempt.\n      Allocation allocation;\n      RMAppAttemptState state \u003d\n          app.getRMAppAttempt(appAttemptId).getAppAttemptState();\n      if (state.equals(RMAppAttemptState.FINAL_SAVING) ||\n          state.equals(RMAppAttemptState.FINISHING) ||\n          app.isAppFinalStateStored()) {\n        LOG.warn(appAttemptId + \" is in \" + state +\n                 \" state, ignore container allocate request.\");\n        allocation \u003d EMPTY_ALLOCATION;\n      } else {\n        allocation \u003d\n            this.rScheduler.allocate(appAttemptId, ask, release,\n                blacklistAdditions, blacklistRemovals,\n                request.getIncreaseRequests(), request.getDecreaseRequests());\n      }\n\n      if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n        LOG.info(\"blacklist are updated in Scheduler.\" +\n            \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n            \"blacklistRemovals: \" + blacklistRemovals);\n      }\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n      if (!allocation.getContainers().isEmpty()) {\n        allocateResponse.setNMTokens(allocation.getNMTokens());\n      }\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeId nodeId \u003d rmNode.getNodeID();\n          NodeReport report \u003d\n              BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n                  rmNode.getHttpAddress(), rmNode.getRackName(), used,\n                  rmNode.getTotalCapability(), numContainers,\n                  rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n                  rmNode.getNodeLabels());\n\n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n      \n      // Handling increased/decreased containers\n      allocateResponse.setIncreasedContainers(allocation.getIncreasedContainers());\n      allocateResponse.setDecreasedContainers(allocation.getDecreasedContainers());\n\n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n\n      // add preemption to the allocateResponse message (if any)\n      allocateResponse\n          .setPreemptionMessage(generatePreemptionMessage(allocation));\n\n      // Set application priority\n      allocateResponse.setApplicationPriority(app\n          .getApplicationSubmissionContext().getPriority());\n\n      // update AMRMToken if the token is rolled-up\n      MasterKeyData nextMasterKey \u003d\n          this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n\n      if (nextMasterKey !\u003d null\n          \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n            .getKeyId()) {\n        RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n        Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n        if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n            appAttemptImpl.getAMRMTokenKeyId()) {\n          LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n              + \" to application: \" + applicationId);\n          amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n              .createAndGetAMRMToken(appAttemptId);\n          appAttemptImpl.setAMRMToken(amrmToken);\n        }\n        allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n          .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n            .toString(), amrmToken.getPassword(), amrmToken.getService()\n            .toString()));\n      }\n\n      /*\n       * As we are updating the response inside the lock object so we don\u0027t\n       * need to worry about unregister call occurring in between (which\n       * removes the lock object).\n       */\n      lock.setAllocateResponse(allocateResponse);\n      return allocateResponse;\n    }    \n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "89cab1ba5f0671f8ef30dbe7432079c18362b434": {
      "type": "Ybodychange",
      "commitMessage": "YARN-1651. CapacityScheduler side changes to support container resize. Contributed by Wangda Tan\n",
      "commitDate": "23/09/15 1:29 PM",
      "commitName": "89cab1ba5f0671f8ef30dbe7432079c18362b434",
      "commitAuthor": "Jian He",
      "commitDateOld": "07/09/15 6:35 PM",
      "commitNameOld": "6f72f1e6003ab11679bebeb96f27f1f62b3b3e02",
      "commitAuthorOld": "Jian He",
      "daysBetweenCommits": 15.79,
      "commitsBetweenForRepo": 109,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,210 +1,226 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n     AMRMTokenIdentifier amrmTokenIdentifier \u003d\n         YarnServerSecurityUtils.authorizeRequest();\n \n     ApplicationAttemptId appAttemptId \u003d\n         amrmTokenIdentifier.getApplicationAttemptId();\n     ApplicationId applicationId \u003d appAttemptId.getApplicationId();\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n     if (lock \u003d\u003d null) {\n       String message \u003d\n           \"Application attempt \" + appAttemptId\n               + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n       LOG.error(message);\n       throw new ApplicationAttemptNotFoundException(message);\n     }\n     synchronized (lock) {\n       AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n       if (!hasApplicationMasterRegistered(appAttemptId)) {\n         String message \u003d\n             \"AM is not registered for known application attempt: \" + appAttemptId\n                 + \" or RM had restarted after AM registered . AM should re-register.\";\n         LOG.info(message);\n         RMAuditLogger.logFailure(\n           this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n             .getUser(), AuditConstants.AM_ALLOCATE, \"\",\n           \"ApplicationMasterService\", message, applicationId, appAttemptId);\n         throw new ApplicationMasterNotRegisteredException(message);\n       }\n \n       if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n         /* old heartbeat */\n         return lastResponse;\n       } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n         String message \u003d\n             \"Invalid responseId in AllocateRequest from application attempt: \"\n                 + appAttemptId + \", expect responseId to be \"\n                 + (lastResponse.getResponseId() + 1);\n         throw new InvalidApplicationMasterRequestException(message);\n       }\n \n       //filter illegal progress values\n       float filteredProgress \u003d request.getProgress();\n       if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n         || filteredProgress \u003c 0) {\n          request.setProgress(0);\n       } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n         request.setProgress(1);\n       }\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n       ResourceBlacklistRequest blacklistRequest \u003d\n           request.getResourceBlacklistRequest();\n       List\u003cString\u003e blacklistAdditions \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n       List\u003cString\u003e blacklistRemovals \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n       RMApp app \u003d\n           this.rmContext.getRMApps().get(applicationId);\n       \n       // set label expression for Resource Requests if resourceName\u003dANY \n       ApplicationSubmissionContext asc \u003d app.getApplicationSubmissionContext();\n       for (ResourceRequest req : ask) {\n         if (null \u003d\u003d req.getNodeLabelExpression()\n             \u0026\u0026 ResourceRequest.ANY.equals(req.getResourceName())) {\n           req.setNodeLabelExpression(asc.getNodeLabelExpression());\n         }\n       }\n+      \n+      Resource maximumCapacity \u003d rScheduler.getMaximumResourceCapability();\n               \n       // sanity check\n       try {\n         RMServerUtils.normalizeAndValidateRequests(ask,\n-            rScheduler.getMaximumResourceCapability(), app.getQueue(),\n+            maximumCapacity, app.getQueue(),\n             rScheduler, rmContext);\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       try {\n         RMServerUtils.validateBlacklistRequest(blacklistRequest);\n       }  catch (InvalidResourceBlacklistRequestException e) {\n         LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n         throw e;\n       }\n \n+      try {\n+        RMServerUtils.increaseDecreaseRequestSanityCheck(rmContext,\n+            request.getIncreaseRequests(), request.getDecreaseRequests(),\n+            maximumCapacity);\n+      } catch (InvalidResourceRequestException e) {\n+        LOG.warn(e);\n+        throw e;\n+      }\n+\n       // In the case of work-preserving AM restart, it\u0027s possible for the\n       // AM to release containers from the earlier attempt.\n       if (!app.getApplicationSubmissionContext()\n         .getKeepContainersAcrossApplicationAttempts()) {\n         try {\n           RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n         } catch (InvalidContainerReleaseException e) {\n           LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n           throw e;\n         }\n       }\n \n       // Send new requests to appAttempt.\n       Allocation allocation;\n       RMAppAttemptState state \u003d\n           app.getRMAppAttempt(appAttemptId).getAppAttemptState();\n       if (state.equals(RMAppAttemptState.FINAL_SAVING) ||\n           state.equals(RMAppAttemptState.FINISHING) ||\n           app.isAppFinalStateStored()) {\n         LOG.warn(appAttemptId + \" is in \" + state +\n                  \" state, ignore container allocate request.\");\n         allocation \u003d EMPTY_ALLOCATION;\n       } else {\n         allocation \u003d\n-          this.rScheduler.allocate(appAttemptId, ask, release,\n-              blacklistAdditions, blacklistRemovals);\n+            this.rScheduler.allocate(appAttemptId, ask, release,\n+                blacklistAdditions, blacklistRemovals,\n+                request.getIncreaseRequests(), request.getDecreaseRequests());\n       }\n \n       if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n         LOG.info(\"blacklist are updated in Scheduler.\" +\n             \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n             \"blacklistRemovals: \" + blacklistRemovals);\n       }\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n       if (!allocation.getContainers().isEmpty()) {\n         allocateResponse.setNMTokens(allocation.getNMTokens());\n       }\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeId nodeId \u003d rmNode.getNodeID();\n           NodeReport report \u003d\n               BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n                   rmNode.getHttpAddress(), rmNode.getRackName(), used,\n                   rmNode.getTotalCapability(), numContainers,\n                   rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n                   rmNode.getNodeLabels());\n \n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n+      \n+      // Handling increased/decreased containers\n+      allocateResponse.setIncreasedContainers(allocation.getIncreasedContainers());\n+      allocateResponse.setDecreasedContainers(allocation.getDecreasedContainers());\n \n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n \n       // add preemption to the allocateResponse message (if any)\n       allocateResponse\n           .setPreemptionMessage(generatePreemptionMessage(allocation));\n \n       // update AMRMToken if the token is rolled-up\n       MasterKeyData nextMasterKey \u003d\n           this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n \n       if (nextMasterKey !\u003d null\n           \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n             .getKeyId()) {\n         RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n         Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n         if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n             appAttemptImpl.getAMRMTokenKeyId()) {\n           LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n               + \" to application: \" + applicationId);\n           amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n               .createAndGetAMRMToken(appAttemptId);\n           appAttemptImpl.setAMRMToken(amrmToken);\n         }\n         allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n           .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n             .toString(), amrmToken.getPassword(), amrmToken.getService()\n             .toString()));\n       }\n \n       /*\n        * As we are updating the response inside the lock object so we don\u0027t\n        * need to worry about unregister call occurring in between (which\n        * removes the lock object).\n        */\n       lock.setAllocateResponse(allocateResponse);\n       return allocateResponse;\n     }    \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    AMRMTokenIdentifier amrmTokenIdentifier \u003d\n        YarnServerSecurityUtils.authorizeRequest();\n\n    ApplicationAttemptId appAttemptId \u003d\n        amrmTokenIdentifier.getApplicationAttemptId();\n    ApplicationId applicationId \u003d appAttemptId.getApplicationId();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n    if (lock \u003d\u003d null) {\n      String message \u003d\n          \"Application attempt \" + appAttemptId\n              + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n      LOG.error(message);\n      throw new ApplicationAttemptNotFoundException(message);\n    }\n    synchronized (lock) {\n      AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n      if (!hasApplicationMasterRegistered(appAttemptId)) {\n        String message \u003d\n            \"AM is not registered for known application attempt: \" + appAttemptId\n                + \" or RM had restarted after AM registered . AM should re-register.\";\n        LOG.info(message);\n        RMAuditLogger.logFailure(\n          this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n            .getUser(), AuditConstants.AM_ALLOCATE, \"\",\n          \"ApplicationMasterService\", message, applicationId, appAttemptId);\n        throw new ApplicationMasterNotRegisteredException(message);\n      }\n\n      if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n        /* old heartbeat */\n        return lastResponse;\n      } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n        String message \u003d\n            \"Invalid responseId in AllocateRequest from application attempt: \"\n                + appAttemptId + \", expect responseId to be \"\n                + (lastResponse.getResponseId() + 1);\n        throw new InvalidApplicationMasterRequestException(message);\n      }\n\n      //filter illegal progress values\n      float filteredProgress \u003d request.getProgress();\n      if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n        || filteredProgress \u003c 0) {\n         request.setProgress(0);\n      } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n        request.setProgress(1);\n      }\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      ResourceBlacklistRequest blacklistRequest \u003d\n          request.getResourceBlacklistRequest();\n      List\u003cString\u003e blacklistAdditions \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n      List\u003cString\u003e blacklistRemovals \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n      RMApp app \u003d\n          this.rmContext.getRMApps().get(applicationId);\n      \n      // set label expression for Resource Requests if resourceName\u003dANY \n      ApplicationSubmissionContext asc \u003d app.getApplicationSubmissionContext();\n      for (ResourceRequest req : ask) {\n        if (null \u003d\u003d req.getNodeLabelExpression()\n            \u0026\u0026 ResourceRequest.ANY.equals(req.getResourceName())) {\n          req.setNodeLabelExpression(asc.getNodeLabelExpression());\n        }\n      }\n      \n      Resource maximumCapacity \u003d rScheduler.getMaximumResourceCapability();\n              \n      // sanity check\n      try {\n        RMServerUtils.normalizeAndValidateRequests(ask,\n            maximumCapacity, app.getQueue(),\n            rScheduler, rmContext);\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      try {\n        RMServerUtils.validateBlacklistRequest(blacklistRequest);\n      }  catch (InvalidResourceBlacklistRequestException e) {\n        LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n        throw e;\n      }\n\n      try {\n        RMServerUtils.increaseDecreaseRequestSanityCheck(rmContext,\n            request.getIncreaseRequests(), request.getDecreaseRequests(),\n            maximumCapacity);\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(e);\n        throw e;\n      }\n\n      // In the case of work-preserving AM restart, it\u0027s possible for the\n      // AM to release containers from the earlier attempt.\n      if (!app.getApplicationSubmissionContext()\n        .getKeepContainersAcrossApplicationAttempts()) {\n        try {\n          RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n        } catch (InvalidContainerReleaseException e) {\n          LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n          throw e;\n        }\n      }\n\n      // Send new requests to appAttempt.\n      Allocation allocation;\n      RMAppAttemptState state \u003d\n          app.getRMAppAttempt(appAttemptId).getAppAttemptState();\n      if (state.equals(RMAppAttemptState.FINAL_SAVING) ||\n          state.equals(RMAppAttemptState.FINISHING) ||\n          app.isAppFinalStateStored()) {\n        LOG.warn(appAttemptId + \" is in \" + state +\n                 \" state, ignore container allocate request.\");\n        allocation \u003d EMPTY_ALLOCATION;\n      } else {\n        allocation \u003d\n            this.rScheduler.allocate(appAttemptId, ask, release,\n                blacklistAdditions, blacklistRemovals,\n                request.getIncreaseRequests(), request.getDecreaseRequests());\n      }\n\n      if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n        LOG.info(\"blacklist are updated in Scheduler.\" +\n            \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n            \"blacklistRemovals: \" + blacklistRemovals);\n      }\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n      if (!allocation.getContainers().isEmpty()) {\n        allocateResponse.setNMTokens(allocation.getNMTokens());\n      }\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeId nodeId \u003d rmNode.getNodeID();\n          NodeReport report \u003d\n              BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n                  rmNode.getHttpAddress(), rmNode.getRackName(), used,\n                  rmNode.getTotalCapability(), numContainers,\n                  rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n                  rmNode.getNodeLabels());\n\n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n      \n      // Handling increased/decreased containers\n      allocateResponse.setIncreasedContainers(allocation.getIncreasedContainers());\n      allocateResponse.setDecreasedContainers(allocation.getDecreasedContainers());\n\n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n\n      // add preemption to the allocateResponse message (if any)\n      allocateResponse\n          .setPreemptionMessage(generatePreemptionMessage(allocation));\n\n      // update AMRMToken if the token is rolled-up\n      MasterKeyData nextMasterKey \u003d\n          this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n\n      if (nextMasterKey !\u003d null\n          \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n            .getKeyId()) {\n        RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n        Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n        if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n            appAttemptImpl.getAMRMTokenKeyId()) {\n          LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n              + \" to application: \" + applicationId);\n          amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n              .createAndGetAMRMToken(appAttemptId);\n          appAttemptImpl.setAMRMToken(amrmToken);\n        }\n        allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n          .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n            .toString(), amrmToken.getPassword(), amrmToken.getService()\n            .toString()));\n      }\n\n      /*\n       * As we are updating the response inside the lock object so we don\u0027t\n       * need to worry about unregister call occurring in between (which\n       * removes the lock object).\n       */\n      lock.setAllocateResponse(allocateResponse);\n      return allocateResponse;\n    }    \n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "6f72f1e6003ab11679bebeb96f27f1f62b3b3e02": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2884. Added a proxy service in NM to proxy the the communication between AM and RM. Contributed by Kishore Chaliparambil\n",
      "commitDate": "07/09/15 6:35 PM",
      "commitName": "6f72f1e6003ab11679bebeb96f27f1f62b3b3e02",
      "commitAuthor": "Jian He",
      "commitDateOld": "20/08/15 10:21 PM",
      "commitNameOld": "22de7c1dca1be63d523de833163ae51bfe638a79",
      "commitAuthorOld": "Rohith Sharma K S",
      "daysBetweenCommits": 17.84,
      "commitsBetweenForRepo": 89,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,209 +1,210 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n-    AMRMTokenIdentifier amrmTokenIdentifier \u003d authorizeRequest();\n+    AMRMTokenIdentifier amrmTokenIdentifier \u003d\n+        YarnServerSecurityUtils.authorizeRequest();\n \n     ApplicationAttemptId appAttemptId \u003d\n         amrmTokenIdentifier.getApplicationAttemptId();\n     ApplicationId applicationId \u003d appAttemptId.getApplicationId();\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n     if (lock \u003d\u003d null) {\n       String message \u003d\n           \"Application attempt \" + appAttemptId\n               + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n       LOG.error(message);\n       throw new ApplicationAttemptNotFoundException(message);\n     }\n     synchronized (lock) {\n       AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n       if (!hasApplicationMasterRegistered(appAttemptId)) {\n         String message \u003d\n             \"AM is not registered for known application attempt: \" + appAttemptId\n                 + \" or RM had restarted after AM registered . AM should re-register.\";\n         LOG.info(message);\n         RMAuditLogger.logFailure(\n           this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n             .getUser(), AuditConstants.AM_ALLOCATE, \"\",\n           \"ApplicationMasterService\", message, applicationId, appAttemptId);\n         throw new ApplicationMasterNotRegisteredException(message);\n       }\n \n       if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n         /* old heartbeat */\n         return lastResponse;\n       } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n         String message \u003d\n             \"Invalid responseId in AllocateRequest from application attempt: \"\n                 + appAttemptId + \", expect responseId to be \"\n                 + (lastResponse.getResponseId() + 1);\n         throw new InvalidApplicationMasterRequestException(message);\n       }\n \n       //filter illegal progress values\n       float filteredProgress \u003d request.getProgress();\n       if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n         || filteredProgress \u003c 0) {\n          request.setProgress(0);\n       } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n         request.setProgress(1);\n       }\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n       ResourceBlacklistRequest blacklistRequest \u003d\n           request.getResourceBlacklistRequest();\n       List\u003cString\u003e blacklistAdditions \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n       List\u003cString\u003e blacklistRemovals \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n       RMApp app \u003d\n           this.rmContext.getRMApps().get(applicationId);\n       \n       // set label expression for Resource Requests if resourceName\u003dANY \n       ApplicationSubmissionContext asc \u003d app.getApplicationSubmissionContext();\n       for (ResourceRequest req : ask) {\n         if (null \u003d\u003d req.getNodeLabelExpression()\n             \u0026\u0026 ResourceRequest.ANY.equals(req.getResourceName())) {\n           req.setNodeLabelExpression(asc.getNodeLabelExpression());\n         }\n       }\n               \n       // sanity check\n       try {\n         RMServerUtils.normalizeAndValidateRequests(ask,\n             rScheduler.getMaximumResourceCapability(), app.getQueue(),\n             rScheduler, rmContext);\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       try {\n         RMServerUtils.validateBlacklistRequest(blacklistRequest);\n       }  catch (InvalidResourceBlacklistRequestException e) {\n         LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n         throw e;\n       }\n \n       // In the case of work-preserving AM restart, it\u0027s possible for the\n       // AM to release containers from the earlier attempt.\n       if (!app.getApplicationSubmissionContext()\n         .getKeepContainersAcrossApplicationAttempts()) {\n         try {\n           RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n         } catch (InvalidContainerReleaseException e) {\n           LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n           throw e;\n         }\n       }\n \n       // Send new requests to appAttempt.\n       Allocation allocation;\n       RMAppAttemptState state \u003d\n           app.getRMAppAttempt(appAttemptId).getAppAttemptState();\n       if (state.equals(RMAppAttemptState.FINAL_SAVING) ||\n           state.equals(RMAppAttemptState.FINISHING) ||\n           app.isAppFinalStateStored()) {\n         LOG.warn(appAttemptId + \" is in \" + state +\n                  \" state, ignore container allocate request.\");\n         allocation \u003d EMPTY_ALLOCATION;\n       } else {\n         allocation \u003d\n           this.rScheduler.allocate(appAttemptId, ask, release,\n               blacklistAdditions, blacklistRemovals);\n       }\n \n       if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n         LOG.info(\"blacklist are updated in Scheduler.\" +\n             \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n             \"blacklistRemovals: \" + blacklistRemovals);\n       }\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n       if (!allocation.getContainers().isEmpty()) {\n         allocateResponse.setNMTokens(allocation.getNMTokens());\n       }\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeId nodeId \u003d rmNode.getNodeID();\n           NodeReport report \u003d\n               BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n                   rmNode.getHttpAddress(), rmNode.getRackName(), used,\n                   rmNode.getTotalCapability(), numContainers,\n                   rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n                   rmNode.getNodeLabels());\n \n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n \n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n \n       // add preemption to the allocateResponse message (if any)\n       allocateResponse\n           .setPreemptionMessage(generatePreemptionMessage(allocation));\n \n       // update AMRMToken if the token is rolled-up\n       MasterKeyData nextMasterKey \u003d\n           this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n \n       if (nextMasterKey !\u003d null\n           \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n             .getKeyId()) {\n         RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n         Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n         if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n             appAttemptImpl.getAMRMTokenKeyId()) {\n           LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n               + \" to application: \" + applicationId);\n           amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n               .createAndGetAMRMToken(appAttemptId);\n           appAttemptImpl.setAMRMToken(amrmToken);\n         }\n         allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n           .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n             .toString(), amrmToken.getPassword(), amrmToken.getService()\n             .toString()));\n       }\n \n       /*\n        * As we are updating the response inside the lock object so we don\u0027t\n        * need to worry about unregister call occurring in between (which\n        * removes the lock object).\n        */\n       lock.setAllocateResponse(allocateResponse);\n       return allocateResponse;\n     }    \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    AMRMTokenIdentifier amrmTokenIdentifier \u003d\n        YarnServerSecurityUtils.authorizeRequest();\n\n    ApplicationAttemptId appAttemptId \u003d\n        amrmTokenIdentifier.getApplicationAttemptId();\n    ApplicationId applicationId \u003d appAttemptId.getApplicationId();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n    if (lock \u003d\u003d null) {\n      String message \u003d\n          \"Application attempt \" + appAttemptId\n              + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n      LOG.error(message);\n      throw new ApplicationAttemptNotFoundException(message);\n    }\n    synchronized (lock) {\n      AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n      if (!hasApplicationMasterRegistered(appAttemptId)) {\n        String message \u003d\n            \"AM is not registered for known application attempt: \" + appAttemptId\n                + \" or RM had restarted after AM registered . AM should re-register.\";\n        LOG.info(message);\n        RMAuditLogger.logFailure(\n          this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n            .getUser(), AuditConstants.AM_ALLOCATE, \"\",\n          \"ApplicationMasterService\", message, applicationId, appAttemptId);\n        throw new ApplicationMasterNotRegisteredException(message);\n      }\n\n      if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n        /* old heartbeat */\n        return lastResponse;\n      } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n        String message \u003d\n            \"Invalid responseId in AllocateRequest from application attempt: \"\n                + appAttemptId + \", expect responseId to be \"\n                + (lastResponse.getResponseId() + 1);\n        throw new InvalidApplicationMasterRequestException(message);\n      }\n\n      //filter illegal progress values\n      float filteredProgress \u003d request.getProgress();\n      if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n        || filteredProgress \u003c 0) {\n         request.setProgress(0);\n      } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n        request.setProgress(1);\n      }\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      ResourceBlacklistRequest blacklistRequest \u003d\n          request.getResourceBlacklistRequest();\n      List\u003cString\u003e blacklistAdditions \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n      List\u003cString\u003e blacklistRemovals \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n      RMApp app \u003d\n          this.rmContext.getRMApps().get(applicationId);\n      \n      // set label expression for Resource Requests if resourceName\u003dANY \n      ApplicationSubmissionContext asc \u003d app.getApplicationSubmissionContext();\n      for (ResourceRequest req : ask) {\n        if (null \u003d\u003d req.getNodeLabelExpression()\n            \u0026\u0026 ResourceRequest.ANY.equals(req.getResourceName())) {\n          req.setNodeLabelExpression(asc.getNodeLabelExpression());\n        }\n      }\n              \n      // sanity check\n      try {\n        RMServerUtils.normalizeAndValidateRequests(ask,\n            rScheduler.getMaximumResourceCapability(), app.getQueue(),\n            rScheduler, rmContext);\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      try {\n        RMServerUtils.validateBlacklistRequest(blacklistRequest);\n      }  catch (InvalidResourceBlacklistRequestException e) {\n        LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n        throw e;\n      }\n\n      // In the case of work-preserving AM restart, it\u0027s possible for the\n      // AM to release containers from the earlier attempt.\n      if (!app.getApplicationSubmissionContext()\n        .getKeepContainersAcrossApplicationAttempts()) {\n        try {\n          RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n        } catch (InvalidContainerReleaseException e) {\n          LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n          throw e;\n        }\n      }\n\n      // Send new requests to appAttempt.\n      Allocation allocation;\n      RMAppAttemptState state \u003d\n          app.getRMAppAttempt(appAttemptId).getAppAttemptState();\n      if (state.equals(RMAppAttemptState.FINAL_SAVING) ||\n          state.equals(RMAppAttemptState.FINISHING) ||\n          app.isAppFinalStateStored()) {\n        LOG.warn(appAttemptId + \" is in \" + state +\n                 \" state, ignore container allocate request.\");\n        allocation \u003d EMPTY_ALLOCATION;\n      } else {\n        allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release,\n              blacklistAdditions, blacklistRemovals);\n      }\n\n      if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n        LOG.info(\"blacklist are updated in Scheduler.\" +\n            \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n            \"blacklistRemovals: \" + blacklistRemovals);\n      }\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n      if (!allocation.getContainers().isEmpty()) {\n        allocateResponse.setNMTokens(allocation.getNMTokens());\n      }\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeId nodeId \u003d rmNode.getNodeID();\n          NodeReport report \u003d\n              BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n                  rmNode.getHttpAddress(), rmNode.getRackName(), used,\n                  rmNode.getTotalCapability(), numContainers,\n                  rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n                  rmNode.getNodeLabels());\n\n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n\n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n\n      // add preemption to the allocateResponse message (if any)\n      allocateResponse\n          .setPreemptionMessage(generatePreemptionMessage(allocation));\n\n      // update AMRMToken if the token is rolled-up\n      MasterKeyData nextMasterKey \u003d\n          this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n\n      if (nextMasterKey !\u003d null\n          \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n            .getKeyId()) {\n        RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n        Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n        if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n            appAttemptImpl.getAMRMTokenKeyId()) {\n          LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n              + \" to application: \" + applicationId);\n          amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n              .createAndGetAMRMToken(appAttemptId);\n          appAttemptImpl.setAMRMToken(amrmToken);\n        }\n        allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n          .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n            .toString(), amrmToken.getPassword(), amrmToken.getService()\n            .toString()));\n      }\n\n      /*\n       * As we are updating the response inside the lock object so we don\u0027t\n       * need to worry about unregister call occurring in between (which\n       * removes the lock object).\n       */\n      lock.setAllocateResponse(allocateResponse);\n      return allocateResponse;\n    }    \n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "f7e051c4310024d4040ad466c34432c72e88b0fc": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2421. RM still allocates containers to an app in the FINISHING state. Contributed by Chang Li\n",
      "commitDate": "15/05/15 3:09 PM",
      "commitName": "f7e051c4310024d4040ad466c34432c72e88b0fc",
      "commitAuthor": "Jason Lowe",
      "commitDateOld": "07/05/15 5:35 PM",
      "commitNameOld": "f489a4ec969f3727d03c8e85d51af1018fc0b2a1",
      "commitAuthorOld": "Jian He",
      "daysBetweenCommits": 7.9,
      "commitsBetweenForRepo": 139,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,198 +1,209 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n     AMRMTokenIdentifier amrmTokenIdentifier \u003d authorizeRequest();\n \n     ApplicationAttemptId appAttemptId \u003d\n         amrmTokenIdentifier.getApplicationAttemptId();\n     ApplicationId applicationId \u003d appAttemptId.getApplicationId();\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n     if (lock \u003d\u003d null) {\n       String message \u003d\n           \"Application attempt \" + appAttemptId\n               + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n       LOG.error(message);\n       throw new ApplicationAttemptNotFoundException(message);\n     }\n     synchronized (lock) {\n       AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n       if (!hasApplicationMasterRegistered(appAttemptId)) {\n         String message \u003d\n             \"AM is not registered for known application attempt: \" + appAttemptId\n                 + \" or RM had restarted after AM registered . AM should re-register.\";\n         LOG.info(message);\n         RMAuditLogger.logFailure(\n           this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n             .getUser(), AuditConstants.AM_ALLOCATE, \"\",\n           \"ApplicationMasterService\", message, applicationId, appAttemptId);\n         throw new ApplicationMasterNotRegisteredException(message);\n       }\n \n       if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n         /* old heartbeat */\n         return lastResponse;\n       } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n         String message \u003d\n             \"Invalid responseId in AllocateRequest from application attempt: \"\n                 + appAttemptId + \", expect responseId to be \"\n                 + (lastResponse.getResponseId() + 1);\n         throw new InvalidApplicationMasterRequestException(message);\n       }\n \n       //filter illegal progress values\n       float filteredProgress \u003d request.getProgress();\n       if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n         || filteredProgress \u003c 0) {\n          request.setProgress(0);\n       } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n         request.setProgress(1);\n       }\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n       ResourceBlacklistRequest blacklistRequest \u003d\n           request.getResourceBlacklistRequest();\n       List\u003cString\u003e blacklistAdditions \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n       List\u003cString\u003e blacklistRemovals \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n       RMApp app \u003d\n           this.rmContext.getRMApps().get(applicationId);\n       \n       // set label expression for Resource Requests if resourceName\u003dANY \n       ApplicationSubmissionContext asc \u003d app.getApplicationSubmissionContext();\n       for (ResourceRequest req : ask) {\n         if (null \u003d\u003d req.getNodeLabelExpression()\n             \u0026\u0026 ResourceRequest.ANY.equals(req.getResourceName())) {\n           req.setNodeLabelExpression(asc.getNodeLabelExpression());\n         }\n       }\n               \n       // sanity check\n       try {\n         RMServerUtils.normalizeAndValidateRequests(ask,\n             rScheduler.getMaximumResourceCapability(), app.getQueue(),\n             rScheduler, rmContext);\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       try {\n         RMServerUtils.validateBlacklistRequest(blacklistRequest);\n       }  catch (InvalidResourceBlacklistRequestException e) {\n         LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n         throw e;\n       }\n \n       // In the case of work-preserving AM restart, it\u0027s possible for the\n       // AM to release containers from the earlier attempt.\n       if (!app.getApplicationSubmissionContext()\n         .getKeepContainersAcrossApplicationAttempts()) {\n         try {\n           RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n         } catch (InvalidContainerReleaseException e) {\n           LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n           throw e;\n         }\n       }\n \n       // Send new requests to appAttempt.\n-      Allocation allocation \u003d\n-          this.rScheduler.allocate(appAttemptId, ask, release, \n+      Allocation allocation;\n+      RMAppAttemptState state \u003d\n+          app.getRMAppAttempt(appAttemptId).getAppAttemptState();\n+      if (state.equals(RMAppAttemptState.FINAL_SAVING) ||\n+          state.equals(RMAppAttemptState.FINISHING) ||\n+          app.isAppFinalStateStored()) {\n+        LOG.warn(appAttemptId + \" is in \" + state +\n+                 \" state, ignore container allocate request.\");\n+        allocation \u003d EMPTY_ALLOCATION;\n+      } else {\n+        allocation \u003d\n+          this.rScheduler.allocate(appAttemptId, ask, release,\n               blacklistAdditions, blacklistRemovals);\n+      }\n \n       if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n         LOG.info(\"blacklist are updated in Scheduler.\" +\n             \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n             \"blacklistRemovals: \" + blacklistRemovals);\n       }\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n       if (!allocation.getContainers().isEmpty()) {\n         allocateResponse.setNMTokens(allocation.getNMTokens());\n       }\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeId nodeId \u003d rmNode.getNodeID();\n           NodeReport report \u003d\n               BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n                   rmNode.getHttpAddress(), rmNode.getRackName(), used,\n                   rmNode.getTotalCapability(), numContainers,\n                   rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n                   rmNode.getNodeLabels());\n \n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n \n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n \n       // add preemption to the allocateResponse message (if any)\n       allocateResponse\n           .setPreemptionMessage(generatePreemptionMessage(allocation));\n \n       // update AMRMToken if the token is rolled-up\n       MasterKeyData nextMasterKey \u003d\n           this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n \n       if (nextMasterKey !\u003d null\n           \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n             .getKeyId()) {\n         RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n         Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n         if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n             appAttemptImpl.getAMRMTokenKeyId()) {\n           LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n               + \" to application: \" + applicationId);\n           amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n               .createAndGetAMRMToken(appAttemptId);\n           appAttemptImpl.setAMRMToken(amrmToken);\n         }\n         allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n           .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n             .toString(), amrmToken.getPassword(), amrmToken.getService()\n             .toString()));\n       }\n \n       /*\n        * As we are updating the response inside the lock object so we don\u0027t\n        * need to worry about unregister call occurring in between (which\n        * removes the lock object).\n        */\n       lock.setAllocateResponse(allocateResponse);\n       return allocateResponse;\n     }    \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    AMRMTokenIdentifier amrmTokenIdentifier \u003d authorizeRequest();\n\n    ApplicationAttemptId appAttemptId \u003d\n        amrmTokenIdentifier.getApplicationAttemptId();\n    ApplicationId applicationId \u003d appAttemptId.getApplicationId();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n    if (lock \u003d\u003d null) {\n      String message \u003d\n          \"Application attempt \" + appAttemptId\n              + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n      LOG.error(message);\n      throw new ApplicationAttemptNotFoundException(message);\n    }\n    synchronized (lock) {\n      AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n      if (!hasApplicationMasterRegistered(appAttemptId)) {\n        String message \u003d\n            \"AM is not registered for known application attempt: \" + appAttemptId\n                + \" or RM had restarted after AM registered . AM should re-register.\";\n        LOG.info(message);\n        RMAuditLogger.logFailure(\n          this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n            .getUser(), AuditConstants.AM_ALLOCATE, \"\",\n          \"ApplicationMasterService\", message, applicationId, appAttemptId);\n        throw new ApplicationMasterNotRegisteredException(message);\n      }\n\n      if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n        /* old heartbeat */\n        return lastResponse;\n      } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n        String message \u003d\n            \"Invalid responseId in AllocateRequest from application attempt: \"\n                + appAttemptId + \", expect responseId to be \"\n                + (lastResponse.getResponseId() + 1);\n        throw new InvalidApplicationMasterRequestException(message);\n      }\n\n      //filter illegal progress values\n      float filteredProgress \u003d request.getProgress();\n      if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n        || filteredProgress \u003c 0) {\n         request.setProgress(0);\n      } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n        request.setProgress(1);\n      }\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      ResourceBlacklistRequest blacklistRequest \u003d\n          request.getResourceBlacklistRequest();\n      List\u003cString\u003e blacklistAdditions \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n      List\u003cString\u003e blacklistRemovals \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n      RMApp app \u003d\n          this.rmContext.getRMApps().get(applicationId);\n      \n      // set label expression for Resource Requests if resourceName\u003dANY \n      ApplicationSubmissionContext asc \u003d app.getApplicationSubmissionContext();\n      for (ResourceRequest req : ask) {\n        if (null \u003d\u003d req.getNodeLabelExpression()\n            \u0026\u0026 ResourceRequest.ANY.equals(req.getResourceName())) {\n          req.setNodeLabelExpression(asc.getNodeLabelExpression());\n        }\n      }\n              \n      // sanity check\n      try {\n        RMServerUtils.normalizeAndValidateRequests(ask,\n            rScheduler.getMaximumResourceCapability(), app.getQueue(),\n            rScheduler, rmContext);\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      try {\n        RMServerUtils.validateBlacklistRequest(blacklistRequest);\n      }  catch (InvalidResourceBlacklistRequestException e) {\n        LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n        throw e;\n      }\n\n      // In the case of work-preserving AM restart, it\u0027s possible for the\n      // AM to release containers from the earlier attempt.\n      if (!app.getApplicationSubmissionContext()\n        .getKeepContainersAcrossApplicationAttempts()) {\n        try {\n          RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n        } catch (InvalidContainerReleaseException e) {\n          LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n          throw e;\n        }\n      }\n\n      // Send new requests to appAttempt.\n      Allocation allocation;\n      RMAppAttemptState state \u003d\n          app.getRMAppAttempt(appAttemptId).getAppAttemptState();\n      if (state.equals(RMAppAttemptState.FINAL_SAVING) ||\n          state.equals(RMAppAttemptState.FINISHING) ||\n          app.isAppFinalStateStored()) {\n        LOG.warn(appAttemptId + \" is in \" + state +\n                 \" state, ignore container allocate request.\");\n        allocation \u003d EMPTY_ALLOCATION;\n      } else {\n        allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release,\n              blacklistAdditions, blacklistRemovals);\n      }\n\n      if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n        LOG.info(\"blacklist are updated in Scheduler.\" +\n            \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n            \"blacklistRemovals: \" + blacklistRemovals);\n      }\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n      if (!allocation.getContainers().isEmpty()) {\n        allocateResponse.setNMTokens(allocation.getNMTokens());\n      }\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeId nodeId \u003d rmNode.getNodeID();\n          NodeReport report \u003d\n              BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n                  rmNode.getHttpAddress(), rmNode.getRackName(), used,\n                  rmNode.getTotalCapability(), numContainers,\n                  rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n                  rmNode.getNodeLabels());\n\n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n\n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n\n      // add preemption to the allocateResponse message (if any)\n      allocateResponse\n          .setPreemptionMessage(generatePreemptionMessage(allocation));\n\n      // update AMRMToken if the token is rolled-up\n      MasterKeyData nextMasterKey \u003d\n          this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n\n      if (nextMasterKey !\u003d null\n          \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n            .getKeyId()) {\n        RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n        Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n        if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n            appAttemptImpl.getAMRMTokenKeyId()) {\n          LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n              + \" to application: \" + applicationId);\n          amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n              .createAndGetAMRMToken(appAttemptId);\n          appAttemptImpl.setAMRMToken(amrmToken);\n        }\n        allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n          .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n            .toString(), amrmToken.getPassword(), amrmToken.getService()\n            .toString()));\n      }\n\n      /*\n       * As we are updating the response inside the lock object so we don\u0027t\n       * need to worry about unregister call occurring in between (which\n       * removes the lock object).\n       */\n      lock.setAllocateResponse(allocateResponse);\n      return allocateResponse;\n    }    \n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "f489a4ec969f3727d03c8e85d51af1018fc0b2a1": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2918. RM should not fail on startup if queue\u0027s configured labels do not exist in cluster-node-labels. Contributed by Wangda Tan\n",
      "commitDate": "07/05/15 5:35 PM",
      "commitName": "f489a4ec969f3727d03c8e85d51af1018fc0b2a1",
      "commitAuthor": "Jian He",
      "commitDateOld": "18/04/15 12:46 PM",
      "commitNameOld": "497c86b485b1bb8a2eba52308646d8e1ee76bce3",
      "commitAuthorOld": "Jian He",
      "daysBetweenCommits": 19.2,
      "commitsBetweenForRepo": 186,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,198 +1,198 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n     AMRMTokenIdentifier amrmTokenIdentifier \u003d authorizeRequest();\n \n     ApplicationAttemptId appAttemptId \u003d\n         amrmTokenIdentifier.getApplicationAttemptId();\n     ApplicationId applicationId \u003d appAttemptId.getApplicationId();\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n     if (lock \u003d\u003d null) {\n       String message \u003d\n           \"Application attempt \" + appAttemptId\n               + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n       LOG.error(message);\n       throw new ApplicationAttemptNotFoundException(message);\n     }\n     synchronized (lock) {\n       AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n       if (!hasApplicationMasterRegistered(appAttemptId)) {\n         String message \u003d\n             \"AM is not registered for known application attempt: \" + appAttemptId\n                 + \" or RM had restarted after AM registered . AM should re-register.\";\n         LOG.info(message);\n         RMAuditLogger.logFailure(\n           this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n             .getUser(), AuditConstants.AM_ALLOCATE, \"\",\n           \"ApplicationMasterService\", message, applicationId, appAttemptId);\n         throw new ApplicationMasterNotRegisteredException(message);\n       }\n \n       if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n         /* old heartbeat */\n         return lastResponse;\n       } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n         String message \u003d\n             \"Invalid responseId in AllocateRequest from application attempt: \"\n                 + appAttemptId + \", expect responseId to be \"\n                 + (lastResponse.getResponseId() + 1);\n         throw new InvalidApplicationMasterRequestException(message);\n       }\n \n       //filter illegal progress values\n       float filteredProgress \u003d request.getProgress();\n       if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n         || filteredProgress \u003c 0) {\n          request.setProgress(0);\n       } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n         request.setProgress(1);\n       }\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n       ResourceBlacklistRequest blacklistRequest \u003d\n           request.getResourceBlacklistRequest();\n       List\u003cString\u003e blacklistAdditions \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n       List\u003cString\u003e blacklistRemovals \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n       RMApp app \u003d\n           this.rmContext.getRMApps().get(applicationId);\n       \n       // set label expression for Resource Requests if resourceName\u003dANY \n       ApplicationSubmissionContext asc \u003d app.getApplicationSubmissionContext();\n       for (ResourceRequest req : ask) {\n         if (null \u003d\u003d req.getNodeLabelExpression()\n             \u0026\u0026 ResourceRequest.ANY.equals(req.getResourceName())) {\n           req.setNodeLabelExpression(asc.getNodeLabelExpression());\n         }\n       }\n               \n       // sanity check\n       try {\n         RMServerUtils.normalizeAndValidateRequests(ask,\n             rScheduler.getMaximumResourceCapability(), app.getQueue(),\n-            rScheduler);\n+            rScheduler, rmContext);\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       try {\n         RMServerUtils.validateBlacklistRequest(blacklistRequest);\n       }  catch (InvalidResourceBlacklistRequestException e) {\n         LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n         throw e;\n       }\n \n       // In the case of work-preserving AM restart, it\u0027s possible for the\n       // AM to release containers from the earlier attempt.\n       if (!app.getApplicationSubmissionContext()\n         .getKeepContainersAcrossApplicationAttempts()) {\n         try {\n           RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n         } catch (InvalidContainerReleaseException e) {\n           LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n           throw e;\n         }\n       }\n \n       // Send new requests to appAttempt.\n       Allocation allocation \u003d\n           this.rScheduler.allocate(appAttemptId, ask, release, \n               blacklistAdditions, blacklistRemovals);\n \n       if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n         LOG.info(\"blacklist are updated in Scheduler.\" +\n             \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n             \"blacklistRemovals: \" + blacklistRemovals);\n       }\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n       if (!allocation.getContainers().isEmpty()) {\n         allocateResponse.setNMTokens(allocation.getNMTokens());\n       }\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeId nodeId \u003d rmNode.getNodeID();\n           NodeReport report \u003d\n               BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n                   rmNode.getHttpAddress(), rmNode.getRackName(), used,\n                   rmNode.getTotalCapability(), numContainers,\n                   rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n                   rmNode.getNodeLabels());\n \n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n \n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n \n       // add preemption to the allocateResponse message (if any)\n       allocateResponse\n           .setPreemptionMessage(generatePreemptionMessage(allocation));\n \n       // update AMRMToken if the token is rolled-up\n       MasterKeyData nextMasterKey \u003d\n           this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n \n       if (nextMasterKey !\u003d null\n           \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n             .getKeyId()) {\n         RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n         Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n         if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n             appAttemptImpl.getAMRMTokenKeyId()) {\n           LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n               + \" to application: \" + applicationId);\n           amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n               .createAndGetAMRMToken(appAttemptId);\n           appAttemptImpl.setAMRMToken(amrmToken);\n         }\n         allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n           .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n             .toString(), amrmToken.getPassword(), amrmToken.getService()\n             .toString()));\n       }\n \n       /*\n        * As we are updating the response inside the lock object so we don\u0027t\n        * need to worry about unregister call occurring in between (which\n        * removes the lock object).\n        */\n       lock.setAllocateResponse(allocateResponse);\n       return allocateResponse;\n     }    \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    AMRMTokenIdentifier amrmTokenIdentifier \u003d authorizeRequest();\n\n    ApplicationAttemptId appAttemptId \u003d\n        amrmTokenIdentifier.getApplicationAttemptId();\n    ApplicationId applicationId \u003d appAttemptId.getApplicationId();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n    if (lock \u003d\u003d null) {\n      String message \u003d\n          \"Application attempt \" + appAttemptId\n              + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n      LOG.error(message);\n      throw new ApplicationAttemptNotFoundException(message);\n    }\n    synchronized (lock) {\n      AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n      if (!hasApplicationMasterRegistered(appAttemptId)) {\n        String message \u003d\n            \"AM is not registered for known application attempt: \" + appAttemptId\n                + \" or RM had restarted after AM registered . AM should re-register.\";\n        LOG.info(message);\n        RMAuditLogger.logFailure(\n          this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n            .getUser(), AuditConstants.AM_ALLOCATE, \"\",\n          \"ApplicationMasterService\", message, applicationId, appAttemptId);\n        throw new ApplicationMasterNotRegisteredException(message);\n      }\n\n      if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n        /* old heartbeat */\n        return lastResponse;\n      } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n        String message \u003d\n            \"Invalid responseId in AllocateRequest from application attempt: \"\n                + appAttemptId + \", expect responseId to be \"\n                + (lastResponse.getResponseId() + 1);\n        throw new InvalidApplicationMasterRequestException(message);\n      }\n\n      //filter illegal progress values\n      float filteredProgress \u003d request.getProgress();\n      if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n        || filteredProgress \u003c 0) {\n         request.setProgress(0);\n      } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n        request.setProgress(1);\n      }\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      ResourceBlacklistRequest blacklistRequest \u003d\n          request.getResourceBlacklistRequest();\n      List\u003cString\u003e blacklistAdditions \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n      List\u003cString\u003e blacklistRemovals \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n      RMApp app \u003d\n          this.rmContext.getRMApps().get(applicationId);\n      \n      // set label expression for Resource Requests if resourceName\u003dANY \n      ApplicationSubmissionContext asc \u003d app.getApplicationSubmissionContext();\n      for (ResourceRequest req : ask) {\n        if (null \u003d\u003d req.getNodeLabelExpression()\n            \u0026\u0026 ResourceRequest.ANY.equals(req.getResourceName())) {\n          req.setNodeLabelExpression(asc.getNodeLabelExpression());\n        }\n      }\n              \n      // sanity check\n      try {\n        RMServerUtils.normalizeAndValidateRequests(ask,\n            rScheduler.getMaximumResourceCapability(), app.getQueue(),\n            rScheduler, rmContext);\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      try {\n        RMServerUtils.validateBlacklistRequest(blacklistRequest);\n      }  catch (InvalidResourceBlacklistRequestException e) {\n        LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n        throw e;\n      }\n\n      // In the case of work-preserving AM restart, it\u0027s possible for the\n      // AM to release containers from the earlier attempt.\n      if (!app.getApplicationSubmissionContext()\n        .getKeepContainersAcrossApplicationAttempts()) {\n        try {\n          RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n        } catch (InvalidContainerReleaseException e) {\n          LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n          throw e;\n        }\n      }\n\n      // Send new requests to appAttempt.\n      Allocation allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release, \n              blacklistAdditions, blacklistRemovals);\n\n      if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n        LOG.info(\"blacklist are updated in Scheduler.\" +\n            \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n            \"blacklistRemovals: \" + blacklistRemovals);\n      }\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n      if (!allocation.getContainers().isEmpty()) {\n        allocateResponse.setNMTokens(allocation.getNMTokens());\n      }\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeId nodeId \u003d rmNode.getNodeID();\n          NodeReport report \u003d\n              BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n                  rmNode.getHttpAddress(), rmNode.getRackName(), used,\n                  rmNode.getTotalCapability(), numContainers,\n                  rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n                  rmNode.getNodeLabels());\n\n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n\n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n\n      // add preemption to the allocateResponse message (if any)\n      allocateResponse\n          .setPreemptionMessage(generatePreemptionMessage(allocation));\n\n      // update AMRMToken if the token is rolled-up\n      MasterKeyData nextMasterKey \u003d\n          this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n\n      if (nextMasterKey !\u003d null\n          \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n            .getKeyId()) {\n        RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n        Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n        if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n            appAttemptImpl.getAMRMTokenKeyId()) {\n          LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n              + \" to application: \" + applicationId);\n          amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n              .createAndGetAMRMToken(appAttemptId);\n          appAttemptImpl.setAMRMToken(amrmToken);\n        }\n        allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n          .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n            .toString(), amrmToken.getPassword(), amrmToken.getService()\n            .toString()));\n      }\n\n      /*\n       * As we are updating the response inside the lock object so we don\u0027t\n       * need to worry about unregister call occurring in between (which\n       * removes the lock object).\n       */\n      lock.setAllocateResponse(allocateResponse);\n      return allocateResponse;\n    }    \n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "f65eeb412d140a3808bcf99344a9f3a965918f70": {
      "type": "Ybodychange",
      "commitMessage": "YARN-3493. RM fails to come up with error \"Failed to load/recover state\" when mem settings are changed. (Jian He via wangda)\n",
      "commitDate": "17/04/15 5:11 PM",
      "commitName": "f65eeb412d140a3808bcf99344a9f3a965918f70",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "12/02/15 4:02 PM",
      "commitNameOld": "18297e09727e4af95140084760ae1267e8fe51c4",
      "commitAuthorOld": "Jian He",
      "daysBetweenCommits": 64.01,
      "commitsBetweenForRepo": 555,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,198 +1,198 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n     AMRMTokenIdentifier amrmTokenIdentifier \u003d authorizeRequest();\n \n     ApplicationAttemptId appAttemptId \u003d\n         amrmTokenIdentifier.getApplicationAttemptId();\n     ApplicationId applicationId \u003d appAttemptId.getApplicationId();\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n     if (lock \u003d\u003d null) {\n       String message \u003d\n           \"Application attempt \" + appAttemptId\n               + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n       LOG.error(message);\n       throw new ApplicationAttemptNotFoundException(message);\n     }\n     synchronized (lock) {\n       AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n       if (!hasApplicationMasterRegistered(appAttemptId)) {\n         String message \u003d\n             \"AM is not registered for known application attempt: \" + appAttemptId\n                 + \" or RM had restarted after AM registered . AM should re-register.\";\n         LOG.info(message);\n         RMAuditLogger.logFailure(\n           this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n             .getUser(), AuditConstants.AM_ALLOCATE, \"\",\n           \"ApplicationMasterService\", message, applicationId, appAttemptId);\n         throw new ApplicationMasterNotRegisteredException(message);\n       }\n \n       if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n         /* old heartbeat */\n         return lastResponse;\n       } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n         String message \u003d\n             \"Invalid responseId in AllocateRequest from application attempt: \"\n                 + appAttemptId + \", expect responseId to be \"\n                 + (lastResponse.getResponseId() + 1);\n         throw new InvalidApplicationMasterRequestException(message);\n       }\n \n       //filter illegal progress values\n       float filteredProgress \u003d request.getProgress();\n       if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n         || filteredProgress \u003c 0) {\n          request.setProgress(0);\n       } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n         request.setProgress(1);\n       }\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n       ResourceBlacklistRequest blacklistRequest \u003d\n           request.getResourceBlacklistRequest();\n       List\u003cString\u003e blacklistAdditions \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n       List\u003cString\u003e blacklistRemovals \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n       RMApp app \u003d\n           this.rmContext.getRMApps().get(applicationId);\n       \n       // set label expression for Resource Requests if resourceName\u003dANY \n       ApplicationSubmissionContext asc \u003d app.getApplicationSubmissionContext();\n       for (ResourceRequest req : ask) {\n         if (null \u003d\u003d req.getNodeLabelExpression()\n             \u0026\u0026 ResourceRequest.ANY.equals(req.getResourceName())) {\n           req.setNodeLabelExpression(asc.getNodeLabelExpression());\n         }\n       }\n               \n       // sanity check\n       try {\n-        RMServerUtils.validateResourceRequests(ask,\n+        RMServerUtils.normalizeAndValidateRequests(ask,\n             rScheduler.getMaximumResourceCapability(), app.getQueue(),\n             rScheduler);\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       try {\n         RMServerUtils.validateBlacklistRequest(blacklistRequest);\n       }  catch (InvalidResourceBlacklistRequestException e) {\n         LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n         throw e;\n       }\n \n       // In the case of work-preserving AM restart, it\u0027s possible for the\n       // AM to release containers from the earlier attempt.\n       if (!app.getApplicationSubmissionContext()\n         .getKeepContainersAcrossApplicationAttempts()) {\n         try {\n           RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n         } catch (InvalidContainerReleaseException e) {\n           LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n           throw e;\n         }\n       }\n \n       // Send new requests to appAttempt.\n       Allocation allocation \u003d\n           this.rScheduler.allocate(appAttemptId, ask, release, \n               blacklistAdditions, blacklistRemovals);\n \n       if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n         LOG.info(\"blacklist are updated in Scheduler.\" +\n             \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n             \"blacklistRemovals: \" + blacklistRemovals);\n       }\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n       if (!allocation.getContainers().isEmpty()) {\n         allocateResponse.setNMTokens(allocation.getNMTokens());\n       }\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeId nodeId \u003d rmNode.getNodeID();\n           NodeReport report \u003d\n               BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n                   rmNode.getHttpAddress(), rmNode.getRackName(), used,\n                   rmNode.getTotalCapability(), numContainers,\n                   rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n                   rmNode.getNodeLabels());\n \n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n \n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n \n       // add preemption to the allocateResponse message (if any)\n       allocateResponse\n           .setPreemptionMessage(generatePreemptionMessage(allocation));\n \n       // update AMRMToken if the token is rolled-up\n       MasterKeyData nextMasterKey \u003d\n           this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n \n       if (nextMasterKey !\u003d null\n           \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n             .getKeyId()) {\n         RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n         Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n         if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n             appAttemptImpl.getAMRMTokenKeyId()) {\n           LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n               + \" to application: \" + applicationId);\n           amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n               .createAndGetAMRMToken(appAttemptId);\n           appAttemptImpl.setAMRMToken(amrmToken);\n         }\n         allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n           .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n             .toString(), amrmToken.getPassword(), amrmToken.getService()\n             .toString()));\n       }\n \n       /*\n        * As we are updating the response inside the lock object so we don\u0027t\n        * need to worry about unregister call occurring in between (which\n        * removes the lock object).\n        */\n       lock.setAllocateResponse(allocateResponse);\n       return allocateResponse;\n     }    \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    AMRMTokenIdentifier amrmTokenIdentifier \u003d authorizeRequest();\n\n    ApplicationAttemptId appAttemptId \u003d\n        amrmTokenIdentifier.getApplicationAttemptId();\n    ApplicationId applicationId \u003d appAttemptId.getApplicationId();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n    if (lock \u003d\u003d null) {\n      String message \u003d\n          \"Application attempt \" + appAttemptId\n              + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n      LOG.error(message);\n      throw new ApplicationAttemptNotFoundException(message);\n    }\n    synchronized (lock) {\n      AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n      if (!hasApplicationMasterRegistered(appAttemptId)) {\n        String message \u003d\n            \"AM is not registered for known application attempt: \" + appAttemptId\n                + \" or RM had restarted after AM registered . AM should re-register.\";\n        LOG.info(message);\n        RMAuditLogger.logFailure(\n          this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n            .getUser(), AuditConstants.AM_ALLOCATE, \"\",\n          \"ApplicationMasterService\", message, applicationId, appAttemptId);\n        throw new ApplicationMasterNotRegisteredException(message);\n      }\n\n      if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n        /* old heartbeat */\n        return lastResponse;\n      } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n        String message \u003d\n            \"Invalid responseId in AllocateRequest from application attempt: \"\n                + appAttemptId + \", expect responseId to be \"\n                + (lastResponse.getResponseId() + 1);\n        throw new InvalidApplicationMasterRequestException(message);\n      }\n\n      //filter illegal progress values\n      float filteredProgress \u003d request.getProgress();\n      if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n        || filteredProgress \u003c 0) {\n         request.setProgress(0);\n      } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n        request.setProgress(1);\n      }\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      ResourceBlacklistRequest blacklistRequest \u003d\n          request.getResourceBlacklistRequest();\n      List\u003cString\u003e blacklistAdditions \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n      List\u003cString\u003e blacklistRemovals \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n      RMApp app \u003d\n          this.rmContext.getRMApps().get(applicationId);\n      \n      // set label expression for Resource Requests if resourceName\u003dANY \n      ApplicationSubmissionContext asc \u003d app.getApplicationSubmissionContext();\n      for (ResourceRequest req : ask) {\n        if (null \u003d\u003d req.getNodeLabelExpression()\n            \u0026\u0026 ResourceRequest.ANY.equals(req.getResourceName())) {\n          req.setNodeLabelExpression(asc.getNodeLabelExpression());\n        }\n      }\n              \n      // sanity check\n      try {\n        RMServerUtils.normalizeAndValidateRequests(ask,\n            rScheduler.getMaximumResourceCapability(), app.getQueue(),\n            rScheduler);\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      try {\n        RMServerUtils.validateBlacklistRequest(blacklistRequest);\n      }  catch (InvalidResourceBlacklistRequestException e) {\n        LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n        throw e;\n      }\n\n      // In the case of work-preserving AM restart, it\u0027s possible for the\n      // AM to release containers from the earlier attempt.\n      if (!app.getApplicationSubmissionContext()\n        .getKeepContainersAcrossApplicationAttempts()) {\n        try {\n          RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n        } catch (InvalidContainerReleaseException e) {\n          LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n          throw e;\n        }\n      }\n\n      // Send new requests to appAttempt.\n      Allocation allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release, \n              blacklistAdditions, blacklistRemovals);\n\n      if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n        LOG.info(\"blacklist are updated in Scheduler.\" +\n            \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n            \"blacklistRemovals: \" + blacklistRemovals);\n      }\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n      if (!allocation.getContainers().isEmpty()) {\n        allocateResponse.setNMTokens(allocation.getNMTokens());\n      }\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeId nodeId \u003d rmNode.getNodeID();\n          NodeReport report \u003d\n              BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n                  rmNode.getHttpAddress(), rmNode.getRackName(), used,\n                  rmNode.getTotalCapability(), numContainers,\n                  rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n                  rmNode.getNodeLabels());\n\n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n\n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n\n      // add preemption to the allocateResponse message (if any)\n      allocateResponse\n          .setPreemptionMessage(generatePreemptionMessage(allocation));\n\n      // update AMRMToken if the token is rolled-up\n      MasterKeyData nextMasterKey \u003d\n          this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n\n      if (nextMasterKey !\u003d null\n          \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n            .getKeyId()) {\n        RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n        Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n        if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n            appAttemptImpl.getAMRMTokenKeyId()) {\n          LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n              + \" to application: \" + applicationId);\n          amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n              .createAndGetAMRMToken(appAttemptId);\n          appAttemptImpl.setAMRMToken(amrmToken);\n        }\n        allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n          .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n            .toString(), amrmToken.getPassword(), amrmToken.getService()\n            .toString()));\n      }\n\n      /*\n       * As we are updating the response inside the lock object so we don\u0027t\n       * need to worry about unregister call occurring in between (which\n       * removes the lock object).\n       */\n      lock.setAllocateResponse(allocateResponse);\n      return allocateResponse;\n    }    \n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "18297e09727e4af95140084760ae1267e8fe51c4": {
      "type": "Ybodychange",
      "commitMessage": "YARN-3104. Fixed RM to not generate new AMRM tokens on every heartbeat between rolling and activation. Contributed by Jason Lowe\n",
      "commitDate": "12/02/15 4:02 PM",
      "commitName": "18297e09727e4af95140084760ae1267e8fe51c4",
      "commitAuthor": "Jian He",
      "commitDateOld": "06/02/15 11:34 AM",
      "commitNameOld": "c1957fef29b07fea70938e971b30532a1e131fd0",
      "commitAuthorOld": "Jian He",
      "daysBetweenCommits": 6.19,
      "commitsBetweenForRepo": 89,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,194 +1,198 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n     AMRMTokenIdentifier amrmTokenIdentifier \u003d authorizeRequest();\n \n     ApplicationAttemptId appAttemptId \u003d\n         amrmTokenIdentifier.getApplicationAttemptId();\n     ApplicationId applicationId \u003d appAttemptId.getApplicationId();\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n     if (lock \u003d\u003d null) {\n       String message \u003d\n           \"Application attempt \" + appAttemptId\n               + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n       LOG.error(message);\n       throw new ApplicationAttemptNotFoundException(message);\n     }\n     synchronized (lock) {\n       AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n       if (!hasApplicationMasterRegistered(appAttemptId)) {\n         String message \u003d\n             \"AM is not registered for known application attempt: \" + appAttemptId\n                 + \" or RM had restarted after AM registered . AM should re-register.\";\n         LOG.info(message);\n         RMAuditLogger.logFailure(\n           this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n             .getUser(), AuditConstants.AM_ALLOCATE, \"\",\n           \"ApplicationMasterService\", message, applicationId, appAttemptId);\n         throw new ApplicationMasterNotRegisteredException(message);\n       }\n \n       if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n         /* old heartbeat */\n         return lastResponse;\n       } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n         String message \u003d\n             \"Invalid responseId in AllocateRequest from application attempt: \"\n                 + appAttemptId + \", expect responseId to be \"\n                 + (lastResponse.getResponseId() + 1);\n         throw new InvalidApplicationMasterRequestException(message);\n       }\n \n       //filter illegal progress values\n       float filteredProgress \u003d request.getProgress();\n       if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n         || filteredProgress \u003c 0) {\n          request.setProgress(0);\n       } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n         request.setProgress(1);\n       }\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n       ResourceBlacklistRequest blacklistRequest \u003d\n           request.getResourceBlacklistRequest();\n       List\u003cString\u003e blacklistAdditions \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n       List\u003cString\u003e blacklistRemovals \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n       RMApp app \u003d\n           this.rmContext.getRMApps().get(applicationId);\n       \n       // set label expression for Resource Requests if resourceName\u003dANY \n       ApplicationSubmissionContext asc \u003d app.getApplicationSubmissionContext();\n       for (ResourceRequest req : ask) {\n         if (null \u003d\u003d req.getNodeLabelExpression()\n             \u0026\u0026 ResourceRequest.ANY.equals(req.getResourceName())) {\n           req.setNodeLabelExpression(asc.getNodeLabelExpression());\n         }\n       }\n               \n       // sanity check\n       try {\n         RMServerUtils.validateResourceRequests(ask,\n             rScheduler.getMaximumResourceCapability(), app.getQueue(),\n             rScheduler);\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       try {\n         RMServerUtils.validateBlacklistRequest(blacklistRequest);\n       }  catch (InvalidResourceBlacklistRequestException e) {\n         LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n         throw e;\n       }\n \n       // In the case of work-preserving AM restart, it\u0027s possible for the\n       // AM to release containers from the earlier attempt.\n       if (!app.getApplicationSubmissionContext()\n         .getKeepContainersAcrossApplicationAttempts()) {\n         try {\n           RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n         } catch (InvalidContainerReleaseException e) {\n           LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n           throw e;\n         }\n       }\n \n       // Send new requests to appAttempt.\n       Allocation allocation \u003d\n           this.rScheduler.allocate(appAttemptId, ask, release, \n               blacklistAdditions, blacklistRemovals);\n \n       if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n         LOG.info(\"blacklist are updated in Scheduler.\" +\n             \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n             \"blacklistRemovals: \" + blacklistRemovals);\n       }\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n       if (!allocation.getContainers().isEmpty()) {\n         allocateResponse.setNMTokens(allocation.getNMTokens());\n       }\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeId nodeId \u003d rmNode.getNodeID();\n           NodeReport report \u003d\n               BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n                   rmNode.getHttpAddress(), rmNode.getRackName(), used,\n                   rmNode.getTotalCapability(), numContainers,\n                   rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n                   rmNode.getNodeLabels());\n \n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n \n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n \n       // add preemption to the allocateResponse message (if any)\n       allocateResponse\n           .setPreemptionMessage(generatePreemptionMessage(allocation));\n \n       // update AMRMToken if the token is rolled-up\n       MasterKeyData nextMasterKey \u003d\n           this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n \n       if (nextMasterKey !\u003d null\n           \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n             .getKeyId()) {\n-        Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d\n-            rmContext.getAMRMTokenSecretManager().createAndGetAMRMToken(\n-              appAttemptId);\n-        ((RMAppAttemptImpl)appAttempt).setAMRMToken(amrmToken);\n+        RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n+        Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n+        if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n+            appAttemptImpl.getAMRMTokenKeyId()) {\n+          LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n+              + \" to application: \" + applicationId);\n+          amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n+              .createAndGetAMRMToken(appAttemptId);\n+          appAttemptImpl.setAMRMToken(amrmToken);\n+        }\n         allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n           .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n             .toString(), amrmToken.getPassword(), amrmToken.getService()\n             .toString()));\n-        LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n-            + \" to application: \" + applicationId);\n       }\n \n       /*\n        * As we are updating the response inside the lock object so we don\u0027t\n        * need to worry about unregister call occurring in between (which\n        * removes the lock object).\n        */\n       lock.setAllocateResponse(allocateResponse);\n       return allocateResponse;\n     }    \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    AMRMTokenIdentifier amrmTokenIdentifier \u003d authorizeRequest();\n\n    ApplicationAttemptId appAttemptId \u003d\n        amrmTokenIdentifier.getApplicationAttemptId();\n    ApplicationId applicationId \u003d appAttemptId.getApplicationId();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n    if (lock \u003d\u003d null) {\n      String message \u003d\n          \"Application attempt \" + appAttemptId\n              + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n      LOG.error(message);\n      throw new ApplicationAttemptNotFoundException(message);\n    }\n    synchronized (lock) {\n      AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n      if (!hasApplicationMasterRegistered(appAttemptId)) {\n        String message \u003d\n            \"AM is not registered for known application attempt: \" + appAttemptId\n                + \" or RM had restarted after AM registered . AM should re-register.\";\n        LOG.info(message);\n        RMAuditLogger.logFailure(\n          this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n            .getUser(), AuditConstants.AM_ALLOCATE, \"\",\n          \"ApplicationMasterService\", message, applicationId, appAttemptId);\n        throw new ApplicationMasterNotRegisteredException(message);\n      }\n\n      if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n        /* old heartbeat */\n        return lastResponse;\n      } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n        String message \u003d\n            \"Invalid responseId in AllocateRequest from application attempt: \"\n                + appAttemptId + \", expect responseId to be \"\n                + (lastResponse.getResponseId() + 1);\n        throw new InvalidApplicationMasterRequestException(message);\n      }\n\n      //filter illegal progress values\n      float filteredProgress \u003d request.getProgress();\n      if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n        || filteredProgress \u003c 0) {\n         request.setProgress(0);\n      } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n        request.setProgress(1);\n      }\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      ResourceBlacklistRequest blacklistRequest \u003d\n          request.getResourceBlacklistRequest();\n      List\u003cString\u003e blacklistAdditions \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n      List\u003cString\u003e blacklistRemovals \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n      RMApp app \u003d\n          this.rmContext.getRMApps().get(applicationId);\n      \n      // set label expression for Resource Requests if resourceName\u003dANY \n      ApplicationSubmissionContext asc \u003d app.getApplicationSubmissionContext();\n      for (ResourceRequest req : ask) {\n        if (null \u003d\u003d req.getNodeLabelExpression()\n            \u0026\u0026 ResourceRequest.ANY.equals(req.getResourceName())) {\n          req.setNodeLabelExpression(asc.getNodeLabelExpression());\n        }\n      }\n              \n      // sanity check\n      try {\n        RMServerUtils.validateResourceRequests(ask,\n            rScheduler.getMaximumResourceCapability(), app.getQueue(),\n            rScheduler);\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      try {\n        RMServerUtils.validateBlacklistRequest(blacklistRequest);\n      }  catch (InvalidResourceBlacklistRequestException e) {\n        LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n        throw e;\n      }\n\n      // In the case of work-preserving AM restart, it\u0027s possible for the\n      // AM to release containers from the earlier attempt.\n      if (!app.getApplicationSubmissionContext()\n        .getKeepContainersAcrossApplicationAttempts()) {\n        try {\n          RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n        } catch (InvalidContainerReleaseException e) {\n          LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n          throw e;\n        }\n      }\n\n      // Send new requests to appAttempt.\n      Allocation allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release, \n              blacklistAdditions, blacklistRemovals);\n\n      if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n        LOG.info(\"blacklist are updated in Scheduler.\" +\n            \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n            \"blacklistRemovals: \" + blacklistRemovals);\n      }\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n      if (!allocation.getContainers().isEmpty()) {\n        allocateResponse.setNMTokens(allocation.getNMTokens());\n      }\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeId nodeId \u003d rmNode.getNodeID();\n          NodeReport report \u003d\n              BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n                  rmNode.getHttpAddress(), rmNode.getRackName(), used,\n                  rmNode.getTotalCapability(), numContainers,\n                  rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n                  rmNode.getNodeLabels());\n\n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n\n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n\n      // add preemption to the allocateResponse message (if any)\n      allocateResponse\n          .setPreemptionMessage(generatePreemptionMessage(allocation));\n\n      // update AMRMToken if the token is rolled-up\n      MasterKeyData nextMasterKey \u003d\n          this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n\n      if (nextMasterKey !\u003d null\n          \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n            .getKeyId()) {\n        RMAppAttemptImpl appAttemptImpl \u003d (RMAppAttemptImpl)appAttempt;\n        Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d appAttempt.getAMRMToken();\n        if (nextMasterKey.getMasterKey().getKeyId() !\u003d\n            appAttemptImpl.getAMRMTokenKeyId()) {\n          LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n              + \" to application: \" + applicationId);\n          amrmToken \u003d rmContext.getAMRMTokenSecretManager()\n              .createAndGetAMRMToken(appAttemptId);\n          appAttemptImpl.setAMRMToken(amrmToken);\n        }\n        allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n          .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n            .toString(), amrmToken.getPassword(), amrmToken.getService()\n            .toString()));\n      }\n\n      /*\n       * As we are updating the response inside the lock object so we don\u0027t\n       * need to worry about unregister call occurring in between (which\n       * removes the lock object).\n       */\n      lock.setAllocateResponse(allocateResponse);\n      return allocateResponse;\n    }    \n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "c1957fef29b07fea70938e971b30532a1e131fd0": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2694. Ensure only single node label specified in ResourceRequest. Contributed by Wangda Tan\n",
      "commitDate": "06/02/15 11:34 AM",
      "commitName": "c1957fef29b07fea70938e971b30532a1e131fd0",
      "commitAuthor": "Jian He",
      "commitDateOld": "05/02/15 11:28 AM",
      "commitNameOld": "69c8a7f45be5c0aa6787b07f328d74f1e2ba5628",
      "commitAuthorOld": "Jason Lowe",
      "daysBetweenCommits": 1.0,
      "commitsBetweenForRepo": 10,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,193 +1,194 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n     AMRMTokenIdentifier amrmTokenIdentifier \u003d authorizeRequest();\n \n     ApplicationAttemptId appAttemptId \u003d\n         amrmTokenIdentifier.getApplicationAttemptId();\n     ApplicationId applicationId \u003d appAttemptId.getApplicationId();\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n     if (lock \u003d\u003d null) {\n       String message \u003d\n           \"Application attempt \" + appAttemptId\n               + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n       LOG.error(message);\n       throw new ApplicationAttemptNotFoundException(message);\n     }\n     synchronized (lock) {\n       AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n       if (!hasApplicationMasterRegistered(appAttemptId)) {\n         String message \u003d\n             \"AM is not registered for known application attempt: \" + appAttemptId\n                 + \" or RM had restarted after AM registered . AM should re-register.\";\n         LOG.info(message);\n         RMAuditLogger.logFailure(\n           this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n             .getUser(), AuditConstants.AM_ALLOCATE, \"\",\n           \"ApplicationMasterService\", message, applicationId, appAttemptId);\n         throw new ApplicationMasterNotRegisteredException(message);\n       }\n \n       if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n         /* old heartbeat */\n         return lastResponse;\n       } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n         String message \u003d\n             \"Invalid responseId in AllocateRequest from application attempt: \"\n                 + appAttemptId + \", expect responseId to be \"\n                 + (lastResponse.getResponseId() + 1);\n         throw new InvalidApplicationMasterRequestException(message);\n       }\n \n       //filter illegal progress values\n       float filteredProgress \u003d request.getProgress();\n       if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n         || filteredProgress \u003c 0) {\n          request.setProgress(0);\n       } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n         request.setProgress(1);\n       }\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n       ResourceBlacklistRequest blacklistRequest \u003d\n           request.getResourceBlacklistRequest();\n       List\u003cString\u003e blacklistAdditions \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n       List\u003cString\u003e blacklistRemovals \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n       RMApp app \u003d\n           this.rmContext.getRMApps().get(applicationId);\n       \n-      // set label expression for Resource Requests\n+      // set label expression for Resource Requests if resourceName\u003dANY \n       ApplicationSubmissionContext asc \u003d app.getApplicationSubmissionContext();\n       for (ResourceRequest req : ask) {\n-        if (null \u003d\u003d req.getNodeLabelExpression()) {\n+        if (null \u003d\u003d req.getNodeLabelExpression()\n+            \u0026\u0026 ResourceRequest.ANY.equals(req.getResourceName())) {\n           req.setNodeLabelExpression(asc.getNodeLabelExpression());\n         }\n       }\n               \n       // sanity check\n       try {\n         RMServerUtils.validateResourceRequests(ask,\n             rScheduler.getMaximumResourceCapability(), app.getQueue(),\n             rScheduler);\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       try {\n         RMServerUtils.validateBlacklistRequest(blacklistRequest);\n       }  catch (InvalidResourceBlacklistRequestException e) {\n         LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n         throw e;\n       }\n \n       // In the case of work-preserving AM restart, it\u0027s possible for the\n       // AM to release containers from the earlier attempt.\n       if (!app.getApplicationSubmissionContext()\n         .getKeepContainersAcrossApplicationAttempts()) {\n         try {\n           RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n         } catch (InvalidContainerReleaseException e) {\n           LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n           throw e;\n         }\n       }\n \n       // Send new requests to appAttempt.\n       Allocation allocation \u003d\n           this.rScheduler.allocate(appAttemptId, ask, release, \n               blacklistAdditions, blacklistRemovals);\n \n       if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n         LOG.info(\"blacklist are updated in Scheduler.\" +\n             \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n             \"blacklistRemovals: \" + blacklistRemovals);\n       }\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n       if (!allocation.getContainers().isEmpty()) {\n         allocateResponse.setNMTokens(allocation.getNMTokens());\n       }\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeId nodeId \u003d rmNode.getNodeID();\n           NodeReport report \u003d\n               BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n                   rmNode.getHttpAddress(), rmNode.getRackName(), used,\n                   rmNode.getTotalCapability(), numContainers,\n                   rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n                   rmNode.getNodeLabels());\n \n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n \n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n \n       // add preemption to the allocateResponse message (if any)\n       allocateResponse\n           .setPreemptionMessage(generatePreemptionMessage(allocation));\n \n       // update AMRMToken if the token is rolled-up\n       MasterKeyData nextMasterKey \u003d\n           this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n \n       if (nextMasterKey !\u003d null\n           \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n             .getKeyId()) {\n         Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d\n             rmContext.getAMRMTokenSecretManager().createAndGetAMRMToken(\n               appAttemptId);\n         ((RMAppAttemptImpl)appAttempt).setAMRMToken(amrmToken);\n         allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n           .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n             .toString(), amrmToken.getPassword(), amrmToken.getService()\n             .toString()));\n         LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n             + \" to application: \" + applicationId);\n       }\n \n       /*\n        * As we are updating the response inside the lock object so we don\u0027t\n        * need to worry about unregister call occurring in between (which\n        * removes the lock object).\n        */\n       lock.setAllocateResponse(allocateResponse);\n       return allocateResponse;\n     }    \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    AMRMTokenIdentifier amrmTokenIdentifier \u003d authorizeRequest();\n\n    ApplicationAttemptId appAttemptId \u003d\n        amrmTokenIdentifier.getApplicationAttemptId();\n    ApplicationId applicationId \u003d appAttemptId.getApplicationId();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n    if (lock \u003d\u003d null) {\n      String message \u003d\n          \"Application attempt \" + appAttemptId\n              + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n      LOG.error(message);\n      throw new ApplicationAttemptNotFoundException(message);\n    }\n    synchronized (lock) {\n      AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n      if (!hasApplicationMasterRegistered(appAttemptId)) {\n        String message \u003d\n            \"AM is not registered for known application attempt: \" + appAttemptId\n                + \" or RM had restarted after AM registered . AM should re-register.\";\n        LOG.info(message);\n        RMAuditLogger.logFailure(\n          this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n            .getUser(), AuditConstants.AM_ALLOCATE, \"\",\n          \"ApplicationMasterService\", message, applicationId, appAttemptId);\n        throw new ApplicationMasterNotRegisteredException(message);\n      }\n\n      if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n        /* old heartbeat */\n        return lastResponse;\n      } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n        String message \u003d\n            \"Invalid responseId in AllocateRequest from application attempt: \"\n                + appAttemptId + \", expect responseId to be \"\n                + (lastResponse.getResponseId() + 1);\n        throw new InvalidApplicationMasterRequestException(message);\n      }\n\n      //filter illegal progress values\n      float filteredProgress \u003d request.getProgress();\n      if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n        || filteredProgress \u003c 0) {\n         request.setProgress(0);\n      } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n        request.setProgress(1);\n      }\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      ResourceBlacklistRequest blacklistRequest \u003d\n          request.getResourceBlacklistRequest();\n      List\u003cString\u003e blacklistAdditions \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n      List\u003cString\u003e blacklistRemovals \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n      RMApp app \u003d\n          this.rmContext.getRMApps().get(applicationId);\n      \n      // set label expression for Resource Requests if resourceName\u003dANY \n      ApplicationSubmissionContext asc \u003d app.getApplicationSubmissionContext();\n      for (ResourceRequest req : ask) {\n        if (null \u003d\u003d req.getNodeLabelExpression()\n            \u0026\u0026 ResourceRequest.ANY.equals(req.getResourceName())) {\n          req.setNodeLabelExpression(asc.getNodeLabelExpression());\n        }\n      }\n              \n      // sanity check\n      try {\n        RMServerUtils.validateResourceRequests(ask,\n            rScheduler.getMaximumResourceCapability(), app.getQueue(),\n            rScheduler);\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      try {\n        RMServerUtils.validateBlacklistRequest(blacklistRequest);\n      }  catch (InvalidResourceBlacklistRequestException e) {\n        LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n        throw e;\n      }\n\n      // In the case of work-preserving AM restart, it\u0027s possible for the\n      // AM to release containers from the earlier attempt.\n      if (!app.getApplicationSubmissionContext()\n        .getKeepContainersAcrossApplicationAttempts()) {\n        try {\n          RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n        } catch (InvalidContainerReleaseException e) {\n          LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n          throw e;\n        }\n      }\n\n      // Send new requests to appAttempt.\n      Allocation allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release, \n              blacklistAdditions, blacklistRemovals);\n\n      if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n        LOG.info(\"blacklist are updated in Scheduler.\" +\n            \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n            \"blacklistRemovals: \" + blacklistRemovals);\n      }\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n      if (!allocation.getContainers().isEmpty()) {\n        allocateResponse.setNMTokens(allocation.getNMTokens());\n      }\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeId nodeId \u003d rmNode.getNodeID();\n          NodeReport report \u003d\n              BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n                  rmNode.getHttpAddress(), rmNode.getRackName(), used,\n                  rmNode.getTotalCapability(), numContainers,\n                  rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n                  rmNode.getNodeLabels());\n\n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n\n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n\n      // add preemption to the allocateResponse message (if any)\n      allocateResponse\n          .setPreemptionMessage(generatePreemptionMessage(allocation));\n\n      // update AMRMToken if the token is rolled-up\n      MasterKeyData nextMasterKey \u003d\n          this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n\n      if (nextMasterKey !\u003d null\n          \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n            .getKeyId()) {\n        Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d\n            rmContext.getAMRMTokenSecretManager().createAndGetAMRMToken(\n              appAttemptId);\n        ((RMAppAttemptImpl)appAttempt).setAMRMToken(amrmToken);\n        allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n          .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n            .toString(), amrmToken.getPassword(), amrmToken.getService()\n            .toString()));\n        LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n            + \" to application: \" + applicationId);\n      }\n\n      /*\n       * As we are updating the response inside the lock object so we don\u0027t\n       * need to worry about unregister call occurring in between (which\n       * removes the lock object).\n       */\n      lock.setAllocateResponse(allocateResponse);\n      return allocateResponse;\n    }    \n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "e0233c16ebd06bb3aabeb523cd17259008e243ef": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2698. Moved some node label APIs to be correctly placed in client protocol. Contributed by Wangda Tan.\n",
      "commitDate": "30/10/14 10:59 PM",
      "commitName": "e0233c16ebd06bb3aabeb523cd17259008e243ef",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "23/10/14 9:56 PM",
      "commitNameOld": "0f3b6900be1a3b2e4624f31f84656f4a32dadce9",
      "commitAuthorOld": "Zhijie Shen",
      "daysBetweenCommits": 7.04,
      "commitsBetweenForRepo": 82,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,192 +1,193 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n     AMRMTokenIdentifier amrmTokenIdentifier \u003d authorizeRequest();\n \n     ApplicationAttemptId appAttemptId \u003d\n         amrmTokenIdentifier.getApplicationAttemptId();\n     ApplicationId applicationId \u003d appAttemptId.getApplicationId();\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n     if (lock \u003d\u003d null) {\n       String message \u003d\n           \"Application attempt \" + appAttemptId\n               + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n       LOG.error(message);\n       throw new ApplicationAttemptNotFoundException(message);\n     }\n     synchronized (lock) {\n       AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n       if (!hasApplicationMasterRegistered(appAttemptId)) {\n         String message \u003d\n             \"AM is not registered for known application attempt: \" + appAttemptId\n                 + \" or RM had restarted after AM registered . AM should re-register.\";\n         LOG.info(message);\n         RMAuditLogger.logFailure(\n           this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n             .getUser(), AuditConstants.AM_ALLOCATE, \"\",\n           \"ApplicationMasterService\", message, applicationId, appAttemptId);\n         throw new ApplicationMasterNotRegisteredException(message);\n       }\n \n       if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n         /* old heartbeat */\n         return lastResponse;\n       } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n         String message \u003d\n             \"Invalid responseId in AllocateRequest from application attempt: \"\n                 + appAttemptId + \", expect responseId to be \"\n                 + (lastResponse.getResponseId() + 1);\n         throw new InvalidApplicationMasterRequestException(message);\n       }\n \n       //filter illegal progress values\n       float filteredProgress \u003d request.getProgress();\n       if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n         || filteredProgress \u003c 0) {\n          request.setProgress(0);\n       } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n         request.setProgress(1);\n       }\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n       ResourceBlacklistRequest blacklistRequest \u003d\n           request.getResourceBlacklistRequest();\n       List\u003cString\u003e blacklistAdditions \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n       List\u003cString\u003e blacklistRemovals \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n       RMApp app \u003d\n           this.rmContext.getRMApps().get(applicationId);\n       \n       // set label expression for Resource Requests\n       ApplicationSubmissionContext asc \u003d app.getApplicationSubmissionContext();\n       for (ResourceRequest req : ask) {\n         if (null \u003d\u003d req.getNodeLabelExpression()) {\n           req.setNodeLabelExpression(asc.getNodeLabelExpression());\n         }\n       }\n               \n       // sanity check\n       try {\n         RMServerUtils.validateResourceRequests(ask,\n             rScheduler.getMaximumResourceCapability(), app.getQueue(),\n             rScheduler);\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       try {\n         RMServerUtils.validateBlacklistRequest(blacklistRequest);\n       }  catch (InvalidResourceBlacklistRequestException e) {\n         LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n         throw e;\n       }\n \n       // In the case of work-preserving AM restart, it\u0027s possible for the\n       // AM to release containers from the earlier attempt.\n       if (!app.getApplicationSubmissionContext()\n         .getKeepContainersAcrossApplicationAttempts()) {\n         try {\n           RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n         } catch (InvalidContainerReleaseException e) {\n           LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n           throw e;\n         }\n       }\n \n       // Send new requests to appAttempt.\n       Allocation allocation \u003d\n           this.rScheduler.allocate(appAttemptId, ask, release, \n               blacklistAdditions, blacklistRemovals);\n \n       if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n         LOG.info(\"blacklist are updated in Scheduler.\" +\n             \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n             \"blacklistRemovals: \" + blacklistRemovals);\n       }\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n       if (!allocation.getContainers().isEmpty()) {\n         allocateResponse.setNMTokens(allocation.getNMTokens());\n       }\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n-          NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n-              rmNode.getState(),\n-              rmNode.getHttpAddress(), rmNode.getRackName(), used,\n-              rmNode.getTotalCapability(), numContainers,\n-              rmNode.getHealthReport(),\n-              rmNode.getLastHealthReportTime());\n+          NodeId nodeId \u003d rmNode.getNodeID();\n+          NodeReport report \u003d\n+              BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n+                  rmNode.getHttpAddress(), rmNode.getRackName(), used,\n+                  rmNode.getTotalCapability(), numContainers,\n+                  rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n+                  rmNode.getNodeLabels());\n \n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n \n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n \n       // add preemption to the allocateResponse message (if any)\n       allocateResponse\n           .setPreemptionMessage(generatePreemptionMessage(allocation));\n \n       // update AMRMToken if the token is rolled-up\n       MasterKeyData nextMasterKey \u003d\n           this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n \n       if (nextMasterKey !\u003d null\n           \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n             .getKeyId()) {\n         Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d\n             rmContext.getAMRMTokenSecretManager().createAndGetAMRMToken(\n               appAttemptId);\n         ((RMAppAttemptImpl)appAttempt).setAMRMToken(amrmToken);\n         allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n           .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n             .toString(), amrmToken.getPassword(), amrmToken.getService()\n             .toString()));\n         LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n             + \" to application: \" + applicationId);\n       }\n \n       /*\n        * As we are updating the response inside the lock object so we don\u0027t\n        * need to worry about unregister call occurring in between (which\n        * removes the lock object).\n        */\n       lock.setAllocateResponse(allocateResponse);\n       return allocateResponse;\n     }    \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    AMRMTokenIdentifier amrmTokenIdentifier \u003d authorizeRequest();\n\n    ApplicationAttemptId appAttemptId \u003d\n        amrmTokenIdentifier.getApplicationAttemptId();\n    ApplicationId applicationId \u003d appAttemptId.getApplicationId();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n    if (lock \u003d\u003d null) {\n      String message \u003d\n          \"Application attempt \" + appAttemptId\n              + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n      LOG.error(message);\n      throw new ApplicationAttemptNotFoundException(message);\n    }\n    synchronized (lock) {\n      AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n      if (!hasApplicationMasterRegistered(appAttemptId)) {\n        String message \u003d\n            \"AM is not registered for known application attempt: \" + appAttemptId\n                + \" or RM had restarted after AM registered . AM should re-register.\";\n        LOG.info(message);\n        RMAuditLogger.logFailure(\n          this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n            .getUser(), AuditConstants.AM_ALLOCATE, \"\",\n          \"ApplicationMasterService\", message, applicationId, appAttemptId);\n        throw new ApplicationMasterNotRegisteredException(message);\n      }\n\n      if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n        /* old heartbeat */\n        return lastResponse;\n      } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n        String message \u003d\n            \"Invalid responseId in AllocateRequest from application attempt: \"\n                + appAttemptId + \", expect responseId to be \"\n                + (lastResponse.getResponseId() + 1);\n        throw new InvalidApplicationMasterRequestException(message);\n      }\n\n      //filter illegal progress values\n      float filteredProgress \u003d request.getProgress();\n      if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n        || filteredProgress \u003c 0) {\n         request.setProgress(0);\n      } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n        request.setProgress(1);\n      }\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      ResourceBlacklistRequest blacklistRequest \u003d\n          request.getResourceBlacklistRequest();\n      List\u003cString\u003e blacklistAdditions \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n      List\u003cString\u003e blacklistRemovals \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n      RMApp app \u003d\n          this.rmContext.getRMApps().get(applicationId);\n      \n      // set label expression for Resource Requests\n      ApplicationSubmissionContext asc \u003d app.getApplicationSubmissionContext();\n      for (ResourceRequest req : ask) {\n        if (null \u003d\u003d req.getNodeLabelExpression()) {\n          req.setNodeLabelExpression(asc.getNodeLabelExpression());\n        }\n      }\n              \n      // sanity check\n      try {\n        RMServerUtils.validateResourceRequests(ask,\n            rScheduler.getMaximumResourceCapability(), app.getQueue(),\n            rScheduler);\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      try {\n        RMServerUtils.validateBlacklistRequest(blacklistRequest);\n      }  catch (InvalidResourceBlacklistRequestException e) {\n        LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n        throw e;\n      }\n\n      // In the case of work-preserving AM restart, it\u0027s possible for the\n      // AM to release containers from the earlier attempt.\n      if (!app.getApplicationSubmissionContext()\n        .getKeepContainersAcrossApplicationAttempts()) {\n        try {\n          RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n        } catch (InvalidContainerReleaseException e) {\n          LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n          throw e;\n        }\n      }\n\n      // Send new requests to appAttempt.\n      Allocation allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release, \n              blacklistAdditions, blacklistRemovals);\n\n      if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n        LOG.info(\"blacklist are updated in Scheduler.\" +\n            \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n            \"blacklistRemovals: \" + blacklistRemovals);\n      }\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n      if (!allocation.getContainers().isEmpty()) {\n        allocateResponse.setNMTokens(allocation.getNMTokens());\n      }\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeId nodeId \u003d rmNode.getNodeID();\n          NodeReport report \u003d\n              BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n                  rmNode.getHttpAddress(), rmNode.getRackName(), used,\n                  rmNode.getTotalCapability(), numContainers,\n                  rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n                  rmNode.getNodeLabels());\n\n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n\n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n\n      // add preemption to the allocateResponse message (if any)\n      allocateResponse\n          .setPreemptionMessage(generatePreemptionMessage(allocation));\n\n      // update AMRMToken if the token is rolled-up\n      MasterKeyData nextMasterKey \u003d\n          this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n\n      if (nextMasterKey !\u003d null\n          \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n            .getKeyId()) {\n        Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d\n            rmContext.getAMRMTokenSecretManager().createAndGetAMRMToken(\n              appAttemptId);\n        ((RMAppAttemptImpl)appAttempt).setAMRMToken(amrmToken);\n        allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n          .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n            .toString(), amrmToken.getPassword(), amrmToken.getService()\n            .toString()));\n        LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n            + \" to application: \" + applicationId);\n      }\n\n      /*\n       * As we are updating the response inside the lock object so we don\u0027t\n       * need to worry about unregister call occurring in between (which\n       * removes the lock object).\n       */\n      lock.setAllocateResponse(allocateResponse);\n      return allocateResponse;\n    }    \n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "0f3b6900be1a3b2e4624f31f84656f4a32dadce9": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2209. Replaced AM resync/shutdown command with corresponding exceptions and made related MR changes. Contributed by Jian He.\n",
      "commitDate": "23/10/14 9:56 PM",
      "commitName": "0f3b6900be1a3b2e4624f31f84656f4a32dadce9",
      "commitAuthor": "Zhijie Shen",
      "commitDateOld": "17/10/14 4:35 PM",
      "commitNameOld": "c3de2412eb7633ff16c67e71e73bbe27a982d984",
      "commitAuthorOld": "Jian He",
      "daysBetweenCommits": 6.22,
      "commitsBetweenForRepo": 49,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,193 +1,192 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n     AMRMTokenIdentifier amrmTokenIdentifier \u003d authorizeRequest();\n \n     ApplicationAttemptId appAttemptId \u003d\n         amrmTokenIdentifier.getApplicationAttemptId();\n     ApplicationId applicationId \u003d appAttemptId.getApplicationId();\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n     if (lock \u003d\u003d null) {\n-      LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n-      return shutdown;\n+      String message \u003d\n+          \"Application attempt \" + appAttemptId\n+              + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n+      LOG.error(message);\n+      throw new ApplicationAttemptNotFoundException(message);\n     }\n     synchronized (lock) {\n       AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n       if (!hasApplicationMasterRegistered(appAttemptId)) {\n         String message \u003d\n-            \"Application Master is not registered for known application: \"\n-                + applicationId\n-                + \". Let AM resync.\";\n+            \"AM is not registered for known application attempt: \" + appAttemptId\n+                + \" or RM had restarted after AM registered . AM should re-register.\";\n         LOG.info(message);\n         RMAuditLogger.logFailure(\n-            this.rmContext.getRMApps().get(applicationId)\n-                .getUser(), AuditConstants.REGISTER_AM, \"\",\n-            \"ApplicationMasterService\", message,\n-            applicationId,\n-            appAttemptId);\n-        return resync;\n+          this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n+            .getUser(), AuditConstants.AM_ALLOCATE, \"\",\n+          \"ApplicationMasterService\", message, applicationId, appAttemptId);\n+        throw new ApplicationMasterNotRegisteredException(message);\n       }\n \n       if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n         /* old heartbeat */\n         return lastResponse;\n       } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n-        LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n-        // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n-        // Reboot is not useful since after AM reboots, it will send register\n-        // and\n-        // get an exception. Might as well throw an exception here.\n-        return resync;\n+        String message \u003d\n+            \"Invalid responseId in AllocateRequest from application attempt: \"\n+                + appAttemptId + \", expect responseId to be \"\n+                + (lastResponse.getResponseId() + 1);\n+        throw new InvalidApplicationMasterRequestException(message);\n       }\n \n       //filter illegal progress values\n       float filteredProgress \u003d request.getProgress();\n       if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n         || filteredProgress \u003c 0) {\n          request.setProgress(0);\n       } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n         request.setProgress(1);\n       }\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n       ResourceBlacklistRequest blacklistRequest \u003d\n           request.getResourceBlacklistRequest();\n       List\u003cString\u003e blacklistAdditions \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n       List\u003cString\u003e blacklistRemovals \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n       RMApp app \u003d\n           this.rmContext.getRMApps().get(applicationId);\n       \n       // set label expression for Resource Requests\n       ApplicationSubmissionContext asc \u003d app.getApplicationSubmissionContext();\n       for (ResourceRequest req : ask) {\n         if (null \u003d\u003d req.getNodeLabelExpression()) {\n           req.setNodeLabelExpression(asc.getNodeLabelExpression());\n         }\n       }\n               \n       // sanity check\n       try {\n         RMServerUtils.validateResourceRequests(ask,\n             rScheduler.getMaximumResourceCapability(), app.getQueue(),\n             rScheduler);\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       try {\n         RMServerUtils.validateBlacklistRequest(blacklistRequest);\n       }  catch (InvalidResourceBlacklistRequestException e) {\n         LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n         throw e;\n       }\n \n       // In the case of work-preserving AM restart, it\u0027s possible for the\n       // AM to release containers from the earlier attempt.\n       if (!app.getApplicationSubmissionContext()\n         .getKeepContainersAcrossApplicationAttempts()) {\n         try {\n           RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n         } catch (InvalidContainerReleaseException e) {\n           LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n           throw e;\n         }\n       }\n \n       // Send new requests to appAttempt.\n       Allocation allocation \u003d\n           this.rScheduler.allocate(appAttemptId, ask, release, \n               blacklistAdditions, blacklistRemovals);\n \n       if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n         LOG.info(\"blacklist are updated in Scheduler.\" +\n             \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n             \"blacklistRemovals: \" + blacklistRemovals);\n       }\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n       if (!allocation.getContainers().isEmpty()) {\n         allocateResponse.setNMTokens(allocation.getNMTokens());\n       }\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n               rmNode.getState(),\n               rmNode.getHttpAddress(), rmNode.getRackName(), used,\n               rmNode.getTotalCapability(), numContainers,\n               rmNode.getHealthReport(),\n               rmNode.getLastHealthReportTime());\n \n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n \n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n \n       // add preemption to the allocateResponse message (if any)\n       allocateResponse\n           .setPreemptionMessage(generatePreemptionMessage(allocation));\n \n       // update AMRMToken if the token is rolled-up\n       MasterKeyData nextMasterKey \u003d\n           this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n \n       if (nextMasterKey !\u003d null\n           \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n             .getKeyId()) {\n         Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d\n             rmContext.getAMRMTokenSecretManager().createAndGetAMRMToken(\n               appAttemptId);\n         ((RMAppAttemptImpl)appAttempt).setAMRMToken(amrmToken);\n         allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n           .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n             .toString(), amrmToken.getPassword(), amrmToken.getService()\n             .toString()));\n         LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n             + \" to application: \" + applicationId);\n       }\n \n       /*\n        * As we are updating the response inside the lock object so we don\u0027t\n        * need to worry about unregister call occurring in between (which\n        * removes the lock object).\n        */\n       lock.setAllocateResponse(allocateResponse);\n       return allocateResponse;\n     }    \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    AMRMTokenIdentifier amrmTokenIdentifier \u003d authorizeRequest();\n\n    ApplicationAttemptId appAttemptId \u003d\n        amrmTokenIdentifier.getApplicationAttemptId();\n    ApplicationId applicationId \u003d appAttemptId.getApplicationId();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n    if (lock \u003d\u003d null) {\n      String message \u003d\n          \"Application attempt \" + appAttemptId\n              + \" doesn\u0027t exist in ApplicationMasterService cache.\";\n      LOG.error(message);\n      throw new ApplicationAttemptNotFoundException(message);\n    }\n    synchronized (lock) {\n      AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n      if (!hasApplicationMasterRegistered(appAttemptId)) {\n        String message \u003d\n            \"AM is not registered for known application attempt: \" + appAttemptId\n                + \" or RM had restarted after AM registered . AM should re-register.\";\n        LOG.info(message);\n        RMAuditLogger.logFailure(\n          this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n            .getUser(), AuditConstants.AM_ALLOCATE, \"\",\n          \"ApplicationMasterService\", message, applicationId, appAttemptId);\n        throw new ApplicationMasterNotRegisteredException(message);\n      }\n\n      if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n        /* old heartbeat */\n        return lastResponse;\n      } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n        String message \u003d\n            \"Invalid responseId in AllocateRequest from application attempt: \"\n                + appAttemptId + \", expect responseId to be \"\n                + (lastResponse.getResponseId() + 1);\n        throw new InvalidApplicationMasterRequestException(message);\n      }\n\n      //filter illegal progress values\n      float filteredProgress \u003d request.getProgress();\n      if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n        || filteredProgress \u003c 0) {\n         request.setProgress(0);\n      } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n        request.setProgress(1);\n      }\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      ResourceBlacklistRequest blacklistRequest \u003d\n          request.getResourceBlacklistRequest();\n      List\u003cString\u003e blacklistAdditions \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n      List\u003cString\u003e blacklistRemovals \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n      RMApp app \u003d\n          this.rmContext.getRMApps().get(applicationId);\n      \n      // set label expression for Resource Requests\n      ApplicationSubmissionContext asc \u003d app.getApplicationSubmissionContext();\n      for (ResourceRequest req : ask) {\n        if (null \u003d\u003d req.getNodeLabelExpression()) {\n          req.setNodeLabelExpression(asc.getNodeLabelExpression());\n        }\n      }\n              \n      // sanity check\n      try {\n        RMServerUtils.validateResourceRequests(ask,\n            rScheduler.getMaximumResourceCapability(), app.getQueue(),\n            rScheduler);\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      try {\n        RMServerUtils.validateBlacklistRequest(blacklistRequest);\n      }  catch (InvalidResourceBlacklistRequestException e) {\n        LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n        throw e;\n      }\n\n      // In the case of work-preserving AM restart, it\u0027s possible for the\n      // AM to release containers from the earlier attempt.\n      if (!app.getApplicationSubmissionContext()\n        .getKeepContainersAcrossApplicationAttempts()) {\n        try {\n          RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n        } catch (InvalidContainerReleaseException e) {\n          LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n          throw e;\n        }\n      }\n\n      // Send new requests to appAttempt.\n      Allocation allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release, \n              blacklistAdditions, blacklistRemovals);\n\n      if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n        LOG.info(\"blacklist are updated in Scheduler.\" +\n            \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n            \"blacklistRemovals: \" + blacklistRemovals);\n      }\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n      if (!allocation.getContainers().isEmpty()) {\n        allocateResponse.setNMTokens(allocation.getNMTokens());\n      }\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n              rmNode.getState(),\n              rmNode.getHttpAddress(), rmNode.getRackName(), used,\n              rmNode.getTotalCapability(), numContainers,\n              rmNode.getHealthReport(),\n              rmNode.getLastHealthReportTime());\n\n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n\n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n\n      // add preemption to the allocateResponse message (if any)\n      allocateResponse\n          .setPreemptionMessage(generatePreemptionMessage(allocation));\n\n      // update AMRMToken if the token is rolled-up\n      MasterKeyData nextMasterKey \u003d\n          this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n\n      if (nextMasterKey !\u003d null\n          \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n            .getKeyId()) {\n        Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d\n            rmContext.getAMRMTokenSecretManager().createAndGetAMRMToken(\n              appAttemptId);\n        ((RMAppAttemptImpl)appAttempt).setAMRMToken(amrmToken);\n        allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n          .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n            .toString(), amrmToken.getPassword(), amrmToken.getService()\n            .toString()));\n        LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n            + \" to application: \" + applicationId);\n      }\n\n      /*\n       * As we are updating the response inside the lock object so we don\u0027t\n       * need to worry about unregister call occurring in between (which\n       * removes the lock object).\n       */\n      lock.setAllocateResponse(allocateResponse);\n      return allocateResponse;\n    }    \n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "f2ea555ac6c06a3f2f6559731f48711fff05d3f1": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2496. Enhanced Capacity Scheduler to have basic support for allocating resources based on node-labels. Contributed by Wangda Tan.\nYARN-2500. Ehnaced ResourceManager to support schedulers allocating resources based on node-labels. Contributed by Wangda Tan.\n",
      "commitDate": "15/10/14 6:33 PM",
      "commitName": "f2ea555ac6c06a3f2f6559731f48711fff05d3f1",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "11/09/14 10:19 PM",
      "commitNameOld": "469ea3dcef6e427d02fd08b859b2789cc25189f9",
      "commitAuthorOld": "Zhijie Shen",
      "daysBetweenCommits": 33.84,
      "commitsBetweenForRepo": 350,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,183 +1,193 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n     AMRMTokenIdentifier amrmTokenIdentifier \u003d authorizeRequest();\n \n     ApplicationAttemptId appAttemptId \u003d\n         amrmTokenIdentifier.getApplicationAttemptId();\n+    ApplicationId applicationId \u003d appAttemptId.getApplicationId();\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n     if (lock \u003d\u003d null) {\n       LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n       return shutdown;\n     }\n     synchronized (lock) {\n       AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n       if (!hasApplicationMasterRegistered(appAttemptId)) {\n         String message \u003d\n             \"Application Master is not registered for known application: \"\n-                + appAttemptId.getApplicationId()\n+                + applicationId\n                 + \". Let AM resync.\";\n         LOG.info(message);\n         RMAuditLogger.logFailure(\n-            this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n+            this.rmContext.getRMApps().get(applicationId)\n                 .getUser(), AuditConstants.REGISTER_AM, \"\",\n             \"ApplicationMasterService\", message,\n-            appAttemptId.getApplicationId(),\n+            applicationId,\n             appAttemptId);\n         return resync;\n       }\n \n       if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n         /* old heartbeat */\n         return lastResponse;\n       } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n         LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n         // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n         // Reboot is not useful since after AM reboots, it will send register\n         // and\n         // get an exception. Might as well throw an exception here.\n         return resync;\n       }\n \n       //filter illegal progress values\n       float filteredProgress \u003d request.getProgress();\n       if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n         || filteredProgress \u003c 0) {\n          request.setProgress(0);\n       } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n         request.setProgress(1);\n       }\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n       ResourceBlacklistRequest blacklistRequest \u003d\n           request.getResourceBlacklistRequest();\n       List\u003cString\u003e blacklistAdditions \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n       List\u003cString\u003e blacklistRemovals \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n-\n+      RMApp app \u003d\n+          this.rmContext.getRMApps().get(applicationId);\n+      \n+      // set label expression for Resource Requests\n+      ApplicationSubmissionContext asc \u003d app.getApplicationSubmissionContext();\n+      for (ResourceRequest req : ask) {\n+        if (null \u003d\u003d req.getNodeLabelExpression()) {\n+          req.setNodeLabelExpression(asc.getNodeLabelExpression());\n+        }\n+      }\n+              \n       // sanity check\n       try {\n         RMServerUtils.validateResourceRequests(ask,\n-            rScheduler.getMaximumResourceCapability());\n+            rScheduler.getMaximumResourceCapability(), app.getQueue(),\n+            rScheduler);\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       try {\n         RMServerUtils.validateBlacklistRequest(blacklistRequest);\n       }  catch (InvalidResourceBlacklistRequestException e) {\n         LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n         throw e;\n       }\n \n-      RMApp app \u003d\n-          this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n       // In the case of work-preserving AM restart, it\u0027s possible for the\n       // AM to release containers from the earlier attempt.\n       if (!app.getApplicationSubmissionContext()\n         .getKeepContainersAcrossApplicationAttempts()) {\n         try {\n           RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n         } catch (InvalidContainerReleaseException e) {\n           LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n           throw e;\n         }\n       }\n \n       // Send new requests to appAttempt.\n       Allocation allocation \u003d\n           this.rScheduler.allocate(appAttemptId, ask, release, \n               blacklistAdditions, blacklistRemovals);\n \n       if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n         LOG.info(\"blacklist are updated in Scheduler.\" +\n             \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n             \"blacklistRemovals: \" + blacklistRemovals);\n       }\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n       if (!allocation.getContainers().isEmpty()) {\n         allocateResponse.setNMTokens(allocation.getNMTokens());\n       }\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n               rmNode.getState(),\n               rmNode.getHttpAddress(), rmNode.getRackName(), used,\n               rmNode.getTotalCapability(), numContainers,\n               rmNode.getHealthReport(),\n               rmNode.getLastHealthReportTime());\n \n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n \n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n \n       // add preemption to the allocateResponse message (if any)\n       allocateResponse\n           .setPreemptionMessage(generatePreemptionMessage(allocation));\n \n       // update AMRMToken if the token is rolled-up\n       MasterKeyData nextMasterKey \u003d\n           this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n \n       if (nextMasterKey !\u003d null\n           \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n             .getKeyId()) {\n         Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d\n             rmContext.getAMRMTokenSecretManager().createAndGetAMRMToken(\n               appAttemptId);\n         ((RMAppAttemptImpl)appAttempt).setAMRMToken(amrmToken);\n         allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n           .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n             .toString(), amrmToken.getPassword(), amrmToken.getService()\n             .toString()));\n         LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n-            + \" to application: \" + appAttemptId.getApplicationId());\n+            + \" to application: \" + applicationId);\n       }\n \n       /*\n        * As we are updating the response inside the lock object so we don\u0027t\n        * need to worry about unregister call occurring in between (which\n        * removes the lock object).\n        */\n       lock.setAllocateResponse(allocateResponse);\n       return allocateResponse;\n     }    \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    AMRMTokenIdentifier amrmTokenIdentifier \u003d authorizeRequest();\n\n    ApplicationAttemptId appAttemptId \u003d\n        amrmTokenIdentifier.getApplicationAttemptId();\n    ApplicationId applicationId \u003d appAttemptId.getApplicationId();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n    if (lock \u003d\u003d null) {\n      LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n      return shutdown;\n    }\n    synchronized (lock) {\n      AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n      if (!hasApplicationMasterRegistered(appAttemptId)) {\n        String message \u003d\n            \"Application Master is not registered for known application: \"\n                + applicationId\n                + \". Let AM resync.\";\n        LOG.info(message);\n        RMAuditLogger.logFailure(\n            this.rmContext.getRMApps().get(applicationId)\n                .getUser(), AuditConstants.REGISTER_AM, \"\",\n            \"ApplicationMasterService\", message,\n            applicationId,\n            appAttemptId);\n        return resync;\n      }\n\n      if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n        /* old heartbeat */\n        return lastResponse;\n      } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n        LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n        // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n        // Reboot is not useful since after AM reboots, it will send register\n        // and\n        // get an exception. Might as well throw an exception here.\n        return resync;\n      }\n\n      //filter illegal progress values\n      float filteredProgress \u003d request.getProgress();\n      if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n        || filteredProgress \u003c 0) {\n         request.setProgress(0);\n      } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n        request.setProgress(1);\n      }\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      ResourceBlacklistRequest blacklistRequest \u003d\n          request.getResourceBlacklistRequest();\n      List\u003cString\u003e blacklistAdditions \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n      List\u003cString\u003e blacklistRemovals \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n      RMApp app \u003d\n          this.rmContext.getRMApps().get(applicationId);\n      \n      // set label expression for Resource Requests\n      ApplicationSubmissionContext asc \u003d app.getApplicationSubmissionContext();\n      for (ResourceRequest req : ask) {\n        if (null \u003d\u003d req.getNodeLabelExpression()) {\n          req.setNodeLabelExpression(asc.getNodeLabelExpression());\n        }\n      }\n              \n      // sanity check\n      try {\n        RMServerUtils.validateResourceRequests(ask,\n            rScheduler.getMaximumResourceCapability(), app.getQueue(),\n            rScheduler);\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      try {\n        RMServerUtils.validateBlacklistRequest(blacklistRequest);\n      }  catch (InvalidResourceBlacklistRequestException e) {\n        LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n        throw e;\n      }\n\n      // In the case of work-preserving AM restart, it\u0027s possible for the\n      // AM to release containers from the earlier attempt.\n      if (!app.getApplicationSubmissionContext()\n        .getKeepContainersAcrossApplicationAttempts()) {\n        try {\n          RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n        } catch (InvalidContainerReleaseException e) {\n          LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n          throw e;\n        }\n      }\n\n      // Send new requests to appAttempt.\n      Allocation allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release, \n              blacklistAdditions, blacklistRemovals);\n\n      if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n        LOG.info(\"blacklist are updated in Scheduler.\" +\n            \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n            \"blacklistRemovals: \" + blacklistRemovals);\n      }\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n      if (!allocation.getContainers().isEmpty()) {\n        allocateResponse.setNMTokens(allocation.getNMTokens());\n      }\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n              rmNode.getState(),\n              rmNode.getHttpAddress(), rmNode.getRackName(), used,\n              rmNode.getTotalCapability(), numContainers,\n              rmNode.getHealthReport(),\n              rmNode.getLastHealthReportTime());\n\n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n\n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n\n      // add preemption to the allocateResponse message (if any)\n      allocateResponse\n          .setPreemptionMessage(generatePreemptionMessage(allocation));\n\n      // update AMRMToken if the token is rolled-up\n      MasterKeyData nextMasterKey \u003d\n          this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n\n      if (nextMasterKey !\u003d null\n          \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n            .getKeyId()) {\n        Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d\n            rmContext.getAMRMTokenSecretManager().createAndGetAMRMToken(\n              appAttemptId);\n        ((RMAppAttemptImpl)appAttempt).setAMRMToken(amrmToken);\n        allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n          .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n            .toString(), amrmToken.getPassword(), amrmToken.getService()\n            .toString()));\n        LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n            + \" to application: \" + applicationId);\n      }\n\n      /*\n       * As we are updating the response inside the lock object so we don\u0027t\n       * need to worry about unregister call occurring in between (which\n       * removes the lock object).\n       */\n      lock.setAllocateResponse(allocateResponse);\n      return allocateResponse;\n    }    \n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "469ea3dcef6e427d02fd08b859b2789cc25189f9": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2538. Added logs when RM sends roll-overed AMRMToken to AM. Contributed by Xuan Gong.\n",
      "commitDate": "11/09/14 10:19 PM",
      "commitName": "469ea3dcef6e427d02fd08b859b2789cc25189f9",
      "commitAuthor": "Zhijie Shen",
      "commitDateOld": "10/09/14 10:15 AM",
      "commitNameOld": "b67d5ba7842cc10695d987f217027848a5a8c3d8",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 1.5,
      "commitsBetweenForRepo": 24,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,181 +1,183 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n     AMRMTokenIdentifier amrmTokenIdentifier \u003d authorizeRequest();\n \n     ApplicationAttemptId appAttemptId \u003d\n         amrmTokenIdentifier.getApplicationAttemptId();\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n     if (lock \u003d\u003d null) {\n       LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n       return shutdown;\n     }\n     synchronized (lock) {\n       AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n       if (!hasApplicationMasterRegistered(appAttemptId)) {\n         String message \u003d\n             \"Application Master is not registered for known application: \"\n                 + appAttemptId.getApplicationId()\n                 + \". Let AM resync.\";\n         LOG.info(message);\n         RMAuditLogger.logFailure(\n             this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n                 .getUser(), AuditConstants.REGISTER_AM, \"\",\n             \"ApplicationMasterService\", message,\n             appAttemptId.getApplicationId(),\n             appAttemptId);\n         return resync;\n       }\n \n       if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n         /* old heartbeat */\n         return lastResponse;\n       } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n         LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n         // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n         // Reboot is not useful since after AM reboots, it will send register\n         // and\n         // get an exception. Might as well throw an exception here.\n         return resync;\n       }\n \n       //filter illegal progress values\n       float filteredProgress \u003d request.getProgress();\n       if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n         || filteredProgress \u003c 0) {\n          request.setProgress(0);\n       } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n         request.setProgress(1);\n       }\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n       ResourceBlacklistRequest blacklistRequest \u003d\n           request.getResourceBlacklistRequest();\n       List\u003cString\u003e blacklistAdditions \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n       List\u003cString\u003e blacklistRemovals \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n \n       // sanity check\n       try {\n         RMServerUtils.validateResourceRequests(ask,\n             rScheduler.getMaximumResourceCapability());\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       try {\n         RMServerUtils.validateBlacklistRequest(blacklistRequest);\n       }  catch (InvalidResourceBlacklistRequestException e) {\n         LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n         throw e;\n       }\n \n       RMApp app \u003d\n           this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n       // In the case of work-preserving AM restart, it\u0027s possible for the\n       // AM to release containers from the earlier attempt.\n       if (!app.getApplicationSubmissionContext()\n         .getKeepContainersAcrossApplicationAttempts()) {\n         try {\n           RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n         } catch (InvalidContainerReleaseException e) {\n           LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n           throw e;\n         }\n       }\n \n       // Send new requests to appAttempt.\n       Allocation allocation \u003d\n           this.rScheduler.allocate(appAttemptId, ask, release, \n               blacklistAdditions, blacklistRemovals);\n \n       if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n         LOG.info(\"blacklist are updated in Scheduler.\" +\n             \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n             \"blacklistRemovals: \" + blacklistRemovals);\n       }\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n       if (!allocation.getContainers().isEmpty()) {\n         allocateResponse.setNMTokens(allocation.getNMTokens());\n       }\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n               rmNode.getState(),\n               rmNode.getHttpAddress(), rmNode.getRackName(), used,\n               rmNode.getTotalCapability(), numContainers,\n               rmNode.getHealthReport(),\n               rmNode.getLastHealthReportTime());\n \n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n \n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n \n       // add preemption to the allocateResponse message (if any)\n       allocateResponse\n           .setPreemptionMessage(generatePreemptionMessage(allocation));\n \n       // update AMRMToken if the token is rolled-up\n       MasterKeyData nextMasterKey \u003d\n           this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n \n       if (nextMasterKey !\u003d null\n           \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n             .getKeyId()) {\n         Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d\n             rmContext.getAMRMTokenSecretManager().createAndGetAMRMToken(\n               appAttemptId);\n         ((RMAppAttemptImpl)appAttempt).setAMRMToken(amrmToken);\n         allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n           .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n             .toString(), amrmToken.getPassword(), amrmToken.getService()\n             .toString()));\n+        LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n+            + \" to application: \" + appAttemptId.getApplicationId());\n       }\n \n       /*\n        * As we are updating the response inside the lock object so we don\u0027t\n        * need to worry about unregister call occurring in between (which\n        * removes the lock object).\n        */\n       lock.setAllocateResponse(allocateResponse);\n       return allocateResponse;\n     }    \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    AMRMTokenIdentifier amrmTokenIdentifier \u003d authorizeRequest();\n\n    ApplicationAttemptId appAttemptId \u003d\n        amrmTokenIdentifier.getApplicationAttemptId();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n    if (lock \u003d\u003d null) {\n      LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n      return shutdown;\n    }\n    synchronized (lock) {\n      AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n      if (!hasApplicationMasterRegistered(appAttemptId)) {\n        String message \u003d\n            \"Application Master is not registered for known application: \"\n                + appAttemptId.getApplicationId()\n                + \". Let AM resync.\";\n        LOG.info(message);\n        RMAuditLogger.logFailure(\n            this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n                .getUser(), AuditConstants.REGISTER_AM, \"\",\n            \"ApplicationMasterService\", message,\n            appAttemptId.getApplicationId(),\n            appAttemptId);\n        return resync;\n      }\n\n      if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n        /* old heartbeat */\n        return lastResponse;\n      } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n        LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n        // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n        // Reboot is not useful since after AM reboots, it will send register\n        // and\n        // get an exception. Might as well throw an exception here.\n        return resync;\n      }\n\n      //filter illegal progress values\n      float filteredProgress \u003d request.getProgress();\n      if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n        || filteredProgress \u003c 0) {\n         request.setProgress(0);\n      } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n        request.setProgress(1);\n      }\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      ResourceBlacklistRequest blacklistRequest \u003d\n          request.getResourceBlacklistRequest();\n      List\u003cString\u003e blacklistAdditions \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n      List\u003cString\u003e blacklistRemovals \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n\n      // sanity check\n      try {\n        RMServerUtils.validateResourceRequests(ask,\n            rScheduler.getMaximumResourceCapability());\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      try {\n        RMServerUtils.validateBlacklistRequest(blacklistRequest);\n      }  catch (InvalidResourceBlacklistRequestException e) {\n        LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n        throw e;\n      }\n\n      RMApp app \u003d\n          this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n      // In the case of work-preserving AM restart, it\u0027s possible for the\n      // AM to release containers from the earlier attempt.\n      if (!app.getApplicationSubmissionContext()\n        .getKeepContainersAcrossApplicationAttempts()) {\n        try {\n          RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n        } catch (InvalidContainerReleaseException e) {\n          LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n          throw e;\n        }\n      }\n\n      // Send new requests to appAttempt.\n      Allocation allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release, \n              blacklistAdditions, blacklistRemovals);\n\n      if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n        LOG.info(\"blacklist are updated in Scheduler.\" +\n            \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n            \"blacklistRemovals: \" + blacklistRemovals);\n      }\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n      if (!allocation.getContainers().isEmpty()) {\n        allocateResponse.setNMTokens(allocation.getNMTokens());\n      }\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n              rmNode.getState(),\n              rmNode.getHttpAddress(), rmNode.getRackName(), used,\n              rmNode.getTotalCapability(), numContainers,\n              rmNode.getHealthReport(),\n              rmNode.getLastHealthReportTime());\n\n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n\n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n\n      // add preemption to the allocateResponse message (if any)\n      allocateResponse\n          .setPreemptionMessage(generatePreemptionMessage(allocation));\n\n      // update AMRMToken if the token is rolled-up\n      MasterKeyData nextMasterKey \u003d\n          this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n\n      if (nextMasterKey !\u003d null\n          \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n            .getKeyId()) {\n        Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d\n            rmContext.getAMRMTokenSecretManager().createAndGetAMRMToken(\n              appAttemptId);\n        ((RMAppAttemptImpl)appAttempt).setAMRMToken(amrmToken);\n        allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n          .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n            .toString(), amrmToken.getPassword(), amrmToken.getService()\n            .toString()));\n        LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n            + \" to application: \" + appAttemptId.getApplicationId());\n      }\n\n      /*\n       * As we are updating the response inside the lock object so we don\u0027t\n       * need to worry about unregister call occurring in between (which\n       * removes the lock object).\n       */\n      lock.setAllocateResponse(allocateResponse);\n      return allocateResponse;\n    }    \n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "eeb4acd955802e2a84ea94cecf2e2341b83d5efb": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2212: ApplicationMaster needs to find a way to update the AMRMToken periodically. Contributed by Xuan Gong\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1616892 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/08/14 2:38 PM",
      "commitName": "eeb4acd955802e2a84ea94cecf2e2341b83d5efb",
      "commitAuthor": "Xuan Gong",
      "commitDateOld": "31/07/14 1:06 PM",
      "commitNameOld": "e52f67e3897a67a0b6d29e557a31cfa881738821",
      "commitAuthorOld": "Xuan Gong",
      "daysBetweenCommits": 8.06,
      "commitsBetweenForRepo": 70,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,161 +1,181 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n-    ApplicationAttemptId appAttemptId \u003d authorizeRequest();\n+    AMRMTokenIdentifier amrmTokenIdentifier \u003d authorizeRequest();\n+\n+    ApplicationAttemptId appAttemptId \u003d\n+        amrmTokenIdentifier.getApplicationAttemptId();\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n     if (lock \u003d\u003d null) {\n       LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n       return shutdown;\n     }\n     synchronized (lock) {\n       AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n       if (!hasApplicationMasterRegistered(appAttemptId)) {\n         String message \u003d\n             \"Application Master is not registered for known application: \"\n                 + appAttemptId.getApplicationId()\n                 + \". Let AM resync.\";\n         LOG.info(message);\n         RMAuditLogger.logFailure(\n             this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n                 .getUser(), AuditConstants.REGISTER_AM, \"\",\n             \"ApplicationMasterService\", message,\n             appAttemptId.getApplicationId(),\n             appAttemptId);\n         return resync;\n       }\n \n       if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n         /* old heartbeat */\n         return lastResponse;\n       } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n         LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n         // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n         // Reboot is not useful since after AM reboots, it will send register\n         // and\n         // get an exception. Might as well throw an exception here.\n         return resync;\n       }\n \n       //filter illegal progress values\n       float filteredProgress \u003d request.getProgress();\n       if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n         || filteredProgress \u003c 0) {\n          request.setProgress(0);\n       } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n         request.setProgress(1);\n       }\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n       ResourceBlacklistRequest blacklistRequest \u003d\n           request.getResourceBlacklistRequest();\n       List\u003cString\u003e blacklistAdditions \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n       List\u003cString\u003e blacklistRemovals \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n \n       // sanity check\n       try {\n         RMServerUtils.validateResourceRequests(ask,\n             rScheduler.getMaximumResourceCapability());\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       try {\n         RMServerUtils.validateBlacklistRequest(blacklistRequest);\n       }  catch (InvalidResourceBlacklistRequestException e) {\n         LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n         throw e;\n       }\n \n       RMApp app \u003d\n           this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n       // In the case of work-preserving AM restart, it\u0027s possible for the\n       // AM to release containers from the earlier attempt.\n       if (!app.getApplicationSubmissionContext()\n         .getKeepContainersAcrossApplicationAttempts()) {\n         try {\n           RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n         } catch (InvalidContainerReleaseException e) {\n           LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n           throw e;\n         }\n       }\n \n       // Send new requests to appAttempt.\n       Allocation allocation \u003d\n           this.rScheduler.allocate(appAttemptId, ask, release, \n               blacklistAdditions, blacklistRemovals);\n \n       if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n         LOG.info(\"blacklist are updated in Scheduler.\" +\n             \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n             \"blacklistRemovals: \" + blacklistRemovals);\n       }\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n       if (!allocation.getContainers().isEmpty()) {\n         allocateResponse.setNMTokens(allocation.getNMTokens());\n       }\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n               rmNode.getState(),\n               rmNode.getHttpAddress(), rmNode.getRackName(), used,\n               rmNode.getTotalCapability(), numContainers,\n               rmNode.getHealthReport(),\n               rmNode.getLastHealthReportTime());\n \n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n \n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n \n       // add preemption to the allocateResponse message (if any)\n       allocateResponse\n           .setPreemptionMessage(generatePreemptionMessage(allocation));\n \n+      // update AMRMToken if the token is rolled-up\n+      MasterKeyData nextMasterKey \u003d\n+          this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n+\n+      if (nextMasterKey !\u003d null\n+          \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n+            .getKeyId()) {\n+        Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d\n+            rmContext.getAMRMTokenSecretManager().createAndGetAMRMToken(\n+              appAttemptId);\n+        ((RMAppAttemptImpl)appAttempt).setAMRMToken(amrmToken);\n+        allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n+          .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n+            .toString(), amrmToken.getPassword(), amrmToken.getService()\n+            .toString()));\n+      }\n+\n       /*\n        * As we are updating the response inside the lock object so we don\u0027t\n        * need to worry about unregister call occurring in between (which\n        * removes the lock object).\n        */\n       lock.setAllocateResponse(allocateResponse);\n       return allocateResponse;\n     }    \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    AMRMTokenIdentifier amrmTokenIdentifier \u003d authorizeRequest();\n\n    ApplicationAttemptId appAttemptId \u003d\n        amrmTokenIdentifier.getApplicationAttemptId();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n    if (lock \u003d\u003d null) {\n      LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n      return shutdown;\n    }\n    synchronized (lock) {\n      AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n      if (!hasApplicationMasterRegistered(appAttemptId)) {\n        String message \u003d\n            \"Application Master is not registered for known application: \"\n                + appAttemptId.getApplicationId()\n                + \". Let AM resync.\";\n        LOG.info(message);\n        RMAuditLogger.logFailure(\n            this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n                .getUser(), AuditConstants.REGISTER_AM, \"\",\n            \"ApplicationMasterService\", message,\n            appAttemptId.getApplicationId(),\n            appAttemptId);\n        return resync;\n      }\n\n      if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n        /* old heartbeat */\n        return lastResponse;\n      } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n        LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n        // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n        // Reboot is not useful since after AM reboots, it will send register\n        // and\n        // get an exception. Might as well throw an exception here.\n        return resync;\n      }\n\n      //filter illegal progress values\n      float filteredProgress \u003d request.getProgress();\n      if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n        || filteredProgress \u003c 0) {\n         request.setProgress(0);\n      } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n        request.setProgress(1);\n      }\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      ResourceBlacklistRequest blacklistRequest \u003d\n          request.getResourceBlacklistRequest();\n      List\u003cString\u003e blacklistAdditions \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n      List\u003cString\u003e blacklistRemovals \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n\n      // sanity check\n      try {\n        RMServerUtils.validateResourceRequests(ask,\n            rScheduler.getMaximumResourceCapability());\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      try {\n        RMServerUtils.validateBlacklistRequest(blacklistRequest);\n      }  catch (InvalidResourceBlacklistRequestException e) {\n        LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n        throw e;\n      }\n\n      RMApp app \u003d\n          this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n      // In the case of work-preserving AM restart, it\u0027s possible for the\n      // AM to release containers from the earlier attempt.\n      if (!app.getApplicationSubmissionContext()\n        .getKeepContainersAcrossApplicationAttempts()) {\n        try {\n          RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n        } catch (InvalidContainerReleaseException e) {\n          LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n          throw e;\n        }\n      }\n\n      // Send new requests to appAttempt.\n      Allocation allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release, \n              blacklistAdditions, blacklistRemovals);\n\n      if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n        LOG.info(\"blacklist are updated in Scheduler.\" +\n            \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n            \"blacklistRemovals: \" + blacklistRemovals);\n      }\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n      if (!allocation.getContainers().isEmpty()) {\n        allocateResponse.setNMTokens(allocation.getNMTokens());\n      }\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n              rmNode.getState(),\n              rmNode.getHttpAddress(), rmNode.getRackName(), used,\n              rmNode.getTotalCapability(), numContainers,\n              rmNode.getHealthReport(),\n              rmNode.getLastHealthReportTime());\n\n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n\n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n\n      // add preemption to the allocateResponse message (if any)\n      allocateResponse\n          .setPreemptionMessage(generatePreemptionMessage(allocation));\n\n      // update AMRMToken if the token is rolled-up\n      MasterKeyData nextMasterKey \u003d\n          this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n\n      if (nextMasterKey !\u003d null\n          \u0026\u0026 nextMasterKey.getMasterKey().getKeyId() !\u003d amrmTokenIdentifier\n            .getKeyId()) {\n        Token\u003cAMRMTokenIdentifier\u003e amrmToken \u003d\n            rmContext.getAMRMTokenSecretManager().createAndGetAMRMToken(\n              appAttemptId);\n        ((RMAppAttemptImpl)appAttempt).setAMRMToken(amrmToken);\n        allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n          .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n            .toString(), amrmToken.getPassword(), amrmToken.getService()\n            .toString()));\n      }\n\n      /*\n       * As we are updating the response inside the lock object so we don\u0027t\n       * need to worry about unregister call occurring in between (which\n       * removes the lock object).\n       */\n      lock.setAllocateResponse(allocateResponse);\n      return allocateResponse;\n    }    \n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "c3f1c30e65cc6a10928299f50801782ecbb4ccb6": {
      "type": "Ybodychange",
      "commitMessage": "YARN-1365. Changed ApplicationMasterService to allow an app to re-register after RM restart. Contributed by Anubhav Dhoot\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1605263 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/06/14 9:42 PM",
      "commitName": "c3f1c30e65cc6a10928299f50801782ecbb4ccb6",
      "commitAuthor": "Jian He",
      "commitDateOld": "15/05/14 11:22 PM",
      "commitNameOld": "0f9147c8579a8e8a1600e8c8182662d94296bd51",
      "commitAuthorOld": "Jian He",
      "daysBetweenCommits": 39.93,
      "commitsBetweenForRepo": 242,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,160 +1,161 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n     ApplicationAttemptId appAttemptId \u003d authorizeRequest();\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n     if (lock \u003d\u003d null) {\n       LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n-      return resync;\n+      return shutdown;\n     }\n     synchronized (lock) {\n       AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n       if (!hasApplicationMasterRegistered(appAttemptId)) {\n         String message \u003d\n-            \"Application Master is trying to allocate before registering for: \"\n-                + appAttemptId.getApplicationId();\n-        LOG.error(message);\n+            \"Application Master is not registered for known application: \"\n+                + appAttemptId.getApplicationId()\n+                + \". Let AM resync.\";\n+        LOG.info(message);\n         RMAuditLogger.logFailure(\n             this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n                 .getUser(), AuditConstants.REGISTER_AM, \"\",\n             \"ApplicationMasterService\", message,\n             appAttemptId.getApplicationId(),\n             appAttemptId);\n-        throw new InvalidApplicationMasterRequestException(message);\n+        return resync;\n       }\n \n       if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n         /* old heartbeat */\n         return lastResponse;\n       } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n         LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n         // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n         // Reboot is not useful since after AM reboots, it will send register\n         // and\n         // get an exception. Might as well throw an exception here.\n         return resync;\n       }\n \n       //filter illegal progress values\n       float filteredProgress \u003d request.getProgress();\n       if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n         || filteredProgress \u003c 0) {\n          request.setProgress(0);\n       } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n         request.setProgress(1);\n       }\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n       ResourceBlacklistRequest blacklistRequest \u003d\n           request.getResourceBlacklistRequest();\n       List\u003cString\u003e blacklistAdditions \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n       List\u003cString\u003e blacklistRemovals \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n \n       // sanity check\n       try {\n         RMServerUtils.validateResourceRequests(ask,\n             rScheduler.getMaximumResourceCapability());\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       try {\n         RMServerUtils.validateBlacklistRequest(blacklistRequest);\n       }  catch (InvalidResourceBlacklistRequestException e) {\n         LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n         throw e;\n       }\n \n       RMApp app \u003d\n           this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n       // In the case of work-preserving AM restart, it\u0027s possible for the\n       // AM to release containers from the earlier attempt.\n       if (!app.getApplicationSubmissionContext()\n         .getKeepContainersAcrossApplicationAttempts()) {\n         try {\n           RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n         } catch (InvalidContainerReleaseException e) {\n           LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n           throw e;\n         }\n       }\n \n       // Send new requests to appAttempt.\n       Allocation allocation \u003d\n           this.rScheduler.allocate(appAttemptId, ask, release, \n               blacklistAdditions, blacklistRemovals);\n \n       if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n         LOG.info(\"blacklist are updated in Scheduler.\" +\n             \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n             \"blacklistRemovals: \" + blacklistRemovals);\n       }\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n       if (!allocation.getContainers().isEmpty()) {\n         allocateResponse.setNMTokens(allocation.getNMTokens());\n       }\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n               rmNode.getState(),\n               rmNode.getHttpAddress(), rmNode.getRackName(), used,\n               rmNode.getTotalCapability(), numContainers,\n               rmNode.getHealthReport(),\n               rmNode.getLastHealthReportTime());\n \n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n \n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n \n       // add preemption to the allocateResponse message (if any)\n       allocateResponse\n           .setPreemptionMessage(generatePreemptionMessage(allocation));\n \n       /*\n        * As we are updating the response inside the lock object so we don\u0027t\n        * need to worry about unregister call occurring in between (which\n        * removes the lock object).\n        */\n       lock.setAllocateResponse(allocateResponse);\n       return allocateResponse;\n     }    \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    ApplicationAttemptId appAttemptId \u003d authorizeRequest();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n    if (lock \u003d\u003d null) {\n      LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n      return shutdown;\n    }\n    synchronized (lock) {\n      AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n      if (!hasApplicationMasterRegistered(appAttemptId)) {\n        String message \u003d\n            \"Application Master is not registered for known application: \"\n                + appAttemptId.getApplicationId()\n                + \". Let AM resync.\";\n        LOG.info(message);\n        RMAuditLogger.logFailure(\n            this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n                .getUser(), AuditConstants.REGISTER_AM, \"\",\n            \"ApplicationMasterService\", message,\n            appAttemptId.getApplicationId(),\n            appAttemptId);\n        return resync;\n      }\n\n      if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n        /* old heartbeat */\n        return lastResponse;\n      } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n        LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n        // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n        // Reboot is not useful since after AM reboots, it will send register\n        // and\n        // get an exception. Might as well throw an exception here.\n        return resync;\n      }\n\n      //filter illegal progress values\n      float filteredProgress \u003d request.getProgress();\n      if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n        || filteredProgress \u003c 0) {\n         request.setProgress(0);\n      } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n        request.setProgress(1);\n      }\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      ResourceBlacklistRequest blacklistRequest \u003d\n          request.getResourceBlacklistRequest();\n      List\u003cString\u003e blacklistAdditions \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n      List\u003cString\u003e blacklistRemovals \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n\n      // sanity check\n      try {\n        RMServerUtils.validateResourceRequests(ask,\n            rScheduler.getMaximumResourceCapability());\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      try {\n        RMServerUtils.validateBlacklistRequest(blacklistRequest);\n      }  catch (InvalidResourceBlacklistRequestException e) {\n        LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n        throw e;\n      }\n\n      RMApp app \u003d\n          this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n      // In the case of work-preserving AM restart, it\u0027s possible for the\n      // AM to release containers from the earlier attempt.\n      if (!app.getApplicationSubmissionContext()\n        .getKeepContainersAcrossApplicationAttempts()) {\n        try {\n          RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n        } catch (InvalidContainerReleaseException e) {\n          LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n          throw e;\n        }\n      }\n\n      // Send new requests to appAttempt.\n      Allocation allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release, \n              blacklistAdditions, blacklistRemovals);\n\n      if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n        LOG.info(\"blacklist are updated in Scheduler.\" +\n            \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n            \"blacklistRemovals: \" + blacklistRemovals);\n      }\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n      if (!allocation.getContainers().isEmpty()) {\n        allocateResponse.setNMTokens(allocation.getNMTokens());\n      }\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n              rmNode.getState(),\n              rmNode.getHttpAddress(), rmNode.getRackName(), used,\n              rmNode.getTotalCapability(), numContainers,\n              rmNode.getHealthReport(),\n              rmNode.getLastHealthReportTime());\n\n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n\n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n\n      // add preemption to the allocateResponse message (if any)\n      allocateResponse\n          .setPreemptionMessage(generatePreemptionMessage(allocation));\n\n      /*\n       * As we are updating the response inside the lock object so we don\u0027t\n       * need to worry about unregister call occurring in between (which\n       * removes the lock object).\n       */\n      lock.setAllocateResponse(allocateResponse);\n      return allocateResponse;\n    }    \n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "faddccc216f4ba5b503a7d21ce699217d75fb400": {
      "type": "Ybodychange",
      "commitMessage": "YARN-1301. Added the INFO level log of the non-empty blacklist additions and removals inside ApplicationMasterService. Contributed by Tsuyoshi Ozawa.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1572400 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/02/14 6:07 PM",
      "commitName": "faddccc216f4ba5b503a7d21ce699217d75fb400",
      "commitAuthor": "Zhijie Shen",
      "commitDateOld": "26/02/14 12:20 PM",
      "commitNameOld": "0fbc7fe816007b4e330604e9f8bae6b1e4b448bc",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 0.24,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,155 +1,160 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n     ApplicationAttemptId appAttemptId \u003d authorizeRequest();\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n     if (lock \u003d\u003d null) {\n       LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n       return resync;\n     }\n     synchronized (lock) {\n       AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n       if (!hasApplicationMasterRegistered(appAttemptId)) {\n         String message \u003d\n             \"Application Master is trying to allocate before registering for: \"\n                 + appAttemptId.getApplicationId();\n         LOG.error(message);\n         RMAuditLogger.logFailure(\n             this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n                 .getUser(), AuditConstants.REGISTER_AM, \"\",\n             \"ApplicationMasterService\", message,\n             appAttemptId.getApplicationId(),\n             appAttemptId);\n         throw new InvalidApplicationMasterRequestException(message);\n       }\n \n       if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n         /* old heartbeat */\n         return lastResponse;\n       } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n         LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n         // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n         // Reboot is not useful since after AM reboots, it will send register\n         // and\n         // get an exception. Might as well throw an exception here.\n         return resync;\n       }\n \n       //filter illegal progress values\n       float filteredProgress \u003d request.getProgress();\n       if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n         || filteredProgress \u003c 0) {\n          request.setProgress(0);\n       } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n         request.setProgress(1);\n       }\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n       ResourceBlacklistRequest blacklistRequest \u003d\n           request.getResourceBlacklistRequest();\n       List\u003cString\u003e blacklistAdditions \u003d\n           (blacklistRequest !\u003d null) ?\n-              blacklistRequest.getBlacklistAdditions() : null;\n+              blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n       List\u003cString\u003e blacklistRemovals \u003d\n           (blacklistRequest !\u003d null) ?\n-              blacklistRequest.getBlacklistRemovals() : null;\n+              blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n \n       // sanity check\n       try {\n         RMServerUtils.validateResourceRequests(ask,\n             rScheduler.getMaximumResourceCapability());\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       try {\n         RMServerUtils.validateBlacklistRequest(blacklistRequest);\n       }  catch (InvalidResourceBlacklistRequestException e) {\n         LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n         throw e;\n       }\n \n       RMApp app \u003d\n           this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n       // In the case of work-preserving AM restart, it\u0027s possible for the\n       // AM to release containers from the earlier attempt.\n       if (!app.getApplicationSubmissionContext()\n         .getKeepContainersAcrossApplicationAttempts()) {\n         try {\n           RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n         } catch (InvalidContainerReleaseException e) {\n           LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n           throw e;\n         }\n       }\n \n       // Send new requests to appAttempt.\n       Allocation allocation \u003d\n           this.rScheduler.allocate(appAttemptId, ask, release, \n               blacklistAdditions, blacklistRemovals);\n \n+      if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n+        LOG.info(\"blacklist are updated in Scheduler.\" +\n+            \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n+            \"blacklistRemovals: \" + blacklistRemovals);\n+      }\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n       if (!allocation.getContainers().isEmpty()) {\n         allocateResponse.setNMTokens(allocation.getNMTokens());\n       }\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n               rmNode.getState(),\n               rmNode.getHttpAddress(), rmNode.getRackName(), used,\n               rmNode.getTotalCapability(), numContainers,\n               rmNode.getHealthReport(),\n               rmNode.getLastHealthReportTime());\n \n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n \n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n \n       // add preemption to the allocateResponse message (if any)\n       allocateResponse\n           .setPreemptionMessage(generatePreemptionMessage(allocation));\n \n       /*\n        * As we are updating the response inside the lock object so we don\u0027t\n        * need to worry about unregister call occurring in between (which\n        * removes the lock object).\n        */\n       lock.setAllocateResponse(allocateResponse);\n       return allocateResponse;\n     }    \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    ApplicationAttemptId appAttemptId \u003d authorizeRequest();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n    if (lock \u003d\u003d null) {\n      LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n      return resync;\n    }\n    synchronized (lock) {\n      AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n      if (!hasApplicationMasterRegistered(appAttemptId)) {\n        String message \u003d\n            \"Application Master is trying to allocate before registering for: \"\n                + appAttemptId.getApplicationId();\n        LOG.error(message);\n        RMAuditLogger.logFailure(\n            this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n                .getUser(), AuditConstants.REGISTER_AM, \"\",\n            \"ApplicationMasterService\", message,\n            appAttemptId.getApplicationId(),\n            appAttemptId);\n        throw new InvalidApplicationMasterRequestException(message);\n      }\n\n      if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n        /* old heartbeat */\n        return lastResponse;\n      } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n        LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n        // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n        // Reboot is not useful since after AM reboots, it will send register\n        // and\n        // get an exception. Might as well throw an exception here.\n        return resync;\n      }\n\n      //filter illegal progress values\n      float filteredProgress \u003d request.getProgress();\n      if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n        || filteredProgress \u003c 0) {\n         request.setProgress(0);\n      } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n        request.setProgress(1);\n      }\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      ResourceBlacklistRequest blacklistRequest \u003d\n          request.getResourceBlacklistRequest();\n      List\u003cString\u003e blacklistAdditions \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n      List\u003cString\u003e blacklistRemovals \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n\n      // sanity check\n      try {\n        RMServerUtils.validateResourceRequests(ask,\n            rScheduler.getMaximumResourceCapability());\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      try {\n        RMServerUtils.validateBlacklistRequest(blacklistRequest);\n      }  catch (InvalidResourceBlacklistRequestException e) {\n        LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n        throw e;\n      }\n\n      RMApp app \u003d\n          this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n      // In the case of work-preserving AM restart, it\u0027s possible for the\n      // AM to release containers from the earlier attempt.\n      if (!app.getApplicationSubmissionContext()\n        .getKeepContainersAcrossApplicationAttempts()) {\n        try {\n          RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n        } catch (InvalidContainerReleaseException e) {\n          LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n          throw e;\n        }\n      }\n\n      // Send new requests to appAttempt.\n      Allocation allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release, \n              blacklistAdditions, blacklistRemovals);\n\n      if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n        LOG.info(\"blacklist are updated in Scheduler.\" +\n            \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n            \"blacklistRemovals: \" + blacklistRemovals);\n      }\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n      if (!allocation.getContainers().isEmpty()) {\n        allocateResponse.setNMTokens(allocation.getNMTokens());\n      }\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n              rmNode.getState(),\n              rmNode.getHttpAddress(), rmNode.getRackName(), used,\n              rmNode.getTotalCapability(), numContainers,\n              rmNode.getHealthReport(),\n              rmNode.getLastHealthReportTime());\n\n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n\n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n\n      // add preemption to the allocateResponse message (if any)\n      allocateResponse\n          .setPreemptionMessage(generatePreemptionMessage(allocation));\n\n      /*\n       * As we are updating the response inside the lock object so we don\u0027t\n       * need to worry about unregister call occurring in between (which\n       * removes the lock object).\n       */\n      lock.setAllocateResponse(allocateResponse);\n      return allocateResponse;\n    }    \n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "5fd5c9900cfd299428acbc8dff767273e44647c0": {
      "type": "Ybodychange",
      "commitMessage": "YARN-713. Fixed ResourceManager to not crash while building tokens when DNS issues happen transmittently. Contributed by Jian He.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1569979 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/02/14 3:39 PM",
      "commitName": "5fd5c9900cfd299428acbc8dff767273e44647c0",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "19/02/14 9:52 AM",
      "commitNameOld": "9da9f7d4d8f1dce210995a06863a8836c23d7c3a",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 0.24,
      "commitsBetweenForRepo": 7,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,159 +1,155 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n     ApplicationAttemptId appAttemptId \u003d authorizeRequest();\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n     if (lock \u003d\u003d null) {\n       LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n       return resync;\n     }\n     synchronized (lock) {\n       AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n       if (!hasApplicationMasterRegistered(appAttemptId)) {\n         String message \u003d\n             \"Application Master is trying to allocate before registering for: \"\n                 + appAttemptId.getApplicationId();\n         LOG.error(message);\n         RMAuditLogger.logFailure(\n             this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n                 .getUser(), AuditConstants.REGISTER_AM, \"\",\n             \"ApplicationMasterService\", message,\n             appAttemptId.getApplicationId(),\n             appAttemptId);\n         throw new InvalidApplicationMasterRequestException(message);\n       }\n \n       if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n         /* old heartbeat */\n         return lastResponse;\n       } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n         LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n         // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n         // Reboot is not useful since after AM reboots, it will send register\n         // and\n         // get an exception. Might as well throw an exception here.\n         return resync;\n       }\n \n       //filter illegal progress values\n       float filteredProgress \u003d request.getProgress();\n       if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n         || filteredProgress \u003c 0) {\n          request.setProgress(0);\n       } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n         request.setProgress(1);\n       }\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n       ResourceBlacklistRequest blacklistRequest \u003d\n           request.getResourceBlacklistRequest();\n       List\u003cString\u003e blacklistAdditions \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistAdditions() : null;\n       List\u003cString\u003e blacklistRemovals \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistRemovals() : null;\n \n       // sanity check\n       try {\n         RMServerUtils.validateResourceRequests(ask,\n             rScheduler.getMaximumResourceCapability());\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       try {\n         RMServerUtils.validateBlacklistRequest(blacklistRequest);\n       }  catch (InvalidResourceBlacklistRequestException e) {\n         LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n         throw e;\n       }\n \n       RMApp app \u003d\n           this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n       // In the case of work-preserving AM restart, it\u0027s possible for the\n       // AM to release containers from the earlier attempt.\n       if (!app.getApplicationSubmissionContext()\n         .getKeepContainersAcrossApplicationAttempts()) {\n         try {\n           RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n         } catch (InvalidContainerReleaseException e) {\n           LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n           throw e;\n         }\n       }\n \n       // Send new requests to appAttempt.\n       Allocation allocation \u003d\n           this.rScheduler.allocate(appAttemptId, ask, release, \n               blacklistAdditions, blacklistRemovals);\n \n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n-      \n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n+      if (!allocation.getContainers().isEmpty()) {\n+        allocateResponse.setNMTokens(allocation.getNMTokens());\n+      }\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n               rmNode.getState(),\n               rmNode.getHttpAddress(), rmNode.getRackName(), used,\n               rmNode.getTotalCapability(), numContainers,\n               rmNode.getHealthReport(),\n               rmNode.getLastHealthReportTime());\n \n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n \n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n \n       // add preemption to the allocateResponse message (if any)\n       allocateResponse\n           .setPreemptionMessage(generatePreemptionMessage(allocation));\n \n-      // Adding NMTokens for allocated containers.\n-      if (!allocation.getContainers().isEmpty()) {\n-        allocateResponse.setNMTokens(rmContext.getNMTokenSecretManager()\n-            .createAndGetNMTokens(app.getUser(), appAttemptId,\n-                allocation.getContainers()));\n-      }\n       /*\n        * As we are updating the response inside the lock object so we don\u0027t\n        * need to worry about unregister call occurring in between (which\n        * removes the lock object).\n        */\n       lock.setAllocateResponse(allocateResponse);\n       return allocateResponse;\n     }    \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    ApplicationAttemptId appAttemptId \u003d authorizeRequest();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n    if (lock \u003d\u003d null) {\n      LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n      return resync;\n    }\n    synchronized (lock) {\n      AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n      if (!hasApplicationMasterRegistered(appAttemptId)) {\n        String message \u003d\n            \"Application Master is trying to allocate before registering for: \"\n                + appAttemptId.getApplicationId();\n        LOG.error(message);\n        RMAuditLogger.logFailure(\n            this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n                .getUser(), AuditConstants.REGISTER_AM, \"\",\n            \"ApplicationMasterService\", message,\n            appAttemptId.getApplicationId(),\n            appAttemptId);\n        throw new InvalidApplicationMasterRequestException(message);\n      }\n\n      if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n        /* old heartbeat */\n        return lastResponse;\n      } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n        LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n        // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n        // Reboot is not useful since after AM reboots, it will send register\n        // and\n        // get an exception. Might as well throw an exception here.\n        return resync;\n      }\n\n      //filter illegal progress values\n      float filteredProgress \u003d request.getProgress();\n      if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n        || filteredProgress \u003c 0) {\n         request.setProgress(0);\n      } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n        request.setProgress(1);\n      }\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      ResourceBlacklistRequest blacklistRequest \u003d\n          request.getResourceBlacklistRequest();\n      List\u003cString\u003e blacklistAdditions \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistAdditions() : null;\n      List\u003cString\u003e blacklistRemovals \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistRemovals() : null;\n\n      // sanity check\n      try {\n        RMServerUtils.validateResourceRequests(ask,\n            rScheduler.getMaximumResourceCapability());\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      try {\n        RMServerUtils.validateBlacklistRequest(blacklistRequest);\n      }  catch (InvalidResourceBlacklistRequestException e) {\n        LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n        throw e;\n      }\n\n      RMApp app \u003d\n          this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n      // In the case of work-preserving AM restart, it\u0027s possible for the\n      // AM to release containers from the earlier attempt.\n      if (!app.getApplicationSubmissionContext()\n        .getKeepContainersAcrossApplicationAttempts()) {\n        try {\n          RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n        } catch (InvalidContainerReleaseException e) {\n          LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n          throw e;\n        }\n      }\n\n      // Send new requests to appAttempt.\n      Allocation allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release, \n              blacklistAdditions, blacklistRemovals);\n\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n      if (!allocation.getContainers().isEmpty()) {\n        allocateResponse.setNMTokens(allocation.getNMTokens());\n      }\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n              rmNode.getState(),\n              rmNode.getHttpAddress(), rmNode.getRackName(), used,\n              rmNode.getTotalCapability(), numContainers,\n              rmNode.getHealthReport(),\n              rmNode.getLastHealthReportTime());\n\n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n\n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n\n      // add preemption to the allocateResponse message (if any)\n      allocateResponse\n          .setPreemptionMessage(generatePreemptionMessage(allocation));\n\n      /*\n       * As we are updating the response inside the lock object so we don\u0027t\n       * need to worry about unregister call occurring in between (which\n       * removes the lock object).\n       */\n      lock.setAllocateResponse(allocateResponse);\n      return allocateResponse;\n    }    \n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "996acc834e969bcb71b3d9808854a259490cb32d": {
      "type": "Ybodychange",
      "commitMessage": "YARN-1479. Invalid NaN values in Hadoop REST API JSON response (Chen He via jeagles)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1569853 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/02/14 9:49 AM",
      "commitName": "996acc834e969bcb71b3d9808854a259490cb32d",
      "commitAuthor": "Jonathan Turner Eagles",
      "commitDateOld": "10/02/14 2:50 PM",
      "commitNameOld": "1fa6ab249b0fa63cab550e1b7703339c4d888c5d",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 8.79,
      "commitsBetweenForRepo": 63,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,150 +1,159 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n     ApplicationAttemptId appAttemptId \u003d authorizeRequest();\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n     if (lock \u003d\u003d null) {\n       LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n       return resync;\n     }\n     synchronized (lock) {\n       AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n       if (!hasApplicationMasterRegistered(appAttemptId)) {\n         String message \u003d\n             \"Application Master is trying to allocate before registering for: \"\n                 + appAttemptId.getApplicationId();\n         LOG.error(message);\n         RMAuditLogger.logFailure(\n             this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n                 .getUser(), AuditConstants.REGISTER_AM, \"\",\n             \"ApplicationMasterService\", message,\n             appAttemptId.getApplicationId(),\n             appAttemptId);\n         throw new InvalidApplicationMasterRequestException(message);\n       }\n \n       if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n         /* old heartbeat */\n         return lastResponse;\n       } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n         LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n         // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n         // Reboot is not useful since after AM reboots, it will send register\n         // and\n         // get an exception. Might as well throw an exception here.\n         return resync;\n       }\n \n+      //filter illegal progress values\n+      float filteredProgress \u003d request.getProgress();\n+      if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n+        || filteredProgress \u003c 0) {\n+         request.setProgress(0);\n+      } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n+        request.setProgress(1);\n+      }\n+\n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n       ResourceBlacklistRequest blacklistRequest \u003d\n           request.getResourceBlacklistRequest();\n       List\u003cString\u003e blacklistAdditions \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistAdditions() : null;\n       List\u003cString\u003e blacklistRemovals \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistRemovals() : null;\n \n       // sanity check\n       try {\n         RMServerUtils.validateResourceRequests(ask,\n             rScheduler.getMaximumResourceCapability());\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       try {\n         RMServerUtils.validateBlacklistRequest(blacklistRequest);\n       }  catch (InvalidResourceBlacklistRequestException e) {\n         LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n         throw e;\n       }\n \n       RMApp app \u003d\n           this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n       // In the case of work-preserving AM restart, it\u0027s possible for the\n       // AM to release containers from the earlier attempt.\n       if (!app.getApplicationSubmissionContext()\n         .getKeepContainersAcrossApplicationAttempts()) {\n         try {\n           RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n         } catch (InvalidContainerReleaseException e) {\n           LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n           throw e;\n         }\n       }\n \n       // Send new requests to appAttempt.\n       Allocation allocation \u003d\n           this.rScheduler.allocate(appAttemptId, ask, release, \n               blacklistAdditions, blacklistRemovals);\n \n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       \n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n               rmNode.getState(),\n               rmNode.getHttpAddress(), rmNode.getRackName(), used,\n               rmNode.getTotalCapability(), numContainers,\n               rmNode.getHealthReport(),\n               rmNode.getLastHealthReportTime());\n \n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n \n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n \n       // add preemption to the allocateResponse message (if any)\n       allocateResponse\n           .setPreemptionMessage(generatePreemptionMessage(allocation));\n \n       // Adding NMTokens for allocated containers.\n       if (!allocation.getContainers().isEmpty()) {\n         allocateResponse.setNMTokens(rmContext.getNMTokenSecretManager()\n             .createAndGetNMTokens(app.getUser(), appAttemptId,\n                 allocation.getContainers()));\n       }\n       /*\n        * As we are updating the response inside the lock object so we don\u0027t\n        * need to worry about unregister call occurring in between (which\n        * removes the lock object).\n        */\n       lock.setAllocateResponse(allocateResponse);\n       return allocateResponse;\n     }    \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    ApplicationAttemptId appAttemptId \u003d authorizeRequest();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n    if (lock \u003d\u003d null) {\n      LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n      return resync;\n    }\n    synchronized (lock) {\n      AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n      if (!hasApplicationMasterRegistered(appAttemptId)) {\n        String message \u003d\n            \"Application Master is trying to allocate before registering for: \"\n                + appAttemptId.getApplicationId();\n        LOG.error(message);\n        RMAuditLogger.logFailure(\n            this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n                .getUser(), AuditConstants.REGISTER_AM, \"\",\n            \"ApplicationMasterService\", message,\n            appAttemptId.getApplicationId(),\n            appAttemptId);\n        throw new InvalidApplicationMasterRequestException(message);\n      }\n\n      if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n        /* old heartbeat */\n        return lastResponse;\n      } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n        LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n        // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n        // Reboot is not useful since after AM reboots, it will send register\n        // and\n        // get an exception. Might as well throw an exception here.\n        return resync;\n      }\n\n      //filter illegal progress values\n      float filteredProgress \u003d request.getProgress();\n      if (Float.isNaN(filteredProgress) || filteredProgress \u003d\u003d Float.NEGATIVE_INFINITY\n        || filteredProgress \u003c 0) {\n         request.setProgress(0);\n      } else if (filteredProgress \u003e 1 || filteredProgress \u003d\u003d Float.POSITIVE_INFINITY) {\n        request.setProgress(1);\n      }\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      ResourceBlacklistRequest blacklistRequest \u003d\n          request.getResourceBlacklistRequest();\n      List\u003cString\u003e blacklistAdditions \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistAdditions() : null;\n      List\u003cString\u003e blacklistRemovals \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistRemovals() : null;\n\n      // sanity check\n      try {\n        RMServerUtils.validateResourceRequests(ask,\n            rScheduler.getMaximumResourceCapability());\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      try {\n        RMServerUtils.validateBlacklistRequest(blacklistRequest);\n      }  catch (InvalidResourceBlacklistRequestException e) {\n        LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n        throw e;\n      }\n\n      RMApp app \u003d\n          this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n      // In the case of work-preserving AM restart, it\u0027s possible for the\n      // AM to release containers from the earlier attempt.\n      if (!app.getApplicationSubmissionContext()\n        .getKeepContainersAcrossApplicationAttempts()) {\n        try {\n          RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n        } catch (InvalidContainerReleaseException e) {\n          LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n          throw e;\n        }\n      }\n\n      // Send new requests to appAttempt.\n      Allocation allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release, \n              blacklistAdditions, blacklistRemovals);\n\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      \n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n              rmNode.getState(),\n              rmNode.getHttpAddress(), rmNode.getRackName(), used,\n              rmNode.getTotalCapability(), numContainers,\n              rmNode.getHealthReport(),\n              rmNode.getLastHealthReportTime());\n\n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n\n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n\n      // add preemption to the allocateResponse message (if any)\n      allocateResponse\n          .setPreemptionMessage(generatePreemptionMessage(allocation));\n\n      // Adding NMTokens for allocated containers.\n      if (!allocation.getContainers().isEmpty()) {\n        allocateResponse.setNMTokens(rmContext.getNMTokenSecretManager()\n            .createAndGetNMTokens(app.getUser(), appAttemptId,\n                allocation.getContainers()));\n      }\n      /*\n       * As we are updating the response inside the lock object so we don\u0027t\n       * need to worry about unregister call occurring in between (which\n       * removes the lock object).\n       */\n      lock.setAllocateResponse(allocateResponse);\n      return allocateResponse;\n    }    \n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "1393581bceda234c88cafec00dbfc0ef2a402e83": {
      "type": "Ybodychange",
      "commitMessage": "YARN-1490. Introduced the ability to make ResourceManager optionally not kill all containers when an ApplicationMaster exits. Contributed by Jian He.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1557143 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/01/14 7:04 AM",
      "commitName": "1393581bceda234c88cafec00dbfc0ef2a402e83",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "02/01/14 11:54 AM",
      "commitNameOld": "bb2e2fee6071233fa3f708c04c58091f4b8b0f99",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 7.8,
      "commitsBetweenForRepo": 38,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,145 +1,150 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n     ApplicationAttemptId appAttemptId \u003d authorizeRequest();\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n     if (lock \u003d\u003d null) {\n       LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n       return resync;\n     }\n     synchronized (lock) {\n       AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n       if (!hasApplicationMasterRegistered(appAttemptId)) {\n         String message \u003d\n             \"Application Master is trying to allocate before registering for: \"\n                 + appAttemptId.getApplicationId();\n         LOG.error(message);\n         RMAuditLogger.logFailure(\n             this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n                 .getUser(), AuditConstants.REGISTER_AM, \"\",\n             \"ApplicationMasterService\", message,\n             appAttemptId.getApplicationId(),\n             appAttemptId);\n         throw new InvalidApplicationMasterRequestException(message);\n       }\n \n       if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n         /* old heartbeat */\n         return lastResponse;\n       } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n         LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n         // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n         // Reboot is not useful since after AM reboots, it will send register\n         // and\n         // get an exception. Might as well throw an exception here.\n         return resync;\n       }\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n       ResourceBlacklistRequest blacklistRequest \u003d\n           request.getResourceBlacklistRequest();\n       List\u003cString\u003e blacklistAdditions \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistAdditions() : null;\n       List\u003cString\u003e blacklistRemovals \u003d\n           (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistRemovals() : null;\n \n       // sanity check\n       try {\n         RMServerUtils.validateResourceRequests(ask,\n             rScheduler.getMaximumResourceCapability());\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       try {\n         RMServerUtils.validateBlacklistRequest(blacklistRequest);\n       }  catch (InvalidResourceBlacklistRequestException e) {\n         LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n         throw e;\n       }\n-      \n-      try {\n-        RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n-      } catch (InvalidContainerReleaseException e) {\n-        LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n-        throw e;\n+\n+      RMApp app \u003d\n+          this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n+      // In the case of work-preserving AM restart, it\u0027s possible for the\n+      // AM to release containers from the earlier attempt.\n+      if (!app.getApplicationSubmissionContext()\n+        .getKeepContainersAcrossApplicationAttempts()) {\n+        try {\n+          RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n+        } catch (InvalidContainerReleaseException e) {\n+          LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n+          throw e;\n+        }\n       }\n-      \n+\n       // Send new requests to appAttempt.\n       Allocation allocation \u003d\n           this.rScheduler.allocate(appAttemptId, ask, release, \n               blacklistAdditions, blacklistRemovals);\n \n-      RMApp app \u003d this.rmContext.getRMApps().get(\n-          appAttemptId.getApplicationId());\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       \n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n               rmNode.getState(),\n               rmNode.getHttpAddress(), rmNode.getRackName(), used,\n               rmNode.getTotalCapability(), numContainers,\n               rmNode.getHealthReport(),\n               rmNode.getLastHealthReportTime());\n \n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n \n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n \n       // add preemption to the allocateResponse message (if any)\n       allocateResponse\n           .setPreemptionMessage(generatePreemptionMessage(allocation));\n \n       // Adding NMTokens for allocated containers.\n       if (!allocation.getContainers().isEmpty()) {\n         allocateResponse.setNMTokens(rmContext.getNMTokenSecretManager()\n             .createAndGetNMTokens(app.getUser(), appAttemptId,\n                 allocation.getContainers()));\n       }\n       /*\n        * As we are updating the response inside the lock object so we don\u0027t\n        * need to worry about unregister call occurring in between (which\n        * removes the lock object).\n        */\n       lock.setAllocateResponse(allocateResponse);\n       return allocateResponse;\n     }    \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    ApplicationAttemptId appAttemptId \u003d authorizeRequest();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n    if (lock \u003d\u003d null) {\n      LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n      return resync;\n    }\n    synchronized (lock) {\n      AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n      if (!hasApplicationMasterRegistered(appAttemptId)) {\n        String message \u003d\n            \"Application Master is trying to allocate before registering for: \"\n                + appAttemptId.getApplicationId();\n        LOG.error(message);\n        RMAuditLogger.logFailure(\n            this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n                .getUser(), AuditConstants.REGISTER_AM, \"\",\n            \"ApplicationMasterService\", message,\n            appAttemptId.getApplicationId(),\n            appAttemptId);\n        throw new InvalidApplicationMasterRequestException(message);\n      }\n\n      if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n        /* old heartbeat */\n        return lastResponse;\n      } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n        LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n        // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n        // Reboot is not useful since after AM reboots, it will send register\n        // and\n        // get an exception. Might as well throw an exception here.\n        return resync;\n      }\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      ResourceBlacklistRequest blacklistRequest \u003d\n          request.getResourceBlacklistRequest();\n      List\u003cString\u003e blacklistAdditions \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistAdditions() : null;\n      List\u003cString\u003e blacklistRemovals \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistRemovals() : null;\n\n      // sanity check\n      try {\n        RMServerUtils.validateResourceRequests(ask,\n            rScheduler.getMaximumResourceCapability());\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      try {\n        RMServerUtils.validateBlacklistRequest(blacklistRequest);\n      }  catch (InvalidResourceBlacklistRequestException e) {\n        LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n        throw e;\n      }\n\n      RMApp app \u003d\n          this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n      // In the case of work-preserving AM restart, it\u0027s possible for the\n      // AM to release containers from the earlier attempt.\n      if (!app.getApplicationSubmissionContext()\n        .getKeepContainersAcrossApplicationAttempts()) {\n        try {\n          RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n        } catch (InvalidContainerReleaseException e) {\n          LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n          throw e;\n        }\n      }\n\n      // Send new requests to appAttempt.\n      Allocation allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release, \n              blacklistAdditions, blacklistRemovals);\n\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      \n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n              rmNode.getState(),\n              rmNode.getHttpAddress(), rmNode.getRackName(), used,\n              rmNode.getTotalCapability(), numContainers,\n              rmNode.getHealthReport(),\n              rmNode.getLastHealthReportTime());\n\n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n\n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n\n      // add preemption to the allocateResponse message (if any)\n      allocateResponse\n          .setPreemptionMessage(generatePreemptionMessage(allocation));\n\n      // Adding NMTokens for allocated containers.\n      if (!allocation.getContainers().isEmpty()) {\n        allocateResponse.setNMTokens(rmContext.getNMTokenSecretManager()\n            .createAndGetNMTokens(app.getUser(), appAttemptId,\n                allocation.getContainers()));\n      }\n      /*\n       * As we are updating the response inside the lock object so we don\u0027t\n       * need to worry about unregister call occurring in between (which\n       * removes the lock object).\n       */\n      lock.setAllocateResponse(allocateResponse);\n      return allocateResponse;\n    }    \n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "8caae1d5a65bf082eef9bd03a50fd5025c290406": {
      "type": "Ybodychange",
      "commitMessage": "YARN-744. Race condition in ApplicationMasterService.allocate .. It might process same allocate request twice resulting in additional containers getting allocated. (Omkar Vinit Joshi via bikas)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1543707 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/11/13 9:06 PM",
      "commitName": "8caae1d5a65bf082eef9bd03a50fd5025c290406",
      "commitAuthor": "Bikas Saha",
      "commitDateOld": "14/09/13 6:01 PM",
      "commitNameOld": "ec010a29362c6c5572f8681f4e7d0469176345e1",
      "commitAuthorOld": "Bikas Saha",
      "daysBetweenCommits": 66.17,
      "commitsBetweenForRepo": 434,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,150 +1,145 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n     ApplicationAttemptId appAttemptId \u003d authorizeRequest();\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n-    AllocateResponse lastResponse \u003d responseMap.get(appAttemptId);\n-    if (lastResponse \u003d\u003d null) {\n+    AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n+    if (lock \u003d\u003d null) {\n       LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n       return resync;\n     }\n-    \n-    if (!hasApplicationMasterRegistered(appAttemptId)) {\n-      String message \u003d\n-          \"Application Master is trying to allocate before registering for: \"\n-              + appAttemptId.getApplicationId();\n-      LOG.error(message);\n-      RMAuditLogger.logFailure(\n-        this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n-          .getUser(), AuditConstants.REGISTER_AM, \"\",\n-        \"ApplicationMasterService\", message, appAttemptId.getApplicationId(),\n-        appAttemptId);\n-      throw new InvalidApplicationMasterRequestException(message);\n-    }\n+    synchronized (lock) {\n+      AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n+      if (!hasApplicationMasterRegistered(appAttemptId)) {\n+        String message \u003d\n+            \"Application Master is trying to allocate before registering for: \"\n+                + appAttemptId.getApplicationId();\n+        LOG.error(message);\n+        RMAuditLogger.logFailure(\n+            this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n+                .getUser(), AuditConstants.REGISTER_AM, \"\",\n+            \"ApplicationMasterService\", message,\n+            appAttemptId.getApplicationId(),\n+            appAttemptId);\n+        throw new InvalidApplicationMasterRequestException(message);\n+      }\n \n-    if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n-      /* old heartbeat */\n-      return lastResponse;\n-    } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n-      LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n-      // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n-      // Reboot is not useful since after AM reboots, it will send register and \n-      // get an exception. Might as well throw an exception here.\n-      return resync;\n-    } \n-    \n-    // Allow only one thread in AM to do heartbeat at a time.\n-    synchronized (lastResponse) {\n+      if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n+        /* old heartbeat */\n+        return lastResponse;\n+      } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n+        LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n+        // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n+        // Reboot is not useful since after AM reboots, it will send register\n+        // and\n+        // get an exception. Might as well throw an exception here.\n+        return resync;\n+      }\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n-      \n-      ResourceBlacklistRequest blacklistRequest \u003d request.getResourceBlacklistRequest();\n-      List\u003cString\u003e blacklistAdditions \u003d \n-          (blacklistRequest !\u003d null) ? \n+\n+      ResourceBlacklistRequest blacklistRequest \u003d\n+          request.getResourceBlacklistRequest();\n+      List\u003cString\u003e blacklistAdditions \u003d\n+          (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistAdditions() : null;\n-      List\u003cString\u003e blacklistRemovals \u003d \n-          (blacklistRequest !\u003d null) ? \n+      List\u003cString\u003e blacklistRemovals \u003d\n+          (blacklistRequest !\u003d null) ?\n               blacklistRequest.getBlacklistRemovals() : null;\n-      \n+\n       // sanity check\n       try {\n         RMServerUtils.validateResourceRequests(ask,\n             rScheduler.getMaximumResourceCapability());\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       try {\n         RMServerUtils.validateBlacklistRequest(blacklistRequest);\n       }  catch (InvalidResourceBlacklistRequestException e) {\n         LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       try {\n         RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n       } catch (InvalidContainerReleaseException e) {\n         LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       // Send new requests to appAttempt.\n       Allocation allocation \u003d\n           this.rScheduler.allocate(appAttemptId, ask, release, \n               blacklistAdditions, blacklistRemovals);\n \n       RMApp app \u003d this.rmContext.getRMApps().get(\n           appAttemptId.getApplicationId());\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       \n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n               rmNode.getState(),\n               rmNode.getHttpAddress(), rmNode.getRackName(), used,\n               rmNode.getTotalCapability(), numContainers,\n               rmNode.getHealthReport(),\n               rmNode.getLastHealthReportTime());\n-          \n+\n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n-      \n+\n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n-   \n+\n       // add preemption to the allocateResponse message (if any)\n-      allocateResponse.setPreemptionMessage(generatePreemptionMessage(allocation));\n+      allocateResponse\n+          .setPreemptionMessage(generatePreemptionMessage(allocation));\n \n       // Adding NMTokens for allocated containers.\n       if (!allocation.getContainers().isEmpty()) {\n         allocateResponse.setNMTokens(rmContext.getNMTokenSecretManager()\n             .createAndGetNMTokens(app.getUser(), appAttemptId,\n                 allocation.getContainers()));\n       }\n-\n-      // before returning response, verify in sync\n-      AllocateResponse oldResponse \u003d\n-          responseMap.put(appAttemptId, allocateResponse);\n-      if (oldResponse \u003d\u003d null) {\n-        // appAttempt got unregistered, remove it back out\n-        responseMap.remove(appAttemptId);\n-        String message \u003d \"App Attempt removed from the cache during allocate\"\n-            + appAttemptId;\n-        LOG.error(message);\n-        return resync;\n-      }\n-\n+      /*\n+       * As we are updating the response inside the lock object so we don\u0027t\n+       * need to worry about unregister call occurring in between (which\n+       * removes the lock object).\n+       */\n+      lock.setAllocateResponse(allocateResponse);\n       return allocateResponse;\n-    }\n+    }    \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    ApplicationAttemptId appAttemptId \u003d authorizeRequest();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponseLock lock \u003d responseMap.get(appAttemptId);\n    if (lock \u003d\u003d null) {\n      LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n      return resync;\n    }\n    synchronized (lock) {\n      AllocateResponse lastResponse \u003d lock.getAllocateResponse();\n      if (!hasApplicationMasterRegistered(appAttemptId)) {\n        String message \u003d\n            \"Application Master is trying to allocate before registering for: \"\n                + appAttemptId.getApplicationId();\n        LOG.error(message);\n        RMAuditLogger.logFailure(\n            this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n                .getUser(), AuditConstants.REGISTER_AM, \"\",\n            \"ApplicationMasterService\", message,\n            appAttemptId.getApplicationId(),\n            appAttemptId);\n        throw new InvalidApplicationMasterRequestException(message);\n      }\n\n      if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n        /* old heartbeat */\n        return lastResponse;\n      } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n        LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n        // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n        // Reboot is not useful since after AM reboots, it will send register\n        // and\n        // get an exception. Might as well throw an exception here.\n        return resync;\n      }\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      ResourceBlacklistRequest blacklistRequest \u003d\n          request.getResourceBlacklistRequest();\n      List\u003cString\u003e blacklistAdditions \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistAdditions() : null;\n      List\u003cString\u003e blacklistRemovals \u003d\n          (blacklistRequest !\u003d null) ?\n              blacklistRequest.getBlacklistRemovals() : null;\n\n      // sanity check\n      try {\n        RMServerUtils.validateResourceRequests(ask,\n            rScheduler.getMaximumResourceCapability());\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      try {\n        RMServerUtils.validateBlacklistRequest(blacklistRequest);\n      }  catch (InvalidResourceBlacklistRequestException e) {\n        LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      try {\n        RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n      } catch (InvalidContainerReleaseException e) {\n        LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      // Send new requests to appAttempt.\n      Allocation allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release, \n              blacklistAdditions, blacklistRemovals);\n\n      RMApp app \u003d this.rmContext.getRMApps().get(\n          appAttemptId.getApplicationId());\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      \n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n              rmNode.getState(),\n              rmNode.getHttpAddress(), rmNode.getRackName(), used,\n              rmNode.getTotalCapability(), numContainers,\n              rmNode.getHealthReport(),\n              rmNode.getLastHealthReportTime());\n\n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n\n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n\n      // add preemption to the allocateResponse message (if any)\n      allocateResponse\n          .setPreemptionMessage(generatePreemptionMessage(allocation));\n\n      // Adding NMTokens for allocated containers.\n      if (!allocation.getContainers().isEmpty()) {\n        allocateResponse.setNMTokens(rmContext.getNMTokenSecretManager()\n            .createAndGetNMTokens(app.getUser(), appAttemptId,\n                allocation.getContainers()));\n      }\n      /*\n       * As we are updating the response inside the lock object so we don\u0027t\n       * need to worry about unregister call occurring in between (which\n       * removes the lock object).\n       */\n      lock.setAllocateResponse(allocateResponse);\n      return allocateResponse;\n    }    \n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "48264f1994c8b6002d5f1ac2fea46da28798df2d": {
      "type": "Ybodychange",
      "commitMessage": "YARN-948. Changed ResourceManager to validate the release container list before actually releasing them. Contributed by Omkar Vinit Joshi.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1508609 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/07/13 1:30 PM",
      "commitName": "48264f1994c8b6002d5f1ac2fea46da28798df2d",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "29/07/13 3:23 PM",
      "commitNameOld": "c23cf3cddff9d4d52c2e892b26ba20e5640501e0",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 0.92,
      "commitsBetweenForRepo": 14,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,143 +1,150 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n     ApplicationAttemptId appAttemptId \u003d authorizeRequest();\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponse lastResponse \u003d responseMap.get(appAttemptId);\n     if (lastResponse \u003d\u003d null) {\n       LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n       return resync;\n     }\n     \n     if (!hasApplicationMasterRegistered(appAttemptId)) {\n       String message \u003d\n           \"Application Master is trying to allocate before registering for: \"\n               + appAttemptId.getApplicationId();\n       LOG.error(message);\n       RMAuditLogger.logFailure(\n         this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n           .getUser(), AuditConstants.REGISTER_AM, \"\",\n         \"ApplicationMasterService\", message, appAttemptId.getApplicationId(),\n         appAttemptId);\n       throw new InvalidApplicationMasterRequestException(message);\n     }\n \n     if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n       /* old heartbeat */\n       return lastResponse;\n     } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n       LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n       // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n       // Reboot is not useful since after AM reboots, it will send register and \n       // get an exception. Might as well throw an exception here.\n       return resync;\n     } \n     \n     // Allow only one thread in AM to do heartbeat at a time.\n     synchronized (lastResponse) {\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n       \n       ResourceBlacklistRequest blacklistRequest \u003d request.getResourceBlacklistRequest();\n       List\u003cString\u003e blacklistAdditions \u003d \n           (blacklistRequest !\u003d null) ? \n               blacklistRequest.getBlacklistAdditions() : null;\n       List\u003cString\u003e blacklistRemovals \u003d \n           (blacklistRequest !\u003d null) ? \n               blacklistRequest.getBlacklistRemovals() : null;\n       \n       // sanity check\n       try {\n-        SchedulerUtils.validateResourceRequests(ask,\n+        RMServerUtils.validateResourceRequests(ask,\n             rScheduler.getMaximumResourceCapability());\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       try {\n-        SchedulerUtils.validateBlacklistRequest(blacklistRequest);\n+        RMServerUtils.validateBlacklistRequest(blacklistRequest);\n       }  catch (InvalidResourceBlacklistRequestException e) {\n         LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n+      try {\n+        RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n+      } catch (InvalidContainerReleaseException e) {\n+        LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n+        throw e;\n+      }\n+      \n       // Send new requests to appAttempt.\n       Allocation allocation \u003d\n           this.rScheduler.allocate(appAttemptId, ask, release, \n               blacklistAdditions, blacklistRemovals);\n \n       RMApp app \u003d this.rmContext.getRMApps().get(\n           appAttemptId.getApplicationId());\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       \n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n               rmNode.getState(),\n               rmNode.getHttpAddress(), rmNode.getRackName(), used,\n               rmNode.getTotalCapability(), numContainers,\n               rmNode.getHealthReport(),\n               rmNode.getLastHealthReportTime());\n           \n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n       \n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n    \n       // add preemption to the allocateResponse message (if any)\n       allocateResponse.setPreemptionMessage(generatePreemptionMessage(allocation));\n \n       // Adding NMTokens for allocated containers.\n       if (!allocation.getContainers().isEmpty()) {\n         allocateResponse.setNMTokens(rmContext.getNMTokenSecretManager()\n             .createAndGetNMTokens(app.getUser(), appAttemptId,\n                 allocation.getContainers()));\n       }\n \n       // before returning response, verify in sync\n       AllocateResponse oldResponse \u003d\n           responseMap.put(appAttemptId, allocateResponse);\n       if (oldResponse \u003d\u003d null) {\n         // appAttempt got unregistered, remove it back out\n         responseMap.remove(appAttemptId);\n         String message \u003d \"App Attempt removed from the cache during allocate\"\n             + appAttemptId;\n         LOG.error(message);\n         return resync;\n       }\n \n       return allocateResponse;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    ApplicationAttemptId appAttemptId \u003d authorizeRequest();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponse lastResponse \u003d responseMap.get(appAttemptId);\n    if (lastResponse \u003d\u003d null) {\n      LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n      return resync;\n    }\n    \n    if (!hasApplicationMasterRegistered(appAttemptId)) {\n      String message \u003d\n          \"Application Master is trying to allocate before registering for: \"\n              + appAttemptId.getApplicationId();\n      LOG.error(message);\n      RMAuditLogger.logFailure(\n        this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n          .getUser(), AuditConstants.REGISTER_AM, \"\",\n        \"ApplicationMasterService\", message, appAttemptId.getApplicationId(),\n        appAttemptId);\n      throw new InvalidApplicationMasterRequestException(message);\n    }\n\n    if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n      /* old heartbeat */\n      return lastResponse;\n    } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n      LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n      // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n      // Reboot is not useful since after AM reboots, it will send register and \n      // get an exception. Might as well throw an exception here.\n      return resync;\n    } \n    \n    // Allow only one thread in AM to do heartbeat at a time.\n    synchronized (lastResponse) {\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n      \n      ResourceBlacklistRequest blacklistRequest \u003d request.getResourceBlacklistRequest();\n      List\u003cString\u003e blacklistAdditions \u003d \n          (blacklistRequest !\u003d null) ? \n              blacklistRequest.getBlacklistAdditions() : null;\n      List\u003cString\u003e blacklistRemovals \u003d \n          (blacklistRequest !\u003d null) ? \n              blacklistRequest.getBlacklistRemovals() : null;\n      \n      // sanity check\n      try {\n        RMServerUtils.validateResourceRequests(ask,\n            rScheduler.getMaximumResourceCapability());\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      try {\n        RMServerUtils.validateBlacklistRequest(blacklistRequest);\n      }  catch (InvalidResourceBlacklistRequestException e) {\n        LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      try {\n        RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n      } catch (InvalidContainerReleaseException e) {\n        LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      // Send new requests to appAttempt.\n      Allocation allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release, \n              blacklistAdditions, blacklistRemovals);\n\n      RMApp app \u003d this.rmContext.getRMApps().get(\n          appAttemptId.getApplicationId());\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      \n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n              rmNode.getState(),\n              rmNode.getHttpAddress(), rmNode.getRackName(), used,\n              rmNode.getTotalCapability(), numContainers,\n              rmNode.getHealthReport(),\n              rmNode.getLastHealthReportTime());\n          \n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n      \n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n   \n      // add preemption to the allocateResponse message (if any)\n      allocateResponse.setPreemptionMessage(generatePreemptionMessage(allocation));\n\n      // Adding NMTokens for allocated containers.\n      if (!allocation.getContainers().isEmpty()) {\n        allocateResponse.setNMTokens(rmContext.getNMTokenSecretManager()\n            .createAndGetNMTokens(app.getUser(), appAttemptId,\n                allocation.getContainers()));\n      }\n\n      // before returning response, verify in sync\n      AllocateResponse oldResponse \u003d\n          responseMap.put(appAttemptId, allocateResponse);\n      if (oldResponse \u003d\u003d null) {\n        // appAttempt got unregistered, remove it back out\n        responseMap.remove(appAttemptId);\n        String message \u003d \"App Attempt removed from the cache during allocate\"\n            + appAttemptId;\n        LOG.error(message);\n        return resync;\n      }\n\n      return allocateResponse;\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "ac914f79bc80b152e71e7de5497b73f22824f4a7": {
      "type": "Ybodychange",
      "commitMessage": "YARN-918. Remove ApplicationAttemptId from RegisterApplicationMasterRequestProto. Contributed by Vinod K V.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1504735 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/07/13 5:57 PM",
      "commitName": "ac914f79bc80b152e71e7de5497b73f22824f4a7",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "18/07/13 12:03 PM",
      "commitNameOld": "32bc200d54928d39acdc837c2c77b4c443fb46be",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.25,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,144 +1,143 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n-    ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n-    authorizeRequest(appAttemptId);\n+    ApplicationAttemptId appAttemptId \u003d authorizeRequest();\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponse lastResponse \u003d responseMap.get(appAttemptId);\n     if (lastResponse \u003d\u003d null) {\n       LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n       return resync;\n     }\n     \n     if (!hasApplicationMasterRegistered(appAttemptId)) {\n       String message \u003d\n           \"Application Master is trying to allocate before registering for: \"\n               + appAttemptId.getApplicationId();\n       LOG.error(message);\n       RMAuditLogger.logFailure(\n         this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n           .getUser(), AuditConstants.REGISTER_AM, \"\",\n         \"ApplicationMasterService\", message, appAttemptId.getApplicationId(),\n         appAttemptId);\n       throw new InvalidApplicationMasterRequestException(message);\n     }\n \n     if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n       /* old heartbeat */\n       return lastResponse;\n     } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n       LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n       // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n       // Reboot is not useful since after AM reboots, it will send register and \n       // get an exception. Might as well throw an exception here.\n       return resync;\n     } \n     \n     // Allow only one thread in AM to do heartbeat at a time.\n     synchronized (lastResponse) {\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n       \n       ResourceBlacklistRequest blacklistRequest \u003d request.getResourceBlacklistRequest();\n       List\u003cString\u003e blacklistAdditions \u003d \n           (blacklistRequest !\u003d null) ? \n               blacklistRequest.getBlacklistAdditions() : null;\n       List\u003cString\u003e blacklistRemovals \u003d \n           (blacklistRequest !\u003d null) ? \n               blacklistRequest.getBlacklistRemovals() : null;\n       \n       // sanity check\n       try {\n         SchedulerUtils.validateResourceRequests(ask,\n             rScheduler.getMaximumResourceCapability());\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       try {\n         SchedulerUtils.validateBlacklistRequest(blacklistRequest);\n       }  catch (InvalidResourceBlacklistRequestException e) {\n         LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       // Send new requests to appAttempt.\n       Allocation allocation \u003d\n           this.rScheduler.allocate(appAttemptId, ask, release, \n               blacklistAdditions, blacklistRemovals);\n \n       RMApp app \u003d this.rmContext.getRMApps().get(\n           appAttemptId.getApplicationId());\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       \n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n               rmNode.getState(),\n               rmNode.getHttpAddress(), rmNode.getRackName(), used,\n               rmNode.getTotalCapability(), numContainers,\n               rmNode.getHealthReport(),\n               rmNode.getLastHealthReportTime());\n           \n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n       \n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n    \n       // add preemption to the allocateResponse message (if any)\n       allocateResponse.setPreemptionMessage(generatePreemptionMessage(allocation));\n \n       // Adding NMTokens for allocated containers.\n       if (!allocation.getContainers().isEmpty()) {\n         allocateResponse.setNMTokens(rmContext.getNMTokenSecretManager()\n             .createAndGetNMTokens(app.getUser(), appAttemptId,\n                 allocation.getContainers()));\n       }\n \n       // before returning response, verify in sync\n       AllocateResponse oldResponse \u003d\n           responseMap.put(appAttemptId, allocateResponse);\n       if (oldResponse \u003d\u003d null) {\n         // appAttempt got unregistered, remove it back out\n         responseMap.remove(appAttemptId);\n         String message \u003d \"App Attempt removed from the cache during allocate\"\n             + appAttemptId;\n         LOG.error(message);\n         return resync;\n       }\n \n       return allocateResponse;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    ApplicationAttemptId appAttemptId \u003d authorizeRequest();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponse lastResponse \u003d responseMap.get(appAttemptId);\n    if (lastResponse \u003d\u003d null) {\n      LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n      return resync;\n    }\n    \n    if (!hasApplicationMasterRegistered(appAttemptId)) {\n      String message \u003d\n          \"Application Master is trying to allocate before registering for: \"\n              + appAttemptId.getApplicationId();\n      LOG.error(message);\n      RMAuditLogger.logFailure(\n        this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n          .getUser(), AuditConstants.REGISTER_AM, \"\",\n        \"ApplicationMasterService\", message, appAttemptId.getApplicationId(),\n        appAttemptId);\n      throw new InvalidApplicationMasterRequestException(message);\n    }\n\n    if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n      /* old heartbeat */\n      return lastResponse;\n    } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n      LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n      // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n      // Reboot is not useful since after AM reboots, it will send register and \n      // get an exception. Might as well throw an exception here.\n      return resync;\n    } \n    \n    // Allow only one thread in AM to do heartbeat at a time.\n    synchronized (lastResponse) {\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n      \n      ResourceBlacklistRequest blacklistRequest \u003d request.getResourceBlacklistRequest();\n      List\u003cString\u003e blacklistAdditions \u003d \n          (blacklistRequest !\u003d null) ? \n              blacklistRequest.getBlacklistAdditions() : null;\n      List\u003cString\u003e blacklistRemovals \u003d \n          (blacklistRequest !\u003d null) ? \n              blacklistRequest.getBlacklistRemovals() : null;\n      \n      // sanity check\n      try {\n        SchedulerUtils.validateResourceRequests(ask,\n            rScheduler.getMaximumResourceCapability());\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      try {\n        SchedulerUtils.validateBlacklistRequest(blacklistRequest);\n      }  catch (InvalidResourceBlacklistRequestException e) {\n        LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      // Send new requests to appAttempt.\n      Allocation allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release, \n              blacklistAdditions, blacklistRemovals);\n\n      RMApp app \u003d this.rmContext.getRMApps().get(\n          appAttemptId.getApplicationId());\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      \n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n              rmNode.getState(),\n              rmNode.getHttpAddress(), rmNode.getRackName(), used,\n              rmNode.getTotalCapability(), numContainers,\n              rmNode.getHealthReport(),\n              rmNode.getLastHealthReportTime());\n          \n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n      \n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n   \n      // add preemption to the allocateResponse message (if any)\n      allocateResponse.setPreemptionMessage(generatePreemptionMessage(allocation));\n\n      // Adding NMTokens for allocated containers.\n      if (!allocation.getContainers().isEmpty()) {\n        allocateResponse.setNMTokens(rmContext.getNMTokenSecretManager()\n            .createAndGetNMTokens(app.getUser(), appAttemptId,\n                allocation.getContainers()));\n      }\n\n      // before returning response, verify in sync\n      AllocateResponse oldResponse \u003d\n          responseMap.put(appAttemptId, allocateResponse);\n      if (oldResponse \u003d\u003d null) {\n        // appAttempt got unregistered, remove it back out\n        responseMap.remove(appAttemptId);\n        String message \u003d \"App Attempt removed from the cache during allocate\"\n            + appAttemptId;\n        LOG.error(message);\n        return resync;\n      }\n\n      return allocateResponse;\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "85f0efb68f9d1d9ee3466e3939c4fc2f985ccf61": {
      "type": "Ybodychange",
      "commitMessage": "YARN-569. Add support for requesting and enforcing preemption requests via\na capacity monitor. Contributed by Carlo Curino, Chris Douglas\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1502083 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/07/13 6:20 PM",
      "commitName": "85f0efb68f9d1d9ee3466e3939c4fc2f985ccf61",
      "commitAuthor": "Christopher Douglas",
      "commitDateOld": "09/07/13 4:14 PM",
      "commitNameOld": "15ce82b9c5087ac5e51f7a43eb57873c3c374ced",
      "commitAuthorOld": "Bikas Saha",
      "daysBetweenCommits": 1.09,
      "commitsBetweenForRepo": 10,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,142 +1,144 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n     ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n     authorizeRequest(appAttemptId);\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponse lastResponse \u003d responseMap.get(appAttemptId);\n     if (lastResponse \u003d\u003d null) {\n       LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n       return resync;\n     }\n     \n     if (!hasApplicationMasterRegistered(appAttemptId)) {\n       String message \u003d\n           \"Application Master is trying to allocate before registering for: \"\n               + appAttemptId.getApplicationId();\n       LOG.error(message);\n       RMAuditLogger.logFailure(\n         this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n           .getUser(), AuditConstants.REGISTER_AM, \"\",\n         \"ApplicationMasterService\", message, appAttemptId.getApplicationId(),\n         appAttemptId);\n       throw new InvalidApplicationMasterRequestException(message);\n     }\n \n     if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n       /* old heartbeat */\n       return lastResponse;\n     } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n       LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n       // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n       // Reboot is not useful since after AM reboots, it will send register and \n       // get an exception. Might as well throw an exception here.\n       return resync;\n     } \n     \n     // Allow only one thread in AM to do heartbeat at a time.\n     synchronized (lastResponse) {\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n       \n       ResourceBlacklistRequest blacklistRequest \u003d request.getResourceBlacklistRequest();\n       List\u003cString\u003e blacklistAdditions \u003d \n           (blacklistRequest !\u003d null) ? \n               blacklistRequest.getBlacklistAdditions() : null;\n       List\u003cString\u003e blacklistRemovals \u003d \n           (blacklistRequest !\u003d null) ? \n               blacklistRequest.getBlacklistRemovals() : null;\n       \n       // sanity check\n       try {\n         SchedulerUtils.validateResourceRequests(ask,\n             rScheduler.getMaximumResourceCapability());\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       try {\n         SchedulerUtils.validateBlacklistRequest(blacklistRequest);\n       }  catch (InvalidResourceBlacklistRequestException e) {\n         LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       // Send new requests to appAttempt.\n       Allocation allocation \u003d\n           this.rScheduler.allocate(appAttemptId, ask, release, \n               blacklistAdditions, blacklistRemovals);\n \n       RMApp app \u003d this.rmContext.getRMApps().get(\n           appAttemptId.getApplicationId());\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       \n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n               rmNode.getState(),\n               rmNode.getHttpAddress(), rmNode.getRackName(), used,\n               rmNode.getTotalCapability(), numContainers,\n               rmNode.getHealthReport(),\n               rmNode.getLastHealthReportTime());\n           \n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n       \n+      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n+   \n+      // add preemption to the allocateResponse message (if any)\n+      allocateResponse.setPreemptionMessage(generatePreemptionMessage(allocation));\n+\n+      // Adding NMTokens for allocated containers.\n+      if (!allocation.getContainers().isEmpty()) {\n+        allocateResponse.setNMTokens(rmContext.getNMTokenSecretManager()\n+            .createAndGetNMTokens(app.getUser(), appAttemptId,\n+                allocation.getContainers()));\n+      }\n+\n+      // before returning response, verify in sync\n       AllocateResponse oldResponse \u003d\n           responseMap.put(appAttemptId, allocateResponse);\n       if (oldResponse \u003d\u003d null) {\n         // appAttempt got unregistered, remove it back out\n         responseMap.remove(appAttemptId);\n         String message \u003d \"App Attempt removed from the cache during allocate\"\n             + appAttemptId;\n         LOG.error(message);\n         return resync;\n       }\n-      \n-      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n-   \n-      // add preemption to the allocateResponse message (if any)\n-      allocateResponse.setPreemptionMessage(generatePreemptionMessage(allocation));\n-      \n-      // Adding NMTokens for allocated containers.\n-      if (!allocation.getContainers().isEmpty()) {\n-        allocateResponse.setNMTokens(rmContext.getNMTokenSecretManager()\n-            .createAndGetNMTokens(app.getUser(), appAttemptId,\n-                allocation.getContainers()));\n-      }\n+\n       return allocateResponse;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n    authorizeRequest(appAttemptId);\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponse lastResponse \u003d responseMap.get(appAttemptId);\n    if (lastResponse \u003d\u003d null) {\n      LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n      return resync;\n    }\n    \n    if (!hasApplicationMasterRegistered(appAttemptId)) {\n      String message \u003d\n          \"Application Master is trying to allocate before registering for: \"\n              + appAttemptId.getApplicationId();\n      LOG.error(message);\n      RMAuditLogger.logFailure(\n        this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n          .getUser(), AuditConstants.REGISTER_AM, \"\",\n        \"ApplicationMasterService\", message, appAttemptId.getApplicationId(),\n        appAttemptId);\n      throw new InvalidApplicationMasterRequestException(message);\n    }\n\n    if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n      /* old heartbeat */\n      return lastResponse;\n    } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n      LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n      // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n      // Reboot is not useful since after AM reboots, it will send register and \n      // get an exception. Might as well throw an exception here.\n      return resync;\n    } \n    \n    // Allow only one thread in AM to do heartbeat at a time.\n    synchronized (lastResponse) {\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n      \n      ResourceBlacklistRequest blacklistRequest \u003d request.getResourceBlacklistRequest();\n      List\u003cString\u003e blacklistAdditions \u003d \n          (blacklistRequest !\u003d null) ? \n              blacklistRequest.getBlacklistAdditions() : null;\n      List\u003cString\u003e blacklistRemovals \u003d \n          (blacklistRequest !\u003d null) ? \n              blacklistRequest.getBlacklistRemovals() : null;\n      \n      // sanity check\n      try {\n        SchedulerUtils.validateResourceRequests(ask,\n            rScheduler.getMaximumResourceCapability());\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      try {\n        SchedulerUtils.validateBlacklistRequest(blacklistRequest);\n      }  catch (InvalidResourceBlacklistRequestException e) {\n        LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      // Send new requests to appAttempt.\n      Allocation allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release, \n              blacklistAdditions, blacklistRemovals);\n\n      RMApp app \u003d this.rmContext.getRMApps().get(\n          appAttemptId.getApplicationId());\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      \n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n              rmNode.getState(),\n              rmNode.getHttpAddress(), rmNode.getRackName(), used,\n              rmNode.getTotalCapability(), numContainers,\n              rmNode.getHealthReport(),\n              rmNode.getLastHealthReportTime());\n          \n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n      \n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n   \n      // add preemption to the allocateResponse message (if any)\n      allocateResponse.setPreemptionMessage(generatePreemptionMessage(allocation));\n\n      // Adding NMTokens for allocated containers.\n      if (!allocation.getContainers().isEmpty()) {\n        allocateResponse.setNMTokens(rmContext.getNMTokenSecretManager()\n            .createAndGetNMTokens(app.getUser(), appAttemptId,\n                allocation.getContainers()));\n      }\n\n      // before returning response, verify in sync\n      AllocateResponse oldResponse \u003d\n          responseMap.put(appAttemptId, allocateResponse);\n      if (oldResponse \u003d\u003d null) {\n        // appAttempt got unregistered, remove it back out\n        responseMap.remove(appAttemptId);\n        String message \u003d \"App Attempt removed from the cache during allocate\"\n            + appAttemptId;\n        LOG.error(message);\n        return resync;\n      }\n\n      return allocateResponse;\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "15ce82b9c5087ac5e51f7a43eb57873c3c374ced": {
      "type": "Ybodychange",
      "commitMessage": "YARN-369. Handle ( or throw a proper error when receiving) status updates from application masters that have not registered (Mayank Bansal \u0026 Abhishek Kapoor via bikas)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1501605 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/07/13 4:14 PM",
      "commitName": "15ce82b9c5087ac5e51f7a43eb57873c3c374ced",
      "commitAuthor": "Bikas Saha",
      "commitDateOld": "18/06/13 4:19 PM",
      "commitNameOld": "243bcd367ff3130d74676280233041f88aca62a5",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 21.0,
      "commitsBetweenForRepo": 88,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,128 +1,142 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n     ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n     authorizeRequest(appAttemptId);\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponse lastResponse \u003d responseMap.get(appAttemptId);\n     if (lastResponse \u003d\u003d null) {\n       LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n       return resync;\n     }\n+    \n+    if (!hasApplicationMasterRegistered(appAttemptId)) {\n+      String message \u003d\n+          \"Application Master is trying to allocate before registering for: \"\n+              + appAttemptId.getApplicationId();\n+      LOG.error(message);\n+      RMAuditLogger.logFailure(\n+        this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n+          .getUser(), AuditConstants.REGISTER_AM, \"\",\n+        \"ApplicationMasterService\", message, appAttemptId.getApplicationId(),\n+        appAttemptId);\n+      throw new InvalidApplicationMasterRequestException(message);\n+    }\n+\n     if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n       /* old heartbeat */\n       return lastResponse;\n     } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n       LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n       // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n       // Reboot is not useful since after AM reboots, it will send register and \n       // get an exception. Might as well throw an exception here.\n       return resync;\n     } \n     \n     // Allow only one thread in AM to do heartbeat at a time.\n     synchronized (lastResponse) {\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n       \n       ResourceBlacklistRequest blacklistRequest \u003d request.getResourceBlacklistRequest();\n       List\u003cString\u003e blacklistAdditions \u003d \n           (blacklistRequest !\u003d null) ? \n               blacklistRequest.getBlacklistAdditions() : null;\n       List\u003cString\u003e blacklistRemovals \u003d \n           (blacklistRequest !\u003d null) ? \n               blacklistRequest.getBlacklistRemovals() : null;\n       \n       // sanity check\n       try {\n         SchedulerUtils.validateResourceRequests(ask,\n             rScheduler.getMaximumResourceCapability());\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       try {\n         SchedulerUtils.validateBlacklistRequest(blacklistRequest);\n       }  catch (InvalidResourceBlacklistRequestException e) {\n         LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       // Send new requests to appAttempt.\n       Allocation allocation \u003d\n           this.rScheduler.allocate(appAttemptId, ask, release, \n               blacklistAdditions, blacklistRemovals);\n \n       RMApp app \u003d this.rmContext.getRMApps().get(\n           appAttemptId.getApplicationId());\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       \n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n               rmNode.getState(),\n               rmNode.getHttpAddress(), rmNode.getRackName(), used,\n               rmNode.getTotalCapability(), numContainers,\n               rmNode.getHealthReport(),\n               rmNode.getLastHealthReportTime());\n           \n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n       \n       AllocateResponse oldResponse \u003d\n           responseMap.put(appAttemptId, allocateResponse);\n       if (oldResponse \u003d\u003d null) {\n         // appAttempt got unregistered, remove it back out\n         responseMap.remove(appAttemptId);\n         String message \u003d \"App Attempt removed from the cache during allocate\"\n             + appAttemptId;\n         LOG.error(message);\n         return resync;\n       }\n       \n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n    \n       // add preemption to the allocateResponse message (if any)\n       allocateResponse.setPreemptionMessage(generatePreemptionMessage(allocation));\n       \n       // Adding NMTokens for allocated containers.\n       if (!allocation.getContainers().isEmpty()) {\n         allocateResponse.setNMTokens(rmContext.getNMTokenSecretManager()\n             .createAndGetNMTokens(app.getUser(), appAttemptId,\n                 allocation.getContainers()));\n       }\n       return allocateResponse;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n    authorizeRequest(appAttemptId);\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponse lastResponse \u003d responseMap.get(appAttemptId);\n    if (lastResponse \u003d\u003d null) {\n      LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n      return resync;\n    }\n    \n    if (!hasApplicationMasterRegistered(appAttemptId)) {\n      String message \u003d\n          \"Application Master is trying to allocate before registering for: \"\n              + appAttemptId.getApplicationId();\n      LOG.error(message);\n      RMAuditLogger.logFailure(\n        this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n          .getUser(), AuditConstants.REGISTER_AM, \"\",\n        \"ApplicationMasterService\", message, appAttemptId.getApplicationId(),\n        appAttemptId);\n      throw new InvalidApplicationMasterRequestException(message);\n    }\n\n    if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n      /* old heartbeat */\n      return lastResponse;\n    } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n      LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n      // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n      // Reboot is not useful since after AM reboots, it will send register and \n      // get an exception. Might as well throw an exception here.\n      return resync;\n    } \n    \n    // Allow only one thread in AM to do heartbeat at a time.\n    synchronized (lastResponse) {\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n      \n      ResourceBlacklistRequest blacklistRequest \u003d request.getResourceBlacklistRequest();\n      List\u003cString\u003e blacklistAdditions \u003d \n          (blacklistRequest !\u003d null) ? \n              blacklistRequest.getBlacklistAdditions() : null;\n      List\u003cString\u003e blacklistRemovals \u003d \n          (blacklistRequest !\u003d null) ? \n              blacklistRequest.getBlacklistRemovals() : null;\n      \n      // sanity check\n      try {\n        SchedulerUtils.validateResourceRequests(ask,\n            rScheduler.getMaximumResourceCapability());\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      try {\n        SchedulerUtils.validateBlacklistRequest(blacklistRequest);\n      }  catch (InvalidResourceBlacklistRequestException e) {\n        LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      // Send new requests to appAttempt.\n      Allocation allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release, \n              blacklistAdditions, blacklistRemovals);\n\n      RMApp app \u003d this.rmContext.getRMApps().get(\n          appAttemptId.getApplicationId());\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      \n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n              rmNode.getState(),\n              rmNode.getHttpAddress(), rmNode.getRackName(), used,\n              rmNode.getTotalCapability(), numContainers,\n              rmNode.getHealthReport(),\n              rmNode.getLastHealthReportTime());\n          \n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n      \n      AllocateResponse oldResponse \u003d\n          responseMap.put(appAttemptId, allocateResponse);\n      if (oldResponse \u003d\u003d null) {\n        // appAttempt got unregistered, remove it back out\n        responseMap.remove(appAttemptId);\n        String message \u003d \"App Attempt removed from the cache during allocate\"\n            + appAttemptId;\n        LOG.error(message);\n        return resync;\n      }\n      \n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n   \n      // add preemption to the allocateResponse message (if any)\n      allocateResponse.setPreemptionMessage(generatePreemptionMessage(allocation));\n      \n      // Adding NMTokens for allocated containers.\n      if (!allocation.getContainers().isEmpty()) {\n        allocateResponse.setNMTokens(rmContext.getNMTokenSecretManager()\n            .createAndGetNMTokens(app.getUser(), appAttemptId,\n                allocation.getContainers()));\n      }\n      return allocateResponse;\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "243bcd367ff3130d74676280233041f88aca62a5": {
      "type": "Ybodychange",
      "commitMessage": "YARN-694. Starting to use NMTokens to authenticate all communication with NodeManagers. Contributed by Omkar Vinit Joshi.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1494369 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/06/13 4:19 PM",
      "commitName": "243bcd367ff3130d74676280233041f88aca62a5",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "17/06/13 4:13 PM",
      "commitNameOld": "5d1b453b8591d87ffb564857015c26c99fb7437c",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 1.0,
      "commitsBetweenForRepo": 15,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,128 +1,128 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n     ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n     authorizeRequest(appAttemptId);\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponse lastResponse \u003d responseMap.get(appAttemptId);\n     if (lastResponse \u003d\u003d null) {\n       LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n       return resync;\n     }\n     if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n       /* old heartbeat */\n       return lastResponse;\n     } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n       LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n       // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n       // Reboot is not useful since after AM reboots, it will send register and \n       // get an exception. Might as well throw an exception here.\n       return resync;\n     } \n     \n     // Allow only one thread in AM to do heartbeat at a time.\n     synchronized (lastResponse) {\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n       \n       ResourceBlacklistRequest blacklistRequest \u003d request.getResourceBlacklistRequest();\n       List\u003cString\u003e blacklistAdditions \u003d \n           (blacklistRequest !\u003d null) ? \n               blacklistRequest.getBlacklistAdditions() : null;\n       List\u003cString\u003e blacklistRemovals \u003d \n           (blacklistRequest !\u003d null) ? \n               blacklistRequest.getBlacklistRemovals() : null;\n       \n       // sanity check\n       try {\n         SchedulerUtils.validateResourceRequests(ask,\n             rScheduler.getMaximumResourceCapability());\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       try {\n         SchedulerUtils.validateBlacklistRequest(blacklistRequest);\n       }  catch (InvalidResourceBlacklistRequestException e) {\n         LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       // Send new requests to appAttempt.\n       Allocation allocation \u003d\n           this.rScheduler.allocate(appAttemptId, ask, release, \n               blacklistAdditions, blacklistRemovals);\n \n       RMApp app \u003d this.rmContext.getRMApps().get(\n           appAttemptId.getApplicationId());\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       \n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n               rmNode.getState(),\n               rmNode.getHttpAddress(), rmNode.getRackName(), used,\n               rmNode.getTotalCapability(), numContainers,\n               rmNode.getHealthReport(),\n               rmNode.getLastHealthReportTime());\n           \n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n       \n       AllocateResponse oldResponse \u003d\n           responseMap.put(appAttemptId, allocateResponse);\n       if (oldResponse \u003d\u003d null) {\n         // appAttempt got unregistered, remove it back out\n         responseMap.remove(appAttemptId);\n         String message \u003d \"App Attempt removed from the cache during allocate\"\n             + appAttemptId;\n         LOG.error(message);\n         return resync;\n       }\n       \n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n    \n       // add preemption to the allocateResponse message (if any)\n       allocateResponse.setPreemptionMessage(generatePreemptionMessage(allocation));\n       \n       // Adding NMTokens for allocated containers.\n       if (!allocation.getContainers().isEmpty()) {\n         allocateResponse.setNMTokens(rmContext.getNMTokenSecretManager()\n-            .getNMTokens(app.getUser(), appAttemptId,\n+            .createAndGetNMTokens(app.getUser(), appAttemptId,\n                 allocation.getContainers()));\n       }\n       return allocateResponse;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n    authorizeRequest(appAttemptId);\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponse lastResponse \u003d responseMap.get(appAttemptId);\n    if (lastResponse \u003d\u003d null) {\n      LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n      return resync;\n    }\n    if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n      /* old heartbeat */\n      return lastResponse;\n    } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n      LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n      // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n      // Reboot is not useful since after AM reboots, it will send register and \n      // get an exception. Might as well throw an exception here.\n      return resync;\n    } \n    \n    // Allow only one thread in AM to do heartbeat at a time.\n    synchronized (lastResponse) {\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n      \n      ResourceBlacklistRequest blacklistRequest \u003d request.getResourceBlacklistRequest();\n      List\u003cString\u003e blacklistAdditions \u003d \n          (blacklistRequest !\u003d null) ? \n              blacklistRequest.getBlacklistAdditions() : null;\n      List\u003cString\u003e blacklistRemovals \u003d \n          (blacklistRequest !\u003d null) ? \n              blacklistRequest.getBlacklistRemovals() : null;\n      \n      // sanity check\n      try {\n        SchedulerUtils.validateResourceRequests(ask,\n            rScheduler.getMaximumResourceCapability());\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      try {\n        SchedulerUtils.validateBlacklistRequest(blacklistRequest);\n      }  catch (InvalidResourceBlacklistRequestException e) {\n        LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      // Send new requests to appAttempt.\n      Allocation allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release, \n              blacklistAdditions, blacklistRemovals);\n\n      RMApp app \u003d this.rmContext.getRMApps().get(\n          appAttemptId.getApplicationId());\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      \n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n              rmNode.getState(),\n              rmNode.getHttpAddress(), rmNode.getRackName(), used,\n              rmNode.getTotalCapability(), numContainers,\n              rmNode.getHealthReport(),\n              rmNode.getLastHealthReportTime());\n          \n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n      \n      AllocateResponse oldResponse \u003d\n          responseMap.put(appAttemptId, allocateResponse);\n      if (oldResponse \u003d\u003d null) {\n        // appAttempt got unregistered, remove it back out\n        responseMap.remove(appAttemptId);\n        String message \u003d \"App Attempt removed from the cache during allocate\"\n            + appAttemptId;\n        LOG.error(message);\n        return resync;\n      }\n      \n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n   \n      // add preemption to the allocateResponse message (if any)\n      allocateResponse.setPreemptionMessage(generatePreemptionMessage(allocation));\n      \n      // Adding NMTokens for allocated containers.\n      if (!allocation.getContainers().isEmpty()) {\n        allocateResponse.setNMTokens(rmContext.getNMTokenSecretManager()\n            .createAndGetNMTokens(app.getUser(), appAttemptId,\n                allocation.getContainers()));\n      }\n      return allocateResponse;\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "769a0bd8314cd7317c083a9b74abf47242acb58c": {
      "type": "Ybodychange",
      "commitMessage": "YARN-693. Modified RM to send NMTokens on allocate call so that AMs can then use them for authentication with NMs. Contributed by Omkar Vinit Joshi.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1493448 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "15/06/13 8:11 PM",
      "commitName": "769a0bd8314cd7317c083a9b74abf47242acb58c",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "13/06/13 8:54 AM",
      "commitNameOld": "0928502029ef141759008997335ea2cd836a7154",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 2.47,
      "commitsBetweenForRepo": 26,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,122 +1,128 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n     ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n     authorizeRequest(appAttemptId);\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponse lastResponse \u003d responseMap.get(appAttemptId);\n     if (lastResponse \u003d\u003d null) {\n       LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n       return resync;\n     }\n     if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n       /* old heartbeat */\n       return lastResponse;\n     } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n       LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n       // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n       // Reboot is not useful since after AM reboots, it will send register and \n       // get an exception. Might as well throw an exception here.\n       return resync;\n     } \n     \n     // Allow only one thread in AM to do heartbeat at a time.\n     synchronized (lastResponse) {\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n       \n       ResourceBlacklistRequest blacklistRequest \u003d request.getResourceBlacklistRequest();\n       List\u003cString\u003e blacklistAdditions \u003d \n           (blacklistRequest !\u003d null) ? \n               blacklistRequest.getBlacklistAdditions() : null;\n       List\u003cString\u003e blacklistRemovals \u003d \n           (blacklistRequest !\u003d null) ? \n               blacklistRequest.getBlacklistRemovals() : null;\n       \n       // sanity check\n       try {\n         SchedulerUtils.validateResourceRequests(ask,\n             rScheduler.getMaximumResourceCapability());\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       try {\n         SchedulerUtils.validateBlacklistRequest(blacklistRequest);\n       }  catch (InvalidResourceBlacklistRequestException e) {\n         LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       // Send new requests to appAttempt.\n       Allocation allocation \u003d\n           this.rScheduler.allocate(appAttemptId, ask, release, \n               blacklistAdditions, blacklistRemovals);\n \n       RMApp app \u003d this.rmContext.getRMApps().get(\n           appAttemptId.getApplicationId());\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       \n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n               rmNode.getState(),\n               rmNode.getHttpAddress(), rmNode.getRackName(), used,\n               rmNode.getTotalCapability(), numContainers,\n               rmNode.getHealthReport(),\n               rmNode.getLastHealthReportTime());\n           \n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n       \n       AllocateResponse oldResponse \u003d\n           responseMap.put(appAttemptId, allocateResponse);\n       if (oldResponse \u003d\u003d null) {\n         // appAttempt got unregistered, remove it back out\n         responseMap.remove(appAttemptId);\n         String message \u003d \"App Attempt removed from the cache during allocate\"\n             + appAttemptId;\n         LOG.error(message);\n         return resync;\n       }\n       \n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n    \n       // add preemption to the allocateResponse message (if any)\n       allocateResponse.setPreemptionMessage(generatePreemptionMessage(allocation));\n       \n+      // Adding NMTokens for allocated containers.\n+      if (!allocation.getContainers().isEmpty()) {\n+        allocateResponse.setNMTokens(rmContext.getNMTokenSecretManager()\n+            .getNMTokens(app.getUser(), appAttemptId,\n+                allocation.getContainers()));\n+      }\n       return allocateResponse;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n    authorizeRequest(appAttemptId);\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponse lastResponse \u003d responseMap.get(appAttemptId);\n    if (lastResponse \u003d\u003d null) {\n      LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n      return resync;\n    }\n    if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n      /* old heartbeat */\n      return lastResponse;\n    } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n      LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n      // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n      // Reboot is not useful since after AM reboots, it will send register and \n      // get an exception. Might as well throw an exception here.\n      return resync;\n    } \n    \n    // Allow only one thread in AM to do heartbeat at a time.\n    synchronized (lastResponse) {\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n      \n      ResourceBlacklistRequest blacklistRequest \u003d request.getResourceBlacklistRequest();\n      List\u003cString\u003e blacklistAdditions \u003d \n          (blacklistRequest !\u003d null) ? \n              blacklistRequest.getBlacklistAdditions() : null;\n      List\u003cString\u003e blacklistRemovals \u003d \n          (blacklistRequest !\u003d null) ? \n              blacklistRequest.getBlacklistRemovals() : null;\n      \n      // sanity check\n      try {\n        SchedulerUtils.validateResourceRequests(ask,\n            rScheduler.getMaximumResourceCapability());\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      try {\n        SchedulerUtils.validateBlacklistRequest(blacklistRequest);\n      }  catch (InvalidResourceBlacklistRequestException e) {\n        LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      // Send new requests to appAttempt.\n      Allocation allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release, \n              blacklistAdditions, blacklistRemovals);\n\n      RMApp app \u003d this.rmContext.getRMApps().get(\n          appAttemptId.getApplicationId());\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      \n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n              rmNode.getState(),\n              rmNode.getHttpAddress(), rmNode.getRackName(), used,\n              rmNode.getTotalCapability(), numContainers,\n              rmNode.getHealthReport(),\n              rmNode.getLastHealthReportTime());\n          \n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n      \n      AllocateResponse oldResponse \u003d\n          responseMap.put(appAttemptId, allocateResponse);\n      if (oldResponse \u003d\u003d null) {\n        // appAttempt got unregistered, remove it back out\n        responseMap.remove(appAttemptId);\n        String message \u003d \"App Attempt removed from the cache during allocate\"\n            + appAttemptId;\n        LOG.error(message);\n        return resync;\n      }\n      \n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n   \n      // add preemption to the allocateResponse message (if any)\n      allocateResponse.setPreemptionMessage(generatePreemptionMessage(allocation));\n      \n      // Adding NMTokens for allocated containers.\n      if (!allocation.getContainers().isEmpty()) {\n        allocateResponse.setNMTokens(rmContext.getNMTokenSecretManager()\n            .getNMTokens(app.getUser(), appAttemptId,\n                allocation.getContainers()));\n      }\n      return allocateResponse;\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "af8514eef297574240652672d048748100c97733": {
      "type": "Ybodychange",
      "commitMessage": "YARN-686. Flatten NodeReport. (sandyr via tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1490827 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/06/13 1:59 PM",
      "commitName": "af8514eef297574240652672d048748100c97733",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "06/06/13 4:33 PM",
      "commitNameOld": "9fcfbf5f51f2557566694377f94a556226585d68",
      "commitAuthorOld": "Bikas Saha",
      "daysBetweenCommits": 0.89,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,121 +1,122 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n     ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n     authorizeRequest(appAttemptId);\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponse lastResponse \u003d responseMap.get(appAttemptId);\n     if (lastResponse \u003d\u003d null) {\n       LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n       return resync;\n     }\n     if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n       /* old heartbeat */\n       return lastResponse;\n     } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n       LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n       // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n       // Reboot is not useful since after AM reboots, it will send register and \n       // get an exception. Might as well throw an exception here.\n       return resync;\n     } \n     \n     // Allow only one thread in AM to do heartbeat at a time.\n     synchronized (lastResponse) {\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n       \n       ResourceBlacklistRequest blacklistRequest \u003d request.getResourceBlacklistRequest();\n       List\u003cString\u003e blacklistAdditions \u003d \n           (blacklistRequest !\u003d null) ? \n               blacklistRequest.getBlacklistAdditions() : null;\n       List\u003cString\u003e blacklistRemovals \u003d \n           (blacklistRequest !\u003d null) ? \n               blacklistRequest.getBlacklistRemovals() : null;\n       \n       // sanity check\n       try {\n         SchedulerUtils.validateResourceRequests(ask,\n             rScheduler.getMaximumResourceCapability());\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       try {\n         SchedulerUtils.validateBlacklistRequest(blacklistRequest);\n       }  catch (InvalidResourceBlacklistRequestException e) {\n         LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n         throw e;\n       }\n       \n       // Send new requests to appAttempt.\n       Allocation allocation \u003d\n           this.rScheduler.allocate(appAttemptId, ask, release, \n               blacklistAdditions, blacklistRemovals);\n \n       RMApp app \u003d this.rmContext.getRMApps().get(\n           appAttemptId.getApplicationId());\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       \n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n               rmNode.getState(),\n               rmNode.getHttpAddress(), rmNode.getRackName(), used,\n               rmNode.getTotalCapability(), numContainers,\n-              rmNode.getNodeHealthStatus());\n+              rmNode.getHealthReport(),\n+              rmNode.getLastHealthReportTime());\n           \n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n       \n       AllocateResponse oldResponse \u003d\n           responseMap.put(appAttemptId, allocateResponse);\n       if (oldResponse \u003d\u003d null) {\n         // appAttempt got unregistered, remove it back out\n         responseMap.remove(appAttemptId);\n         String message \u003d \"App Attempt removed from the cache during allocate\"\n             + appAttemptId;\n         LOG.error(message);\n         return resync;\n       }\n       \n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n    \n       // add preemption to the allocateResponse message (if any)\n       allocateResponse.setPreemptionMessage(generatePreemptionMessage(allocation));\n       \n       return allocateResponse;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n    authorizeRequest(appAttemptId);\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponse lastResponse \u003d responseMap.get(appAttemptId);\n    if (lastResponse \u003d\u003d null) {\n      LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n      return resync;\n    }\n    if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n      /* old heartbeat */\n      return lastResponse;\n    } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n      LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n      // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n      // Reboot is not useful since after AM reboots, it will send register and \n      // get an exception. Might as well throw an exception here.\n      return resync;\n    } \n    \n    // Allow only one thread in AM to do heartbeat at a time.\n    synchronized (lastResponse) {\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n      \n      ResourceBlacklistRequest blacklistRequest \u003d request.getResourceBlacklistRequest();\n      List\u003cString\u003e blacklistAdditions \u003d \n          (blacklistRequest !\u003d null) ? \n              blacklistRequest.getBlacklistAdditions() : null;\n      List\u003cString\u003e blacklistRemovals \u003d \n          (blacklistRequest !\u003d null) ? \n              blacklistRequest.getBlacklistRemovals() : null;\n      \n      // sanity check\n      try {\n        SchedulerUtils.validateResourceRequests(ask,\n            rScheduler.getMaximumResourceCapability());\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      try {\n        SchedulerUtils.validateBlacklistRequest(blacklistRequest);\n      }  catch (InvalidResourceBlacklistRequestException e) {\n        LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      // Send new requests to appAttempt.\n      Allocation allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release, \n              blacklistAdditions, blacklistRemovals);\n\n      RMApp app \u003d this.rmContext.getRMApps().get(\n          appAttemptId.getApplicationId());\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      \n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n              rmNode.getState(),\n              rmNode.getHttpAddress(), rmNode.getRackName(), used,\n              rmNode.getTotalCapability(), numContainers,\n              rmNode.getHealthReport(),\n              rmNode.getLastHealthReportTime());\n          \n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n      \n      AllocateResponse oldResponse \u003d\n          responseMap.put(appAttemptId, allocateResponse);\n      if (oldResponse \u003d\u003d null) {\n        // appAttempt got unregistered, remove it back out\n        responseMap.remove(appAttemptId);\n        String message \u003d \"App Attempt removed from the cache during allocate\"\n            + appAttemptId;\n        LOG.error(message);\n        return resync;\n      }\n      \n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n   \n      // add preemption to the allocateResponse message (if any)\n      allocateResponse.setPreemptionMessage(generatePreemptionMessage(allocation));\n      \n      return allocateResponse;\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "2051fd5ee29e99df6fe79c70b0c7c8c0c1cc131f": {
      "type": "Ybodychange",
      "commitMessage": "YARN-750. Allow for black-listing resources in YARN API and Impl in CS (acmurthy via bikas)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1490392 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/06/13 11:46 AM",
      "commitName": "2051fd5ee29e99df6fe79c70b0c7c8c0c1cc131f",
      "commitAuthor": "Bikas Saha",
      "commitDateOld": "04/06/13 2:21 PM",
      "commitNameOld": "af65d6f80ee095f8a7652244511d02ce5584a160",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 1.89,
      "commitsBetweenForRepo": 14,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,104 +1,121 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n     ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n     authorizeRequest(appAttemptId);\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponse lastResponse \u003d responseMap.get(appAttemptId);\n     if (lastResponse \u003d\u003d null) {\n       LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n       return resync;\n     }\n     if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n       /* old heartbeat */\n       return lastResponse;\n     } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n       LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n       // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n       // Reboot is not useful since after AM reboots, it will send register and \n       // get an exception. Might as well throw an exception here.\n       return resync;\n     } \n     \n     // Allow only one thread in AM to do heartbeat at a time.\n     synchronized (lastResponse) {\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n-\n+      \n+      ResourceBlacklistRequest blacklistRequest \u003d request.getResourceBlacklistRequest();\n+      List\u003cString\u003e blacklistAdditions \u003d \n+          (blacklistRequest !\u003d null) ? \n+              blacklistRequest.getBlacklistAdditions() : null;\n+      List\u003cString\u003e blacklistRemovals \u003d \n+          (blacklistRequest !\u003d null) ? \n+              blacklistRequest.getBlacklistRemovals() : null;\n+      \n       // sanity check\n       try {\n         SchedulerUtils.validateResourceRequests(ask,\n             rScheduler.getMaximumResourceCapability());\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n-        throw RPCUtil.getRemoteException(e);\n+        throw e;\n       }\n+      \n+      try {\n+        SchedulerUtils.validateBlacklistRequest(blacklistRequest);\n+      }  catch (InvalidResourceBlacklistRequestException e) {\n+        LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n+        throw e;\n+      }\n+      \n       // Send new requests to appAttempt.\n       Allocation allocation \u003d\n-          this.rScheduler.allocate(appAttemptId, ask, release);\n+          this.rScheduler.allocate(appAttemptId, ask, release, \n+              blacklistAdditions, blacklistRemovals);\n \n       RMApp app \u003d this.rmContext.getRMApps().get(\n           appAttemptId.getApplicationId());\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       \n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n               rmNode.getState(),\n               rmNode.getHttpAddress(), rmNode.getRackName(), used,\n               rmNode.getTotalCapability(), numContainers,\n               rmNode.getNodeHealthStatus());\n           \n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n       \n       AllocateResponse oldResponse \u003d\n           responseMap.put(appAttemptId, allocateResponse);\n       if (oldResponse \u003d\u003d null) {\n         // appAttempt got unregistered, remove it back out\n         responseMap.remove(appAttemptId);\n         String message \u003d \"App Attempt removed from the cache during allocate\"\n             + appAttemptId;\n         LOG.error(message);\n         return resync;\n       }\n       \n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n    \n       // add preemption to the allocateResponse message (if any)\n       allocateResponse.setPreemptionMessage(generatePreemptionMessage(allocation));\n       \n       return allocateResponse;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n    authorizeRequest(appAttemptId);\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponse lastResponse \u003d responseMap.get(appAttemptId);\n    if (lastResponse \u003d\u003d null) {\n      LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n      return resync;\n    }\n    if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n      /* old heartbeat */\n      return lastResponse;\n    } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n      LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n      // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n      // Reboot is not useful since after AM reboots, it will send register and \n      // get an exception. Might as well throw an exception here.\n      return resync;\n    } \n    \n    // Allow only one thread in AM to do heartbeat at a time.\n    synchronized (lastResponse) {\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n      \n      ResourceBlacklistRequest blacklistRequest \u003d request.getResourceBlacklistRequest();\n      List\u003cString\u003e blacklistAdditions \u003d \n          (blacklistRequest !\u003d null) ? \n              blacklistRequest.getBlacklistAdditions() : null;\n      List\u003cString\u003e blacklistRemovals \u003d \n          (blacklistRequest !\u003d null) ? \n              blacklistRequest.getBlacklistRemovals() : null;\n      \n      // sanity check\n      try {\n        SchedulerUtils.validateResourceRequests(ask,\n            rScheduler.getMaximumResourceCapability());\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      try {\n        SchedulerUtils.validateBlacklistRequest(blacklistRequest);\n      }  catch (InvalidResourceBlacklistRequestException e) {\n        LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      // Send new requests to appAttempt.\n      Allocation allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release, \n              blacklistAdditions, blacklistRemovals);\n\n      RMApp app \u003d this.rmContext.getRMApps().get(\n          appAttemptId.getApplicationId());\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      \n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n              rmNode.getState(),\n              rmNode.getHttpAddress(), rmNode.getRackName(), used,\n              rmNode.getTotalCapability(), numContainers,\n              rmNode.getNodeHealthStatus());\n          \n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n      \n      AllocateResponse oldResponse \u003d\n          responseMap.put(appAttemptId, allocateResponse);\n      if (oldResponse \u003d\u003d null) {\n        // appAttempt got unregistered, remove it back out\n        responseMap.remove(appAttemptId);\n        String message \u003d \"App Attempt removed from the cache during allocate\"\n            + appAttemptId;\n        LOG.error(message);\n        return resync;\n      }\n      \n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n   \n      // add preemption to the allocateResponse message (if any)\n      allocateResponse.setPreemptionMessage(generatePreemptionMessage(allocation));\n      \n      return allocateResponse;\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "978012b9b6b18985fd60ec5b26c38693a6e86f9a": {
      "type": "Ybodychange",
      "commitMessage": "YARN-755. Renamed AllocateResponse.reboot to AllocateResponse.resync. Contributed by Bikas Saha.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1489295 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/06/13 10:53 PM",
      "commitName": "978012b9b6b18985fd60ec5b26c38693a6e86f9a",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "03/06/13 10:03 PM",
      "commitNameOld": "28aabe0b2bb2321ea7478f8da07743cf150e3f86",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 0.03,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,104 +1,104 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnException, IOException {\n \n     ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n     authorizeRequest(appAttemptId);\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponse lastResponse \u003d responseMap.get(appAttemptId);\n     if (lastResponse \u003d\u003d null) {\n       LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n-      return reboot;\n+      return resync;\n     }\n     if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n       /* old heartbeat */\n       return lastResponse;\n     } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n       LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n       // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n       // Reboot is not useful since after AM reboots, it will send register and \n       // get an exception. Might as well throw an exception here.\n-      return reboot;\n+      return resync;\n     } \n     \n     // Allow only one thread in AM to do heartbeat at a time.\n     synchronized (lastResponse) {\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n       // sanity check\n       try {\n         SchedulerUtils.validateResourceRequests(ask,\n             rScheduler.getMaximumResourceCapability());\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n         throw RPCUtil.getRemoteException(e);\n       }\n       // Send new requests to appAttempt.\n       Allocation allocation \u003d\n           this.rScheduler.allocate(appAttemptId, ask, release);\n \n       RMApp app \u003d this.rmContext.getRMApps().get(\n           appAttemptId.getApplicationId());\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       \n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n               rmNode.getState(),\n               rmNode.getHttpAddress(), rmNode.getRackName(), used,\n               rmNode.getTotalCapability(), numContainers,\n               rmNode.getNodeHealthStatus());\n           \n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n       \n       AllocateResponse oldResponse \u003d\n           responseMap.put(appAttemptId, allocateResponse);\n       if (oldResponse \u003d\u003d null) {\n         // appAttempt got unregistered, remove it back out\n         responseMap.remove(appAttemptId);\n         String message \u003d \"App Attempt removed from the cache during allocate\"\n             + appAttemptId;\n         LOG.error(message);\n-        return reboot;\n+        return resync;\n       }\n       \n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n    \n       // add preemption to the allocateResponse message (if any)\n       allocateResponse.setPreemptionMessage(generatePreemptionMessage(allocation));\n       \n       return allocateResponse;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n    authorizeRequest(appAttemptId);\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponse lastResponse \u003d responseMap.get(appAttemptId);\n    if (lastResponse \u003d\u003d null) {\n      LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n      return resync;\n    }\n    if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n      /* old heartbeat */\n      return lastResponse;\n    } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n      LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n      // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n      // Reboot is not useful since after AM reboots, it will send register and \n      // get an exception. Might as well throw an exception here.\n      return resync;\n    } \n    \n    // Allow only one thread in AM to do heartbeat at a time.\n    synchronized (lastResponse) {\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      // sanity check\n      try {\n        SchedulerUtils.validateResourceRequests(ask,\n            rScheduler.getMaximumResourceCapability());\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw RPCUtil.getRemoteException(e);\n      }\n      // Send new requests to appAttempt.\n      Allocation allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release);\n\n      RMApp app \u003d this.rmContext.getRMApps().get(\n          appAttemptId.getApplicationId());\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      \n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n              rmNode.getState(),\n              rmNode.getHttpAddress(), rmNode.getRackName(), used,\n              rmNode.getTotalCapability(), numContainers,\n              rmNode.getNodeHealthStatus());\n          \n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n      \n      AllocateResponse oldResponse \u003d\n          responseMap.put(appAttemptId, allocateResponse);\n      if (oldResponse \u003d\u003d null) {\n        // appAttempt got unregistered, remove it back out\n        responseMap.remove(appAttemptId);\n        String message \u003d \"App Attempt removed from the cache during allocate\"\n            + appAttemptId;\n        LOG.error(message);\n        return resync;\n      }\n      \n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n   \n      // add preemption to the allocateResponse message (if any)\n      allocateResponse.setPreemptionMessage(generatePreemptionMessage(allocation));\n      \n      return allocateResponse;\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "a83fb61ac07c0468cbc7a38526e92683883dd932": {
      "type": "Yexceptionschange",
      "commitMessage": "YARN-635. Renamed YarnRemoteException to YarnException. Contributed by Siddharth Seth.\nMAPREDUCE-5301. Updated MR code to work with YARN-635 changes of renaming YarnRemoteException to YarnException. Contributed by Siddharth Seth\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1489283 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/06/13 9:05 PM",
      "commitName": "a83fb61ac07c0468cbc7a38526e92683883dd932",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "03/06/13 5:34 PM",
      "commitNameOld": "d33534c4fb35cb82ff8d56abeeb63a949e72a031",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 0.15,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,104 +1,104 @@\n   public AllocateResponse allocate(AllocateRequest request)\n-      throws YarnRemoteException, IOException {\n+      throws YarnException, IOException {\n \n     ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n     authorizeRequest(appAttemptId);\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponse lastResponse \u003d responseMap.get(appAttemptId);\n     if (lastResponse \u003d\u003d null) {\n       LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n       return reboot;\n     }\n     if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n       /* old heartbeat */\n       return lastResponse;\n     } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n       LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n       // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n       // Reboot is not useful since after AM reboots, it will send register and \n       // get an exception. Might as well throw an exception here.\n       return reboot;\n     } \n     \n     // Allow only one thread in AM to do heartbeat at a time.\n     synchronized (lastResponse) {\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n       // sanity check\n       try {\n         SchedulerUtils.validateResourceRequests(ask,\n             rScheduler.getMaximumResourceCapability());\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n         throw RPCUtil.getRemoteException(e);\n       }\n       // Send new requests to appAttempt.\n       Allocation allocation \u003d\n           this.rScheduler.allocate(appAttemptId, ask, release);\n \n       RMApp app \u003d this.rmContext.getRMApps().get(\n           appAttemptId.getApplicationId());\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       \n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n               rmNode.getState(),\n               rmNode.getHttpAddress(), rmNode.getRackName(), used,\n               rmNode.getTotalCapability(), numContainers,\n               rmNode.getNodeHealthStatus());\n           \n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n       \n       AllocateResponse oldResponse \u003d\n           responseMap.put(appAttemptId, allocateResponse);\n       if (oldResponse \u003d\u003d null) {\n         // appAttempt got unregistered, remove it back out\n         responseMap.remove(appAttemptId);\n         String message \u003d \"App Attempt removed from the cache during allocate\"\n             + appAttemptId;\n         LOG.error(message);\n         return reboot;\n       }\n       \n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n    \n       // add preemption to the allocateResponse message (if any)\n       allocateResponse.setPreemptionMessage(generatePreemptionMessage(allocation));\n       \n       return allocateResponse;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n    authorizeRequest(appAttemptId);\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponse lastResponse \u003d responseMap.get(appAttemptId);\n    if (lastResponse \u003d\u003d null) {\n      LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n      return reboot;\n    }\n    if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n      /* old heartbeat */\n      return lastResponse;\n    } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n      LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n      // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n      // Reboot is not useful since after AM reboots, it will send register and \n      // get an exception. Might as well throw an exception here.\n      return reboot;\n    } \n    \n    // Allow only one thread in AM to do heartbeat at a time.\n    synchronized (lastResponse) {\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      // sanity check\n      try {\n        SchedulerUtils.validateResourceRequests(ask,\n            rScheduler.getMaximumResourceCapability());\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw RPCUtil.getRemoteException(e);\n      }\n      // Send new requests to appAttempt.\n      Allocation allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release);\n\n      RMApp app \u003d this.rmContext.getRMApps().get(\n          appAttemptId.getApplicationId());\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      \n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n              rmNode.getState(),\n              rmNode.getHttpAddress(), rmNode.getRackName(), used,\n              rmNode.getTotalCapability(), numContainers,\n              rmNode.getNodeHealthStatus());\n          \n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n      \n      AllocateResponse oldResponse \u003d\n          responseMap.put(appAttemptId, allocateResponse);\n      if (oldResponse \u003d\u003d null) {\n        // appAttempt got unregistered, remove it back out\n        responseMap.remove(appAttemptId);\n        String message \u003d \"App Attempt removed from the cache during allocate\"\n            + appAttemptId;\n        LOG.error(message);\n        return reboot;\n      }\n      \n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n   \n      // add preemption to the allocateResponse message (if any)\n      allocateResponse.setPreemptionMessage(generatePreemptionMessage(allocation));\n      \n      return allocateResponse;\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {
        "oldValue": "[YarnRemoteException, IOException]",
        "newValue": "[YarnException, IOException]"
      }
    },
    "505fe2653941e4f36f61edd0fc2f8e750ceb5d8f": {
      "type": "Ybodychange",
      "commitMessage": "YARN-568. Add support for work preserving preemption to the FairScheduler.\nContributed by Carlo Curino and Sandy Ryza\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1480778 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/05/13 2:21 PM",
      "commitName": "505fe2653941e4f36f61edd0fc2f8e750ceb5d8f",
      "commitAuthor": "Christopher Douglas",
      "commitDateOld": "08/05/13 10:32 PM",
      "commitNameOld": "9c4f86879cad6d6e19255d4ae8f28b61328bd10b",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 0.66,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,100 +1,104 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnRemoteException, IOException {\n \n     ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n     authorizeRequest(appAttemptId);\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponse lastResponse \u003d responseMap.get(appAttemptId);\n     if (lastResponse \u003d\u003d null) {\n       LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n       return reboot;\n     }\n     if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n       /* old heartbeat */\n       return lastResponse;\n     } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n       LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n       // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n       // Reboot is not useful since after AM reboots, it will send register and \n       // get an exception. Might as well throw an exception here.\n       return reboot;\n     } \n     \n     // Allow only one thread in AM to do heartbeat at a time.\n     synchronized (lastResponse) {\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n       // sanity check\n       try {\n         SchedulerUtils.validateResourceRequests(ask,\n             rScheduler.getMaximumResourceCapability());\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n         throw RPCUtil.getRemoteException(e);\n       }\n       // Send new requests to appAttempt.\n       Allocation allocation \u003d\n           this.rScheduler.allocate(appAttemptId, ask, release);\n \n       RMApp app \u003d this.rmContext.getRMApps().get(\n           appAttemptId.getApplicationId());\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       \n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n               rmNode.getState(),\n               rmNode.getHttpAddress(), rmNode.getRackName(), used,\n               rmNode.getTotalCapability(), numContainers,\n               rmNode.getNodeHealthStatus());\n           \n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n       \n       AllocateResponse oldResponse \u003d\n           responseMap.put(appAttemptId, allocateResponse);\n       if (oldResponse \u003d\u003d null) {\n         // appAttempt got unregistered, remove it back out\n         responseMap.remove(appAttemptId);\n         String message \u003d \"App Attempt removed from the cache during allocate\"\n             + appAttemptId;\n         LOG.error(message);\n         return reboot;\n       }\n       \n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n+   \n+      // add preemption to the allocateResponse message (if any)\n+      allocateResponse.setPreemptionMessage(generatePreemptionMessage(allocation));\n+      \n       return allocateResponse;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnRemoteException, IOException {\n\n    ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n    authorizeRequest(appAttemptId);\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponse lastResponse \u003d responseMap.get(appAttemptId);\n    if (lastResponse \u003d\u003d null) {\n      LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n      return reboot;\n    }\n    if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n      /* old heartbeat */\n      return lastResponse;\n    } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n      LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n      // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n      // Reboot is not useful since after AM reboots, it will send register and \n      // get an exception. Might as well throw an exception here.\n      return reboot;\n    } \n    \n    // Allow only one thread in AM to do heartbeat at a time.\n    synchronized (lastResponse) {\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      // sanity check\n      try {\n        SchedulerUtils.validateResourceRequests(ask,\n            rScheduler.getMaximumResourceCapability());\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw RPCUtil.getRemoteException(e);\n      }\n      // Send new requests to appAttempt.\n      Allocation allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release);\n\n      RMApp app \u003d this.rmContext.getRMApps().get(\n          appAttemptId.getApplicationId());\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      \n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n              rmNode.getState(),\n              rmNode.getHttpAddress(), rmNode.getRackName(), used,\n              rmNode.getTotalCapability(), numContainers,\n              rmNode.getNodeHealthStatus());\n          \n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n      \n      AllocateResponse oldResponse \u003d\n          responseMap.put(appAttemptId, allocateResponse);\n      if (oldResponse \u003d\u003d null) {\n        // appAttempt got unregistered, remove it back out\n        responseMap.remove(appAttemptId);\n        String message \u003d \"App Attempt removed from the cache during allocate\"\n            + appAttemptId;\n        LOG.error(message);\n        return reboot;\n      }\n      \n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n   \n      // add preemption to the allocateResponse message (if any)\n      allocateResponse.setPreemptionMessage(generatePreemptionMessage(allocation));\n      \n      return allocateResponse;\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "9c4f86879cad6d6e19255d4ae8f28b61328bd10b": {
      "type": "Yexceptionschange",
      "commitMessage": "YARN-630. Changed AMRMProtocol api to throw IOException and YarnRemoteException. Contributed by Xuan Gong.\nMAPREDUCE-5226. Handling YarnRemoteException separately from IOException in MR App\u0027s use of AMRMProtocol after YARN-630. Contributed by Xuan Gong.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1480529 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/05/13 10:32 PM",
      "commitName": "9c4f86879cad6d6e19255d4ae8f28b61328bd10b",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "05/04/13 10:45 AM",
      "commitNameOld": "bc6777dd5bdcbaef09897b506bc6511ae456033d",
      "commitAuthorOld": "Bikas Saha",
      "daysBetweenCommits": 33.49,
      "commitsBetweenForRepo": 178,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,100 +1,100 @@\n   public AllocateResponse allocate(AllocateRequest request)\n-      throws YarnRemoteException {\n+      throws YarnRemoteException, IOException {\n \n     ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n     authorizeRequest(appAttemptId);\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponse lastResponse \u003d responseMap.get(appAttemptId);\n     if (lastResponse \u003d\u003d null) {\n       LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n       return reboot;\n     }\n     if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n       /* old heartbeat */\n       return lastResponse;\n     } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n       LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n       // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n       // Reboot is not useful since after AM reboots, it will send register and \n       // get an exception. Might as well throw an exception here.\n       return reboot;\n     } \n     \n     // Allow only one thread in AM to do heartbeat at a time.\n     synchronized (lastResponse) {\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n       // sanity check\n       try {\n         SchedulerUtils.validateResourceRequests(ask,\n             rScheduler.getMaximumResourceCapability());\n       } catch (InvalidResourceRequestException e) {\n         LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n         throw RPCUtil.getRemoteException(e);\n       }\n       // Send new requests to appAttempt.\n       Allocation allocation \u003d\n           this.rScheduler.allocate(appAttemptId, ask, release);\n \n       RMApp app \u003d this.rmContext.getRMApps().get(\n           appAttemptId.getApplicationId());\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       \n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n               rmNode.getState(),\n               rmNode.getHttpAddress(), rmNode.getRackName(), used,\n               rmNode.getTotalCapability(), numContainers,\n               rmNode.getNodeHealthStatus());\n           \n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n       \n       AllocateResponse oldResponse \u003d\n           responseMap.put(appAttemptId, allocateResponse);\n       if (oldResponse \u003d\u003d null) {\n         // appAttempt got unregistered, remove it back out\n         responseMap.remove(appAttemptId);\n         String message \u003d \"App Attempt removed from the cache during allocate\"\n             + appAttemptId;\n         LOG.error(message);\n         return reboot;\n       }\n       \n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n       return allocateResponse;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnRemoteException, IOException {\n\n    ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n    authorizeRequest(appAttemptId);\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponse lastResponse \u003d responseMap.get(appAttemptId);\n    if (lastResponse \u003d\u003d null) {\n      LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n      return reboot;\n    }\n    if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n      /* old heartbeat */\n      return lastResponse;\n    } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n      LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n      // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n      // Reboot is not useful since after AM reboots, it will send register and \n      // get an exception. Might as well throw an exception here.\n      return reboot;\n    } \n    \n    // Allow only one thread in AM to do heartbeat at a time.\n    synchronized (lastResponse) {\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      // sanity check\n      try {\n        SchedulerUtils.validateResourceRequests(ask,\n            rScheduler.getMaximumResourceCapability());\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw RPCUtil.getRemoteException(e);\n      }\n      // Send new requests to appAttempt.\n      Allocation allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release);\n\n      RMApp app \u003d this.rmContext.getRMApps().get(\n          appAttemptId.getApplicationId());\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      \n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n              rmNode.getState(),\n              rmNode.getHttpAddress(), rmNode.getRackName(), used,\n              rmNode.getTotalCapability(), numContainers,\n              rmNode.getNodeHealthStatus());\n          \n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n      \n      AllocateResponse oldResponse \u003d\n          responseMap.put(appAttemptId, allocateResponse);\n      if (oldResponse \u003d\u003d null) {\n        // appAttempt got unregistered, remove it back out\n        responseMap.remove(appAttemptId);\n        String message \u003d \"App Attempt removed from the cache during allocate\"\n            + appAttemptId;\n        LOG.error(message);\n        return reboot;\n      }\n      \n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n      return allocateResponse;\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {
        "oldValue": "[YarnRemoteException]",
        "newValue": "[YarnRemoteException, IOException]"
      }
    },
    "bc6777dd5bdcbaef09897b506bc6511ae456033d": {
      "type": "Ybodychange",
      "commitMessage": "YARN-193. Scheduler.normalizeRequest does not account for allocation requests that exceed maximumAllocation limits (Zhijie Shen via bikas)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1465067 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "05/04/13 10:45 AM",
      "commitName": "bc6777dd5bdcbaef09897b506bc6511ae456033d",
      "commitAuthor": "Bikas Saha",
      "commitDateOld": "20/03/13 1:44 PM",
      "commitNameOld": "1bd345d6e3855ab330963efd32e0fac102e61d1a",
      "commitAuthorOld": "Hitesh Shah",
      "daysBetweenCommits": 15.88,
      "commitsBetweenForRepo": 96,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,92 +1,100 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnRemoteException {\n \n     ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n     authorizeRequest(appAttemptId);\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponse lastResponse \u003d responseMap.get(appAttemptId);\n     if (lastResponse \u003d\u003d null) {\n       LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n       return reboot;\n     }\n     if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n       /* old heartbeat */\n       return lastResponse;\n     } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n       LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n       // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n       // Reboot is not useful since after AM reboots, it will send register and \n       // get an exception. Might as well throw an exception here.\n       return reboot;\n     } \n     \n     // Allow only one thread in AM to do heartbeat at a time.\n     synchronized (lastResponse) {\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n+      // sanity check\n+      try {\n+        SchedulerUtils.validateResourceRequests(ask,\n+            rScheduler.getMaximumResourceCapability());\n+      } catch (InvalidResourceRequestException e) {\n+        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n+        throw RPCUtil.getRemoteException(e);\n+      }\n       // Send new requests to appAttempt.\n       Allocation allocation \u003d\n           this.rScheduler.allocate(appAttemptId, ask, release);\n \n       RMApp app \u003d this.rmContext.getRMApps().get(\n           appAttemptId.getApplicationId());\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       \n       AllocateResponse allocateResponse \u003d\n           recordFactory.newRecordInstance(AllocateResponse.class);\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n               rmNode.getState(),\n               rmNode.getHttpAddress(), rmNode.getRackName(), used,\n               rmNode.getTotalCapability(), numContainers,\n               rmNode.getNodeHealthStatus());\n           \n           updatedNodeReports.add(report);\n         }\n         allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n       allocateResponse.setAllocatedContainers(allocation.getContainers());\n       allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n       allocateResponse.setAvailableResources(allocation.getResourceLimit());\n       \n       AllocateResponse oldResponse \u003d\n           responseMap.put(appAttemptId, allocateResponse);\n       if (oldResponse \u003d\u003d null) {\n         // appAttempt got unregistered, remove it back out\n         responseMap.remove(appAttemptId);\n         String message \u003d \"App Attempt removed from the cache during allocate\"\n             + appAttemptId;\n         LOG.error(message);\n         return reboot;\n       }\n       \n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n       return allocateResponse;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnRemoteException {\n\n    ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n    authorizeRequest(appAttemptId);\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponse lastResponse \u003d responseMap.get(appAttemptId);\n    if (lastResponse \u003d\u003d null) {\n      LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n      return reboot;\n    }\n    if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n      /* old heartbeat */\n      return lastResponse;\n    } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n      LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n      // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n      // Reboot is not useful since after AM reboots, it will send register and \n      // get an exception. Might as well throw an exception here.\n      return reboot;\n    } \n    \n    // Allow only one thread in AM to do heartbeat at a time.\n    synchronized (lastResponse) {\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      // sanity check\n      try {\n        SchedulerUtils.validateResourceRequests(ask,\n            rScheduler.getMaximumResourceCapability());\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw RPCUtil.getRemoteException(e);\n      }\n      // Send new requests to appAttempt.\n      Allocation allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release);\n\n      RMApp app \u003d this.rmContext.getRMApps().get(\n          appAttemptId.getApplicationId());\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      \n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n              rmNode.getState(),\n              rmNode.getHttpAddress(), rmNode.getRackName(), used,\n              rmNode.getTotalCapability(), numContainers,\n              rmNode.getNodeHealthStatus());\n          \n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n      \n      AllocateResponse oldResponse \u003d\n          responseMap.put(appAttemptId, allocateResponse);\n      if (oldResponse \u003d\u003d null) {\n        // appAttempt got unregistered, remove it back out\n        responseMap.remove(appAttemptId);\n        String message \u003d \"App Attempt removed from the cache during allocate\"\n            + appAttemptId;\n        LOG.error(message);\n        return reboot;\n      }\n      \n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n      return allocateResponse;\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "1bd345d6e3855ab330963efd32e0fac102e61d1a": {
      "type": "Ybodychange",
      "commitMessage": "YARN-396. Rationalize AllocateResponse in RM Scheduler API. Contributed by Zhijie Shen.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1459040 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/03/13 1:44 PM",
      "commitName": "1bd345d6e3855ab330963efd32e0fac102e61d1a",
      "commitAuthor": "Hitesh Shah",
      "commitDateOld": "08/01/13 9:08 PM",
      "commitNameOld": "453926397182078c65a4428eb5de5a90d6af6448",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 70.65,
      "commitsBetweenForRepo": 330,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,97 +1,92 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnRemoteException {\n \n     ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n     authorizeRequest(appAttemptId);\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n-    AllocateResponse allocateResponse \u003d recordFactory\n-        .newRecordInstance(AllocateResponse.class);\n-    AMResponse lastResponse \u003d responseMap.get(appAttemptId);\n+    AllocateResponse lastResponse \u003d responseMap.get(appAttemptId);\n     if (lastResponse \u003d\u003d null) {\n       LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n-      allocateResponse.setAMResponse(reboot);\n-      return allocateResponse;\n+      return reboot;\n     }\n     if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n       /* old heartbeat */\n-      allocateResponse.setAMResponse(lastResponse);\n-      return allocateResponse;\n+      return lastResponse;\n     } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n       LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n       // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n       // Reboot is not useful since after AM reboots, it will send register and \n       // get an exception. Might as well throw an exception here.\n-      allocateResponse.setAMResponse(reboot);\n-      return allocateResponse;\n+      return reboot;\n     } \n     \n     // Allow only one thread in AM to do heartbeat at a time.\n     synchronized (lastResponse) {\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n       // Send new requests to appAttempt.\n       Allocation allocation \u003d\n           this.rScheduler.allocate(appAttemptId, ask, release);\n \n       RMApp app \u003d this.rmContext.getRMApps().get(\n           appAttemptId.getApplicationId());\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       \n-      AMResponse response \u003d recordFactory.newRecordInstance(AMResponse.class);\n+      AllocateResponse allocateResponse \u003d\n+          recordFactory.newRecordInstance(AllocateResponse.class);\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n               rmNode.getState(),\n               rmNode.getHttpAddress(), rmNode.getRackName(), used,\n               rmNode.getTotalCapability(), numContainers,\n               rmNode.getNodeHealthStatus());\n           \n           updatedNodeReports.add(report);\n         }\n-        response.setUpdatedNodes(updatedNodeReports);\n+        allocateResponse.setUpdatedNodes(updatedNodeReports);\n       }\n \n-      response.setAllocatedContainers(allocation.getContainers());\n-      response.setCompletedContainersStatuses(appAttempt\n+      allocateResponse.setAllocatedContainers(allocation.getContainers());\n+      allocateResponse.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n-      response.setResponseId(lastResponse.getResponseId() + 1);\n-      response.setAvailableResources(allocation.getResourceLimit());\n+      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n+      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n       \n-      AMResponse oldResponse \u003d responseMap.put(appAttemptId, response);\n+      AllocateResponse oldResponse \u003d\n+          responseMap.put(appAttemptId, allocateResponse);\n       if (oldResponse \u003d\u003d null) {\n         // appAttempt got unregistered, remove it back out\n         responseMap.remove(appAttemptId);\n         String message \u003d \"App Attempt removed from the cache during allocate\"\n             + appAttemptId;\n         LOG.error(message);\n-        allocateResponse.setAMResponse(reboot);\n-        return allocateResponse;\n+        return reboot;\n       }\n       \n-      allocateResponse.setAMResponse(response);\n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n       return allocateResponse;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnRemoteException {\n\n    ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n    authorizeRequest(appAttemptId);\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponse lastResponse \u003d responseMap.get(appAttemptId);\n    if (lastResponse \u003d\u003d null) {\n      LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n      return reboot;\n    }\n    if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n      /* old heartbeat */\n      return lastResponse;\n    } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n      LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n      // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n      // Reboot is not useful since after AM reboots, it will send register and \n      // get an exception. Might as well throw an exception here.\n      return reboot;\n    } \n    \n    // Allow only one thread in AM to do heartbeat at a time.\n    synchronized (lastResponse) {\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      // Send new requests to appAttempt.\n      Allocation allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release);\n\n      RMApp app \u003d this.rmContext.getRMApps().get(\n          appAttemptId.getApplicationId());\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      \n      AllocateResponse allocateResponse \u003d\n          recordFactory.newRecordInstance(AllocateResponse.class);\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n              rmNode.getState(),\n              rmNode.getHttpAddress(), rmNode.getRackName(), used,\n              rmNode.getTotalCapability(), numContainers,\n              rmNode.getNodeHealthStatus());\n          \n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n      \n      AllocateResponse oldResponse \u003d\n          responseMap.put(appAttemptId, allocateResponse);\n      if (oldResponse \u003d\u003d null) {\n        // appAttempt got unregistered, remove it back out\n        responseMap.remove(appAttemptId);\n        String message \u003d \"App Attempt removed from the cache during allocate\"\n            + appAttemptId;\n        LOG.error(message);\n        return reboot;\n      }\n      \n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n      return allocateResponse;\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "453926397182078c65a4428eb5de5a90d6af6448": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2. Enhanced CapacityScheduler to account for CPU alongwith memory for multi-dimensional resource scheduling. Contributed by Arun C. Murthy.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1430682 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/01/13 9:08 PM",
      "commitName": "453926397182078c65a4428eb5de5a90d6af6448",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "18/12/12 8:21 PM",
      "commitNameOld": "6cd0736cc57849e4f7c5d38a3986432a9717fe39",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 21.03,
      "commitsBetweenForRepo": 75,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,97 +1,97 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnRemoteException {\n \n     ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n     authorizeRequest(appAttemptId);\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponse allocateResponse \u003d recordFactory\n         .newRecordInstance(AllocateResponse.class);\n     AMResponse lastResponse \u003d responseMap.get(appAttemptId);\n     if (lastResponse \u003d\u003d null) {\n       LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n       allocateResponse.setAMResponse(reboot);\n       return allocateResponse;\n     }\n     if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n       /* old heartbeat */\n       allocateResponse.setAMResponse(lastResponse);\n       return allocateResponse;\n     } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n       LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n       // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n       // Reboot is not useful since after AM reboots, it will send register and \n       // get an exception. Might as well throw an exception here.\n       allocateResponse.setAMResponse(reboot);\n       return allocateResponse;\n     } \n     \n     // Allow only one thread in AM to do heartbeat at a time.\n     synchronized (lastResponse) {\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n       // Send new requests to appAttempt.\n       Allocation allocation \u003d\n           this.rScheduler.allocate(appAttemptId, ask, release);\n \n       RMApp app \u003d this.rmContext.getRMApps().get(\n           appAttemptId.getApplicationId());\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       \n       AMResponse response \u003d recordFactory.newRecordInstance(AMResponse.class);\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n-          Resource used \u003d BuilderUtils.newResource(0);\n+          Resource used \u003d BuilderUtils.newResource(0, 0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n               rmNode.getState(),\n               rmNode.getHttpAddress(), rmNode.getRackName(), used,\n               rmNode.getTotalCapability(), numContainers,\n               rmNode.getNodeHealthStatus());\n           \n           updatedNodeReports.add(report);\n         }\n         response.setUpdatedNodes(updatedNodeReports);\n       }\n \n       response.setAllocatedContainers(allocation.getContainers());\n       response.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       response.setResponseId(lastResponse.getResponseId() + 1);\n       response.setAvailableResources(allocation.getResourceLimit());\n       \n       AMResponse oldResponse \u003d responseMap.put(appAttemptId, response);\n       if (oldResponse \u003d\u003d null) {\n         // appAttempt got unregistered, remove it back out\n         responseMap.remove(appAttemptId);\n         String message \u003d \"App Attempt removed from the cache during allocate\"\n             + appAttemptId;\n         LOG.error(message);\n         allocateResponse.setAMResponse(reboot);\n         return allocateResponse;\n       }\n       \n       allocateResponse.setAMResponse(response);\n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n       return allocateResponse;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnRemoteException {\n\n    ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n    authorizeRequest(appAttemptId);\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponse allocateResponse \u003d recordFactory\n        .newRecordInstance(AllocateResponse.class);\n    AMResponse lastResponse \u003d responseMap.get(appAttemptId);\n    if (lastResponse \u003d\u003d null) {\n      LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n      allocateResponse.setAMResponse(reboot);\n      return allocateResponse;\n    }\n    if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n      /* old heartbeat */\n      allocateResponse.setAMResponse(lastResponse);\n      return allocateResponse;\n    } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n      LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n      // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n      // Reboot is not useful since after AM reboots, it will send register and \n      // get an exception. Might as well throw an exception here.\n      allocateResponse.setAMResponse(reboot);\n      return allocateResponse;\n    } \n    \n    // Allow only one thread in AM to do heartbeat at a time.\n    synchronized (lastResponse) {\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      // Send new requests to appAttempt.\n      Allocation allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release);\n\n      RMApp app \u003d this.rmContext.getRMApps().get(\n          appAttemptId.getApplicationId());\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      \n      AMResponse response \u003d recordFactory.newRecordInstance(AMResponse.class);\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0, 0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n              rmNode.getState(),\n              rmNode.getHttpAddress(), rmNode.getRackName(), used,\n              rmNode.getTotalCapability(), numContainers,\n              rmNode.getNodeHealthStatus());\n          \n          updatedNodeReports.add(report);\n        }\n        response.setUpdatedNodes(updatedNodeReports);\n      }\n\n      response.setAllocatedContainers(allocation.getContainers());\n      response.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      response.setResponseId(lastResponse.getResponseId() + 1);\n      response.setAvailableResources(allocation.getResourceLimit());\n      \n      AMResponse oldResponse \u003d responseMap.put(appAttemptId, response);\n      if (oldResponse \u003d\u003d null) {\n        // appAttempt got unregistered, remove it back out\n        responseMap.remove(appAttemptId);\n        String message \u003d \"App Attempt removed from the cache during allocate\"\n            + appAttemptId;\n        LOG.error(message);\n        allocateResponse.setAMResponse(reboot);\n        return allocateResponse;\n      }\n      \n      allocateResponse.setAMResponse(response);\n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n      return allocateResponse;\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "6cd0736cc57849e4f7c5d38a3986432a9717fe39": {
      "type": "Ybodychange",
      "commitMessage": "YARN-230. RM Restart phase 1 - includes support for saving/restarting all applications on an RM bounce. Contributed by Bikas Saha.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1423758 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/12/12 8:21 PM",
      "commitName": "6cd0736cc57849e4f7c5d38a3986432a9717fe39",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "31/10/12 5:32 PM",
      "commitNameOld": "a124297cf016439ee426d3142627606875b9667a",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 48.16,
      "commitsBetweenForRepo": 213,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,95 +1,97 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnRemoteException {\n \n     ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n     authorizeRequest(appAttemptId);\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponse allocateResponse \u003d recordFactory\n         .newRecordInstance(AllocateResponse.class);\n     AMResponse lastResponse \u003d responseMap.get(appAttemptId);\n     if (lastResponse \u003d\u003d null) {\n       LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n       allocateResponse.setAMResponse(reboot);\n       return allocateResponse;\n     }\n     if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n       /* old heartbeat */\n       allocateResponse.setAMResponse(lastResponse);\n       return allocateResponse;\n     } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n       LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n       // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n+      // Reboot is not useful since after AM reboots, it will send register and \n+      // get an exception. Might as well throw an exception here.\n       allocateResponse.setAMResponse(reboot);\n       return allocateResponse;\n     } \n     \n     // Allow only one thread in AM to do heartbeat at a time.\n     synchronized (lastResponse) {\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n       // Send new requests to appAttempt.\n       Allocation allocation \u003d\n           this.rScheduler.allocate(appAttemptId, ask, release);\n \n       RMApp app \u003d this.rmContext.getRMApps().get(\n           appAttemptId.getApplicationId());\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       \n       AMResponse response \u003d recordFactory.newRecordInstance(AMResponse.class);\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n               rmNode.getState(),\n               rmNode.getHttpAddress(), rmNode.getRackName(), used,\n               rmNode.getTotalCapability(), numContainers,\n               rmNode.getNodeHealthStatus());\n           \n           updatedNodeReports.add(report);\n         }\n         response.setUpdatedNodes(updatedNodeReports);\n       }\n \n       response.setAllocatedContainers(allocation.getContainers());\n       response.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       response.setResponseId(lastResponse.getResponseId() + 1);\n       response.setAvailableResources(allocation.getResourceLimit());\n       \n       AMResponse oldResponse \u003d responseMap.put(appAttemptId, response);\n       if (oldResponse \u003d\u003d null) {\n         // appAttempt got unregistered, remove it back out\n         responseMap.remove(appAttemptId);\n         String message \u003d \"App Attempt removed from the cache during allocate\"\n             + appAttemptId;\n         LOG.error(message);\n         allocateResponse.setAMResponse(reboot);\n         return allocateResponse;\n       }\n       \n       allocateResponse.setAMResponse(response);\n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n       return allocateResponse;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnRemoteException {\n\n    ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n    authorizeRequest(appAttemptId);\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponse allocateResponse \u003d recordFactory\n        .newRecordInstance(AllocateResponse.class);\n    AMResponse lastResponse \u003d responseMap.get(appAttemptId);\n    if (lastResponse \u003d\u003d null) {\n      LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n      allocateResponse.setAMResponse(reboot);\n      return allocateResponse;\n    }\n    if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n      /* old heartbeat */\n      allocateResponse.setAMResponse(lastResponse);\n      return allocateResponse;\n    } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n      LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n      // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n      // Reboot is not useful since after AM reboots, it will send register and \n      // get an exception. Might as well throw an exception here.\n      allocateResponse.setAMResponse(reboot);\n      return allocateResponse;\n    } \n    \n    // Allow only one thread in AM to do heartbeat at a time.\n    synchronized (lastResponse) {\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      // Send new requests to appAttempt.\n      Allocation allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release);\n\n      RMApp app \u003d this.rmContext.getRMApps().get(\n          appAttemptId.getApplicationId());\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      \n      AMResponse response \u003d recordFactory.newRecordInstance(AMResponse.class);\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n              rmNode.getState(),\n              rmNode.getHttpAddress(), rmNode.getRackName(), used,\n              rmNode.getTotalCapability(), numContainers,\n              rmNode.getNodeHealthStatus());\n          \n          updatedNodeReports.add(report);\n        }\n        response.setUpdatedNodes(updatedNodeReports);\n      }\n\n      response.setAllocatedContainers(allocation.getContainers());\n      response.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      response.setResponseId(lastResponse.getResponseId() + 1);\n      response.setAvailableResources(allocation.getResourceLimit());\n      \n      AMResponse oldResponse \u003d responseMap.put(appAttemptId, response);\n      if (oldResponse \u003d\u003d null) {\n        // appAttempt got unregistered, remove it back out\n        responseMap.remove(appAttemptId);\n        String message \u003d \"App Attempt removed from the cache during allocate\"\n            + appAttemptId;\n        LOG.error(message);\n        allocateResponse.setAMResponse(reboot);\n        return allocateResponse;\n      }\n      \n      allocateResponse.setAMResponse(response);\n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n      return allocateResponse;\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "a124297cf016439ee426d3142627606875b9667a": {
      "type": "Ybodychange",
      "commitMessage": "YARN-189. Fixed a deadlock between RM\u0027s ApplicationMasterService and the dispatcher. Contributed by Thomas Graves.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1404431 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "31/10/12 5:32 PM",
      "commitName": "a124297cf016439ee426d3142627606875b9667a",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "07/08/12 10:22 PM",
      "commitNameOld": "e1fdf62123625e4ba399af02f8aad500637d29d1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 84.8,
      "commitsBetweenForRepo": 527,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,83 +1,95 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnRemoteException {\n \n     ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n     authorizeRequest(appAttemptId);\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponse allocateResponse \u003d recordFactory\n         .newRecordInstance(AllocateResponse.class);\n     AMResponse lastResponse \u003d responseMap.get(appAttemptId);\n     if (lastResponse \u003d\u003d null) {\n       LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n       allocateResponse.setAMResponse(reboot);\n       return allocateResponse;\n     }\n     if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n       /* old heartbeat */\n       allocateResponse.setAMResponse(lastResponse);\n       return allocateResponse;\n     } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n       LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n       // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n       allocateResponse.setAMResponse(reboot);\n       return allocateResponse;\n-    }\n-\n+    } \n+    \n     // Allow only one thread in AM to do heartbeat at a time.\n-    synchronized (lastResponse) { // BUG TODO: Locking order is screwed.\n+    synchronized (lastResponse) {\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n       // Send new requests to appAttempt.\n       Allocation allocation \u003d\n           this.rScheduler.allocate(appAttemptId, ask, release);\n \n-      RMApp app \u003d this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n+      RMApp app \u003d this.rmContext.getRMApps().get(\n+          appAttemptId.getApplicationId());\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       \n       AMResponse response \u003d recordFactory.newRecordInstance(AMResponse.class);\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n               rmNode.getState(),\n               rmNode.getHttpAddress(), rmNode.getRackName(), used,\n               rmNode.getTotalCapability(), numContainers,\n               rmNode.getNodeHealthStatus());\n           \n           updatedNodeReports.add(report);\n         }\n         response.setUpdatedNodes(updatedNodeReports);\n       }\n \n       response.setAllocatedContainers(allocation.getContainers());\n       response.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       response.setResponseId(lastResponse.getResponseId() + 1);\n       response.setAvailableResources(allocation.getResourceLimit());\n-      responseMap.put(appAttemptId, response);\n+      \n+      AMResponse oldResponse \u003d responseMap.put(appAttemptId, response);\n+      if (oldResponse \u003d\u003d null) {\n+        // appAttempt got unregistered, remove it back out\n+        responseMap.remove(appAttemptId);\n+        String message \u003d \"App Attempt removed from the cache during allocate\"\n+            + appAttemptId;\n+        LOG.error(message);\n+        allocateResponse.setAMResponse(reboot);\n+        return allocateResponse;\n+      }\n+      \n       allocateResponse.setAMResponse(response);\n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n       return allocateResponse;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnRemoteException {\n\n    ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n    authorizeRequest(appAttemptId);\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponse allocateResponse \u003d recordFactory\n        .newRecordInstance(AllocateResponse.class);\n    AMResponse lastResponse \u003d responseMap.get(appAttemptId);\n    if (lastResponse \u003d\u003d null) {\n      LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n      allocateResponse.setAMResponse(reboot);\n      return allocateResponse;\n    }\n    if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n      /* old heartbeat */\n      allocateResponse.setAMResponse(lastResponse);\n      return allocateResponse;\n    } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n      LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n      // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n      allocateResponse.setAMResponse(reboot);\n      return allocateResponse;\n    } \n    \n    // Allow only one thread in AM to do heartbeat at a time.\n    synchronized (lastResponse) {\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      // Send new requests to appAttempt.\n      Allocation allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release);\n\n      RMApp app \u003d this.rmContext.getRMApps().get(\n          appAttemptId.getApplicationId());\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      \n      AMResponse response \u003d recordFactory.newRecordInstance(AMResponse.class);\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n              rmNode.getState(),\n              rmNode.getHttpAddress(), rmNode.getRackName(), used,\n              rmNode.getTotalCapability(), numContainers,\n              rmNode.getNodeHealthStatus());\n          \n          updatedNodeReports.add(report);\n        }\n        response.setUpdatedNodes(updatedNodeReports);\n      }\n\n      response.setAllocatedContainers(allocation.getContainers());\n      response.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      response.setResponseId(lastResponse.getResponseId() + 1);\n      response.setAvailableResources(allocation.getResourceLimit());\n      \n      AMResponse oldResponse \u003d responseMap.put(appAttemptId, response);\n      if (oldResponse \u003d\u003d null) {\n        // appAttempt got unregistered, remove it back out\n        responseMap.remove(appAttemptId);\n        String message \u003d \"App Attempt removed from the cache during allocate\"\n            + appAttemptId;\n        LOG.error(message);\n        allocateResponse.setAMResponse(reboot);\n        return allocateResponse;\n      }\n      \n      allocateResponse.setAMResponse(response);\n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n      return allocateResponse;\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "e1fdf62123625e4ba399af02f8aad500637d29d1": {
      "type": "Yfilerename",
      "commitMessage": "YARN-1. Promote YARN to be a sub-project of Apache Hadoop.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1370666 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/08/12 10:22 PM",
      "commitName": "e1fdf62123625e4ba399af02f8aad500637d29d1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "07/08/12 7:53 PM",
      "commitNameOld": "34554d1e11ee1d5b564d7d9ed3e6d55931d72749",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 0.1,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnRemoteException {\n\n    ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n    authorizeRequest(appAttemptId);\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponse allocateResponse \u003d recordFactory\n        .newRecordInstance(AllocateResponse.class);\n    AMResponse lastResponse \u003d responseMap.get(appAttemptId);\n    if (lastResponse \u003d\u003d null) {\n      LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n      allocateResponse.setAMResponse(reboot);\n      return allocateResponse;\n    }\n    if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n      /* old heartbeat */\n      allocateResponse.setAMResponse(lastResponse);\n      return allocateResponse;\n    } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n      LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n      // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n      allocateResponse.setAMResponse(reboot);\n      return allocateResponse;\n    }\n\n    // Allow only one thread in AM to do heartbeat at a time.\n    synchronized (lastResponse) { // BUG TODO: Locking order is screwed.\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      // Send new requests to appAttempt.\n      Allocation allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release);\n\n      RMApp app \u003d this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      \n      AMResponse response \u003d recordFactory.newRecordInstance(AMResponse.class);\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n              rmNode.getState(),\n              rmNode.getHttpAddress(), rmNode.getRackName(), used,\n              rmNode.getTotalCapability(), numContainers,\n              rmNode.getNodeHealthStatus());\n          \n          updatedNodeReports.add(report);\n        }\n        response.setUpdatedNodes(updatedNodeReports);\n      }\n\n      response.setAllocatedContainers(allocation.getContainers());\n      response.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      response.setResponseId(lastResponse.getResponseId() + 1);\n      response.setAvailableResources(allocation.getResourceLimit());\n      responseMap.put(appAttemptId, response);\n      allocateResponse.setAMResponse(response);\n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n      return allocateResponse;\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
        "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java"
      }
    },
    "407cfa3b56a0645d64d2d9af305f6ef24307e775": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3958. RM: Remove RMNodeState and replace it with NodeState (Bikas Saha via bobby)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1334043 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/05/12 8:47 AM",
      "commitName": "407cfa3b56a0645d64d2d9af305f6ef24307e775",
      "commitAuthor": "Robert Joseph Evans",
      "commitDateOld": "03/05/12 11:35 AM",
      "commitNameOld": "48414b08277b86cdbc34ae36d7c4d204fd838294",
      "commitAuthorOld": "Robert Joseph Evans",
      "daysBetweenCommits": 0.88,
      "commitsBetweenForRepo": 11,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,83 +1,83 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnRemoteException {\n \n     ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n     authorizeRequest(appAttemptId);\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponse allocateResponse \u003d recordFactory\n         .newRecordInstance(AllocateResponse.class);\n     AMResponse lastResponse \u003d responseMap.get(appAttemptId);\n     if (lastResponse \u003d\u003d null) {\n       LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n       allocateResponse.setAMResponse(reboot);\n       return allocateResponse;\n     }\n     if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n       /* old heartbeat */\n       allocateResponse.setAMResponse(lastResponse);\n       return allocateResponse;\n     } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n       LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n       // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n       allocateResponse.setAMResponse(reboot);\n       return allocateResponse;\n     }\n \n     // Allow only one thread in AM to do heartbeat at a time.\n     synchronized (lastResponse) { // BUG TODO: Locking order is screwed.\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n       // Send new requests to appAttempt.\n       Allocation allocation \u003d\n           this.rScheduler.allocate(appAttemptId, ask, release);\n \n       RMApp app \u003d this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n       \n       AMResponse response \u003d recordFactory.newRecordInstance(AMResponse.class);\n \n       // update the response with the deltas of node status changes\n       List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n       if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n         List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n         for(RMNode rmNode: updatedNodes) {\n           SchedulerNodeReport schedulerNodeReport \u003d  \n               rScheduler.getNodeReport(rmNode.getNodeID());\n           Resource used \u003d BuilderUtils.newResource(0);\n           int numContainers \u003d 0;\n           if (schedulerNodeReport !\u003d null) {\n             used \u003d schedulerNodeReport.getUsedResource();\n             numContainers \u003d schedulerNodeReport.getNumContainers();\n           }\n           NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n-              RMNodeState.toNodeState(rmNode.getState()),\n+              rmNode.getState(),\n               rmNode.getHttpAddress(), rmNode.getRackName(), used,\n               rmNode.getTotalCapability(), numContainers,\n               rmNode.getNodeHealthStatus());\n           \n           updatedNodeReports.add(report);\n         }\n         response.setUpdatedNodes(updatedNodeReports);\n       }\n \n       response.setAllocatedContainers(allocation.getContainers());\n       response.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       response.setResponseId(lastResponse.getResponseId() + 1);\n       response.setAvailableResources(allocation.getResourceLimit());\n       responseMap.put(appAttemptId, response);\n       allocateResponse.setAMResponse(response);\n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n       return allocateResponse;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnRemoteException {\n\n    ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n    authorizeRequest(appAttemptId);\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponse allocateResponse \u003d recordFactory\n        .newRecordInstance(AllocateResponse.class);\n    AMResponse lastResponse \u003d responseMap.get(appAttemptId);\n    if (lastResponse \u003d\u003d null) {\n      LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n      allocateResponse.setAMResponse(reboot);\n      return allocateResponse;\n    }\n    if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n      /* old heartbeat */\n      allocateResponse.setAMResponse(lastResponse);\n      return allocateResponse;\n    } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n      LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n      // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n      allocateResponse.setAMResponse(reboot);\n      return allocateResponse;\n    }\n\n    // Allow only one thread in AM to do heartbeat at a time.\n    synchronized (lastResponse) { // BUG TODO: Locking order is screwed.\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      // Send new requests to appAttempt.\n      Allocation allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release);\n\n      RMApp app \u003d this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      \n      AMResponse response \u003d recordFactory.newRecordInstance(AMResponse.class);\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n              rmNode.getState(),\n              rmNode.getHttpAddress(), rmNode.getRackName(), used,\n              rmNode.getTotalCapability(), numContainers,\n              rmNode.getNodeHealthStatus());\n          \n          updatedNodeReports.add(report);\n        }\n        response.setUpdatedNodes(updatedNodeReports);\n      }\n\n      response.setAllocatedContainers(allocation.getContainers());\n      response.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      response.setResponseId(lastResponse.getResponseId() + 1);\n      response.setAvailableResources(allocation.getResourceLimit());\n      responseMap.put(appAttemptId, response);\n      allocateResponse.setAMResponse(response);\n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n      return allocateResponse;\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "606114d6029758f2be130960b8fc3102457406ba": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3533. Add a channel between RM and AM to get information on nodes. Contributed by Bikas Saha. \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1305230 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/03/12 10:45 PM",
      "commitName": "606114d6029758f2be130960b8fc3102457406ba",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "20/03/12 9:29 AM",
      "commitNameOld": "40a8293d36cbae0fc20abe046a35f229df149f46",
      "commitAuthorOld": "Robert Joseph Evans",
      "daysBetweenCommits": 5.55,
      "commitsBetweenForRepo": 27,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,58 +1,83 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnRemoteException {\n \n     ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n     authorizeRequest(appAttemptId);\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponse allocateResponse \u003d recordFactory\n         .newRecordInstance(AllocateResponse.class);\n     AMResponse lastResponse \u003d responseMap.get(appAttemptId);\n     if (lastResponse \u003d\u003d null) {\n       LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n       allocateResponse.setAMResponse(reboot);\n       return allocateResponse;\n     }\n     if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n       /* old heartbeat */\n       allocateResponse.setAMResponse(lastResponse);\n       return allocateResponse;\n     } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n       LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n       // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n       allocateResponse.setAMResponse(reboot);\n       return allocateResponse;\n     }\n \n     // Allow only one thread in AM to do heartbeat at a time.\n     synchronized (lastResponse) { // BUG TODO: Locking order is screwed.\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n       // Send new requests to appAttempt.\n       Allocation allocation \u003d\n           this.rScheduler.allocate(appAttemptId, ask, release);\n \n       RMApp app \u003d this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n-\n+      \n       AMResponse response \u003d recordFactory.newRecordInstance(AMResponse.class);\n+\n+      // update the response with the deltas of node status changes\n+      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n+      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n+        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n+        for(RMNode rmNode: updatedNodes) {\n+          SchedulerNodeReport schedulerNodeReport \u003d  \n+              rScheduler.getNodeReport(rmNode.getNodeID());\n+          Resource used \u003d BuilderUtils.newResource(0);\n+          int numContainers \u003d 0;\n+          if (schedulerNodeReport !\u003d null) {\n+            used \u003d schedulerNodeReport.getUsedResource();\n+            numContainers \u003d schedulerNodeReport.getNumContainers();\n+          }\n+          NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n+              RMNodeState.toNodeState(rmNode.getState()),\n+              rmNode.getHttpAddress(), rmNode.getRackName(), used,\n+              rmNode.getTotalCapability(), numContainers,\n+              rmNode.getNodeHealthStatus());\n+          \n+          updatedNodeReports.add(report);\n+        }\n+        response.setUpdatedNodes(updatedNodeReports);\n+      }\n+\n       response.setAllocatedContainers(allocation.getContainers());\n       response.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       response.setResponseId(lastResponse.getResponseId() + 1);\n       response.setAvailableResources(allocation.getResourceLimit());\n       responseMap.put(appAttemptId, response);\n       allocateResponse.setAMResponse(response);\n       allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n       return allocateResponse;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnRemoteException {\n\n    ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n    authorizeRequest(appAttemptId);\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponse allocateResponse \u003d recordFactory\n        .newRecordInstance(AllocateResponse.class);\n    AMResponse lastResponse \u003d responseMap.get(appAttemptId);\n    if (lastResponse \u003d\u003d null) {\n      LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n      allocateResponse.setAMResponse(reboot);\n      return allocateResponse;\n    }\n    if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n      /* old heartbeat */\n      allocateResponse.setAMResponse(lastResponse);\n      return allocateResponse;\n    } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n      LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n      // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n      allocateResponse.setAMResponse(reboot);\n      return allocateResponse;\n    }\n\n    // Allow only one thread in AM to do heartbeat at a time.\n    synchronized (lastResponse) { // BUG TODO: Locking order is screwed.\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      // Send new requests to appAttempt.\n      Allocation allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release);\n\n      RMApp app \u003d this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n      \n      AMResponse response \u003d recordFactory.newRecordInstance(AMResponse.class);\n\n      // update the response with the deltas of node status changes\n      List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003cRMNode\u003e();\n      if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n        List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003cNodeReport\u003e();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport \u003d  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used \u003d BuilderUtils.newResource(0);\n          int numContainers \u003d 0;\n          if (schedulerNodeReport !\u003d null) {\n            used \u003d schedulerNodeReport.getUsedResource();\n            numContainers \u003d schedulerNodeReport.getNumContainers();\n          }\n          NodeReport report \u003d BuilderUtils.newNodeReport(rmNode.getNodeID(),\n              RMNodeState.toNodeState(rmNode.getState()),\n              rmNode.getHttpAddress(), rmNode.getRackName(), used,\n              rmNode.getTotalCapability(), numContainers,\n              rmNode.getNodeHealthStatus());\n          \n          updatedNodeReports.add(report);\n        }\n        response.setUpdatedNodes(updatedNodeReports);\n      }\n\n      response.setAllocatedContainers(allocation.getContainers());\n      response.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      response.setResponseId(lastResponse.getResponseId() + 1);\n      response.setAvailableResources(allocation.getResourceLimit());\n      responseMap.put(appAttemptId, response);\n      allocateResponse.setAMResponse(response);\n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n      return allocateResponse;\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "e7543b944c2b35d0a1ca0a92efeca47ad414ac7a": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3339. Fixed MR AM to stop considering node blacklisting after the number of nodes blacklisted crosses a threshold. Contributed by Siddharth Seth.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1221523 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/12/11 3:27 PM",
      "commitName": "e7543b944c2b35d0a1ca0a92efeca47ad414ac7a",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "27/10/11 5:42 AM",
      "commitNameOld": "f114dad5ef9b72875e245803cee150ad12ff59de",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 54.45,
      "commitsBetweenForRepo": 353,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,57 +1,58 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnRemoteException {\n \n     ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n     authorizeRequest(appAttemptId);\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponse allocateResponse \u003d recordFactory\n         .newRecordInstance(AllocateResponse.class);\n     AMResponse lastResponse \u003d responseMap.get(appAttemptId);\n     if (lastResponse \u003d\u003d null) {\n       LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n       allocateResponse.setAMResponse(reboot);\n       return allocateResponse;\n     }\n     if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n       /* old heartbeat */\n       allocateResponse.setAMResponse(lastResponse);\n       return allocateResponse;\n     } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n       LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n       // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n       allocateResponse.setAMResponse(reboot);\n       return allocateResponse;\n     }\n \n     // Allow only one thread in AM to do heartbeat at a time.\n     synchronized (lastResponse) { // BUG TODO: Locking order is screwed.\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n       // Send new requests to appAttempt.\n       Allocation allocation \u003d\n           this.rScheduler.allocate(appAttemptId, ask, release);\n \n       RMApp app \u003d this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n \n       AMResponse response \u003d recordFactory.newRecordInstance(AMResponse.class);\n       response.setAllocatedContainers(allocation.getContainers());\n       response.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       response.setResponseId(lastResponse.getResponseId() + 1);\n       response.setAvailableResources(allocation.getResourceLimit());\n       responseMap.put(appAttemptId, response);\n       allocateResponse.setAMResponse(response);\n+      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n       return allocateResponse;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnRemoteException {\n\n    ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n    authorizeRequest(appAttemptId);\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponse allocateResponse \u003d recordFactory\n        .newRecordInstance(AllocateResponse.class);\n    AMResponse lastResponse \u003d responseMap.get(appAttemptId);\n    if (lastResponse \u003d\u003d null) {\n      LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n      allocateResponse.setAMResponse(reboot);\n      return allocateResponse;\n    }\n    if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n      /* old heartbeat */\n      allocateResponse.setAMResponse(lastResponse);\n      return allocateResponse;\n    } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n      LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n      // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n      allocateResponse.setAMResponse(reboot);\n      return allocateResponse;\n    }\n\n    // Allow only one thread in AM to do heartbeat at a time.\n    synchronized (lastResponse) { // BUG TODO: Locking order is screwed.\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      // Send new requests to appAttempt.\n      Allocation allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release);\n\n      RMApp app \u003d this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n\n      AMResponse response \u003d recordFactory.newRecordInstance(AMResponse.class);\n      response.setAllocatedContainers(allocation.getContainers());\n      response.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      response.setResponseId(lastResponse.getResponseId() + 1);\n      response.setAvailableResources(allocation.getResourceLimit());\n      responseMap.put(appAttemptId, response);\n      allocateResponse.setAMResponse(response);\n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n      return allocateResponse;\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "db8ac0ec3cbec046f9cf32644c16fd2a51dd85a2": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3257. Added authorization checks for the protocol between ResourceManager and ApplicatoinMaster. Contributed by Vinod K V. \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1189630 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/10/11 11:24 PM",
      "commitName": "db8ac0ec3cbec046f9cf32644c16fd2a51dd85a2",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/10/11 11:07 PM",
      "commitNameOld": "d19cfe01642f9582e1fe5d567beb480399c37a01",
      "commitAuthorOld": "Mahadev Konar",
      "daysBetweenCommits": 2.01,
      "commitsBetweenForRepo": 22,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,56 +1,57 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnRemoteException {\n \n     ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n+    authorizeRequest(appAttemptId);\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponse allocateResponse \u003d recordFactory\n         .newRecordInstance(AllocateResponse.class);\n     AMResponse lastResponse \u003d responseMap.get(appAttemptId);\n     if (lastResponse \u003d\u003d null) {\n       LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n       allocateResponse.setAMResponse(reboot);\n       return allocateResponse;\n     }\n     if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n       /* old heartbeat */\n       allocateResponse.setAMResponse(lastResponse);\n       return allocateResponse;\n     } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n       LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n       // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n       allocateResponse.setAMResponse(reboot);\n       return allocateResponse;\n     }\n \n     // Allow only one thread in AM to do heartbeat at a time.\n     synchronized (lastResponse) { // BUG TODO: Locking order is screwed.\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n       // Send new requests to appAttempt.\n       Allocation allocation \u003d\n           this.rScheduler.allocate(appAttemptId, ask, release);\n \n       RMApp app \u003d this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n \n       AMResponse response \u003d recordFactory.newRecordInstance(AMResponse.class);\n       response.setAllocatedContainers(allocation.getContainers());\n       response.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       response.setResponseId(lastResponse.getResponseId() + 1);\n       response.setAvailableResources(allocation.getResourceLimit());\n       responseMap.put(appAttemptId, response);\n       allocateResponse.setAMResponse(response);\n       return allocateResponse;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnRemoteException {\n\n    ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n    authorizeRequest(appAttemptId);\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponse allocateResponse \u003d recordFactory\n        .newRecordInstance(AllocateResponse.class);\n    AMResponse lastResponse \u003d responseMap.get(appAttemptId);\n    if (lastResponse \u003d\u003d null) {\n      LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n      allocateResponse.setAMResponse(reboot);\n      return allocateResponse;\n    }\n    if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n      /* old heartbeat */\n      allocateResponse.setAMResponse(lastResponse);\n      return allocateResponse;\n    } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n      LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n      // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n      allocateResponse.setAMResponse(reboot);\n      return allocateResponse;\n    }\n\n    // Allow only one thread in AM to do heartbeat at a time.\n    synchronized (lastResponse) { // BUG TODO: Locking order is screwed.\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      // Send new requests to appAttempt.\n      Allocation allocation \u003d\n          this.rScheduler.allocate(appAttemptId, ask, release);\n\n      RMApp app \u003d this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n\n      AMResponse response \u003d recordFactory.newRecordInstance(AMResponse.class);\n      response.setAllocatedContainers(allocation.getContainers());\n      response.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      response.setResponseId(lastResponse.getResponseId() + 1);\n      response.setAvailableResources(allocation.getResourceLimit());\n      responseMap.put(appAttemptId, response);\n      allocateResponse.setAMResponse(response);\n      return allocateResponse;\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "817ead65b99f465fc2dfa18072cf23cadf5f05d0": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2933. Change allocate call to return ContainerStatus for completed containers rather than Container.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1169484 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/09/11 10:26 AM",
      "commitName": "817ead65b99f465fc2dfa18072cf23cadf5f05d0",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "08/09/11 6:44 PM",
      "commitNameOld": "fafe8cd28e726566509c679e19d7da622f29f90d",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 2.65,
      "commitsBetweenForRepo": 16,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,56 +1,56 @@\n   public AllocateResponse allocate(AllocateRequest request)\n       throws YarnRemoteException {\n \n     ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n \n     this.amLivelinessMonitor.receivedPing(appAttemptId);\n \n     /* check if its in cache */\n     AllocateResponse allocateResponse \u003d recordFactory\n         .newRecordInstance(AllocateResponse.class);\n     AMResponse lastResponse \u003d responseMap.get(appAttemptId);\n     if (lastResponse \u003d\u003d null) {\n       LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n       allocateResponse.setAMResponse(reboot);\n       return allocateResponse;\n     }\n     if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n       /* old heartbeat */\n       allocateResponse.setAMResponse(lastResponse);\n       return allocateResponse;\n     } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n       LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n       // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n       allocateResponse.setAMResponse(reboot);\n       return allocateResponse;\n     }\n \n     // Allow only one thread in AM to do heartbeat at a time.\n     synchronized (lastResponse) { // BUG TODO: Locking order is screwed.\n \n       // Send the status update to the appAttempt.\n       this.rmContext.getDispatcher().getEventHandler().handle(\n           new RMAppAttemptStatusupdateEvent(appAttemptId, request\n               .getProgress()));\n \n       List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n       List\u003cContainerId\u003e release \u003d request.getReleaseList();\n \n       // Send new requests to appAttempt.\n       Allocation allocation \u003d \n           this.rScheduler.allocate(appAttemptId, ask, release);\n \n       RMApp app \u003d this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n       RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n \n       AMResponse response \u003d recordFactory.newRecordInstance(AMResponse.class);\n-      response.addAllNewContainers(allocation.getContainers());\n-      response.addAllFinishedContainers(appAttempt\n+      response.setAllocatedContainers(allocation.getContainers());\n+      response.setCompletedContainersStatuses(appAttempt\n           .pullJustFinishedContainers());\n       response.setResponseId(lastResponse.getResponseId() + 1);\n       response.setAvailableResources(allocation.getResourceLimit());\n       responseMap.put(appAttemptId, response);\n       allocateResponse.setAMResponse(response);\n       return allocateResponse;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnRemoteException {\n\n    ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponse allocateResponse \u003d recordFactory\n        .newRecordInstance(AllocateResponse.class);\n    AMResponse lastResponse \u003d responseMap.get(appAttemptId);\n    if (lastResponse \u003d\u003d null) {\n      LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n      allocateResponse.setAMResponse(reboot);\n      return allocateResponse;\n    }\n    if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n      /* old heartbeat */\n      allocateResponse.setAMResponse(lastResponse);\n      return allocateResponse;\n    } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n      LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n      // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n      allocateResponse.setAMResponse(reboot);\n      return allocateResponse;\n    }\n\n    // Allow only one thread in AM to do heartbeat at a time.\n    synchronized (lastResponse) { // BUG TODO: Locking order is screwed.\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      // Send new requests to appAttempt.\n      Allocation allocation \u003d \n          this.rScheduler.allocate(appAttemptId, ask, release);\n\n      RMApp app \u003d this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n\n      AMResponse response \u003d recordFactory.newRecordInstance(AMResponse.class);\n      response.setAllocatedContainers(allocation.getContainers());\n      response.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      response.setResponseId(lastResponse.getResponseId() + 1);\n      response.setAvailableResources(allocation.getResourceLimit());\n      responseMap.put(appAttemptId, response);\n      allocateResponse.setAMResponse(response);\n      return allocateResponse;\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnRemoteException {\n\n    ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponse allocateResponse \u003d recordFactory\n        .newRecordInstance(AllocateResponse.class);\n    AMResponse lastResponse \u003d responseMap.get(appAttemptId);\n    if (lastResponse \u003d\u003d null) {\n      LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n      allocateResponse.setAMResponse(reboot);\n      return allocateResponse;\n    }\n    if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n      /* old heartbeat */\n      allocateResponse.setAMResponse(lastResponse);\n      return allocateResponse;\n    } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n      LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n      // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n      allocateResponse.setAMResponse(reboot);\n      return allocateResponse;\n    }\n\n    // Allow only one thread in AM to do heartbeat at a time.\n    synchronized (lastResponse) { // BUG TODO: Locking order is screwed.\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      // Send new requests to appAttempt.\n      Allocation allocation \u003d \n          this.rScheduler.allocate(appAttemptId, ask, release);\n\n      RMApp app \u003d this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n\n      AMResponse response \u003d recordFactory.newRecordInstance(AMResponse.class);\n      response.addAllNewContainers(allocation.getContainers());\n      response.addAllFinishedContainers(appAttempt\n          .pullJustFinishedContainers());\n      response.setResponseId(lastResponse.getResponseId() + 1);\n      response.setAvailableResources(allocation.getResourceLimit());\n      responseMap.put(appAttemptId, response);\n      allocateResponse.setAMResponse(response);\n      return allocateResponse;\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java",
        "newPath": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "diff": "@@ -0,0 +1,56 @@\n+  public AllocateResponse allocate(AllocateRequest request)\n+      throws YarnRemoteException {\n+\n+    ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n+\n+    this.amLivelinessMonitor.receivedPing(appAttemptId);\n+\n+    /* check if its in cache */\n+    AllocateResponse allocateResponse \u003d recordFactory\n+        .newRecordInstance(AllocateResponse.class);\n+    AMResponse lastResponse \u003d responseMap.get(appAttemptId);\n+    if (lastResponse \u003d\u003d null) {\n+      LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n+      allocateResponse.setAMResponse(reboot);\n+      return allocateResponse;\n+    }\n+    if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n+      /* old heartbeat */\n+      allocateResponse.setAMResponse(lastResponse);\n+      return allocateResponse;\n+    } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n+      LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n+      // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n+      allocateResponse.setAMResponse(reboot);\n+      return allocateResponse;\n+    }\n+\n+    // Allow only one thread in AM to do heartbeat at a time.\n+    synchronized (lastResponse) { // BUG TODO: Locking order is screwed.\n+\n+      // Send the status update to the appAttempt.\n+      this.rmContext.getDispatcher().getEventHandler().handle(\n+          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n+              .getProgress()));\n+\n+      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n+      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n+\n+      // Send new requests to appAttempt.\n+      Allocation allocation \u003d \n+          this.rScheduler.allocate(appAttemptId, ask, release);\n+\n+      RMApp app \u003d this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n+      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n+\n+      AMResponse response \u003d recordFactory.newRecordInstance(AMResponse.class);\n+      response.addAllNewContainers(allocation.getContainers());\n+      response.addAllFinishedContainers(appAttempt\n+          .pullJustFinishedContainers());\n+      response.setResponseId(lastResponse.getResponseId() + 1);\n+      response.setAvailableResources(allocation.getResourceLimit());\n+      responseMap.put(appAttemptId, response);\n+      allocateResponse.setAMResponse(response);\n+      return allocateResponse;\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnRemoteException {\n\n    ApplicationAttemptId appAttemptId \u003d request.getApplicationAttemptId();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponse allocateResponse \u003d recordFactory\n        .newRecordInstance(AllocateResponse.class);\n    AMResponse lastResponse \u003d responseMap.get(appAttemptId);\n    if (lastResponse \u003d\u003d null) {\n      LOG.error(\"AppAttemptId doesnt exist in cache \" + appAttemptId);\n      allocateResponse.setAMResponse(reboot);\n      return allocateResponse;\n    }\n    if ((request.getResponseId() + 1) \u003d\u003d lastResponse.getResponseId()) {\n      /* old heartbeat */\n      allocateResponse.setAMResponse(lastResponse);\n      return allocateResponse;\n    } else if (request.getResponseId() + 1 \u003c lastResponse.getResponseId()) {\n      LOG.error(\"Invalid responseid from appAttemptId \" + appAttemptId);\n      // Oh damn! Sending reboot isn\u0027t enough. RM state is corrupted. TODO:\n      allocateResponse.setAMResponse(reboot);\n      return allocateResponse;\n    }\n\n    // Allow only one thread in AM to do heartbeat at a time.\n    synchronized (lastResponse) { // BUG TODO: Locking order is screwed.\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List\u003cResourceRequest\u003e ask \u003d request.getAskList();\n      List\u003cContainerId\u003e release \u003d request.getReleaseList();\n\n      // Send new requests to appAttempt.\n      Allocation allocation \u003d \n          this.rScheduler.allocate(appAttemptId, ask, release);\n\n      RMApp app \u003d this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n      RMAppAttempt appAttempt \u003d app.getRMAppAttempt(appAttemptId);\n\n      AMResponse response \u003d recordFactory.newRecordInstance(AMResponse.class);\n      response.addAllNewContainers(allocation.getContainers());\n      response.addAllFinishedContainers(appAttempt\n          .pullJustFinishedContainers());\n      response.setResponseId(lastResponse.getResponseId() + 1);\n      response.setAvailableResources(allocation.getResourceLimit());\n      responseMap.put(appAttemptId, response);\n      allocateResponse.setAMResponse(response);\n      return allocateResponse;\n    }\n  }",
      "path": "hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java"
    }
  }
}