{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockInfo.java",
  "functionName": "findStorageInfo",
  "functionId": "findStorageInfo___dn-DatanodeDescriptor",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfo.java",
  "functionStartLine": 194,
  "functionEndLine": 213,
  "numCommitsSeen": 116,
  "timeTaken": 6327,
  "changeHistory": [
    "90d1b47a2a400e07e2b6b812c4bbd9c4f2877786",
    "546b95f4843f3cbbbdf72d90d202cad551696082",
    "4928f5473394981829e5ffd4b16ea0801baf5c45",
    "ba9371492036983a9899398907ab41fe548f29b3",
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177",
    "0ed8732feef9f4027e9fc95b6d4852444c1f3426"
  ],
  "changeHistoryShort": {
    "90d1b47a2a400e07e2b6b812c4bbd9c4f2877786": "Ybodychange",
    "546b95f4843f3cbbbdf72d90d202cad551696082": "Ybodychange",
    "4928f5473394981829e5ffd4b16ea0801baf5c45": "Yfilerename",
    "ba9371492036983a9899398907ab41fe548f29b3": "Ymultichange(Ymovefromfile,Ybodychange)",
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177": "Yfilerename",
    "0ed8732feef9f4027e9fc95b6d4852444c1f3426": "Ymultichange(Yparameterchange,Yreturntypechange,Ybodychange)"
  },
  "changeHistoryDetails": {
    "90d1b47a2a400e07e2b6b812c4bbd9c4f2877786": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12776. [READ] Increasing replication for PROVIDED files should create local replicas\n",
      "commitDate": "15/12/17 5:51 PM",
      "commitName": "90d1b47a2a400e07e2b6b812c4bbd9c4f2877786",
      "commitAuthor": "Virajith Jalaparti",
      "commitDateOld": "15/12/17 5:51 PM",
      "commitNameOld": "546b95f4843f3cbbbdf72d90d202cad551696082",
      "commitAuthorOld": "Virajith Jalaparti",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 10,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,20 @@\n   DatanodeStorageInfo findStorageInfo(DatanodeDescriptor dn) {\n     int len \u003d getCapacity();\n+    DatanodeStorageInfo providedStorageInfo \u003d null;\n     for(int idx \u003d 0; idx \u003c len; idx++) {\n       DatanodeStorageInfo cur \u003d getStorageInfo(idx);\n       if(cur !\u003d null) {\n         if (cur.getStorageType() \u003d\u003d StorageType.PROVIDED) {\n           //if block resides on provided storage, only match the storage ids\n           if (dn.getStorageInfo(cur.getStorageID()) !\u003d null) {\n-            return cur;\n+            // do not return here as we have to check the other\n+            // DatanodeStorageInfos for this block which could be local\n+            providedStorageInfo \u003d cur;\n           }\n         } else if (cur.getDatanodeDescriptor() \u003d\u003d dn) {\n           return cur;\n         }\n       }\n     }\n-    return null;\n+    return providedStorageInfo;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  DatanodeStorageInfo findStorageInfo(DatanodeDescriptor dn) {\n    int len \u003d getCapacity();\n    DatanodeStorageInfo providedStorageInfo \u003d null;\n    for(int idx \u003d 0; idx \u003c len; idx++) {\n      DatanodeStorageInfo cur \u003d getStorageInfo(idx);\n      if(cur !\u003d null) {\n        if (cur.getStorageType() \u003d\u003d StorageType.PROVIDED) {\n          //if block resides on provided storage, only match the storage ids\n          if (dn.getStorageInfo(cur.getStorageID()) !\u003d null) {\n            // do not return here as we have to check the other\n            // DatanodeStorageInfos for this block which could be local\n            providedStorageInfo \u003d cur;\n          }\n        } else if (cur.getDatanodeDescriptor() \u003d\u003d dn) {\n          return cur;\n        }\n      }\n    }\n    return providedStorageInfo;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfo.java",
      "extendedDetails": {}
    },
    "546b95f4843f3cbbbdf72d90d202cad551696082": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11673. [READ] Handle failures of Datanode with PROVIDED storage\n",
      "commitDate": "15/12/17 5:51 PM",
      "commitName": "546b95f4843f3cbbbdf72d90d202cad551696082",
      "commitAuthor": "Virajith Jalaparti",
      "commitDateOld": "25/05/17 7:35 AM",
      "commitNameOld": "2e41f8803dd46d1bab16c1b206c71be72ea260a1",
      "commitAuthorOld": "Brahma Reddy Battula",
      "daysBetweenCommits": 204.47,
      "commitsBetweenForRepo": 1494,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,10 +1,17 @@\n   DatanodeStorageInfo findStorageInfo(DatanodeDescriptor dn) {\n     int len \u003d getCapacity();\n     for(int idx \u003d 0; idx \u003c len; idx++) {\n       DatanodeStorageInfo cur \u003d getStorageInfo(idx);\n-      if(cur !\u003d null \u0026\u0026 cur.getDatanodeDescriptor() \u003d\u003d dn) {\n-        return cur;\n+      if(cur !\u003d null) {\n+        if (cur.getStorageType() \u003d\u003d StorageType.PROVIDED) {\n+          //if block resides on provided storage, only match the storage ids\n+          if (dn.getStorageInfo(cur.getStorageID()) !\u003d null) {\n+            return cur;\n+          }\n+        } else if (cur.getDatanodeDescriptor() \u003d\u003d dn) {\n+          return cur;\n+        }\n       }\n     }\n     return null;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  DatanodeStorageInfo findStorageInfo(DatanodeDescriptor dn) {\n    int len \u003d getCapacity();\n    for(int idx \u003d 0; idx \u003c len; idx++) {\n      DatanodeStorageInfo cur \u003d getStorageInfo(idx);\n      if(cur !\u003d null) {\n        if (cur.getStorageType() \u003d\u003d StorageType.PROVIDED) {\n          //if block resides on provided storage, only match the storage ids\n          if (dn.getStorageInfo(cur.getStorageID()) !\u003d null) {\n            return cur;\n          }\n        } else if (cur.getDatanodeDescriptor() \u003d\u003d dn) {\n          return cur;\n        }\n      }\n    }\n    return null;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfo.java",
      "extendedDetails": {}
    },
    "4928f5473394981829e5ffd4b16ea0801baf5c45": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8482. Rename BlockInfoContiguous to BlockInfo. Contributed by Zhe Zhang.\n",
      "commitDate": "27/05/15 3:42 PM",
      "commitName": "4928f5473394981829e5ffd4b16ea0801baf5c45",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "27/05/15 3:34 PM",
      "commitNameOld": "cab7674e54c4fe56838668462de99a6787841309",
      "commitAuthorOld": "Wangda Tan",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  DatanodeStorageInfo findStorageInfo(DatanodeDescriptor dn) {\n    int len \u003d getCapacity();\n    for(int idx \u003d 0; idx \u003c len; idx++) {\n      DatanodeStorageInfo cur \u003d getStorageInfo(idx);\n      if(cur \u003d\u003d null)\n        break;\n      if(cur.getDatanodeDescriptor() \u003d\u003d dn)\n        return cur;\n    }\n    return null;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfo.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoContiguous.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfo.java"
      }
    },
    "ba9371492036983a9899398907ab41fe548f29b3": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange)",
      "commitMessage": "HDFS-7716. Erasure Coding: extend BlockInfo to handle EC info. Contributed by Jing Zhao.\n",
      "commitDate": "26/05/15 11:07 AM",
      "commitName": "ba9371492036983a9899398907ab41fe548f29b3",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-7716. Erasure Coding: extend BlockInfo to handle EC info. Contributed by Jing Zhao.\n",
          "commitDate": "26/05/15 11:07 AM",
          "commitName": "ba9371492036983a9899398907ab41fe548f29b3",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "26/05/15 11:03 AM",
          "commitNameOld": "b29f3bde4d2fd2f2c4abd6d7b5f97a81bb50efb2",
          "commitAuthorOld": "Kai Zheng",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,10 @@\n   DatanodeStorageInfo findStorageInfo(DatanodeDescriptor dn) {\n     int len \u003d getCapacity();\n     for(int idx \u003d 0; idx \u003c len; idx++) {\n       DatanodeStorageInfo cur \u003d getStorageInfo(idx);\n-      if(cur \u003d\u003d null)\n-        break;\n-      if(cur.getDatanodeDescriptor() \u003d\u003d dn)\n+      if(cur !\u003d null \u0026\u0026 cur.getDatanodeDescriptor() \u003d\u003d dn) {\n         return cur;\n+      }\n     }\n     return null;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  DatanodeStorageInfo findStorageInfo(DatanodeDescriptor dn) {\n    int len \u003d getCapacity();\n    for(int idx \u003d 0; idx \u003c len; idx++) {\n      DatanodeStorageInfo cur \u003d getStorageInfo(idx);\n      if(cur !\u003d null \u0026\u0026 cur.getDatanodeDescriptor() \u003d\u003d dn) {\n        return cur;\n      }\n    }\n    return null;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfo.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoContiguous.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfo.java",
            "oldMethodName": "findStorageInfo",
            "newMethodName": "findStorageInfo"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7716. Erasure Coding: extend BlockInfo to handle EC info. Contributed by Jing Zhao.\n",
          "commitDate": "26/05/15 11:07 AM",
          "commitName": "ba9371492036983a9899398907ab41fe548f29b3",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "26/05/15 11:03 AM",
          "commitNameOld": "b29f3bde4d2fd2f2c4abd6d7b5f97a81bb50efb2",
          "commitAuthorOld": "Kai Zheng",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,10 @@\n   DatanodeStorageInfo findStorageInfo(DatanodeDescriptor dn) {\n     int len \u003d getCapacity();\n     for(int idx \u003d 0; idx \u003c len; idx++) {\n       DatanodeStorageInfo cur \u003d getStorageInfo(idx);\n-      if(cur \u003d\u003d null)\n-        break;\n-      if(cur.getDatanodeDescriptor() \u003d\u003d dn)\n+      if(cur !\u003d null \u0026\u0026 cur.getDatanodeDescriptor() \u003d\u003d dn) {\n         return cur;\n+      }\n     }\n     return null;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  DatanodeStorageInfo findStorageInfo(DatanodeDescriptor dn) {\n    int len \u003d getCapacity();\n    for(int idx \u003d 0; idx \u003c len; idx++) {\n      DatanodeStorageInfo cur \u003d getStorageInfo(idx);\n      if(cur !\u003d null \u0026\u0026 cur.getDatanodeDescriptor() \u003d\u003d dn) {\n        return cur;\n      }\n    }\n    return null;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfo.java",
          "extendedDetails": {}
        }
      ]
    },
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-7743. Code cleanup of BlockInfo and rename BlockInfo to BlockInfoContiguous. Contributed by Jing Zhao.\n",
      "commitDate": "08/02/15 11:51 AM",
      "commitName": "1382ae525c67bf95d8f3a436b547dbc72cfbb177",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "07/02/15 10:43 AM",
      "commitNameOld": "ef01768333ec0e59e7d747864183835e756a7bf6",
      "commitAuthorOld": "yliu",
      "daysBetweenCommits": 1.05,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  DatanodeStorageInfo findStorageInfo(DatanodeDescriptor dn) {\n    int len \u003d getCapacity();\n    for(int idx \u003d 0; idx \u003c len; idx++) {\n      DatanodeStorageInfo cur \u003d getStorageInfo(idx);\n      if(cur \u003d\u003d null)\n        break;\n      if(cur.getDatanodeDescriptor() \u003d\u003d dn)\n        return cur;\n    }\n    return null;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoContiguous.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfo.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoContiguous.java"
      }
    },
    "0ed8732feef9f4027e9fc95b6d4852444c1f3426": {
      "type": "Ymultichange(Yparameterchange,Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-6812. Remove addBlock and replaceBlock from DatanodeDescriptor.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1616426 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/08/14 12:30 AM",
      "commitName": "0ed8732feef9f4027e9fc95b6d4852444c1f3426",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6812. Remove addBlock and replaceBlock from DatanodeDescriptor.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1616426 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "07/08/14 12:30 AM",
          "commitName": "0ed8732feef9f4027e9fc95b6d4852444c1f3426",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "18/06/14 12:37 PM",
          "commitNameOld": "52d18aa217a308e8343ca8b23b5a2dedda77270f",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 49.5,
          "commitsBetweenForRepo": 348,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,11 @@\n-  int findStorageInfo(DatanodeInfo dn) {\n+  DatanodeStorageInfo findStorageInfo(DatanodeDescriptor dn) {\n     int len \u003d getCapacity();\n     for(int idx \u003d 0; idx \u003c len; idx++) {\n       DatanodeStorageInfo cur \u003d getStorageInfo(idx);\n       if(cur \u003d\u003d null)\n         break;\n       if(cur.getDatanodeDescriptor() \u003d\u003d dn)\n-        return idx;\n+        return cur;\n     }\n-    return -1;\n+    return null;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  DatanodeStorageInfo findStorageInfo(DatanodeDescriptor dn) {\n    int len \u003d getCapacity();\n    for(int idx \u003d 0; idx \u003c len; idx++) {\n      DatanodeStorageInfo cur \u003d getStorageInfo(idx);\n      if(cur \u003d\u003d null)\n        break;\n      if(cur.getDatanodeDescriptor() \u003d\u003d dn)\n        return cur;\n    }\n    return null;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfo.java",
          "extendedDetails": {
            "oldValue": "[dn-DatanodeInfo]",
            "newValue": "[dn-DatanodeDescriptor]"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-6812. Remove addBlock and replaceBlock from DatanodeDescriptor.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1616426 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "07/08/14 12:30 AM",
          "commitName": "0ed8732feef9f4027e9fc95b6d4852444c1f3426",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "18/06/14 12:37 PM",
          "commitNameOld": "52d18aa217a308e8343ca8b23b5a2dedda77270f",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 49.5,
          "commitsBetweenForRepo": 348,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,11 @@\n-  int findStorageInfo(DatanodeInfo dn) {\n+  DatanodeStorageInfo findStorageInfo(DatanodeDescriptor dn) {\n     int len \u003d getCapacity();\n     for(int idx \u003d 0; idx \u003c len; idx++) {\n       DatanodeStorageInfo cur \u003d getStorageInfo(idx);\n       if(cur \u003d\u003d null)\n         break;\n       if(cur.getDatanodeDescriptor() \u003d\u003d dn)\n-        return idx;\n+        return cur;\n     }\n-    return -1;\n+    return null;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  DatanodeStorageInfo findStorageInfo(DatanodeDescriptor dn) {\n    int len \u003d getCapacity();\n    for(int idx \u003d 0; idx \u003c len; idx++) {\n      DatanodeStorageInfo cur \u003d getStorageInfo(idx);\n      if(cur \u003d\u003d null)\n        break;\n      if(cur.getDatanodeDescriptor() \u003d\u003d dn)\n        return cur;\n    }\n    return null;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfo.java",
          "extendedDetails": {
            "oldValue": "int",
            "newValue": "DatanodeStorageInfo"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6812. Remove addBlock and replaceBlock from DatanodeDescriptor.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1616426 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "07/08/14 12:30 AM",
          "commitName": "0ed8732feef9f4027e9fc95b6d4852444c1f3426",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "18/06/14 12:37 PM",
          "commitNameOld": "52d18aa217a308e8343ca8b23b5a2dedda77270f",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 49.5,
          "commitsBetweenForRepo": 348,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,11 @@\n-  int findStorageInfo(DatanodeInfo dn) {\n+  DatanodeStorageInfo findStorageInfo(DatanodeDescriptor dn) {\n     int len \u003d getCapacity();\n     for(int idx \u003d 0; idx \u003c len; idx++) {\n       DatanodeStorageInfo cur \u003d getStorageInfo(idx);\n       if(cur \u003d\u003d null)\n         break;\n       if(cur.getDatanodeDescriptor() \u003d\u003d dn)\n-        return idx;\n+        return cur;\n     }\n-    return -1;\n+    return null;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  DatanodeStorageInfo findStorageInfo(DatanodeDescriptor dn) {\n    int len \u003d getCapacity();\n    for(int idx \u003d 0; idx \u003c len; idx++) {\n      DatanodeStorageInfo cur \u003d getStorageInfo(idx);\n      if(cur \u003d\u003d null)\n        break;\n      if(cur.getDatanodeDescriptor() \u003d\u003d dn)\n        return cur;\n    }\n    return null;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfo.java",
          "extendedDetails": {}
        }
      ]
    }
  }
}