{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "HttpFSFileSystem.java",
  "functionName": "getXAttrs",
  "functionId": "getXAttrs___f-Path__names-List__String__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-httpfs/src/main/java/org/apache/hadoop/fs/http/client/HttpFSFileSystem.java",
  "functionStartLine": 1390,
  "functionEndLine": 1403,
  "numCommitsSeen": 51,
  "timeTaken": 1736,
  "changeHistory": [
    "70b218748badf079c859c3af2b468a0b7b49c333",
    "46162a213f60f915df76c60b0412f45a021e1e7e"
  ],
  "changeHistoryShort": {
    "70b218748badf079c859c3af2b468a0b7b49c333": "Ybodychange",
    "46162a213f60f915df76c60b0412f45a021e1e7e": "Yintroduced"
  },
  "changeHistoryDetails": {
    "70b218748badf079c859c3af2b468a0b7b49c333": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-11015. Http server/client utils to propagate and recreate Exceptions from server to client. (tucu)\n",
      "commitDate": "04/09/14 9:11 AM",
      "commitName": "70b218748badf079c859c3af2b468a0b7b49c333",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "07/08/14 9:58 PM",
      "commitNameOld": "be9c67930b57c516723d566625f9036a88a84055",
      "commitAuthorOld": "Alejandro Abdelnur",
      "daysBetweenCommits": 27.47,
      "commitsBetweenForRepo": 206,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,14 @@\n   public Map\u003cString, byte[]\u003e getXAttrs(Path f, List\u003cString\u003e names)\n       throws IOException {\n     Preconditions.checkArgument(names !\u003d null \u0026\u0026 !names.isEmpty(), \n         \"XAttr names cannot be null or empty.\");\n     Map\u003cString, String\u003e params \u003d new HashMap\u003cString, String\u003e();\n     params.put(OP_PARAM, Operation.GETXATTRS.toString());\n     Map\u003cString, List\u003cString\u003e\u003e multiValuedParams \u003d Maps.newHashMap();\n     multiValuedParams.put(XATTR_NAME_PARAM, names);\n     HttpURLConnection conn \u003d getConnection(Operation.GETXATTRS.getMethod(),\n         params, multiValuedParams, f, true);\n-    HttpFSUtils.validateResponse(conn, HttpURLConnection.HTTP_OK);\n+    HttpExceptionUtils.validateResponse(conn, HttpURLConnection.HTTP_OK);\n     JSONObject json \u003d (JSONObject) HttpFSUtils.jsonParse(conn);\n     return createXAttrMap((JSONArray) json.get(XATTRS_JSON));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public Map\u003cString, byte[]\u003e getXAttrs(Path f, List\u003cString\u003e names)\n      throws IOException {\n    Preconditions.checkArgument(names !\u003d null \u0026\u0026 !names.isEmpty(), \n        \"XAttr names cannot be null or empty.\");\n    Map\u003cString, String\u003e params \u003d new HashMap\u003cString, String\u003e();\n    params.put(OP_PARAM, Operation.GETXATTRS.toString());\n    Map\u003cString, List\u003cString\u003e\u003e multiValuedParams \u003d Maps.newHashMap();\n    multiValuedParams.put(XATTR_NAME_PARAM, names);\n    HttpURLConnection conn \u003d getConnection(Operation.GETXATTRS.getMethod(),\n        params, multiValuedParams, f, true);\n    HttpExceptionUtils.validateResponse(conn, HttpURLConnection.HTTP_OK);\n    JSONObject json \u003d (JSONObject) HttpFSUtils.jsonParse(conn);\n    return createXAttrMap((JSONArray) json.get(XATTRS_JSON));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-httpfs/src/main/java/org/apache/hadoop/fs/http/client/HttpFSFileSystem.java",
      "extendedDetails": {}
    },
    "46162a213f60f915df76c60b0412f45a021e1e7e": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-6430. HTTPFS - Implement XAttr support. (Yi Liu via tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1605118 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/06/14 8:59 AM",
      "commitName": "46162a213f60f915df76c60b0412f45a021e1e7e",
      "commitAuthor": "Alejandro Abdelnur",
      "diff": "@@ -0,0 +1,14 @@\n+  public Map\u003cString, byte[]\u003e getXAttrs(Path f, List\u003cString\u003e names)\n+      throws IOException {\n+    Preconditions.checkArgument(names !\u003d null \u0026\u0026 !names.isEmpty(), \n+        \"XAttr names cannot be null or empty.\");\n+    Map\u003cString, String\u003e params \u003d new HashMap\u003cString, String\u003e();\n+    params.put(OP_PARAM, Operation.GETXATTRS.toString());\n+    Map\u003cString, List\u003cString\u003e\u003e multiValuedParams \u003d Maps.newHashMap();\n+    multiValuedParams.put(XATTR_NAME_PARAM, names);\n+    HttpURLConnection conn \u003d getConnection(Operation.GETXATTRS.getMethod(),\n+        params, multiValuedParams, f, true);\n+    HttpFSUtils.validateResponse(conn, HttpURLConnection.HTTP_OK);\n+    JSONObject json \u003d (JSONObject) HttpFSUtils.jsonParse(conn);\n+    return createXAttrMap((JSONArray) json.get(XATTRS_JSON));\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public Map\u003cString, byte[]\u003e getXAttrs(Path f, List\u003cString\u003e names)\n      throws IOException {\n    Preconditions.checkArgument(names !\u003d null \u0026\u0026 !names.isEmpty(), \n        \"XAttr names cannot be null or empty.\");\n    Map\u003cString, String\u003e params \u003d new HashMap\u003cString, String\u003e();\n    params.put(OP_PARAM, Operation.GETXATTRS.toString());\n    Map\u003cString, List\u003cString\u003e\u003e multiValuedParams \u003d Maps.newHashMap();\n    multiValuedParams.put(XATTR_NAME_PARAM, names);\n    HttpURLConnection conn \u003d getConnection(Operation.GETXATTRS.getMethod(),\n        params, multiValuedParams, f, true);\n    HttpFSUtils.validateResponse(conn, HttpURLConnection.HTTP_OK);\n    JSONObject json \u003d (JSONObject) HttpFSUtils.jsonParse(conn);\n    return createXAttrMap((JSONArray) json.get(XATTRS_JSON));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-httpfs/src/main/java/org/apache/hadoop/fs/http/client/HttpFSFileSystem.java"
    }
  }
}