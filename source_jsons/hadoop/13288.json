{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DatanodeManager.java",
  "functionName": "addDatanode",
  "functionId": "addDatanode___node-DatanodeDescriptor(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
  "functionStartLine": 802,
  "functionEndLine": 819,
  "numCommitsSeen": 184,
  "timeTaken": 5733,
  "changeHistory": [
    "fde8ac5d8514f5146f438f8d0794116aaef20416",
    "8602692338d6f493647205e0241e4116211fab75",
    "12b5b06c063d93e6c683c9b6fac9a96912f59e59",
    "4551da302d94cffea0313eac79479ab6f9b7cb34",
    "64741f46352f25743bfb77f804a06970d355a177",
    "8acfa66897dc23138f4b0aa41852f50a44407664",
    "5b0187dcd3dee773f58791ff75213bf71527fdb3",
    "27d068b68451d1aebdc4d29ca384e7d8fcd3830b",
    "4f230adc13c70b09083a928b9dc65fa404e6d177",
    "be7dd8333a7e56e732171db0781786987de03195",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "969a263188f7015261719fe45fa1505121ebb80e",
    "233a7aa34f37350bf7bcdd9c84b97d613e7344c9",
    "c3f6575ca44e8ad803d0b46991472465b595cdeb",
    "8327e70be87990c37ac14dcc1cb1a4d209c65593"
  ],
  "changeHistoryShort": {
    "fde8ac5d8514f5146f438f8d0794116aaef20416": "Ybodychange",
    "8602692338d6f493647205e0241e4116211fab75": "Ybodychange",
    "12b5b06c063d93e6c683c9b6fac9a96912f59e59": "Ybodychange",
    "4551da302d94cffea0313eac79479ab6f9b7cb34": "Ybodychange",
    "64741f46352f25743bfb77f804a06970d355a177": "Ybodychange",
    "8acfa66897dc23138f4b0aa41852f50a44407664": "Ymodifierchange",
    "5b0187dcd3dee773f58791ff75213bf71527fdb3": "Ymodifierchange",
    "27d068b68451d1aebdc4d29ca384e7d8fcd3830b": "Ymodifierchange",
    "4f230adc13c70b09083a928b9dc65fa404e6d177": "Ybodychange",
    "be7dd8333a7e56e732171db0781786987de03195": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "969a263188f7015261719fe45fa1505121ebb80e": "Ybodychange",
    "233a7aa34f37350bf7bcdd9c84b97d613e7344c9": "Ymodifierchange",
    "c3f6575ca44e8ad803d0b46991472465b595cdeb": "Ybodychange",
    "8327e70be87990c37ac14dcc1cb1a4d209c65593": "Yintroduced"
  },
  "changeHistoryDetails": {
    "fde8ac5d8514f5146f438f8d0794116aaef20416": {
      "type": "Ybodychange",
      "commitMessage": "Add missing files from HDFS-9005. (lei)\n",
      "commitDate": "25/03/16 5:11 PM",
      "commitName": "fde8ac5d8514f5146f438f8d0794116aaef20416",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "10/03/16 7:03 PM",
      "commitNameOld": "e01c6ea688e62f25c4310e771a0cd85b53a5fb87",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 14.88,
      "commitsBetweenForRepo": 69,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,18 @@\n   void addDatanode(final DatanodeDescriptor node) {\n     // To keep host2DatanodeMap consistent with datanodeMap,\n     // remove  from host2DatanodeMap the datanodeDescriptor removed\n     // from datanodeMap before adding node to host2DatanodeMap.\n     synchronized(this) {\n       host2DatanodeMap.remove(datanodeMap.put(node.getDatanodeUuid(), node));\n     }\n \n     networktopology.add(node); // may throw InvalidTopologyException\n     host2DatanodeMap.add(node);\n     checkIfClusterIsNowMultiRack(node);\n+    resolveUpgradeDomain(node);\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(getClass().getSimpleName() + \".addDatanode: \"\n           + \"node \" + node + \" is added to datanodeMap.\");\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void addDatanode(final DatanodeDescriptor node) {\n    // To keep host2DatanodeMap consistent with datanodeMap,\n    // remove  from host2DatanodeMap the datanodeDescriptor removed\n    // from datanodeMap before adding node to host2DatanodeMap.\n    synchronized(this) {\n      host2DatanodeMap.remove(datanodeMap.put(node.getDatanodeUuid(), node));\n    }\n\n    networktopology.add(node); // may throw InvalidTopologyException\n    host2DatanodeMap.add(node);\n    checkIfClusterIsNowMultiRack(node);\n    resolveUpgradeDomain(node);\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(getClass().getSimpleName() + \".addDatanode: \"\n          + \"node \" + node + \" is added to datanodeMap.\");\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "8602692338d6f493647205e0241e4116211fab75": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9371. Code cleanup for DatanodeManager. Contributed by Jing Zhao.\n",
      "commitDate": "15/12/15 10:47 AM",
      "commitName": "8602692338d6f493647205e0241e4116211fab75",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "01/12/15 4:09 PM",
      "commitNameOld": "a49cc74b4c72195dee1dfb6f9548e5e411dff553",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 13.78,
      "commitsBetweenForRepo": 73,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,17 @@\n   void addDatanode(final DatanodeDescriptor node) {\n     // To keep host2DatanodeMap consistent with datanodeMap,\n     // remove  from host2DatanodeMap the datanodeDescriptor removed\n     // from datanodeMap before adding node to host2DatanodeMap.\n-    synchronized(datanodeMap) {\n+    synchronized(this) {\n       host2DatanodeMap.remove(datanodeMap.put(node.getDatanodeUuid(), node));\n     }\n \n     networktopology.add(node); // may throw InvalidTopologyException\n     host2DatanodeMap.add(node);\n     checkIfClusterIsNowMultiRack(node);\n-    blockManager.getBlockReportLeaseManager().register(node);\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(getClass().getSimpleName() + \".addDatanode: \"\n           + \"node \" + node + \" is added to datanodeMap.\");\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void addDatanode(final DatanodeDescriptor node) {\n    // To keep host2DatanodeMap consistent with datanodeMap,\n    // remove  from host2DatanodeMap the datanodeDescriptor removed\n    // from datanodeMap before adding node to host2DatanodeMap.\n    synchronized(this) {\n      host2DatanodeMap.remove(datanodeMap.put(node.getDatanodeUuid(), node));\n    }\n\n    networktopology.add(node); // may throw InvalidTopologyException\n    host2DatanodeMap.add(node);\n    checkIfClusterIsNowMultiRack(node);\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(getClass().getSimpleName() + \".addDatanode: \"\n          + \"node \" + node + \" is added to datanodeMap.\");\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "12b5b06c063d93e6c683c9b6fac9a96912f59e59": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7923. The DataNodes should rate-limit their full block reports by asking the NN on heartbeat messages (cmccabe)\n",
      "commitDate": "12/06/15 11:17 AM",
      "commitName": "12b5b06c063d93e6c683c9b6fac9a96912f59e59",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "19/05/15 10:50 AM",
      "commitNameOld": "470c87dbc6c24dd3b370f1ad9e7ab1f6dabd2080",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 24.02,
      "commitsBetweenForRepo": 173,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,18 @@\n   void addDatanode(final DatanodeDescriptor node) {\n     // To keep host2DatanodeMap consistent with datanodeMap,\n     // remove  from host2DatanodeMap the datanodeDescriptor removed\n     // from datanodeMap before adding node to host2DatanodeMap.\n     synchronized(datanodeMap) {\n       host2DatanodeMap.remove(datanodeMap.put(node.getDatanodeUuid(), node));\n     }\n \n     networktopology.add(node); // may throw InvalidTopologyException\n     host2DatanodeMap.add(node);\n     checkIfClusterIsNowMultiRack(node);\n+    blockManager.getBlockReportLeaseManager().register(node);\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(getClass().getSimpleName() + \".addDatanode: \"\n           + \"node \" + node + \" is added to datanodeMap.\");\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void addDatanode(final DatanodeDescriptor node) {\n    // To keep host2DatanodeMap consistent with datanodeMap,\n    // remove  from host2DatanodeMap the datanodeDescriptor removed\n    // from datanodeMap before adding node to host2DatanodeMap.\n    synchronized(datanodeMap) {\n      host2DatanodeMap.remove(datanodeMap.put(node.getDatanodeUuid(), node));\n    }\n\n    networktopology.add(node); // may throw InvalidTopologyException\n    host2DatanodeMap.add(node);\n    checkIfClusterIsNowMultiRack(node);\n    blockManager.getBlockReportLeaseManager().register(node);\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(getClass().getSimpleName() + \".addDatanode: \"\n          + \"node \" + node + \" is added to datanodeMap.\");\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "4551da302d94cffea0313eac79479ab6f9b7cb34": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5233. Use Datanode UUID to identify Datanodes.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2832@1525407 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/09/13 11:03 AM",
      "commitName": "4551da302d94cffea0313eac79479ab6f9b7cb34",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "08/09/13 3:53 PM",
      "commitNameOld": "282be1b38e5cd141ed7e2b2194bfb67a7c2f7f15",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 13.8,
      "commitsBetweenForRepo": 61,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n   void addDatanode(final DatanodeDescriptor node) {\n     // To keep host2DatanodeMap consistent with datanodeMap,\n     // remove  from host2DatanodeMap the datanodeDescriptor removed\n     // from datanodeMap before adding node to host2DatanodeMap.\n     synchronized(datanodeMap) {\n-      host2DatanodeMap.remove(datanodeMap.put(node.getStorageID(), node));\n+      host2DatanodeMap.remove(datanodeMap.put(node.getDatanodeUuid(), node));\n     }\n \n     networktopology.add(node); // may throw InvalidTopologyException\n     host2DatanodeMap.add(node);\n     checkIfClusterIsNowMultiRack(node);\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(getClass().getSimpleName() + \".addDatanode: \"\n           + \"node \" + node + \" is added to datanodeMap.\");\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void addDatanode(final DatanodeDescriptor node) {\n    // To keep host2DatanodeMap consistent with datanodeMap,\n    // remove  from host2DatanodeMap the datanodeDescriptor removed\n    // from datanodeMap before adding node to host2DatanodeMap.\n    synchronized(datanodeMap) {\n      host2DatanodeMap.remove(datanodeMap.put(node.getDatanodeUuid(), node));\n    }\n\n    networktopology.add(node); // may throw InvalidTopologyException\n    host2DatanodeMap.add(node);\n    checkIfClusterIsNowMultiRack(node);\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(getClass().getSimpleName() + \".addDatanode: \"\n          + \"node \" + node + \" is added to datanodeMap.\");\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "64741f46352f25743bfb77f804a06970d355a177": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4521. Invalid network toploogies should not be cached. Contributed by Colin Patrick McCabe.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1457878 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/03/13 10:20 AM",
      "commitName": "64741f46352f25743bfb77f804a06970d355a177",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "04/02/13 8:07 PM",
      "commitNameOld": "ef8dd606aba790a097f499dcd3bd129d385a961f",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 41.55,
      "commitsBetweenForRepo": 176,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n   void addDatanode(final DatanodeDescriptor node) {\n     // To keep host2DatanodeMap consistent with datanodeMap,\n     // remove  from host2DatanodeMap the datanodeDescriptor removed\n     // from datanodeMap before adding node to host2DatanodeMap.\n     synchronized(datanodeMap) {\n       host2DatanodeMap.remove(datanodeMap.put(node.getStorageID(), node));\n     }\n \n+    networktopology.add(node); // may throw InvalidTopologyException\n     host2DatanodeMap.add(node);\n-    networktopology.add(node);\n     checkIfClusterIsNowMultiRack(node);\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(getClass().getSimpleName() + \".addDatanode: \"\n           + \"node \" + node + \" is added to datanodeMap.\");\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void addDatanode(final DatanodeDescriptor node) {\n    // To keep host2DatanodeMap consistent with datanodeMap,\n    // remove  from host2DatanodeMap the datanodeDescriptor removed\n    // from datanodeMap before adding node to host2DatanodeMap.\n    synchronized(datanodeMap) {\n      host2DatanodeMap.remove(datanodeMap.put(node.getStorageID(), node));\n    }\n\n    networktopology.add(node); // may throw InvalidTopologyException\n    host2DatanodeMap.add(node);\n    checkIfClusterIsNowMultiRack(node);\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(getClass().getSimpleName() + \".addDatanode: \"\n          + \"node \" + node + \" is added to datanodeMap.\");\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "8acfa66897dc23138f4b0aa41852f50a44407664": {
      "type": "Ymodifierchange",
      "commitMessage": "HDFS-4288. NN accepts incremental BR as IBR in safemode. contributed by Daryn Sharp.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1440192 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/01/13 2:44 PM",
      "commitName": "8acfa66897dc23138f4b0aa41852f50a44407664",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "15/01/13 8:22 PM",
      "commitNameOld": "5b0187dcd3dee773f58791ff75213bf71527fdb3",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 13.77,
      "commitsBetweenForRepo": 53,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n-  private void addDatanode(final DatanodeDescriptor node) {\n+  void addDatanode(final DatanodeDescriptor node) {\n     // To keep host2DatanodeMap consistent with datanodeMap,\n     // remove  from host2DatanodeMap the datanodeDescriptor removed\n     // from datanodeMap before adding node to host2DatanodeMap.\n     synchronized(datanodeMap) {\n       host2DatanodeMap.remove(datanodeMap.put(node.getStorageID(), node));\n     }\n \n     host2DatanodeMap.add(node);\n     networktopology.add(node);\n     checkIfClusterIsNowMultiRack(node);\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(getClass().getSimpleName() + \".addDatanode: \"\n           + \"node \" + node + \" is added to datanodeMap.\");\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void addDatanode(final DatanodeDescriptor node) {\n    // To keep host2DatanodeMap consistent with datanodeMap,\n    // remove  from host2DatanodeMap the datanodeDescriptor removed\n    // from datanodeMap before adding node to host2DatanodeMap.\n    synchronized(datanodeMap) {\n      host2DatanodeMap.remove(datanodeMap.put(node.getStorageID(), node));\n    }\n\n    host2DatanodeMap.add(node);\n    networktopology.add(node);\n    checkIfClusterIsNowMultiRack(node);\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(getClass().getSimpleName() + \".addDatanode: \"\n          + \"node \" + node + \" is added to datanodeMap.\");\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {
        "oldValue": "[private]",
        "newValue": "[]"
      }
    },
    "5b0187dcd3dee773f58791ff75213bf71527fdb3": {
      "type": "Ymodifierchange",
      "commitMessage": "Revert r1433755: HDFS-4288. NN accepts incremental BR as IBR in safemode. Contributed by Daryn Sharp.\n\nThis commit caused TestBlockManager to fail.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1433820 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "15/01/13 8:22 PM",
      "commitName": "5b0187dcd3dee773f58791ff75213bf71527fdb3",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "15/01/13 4:09 PM",
      "commitNameOld": "27d068b68451d1aebdc4d29ca384e7d8fcd3830b",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.18,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n-  void addDatanode(final DatanodeDescriptor node) {\n+  private void addDatanode(final DatanodeDescriptor node) {\n     // To keep host2DatanodeMap consistent with datanodeMap,\n     // remove  from host2DatanodeMap the datanodeDescriptor removed\n     // from datanodeMap before adding node to host2DatanodeMap.\n     synchronized(datanodeMap) {\n       host2DatanodeMap.remove(datanodeMap.put(node.getStorageID(), node));\n     }\n \n     host2DatanodeMap.add(node);\n     networktopology.add(node);\n     checkIfClusterIsNowMultiRack(node);\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(getClass().getSimpleName() + \".addDatanode: \"\n           + \"node \" + node + \" is added to datanodeMap.\");\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void addDatanode(final DatanodeDescriptor node) {\n    // To keep host2DatanodeMap consistent with datanodeMap,\n    // remove  from host2DatanodeMap the datanodeDescriptor removed\n    // from datanodeMap before adding node to host2DatanodeMap.\n    synchronized(datanodeMap) {\n      host2DatanodeMap.remove(datanodeMap.put(node.getStorageID(), node));\n    }\n\n    host2DatanodeMap.add(node);\n    networktopology.add(node);\n    checkIfClusterIsNowMultiRack(node);\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(getClass().getSimpleName() + \".addDatanode: \"\n          + \"node \" + node + \" is added to datanodeMap.\");\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {
        "oldValue": "[]",
        "newValue": "[private]"
      }
    },
    "27d068b68451d1aebdc4d29ca384e7d8fcd3830b": {
      "type": "Ymodifierchange",
      "commitMessage": "HDFS-4288. NN accepts incremental BR as IBR in safemode. Contributed by Daryn Sharp.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1433755 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "15/01/13 4:09 PM",
      "commitName": "27d068b68451d1aebdc4d29ca384e7d8fcd3830b",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "11/12/12 4:14 PM",
      "commitNameOld": "f31b8270db0dd1a4670ce6e921df18725d7a9248",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 35.0,
      "commitsBetweenForRepo": 162,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n-  private void addDatanode(final DatanodeDescriptor node) {\n+  void addDatanode(final DatanodeDescriptor node) {\n     // To keep host2DatanodeMap consistent with datanodeMap,\n     // remove  from host2DatanodeMap the datanodeDescriptor removed\n     // from datanodeMap before adding node to host2DatanodeMap.\n     synchronized(datanodeMap) {\n       host2DatanodeMap.remove(datanodeMap.put(node.getStorageID(), node));\n     }\n \n     host2DatanodeMap.add(node);\n     networktopology.add(node);\n     checkIfClusterIsNowMultiRack(node);\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(getClass().getSimpleName() + \".addDatanode: \"\n           + \"node \" + node + \" is added to datanodeMap.\");\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void addDatanode(final DatanodeDescriptor node) {\n    // To keep host2DatanodeMap consistent with datanodeMap,\n    // remove  from host2DatanodeMap the datanodeDescriptor removed\n    // from datanodeMap before adding node to host2DatanodeMap.\n    synchronized(datanodeMap) {\n      host2DatanodeMap.remove(datanodeMap.put(node.getStorageID(), node));\n    }\n\n    host2DatanodeMap.add(node);\n    networktopology.add(node);\n    checkIfClusterIsNowMultiRack(node);\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(getClass().getSimpleName() + \".addDatanode: \"\n          + \"node \" + node + \" is added to datanodeMap.\");\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {
        "oldValue": "[private]",
        "newValue": "[]"
      }
    },
    "4f230adc13c70b09083a928b9dc65fa404e6d177": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3256. HDFS considers blocks under-replicated if topology script is configured with only 1 rack. Contributed by Aaron T. Myers.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1325531 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/04/12 2:28 PM",
      "commitName": "4f230adc13c70b09083a928b9dc65fa404e6d177",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "05/04/12 5:20 PM",
      "commitNameOld": "e505b7e704ff83893a40190695977ce1393f6248",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 6.88,
      "commitsBetweenForRepo": 64,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,17 @@\n   private void addDatanode(final DatanodeDescriptor node) {\n     // To keep host2DatanodeMap consistent with datanodeMap,\n     // remove  from host2DatanodeMap the datanodeDescriptor removed\n     // from datanodeMap before adding node to host2DatanodeMap.\n     synchronized(datanodeMap) {\n       host2DatanodeMap.remove(datanodeMap.put(node.getStorageID(), node));\n     }\n \n     host2DatanodeMap.add(node);\n     networktopology.add(node);\n+    checkIfClusterIsNowMultiRack(node);\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(getClass().getSimpleName() + \".addDatanode: \"\n           + \"node \" + node + \" is added to datanodeMap.\");\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void addDatanode(final DatanodeDescriptor node) {\n    // To keep host2DatanodeMap consistent with datanodeMap,\n    // remove  from host2DatanodeMap the datanodeDescriptor removed\n    // from datanodeMap before adding node to host2DatanodeMap.\n    synchronized(datanodeMap) {\n      host2DatanodeMap.remove(datanodeMap.put(node.getStorageID(), node));\n    }\n\n    host2DatanodeMap.add(node);\n    networktopology.add(node);\n    checkIfClusterIsNowMultiRack(node);\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(getClass().getSimpleName() + \".addDatanode: \"\n          + \"node \" + node + \" is added to datanodeMap.\");\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "be7dd8333a7e56e732171db0781786987de03195": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3144. Refactor DatanodeID#getName by use. Contributed by Eli Collins\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1308205 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "01/04/12 3:12 PM",
      "commitName": "be7dd8333a7e56e732171db0781786987de03195",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "31/03/12 8:41 PM",
      "commitNameOld": "0663dbaac0a19719ddf9cd4290ba893bfca69da2",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 0.77,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,16 @@\n   private void addDatanode(final DatanodeDescriptor node) {\n     // To keep host2DatanodeMap consistent with datanodeMap,\n     // remove  from host2DatanodeMap the datanodeDescriptor removed\n     // from datanodeMap before adding node to host2DatanodeMap.\n     synchronized(datanodeMap) {\n       host2DatanodeMap.remove(datanodeMap.put(node.getStorageID(), node));\n     }\n \n     host2DatanodeMap.add(node);\n     networktopology.add(node);\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(getClass().getSimpleName() + \".addDatanode: \"\n-          + \"node \" + node.getName() + \" is added to datanodeMap.\");\n+          + \"node \" + node + \" is added to datanodeMap.\");\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void addDatanode(final DatanodeDescriptor node) {\n    // To keep host2DatanodeMap consistent with datanodeMap,\n    // remove  from host2DatanodeMap the datanodeDescriptor removed\n    // from datanodeMap before adding node to host2DatanodeMap.\n    synchronized(datanodeMap) {\n      host2DatanodeMap.remove(datanodeMap.put(node.getStorageID(), node));\n    }\n\n    host2DatanodeMap.add(node);\n    networktopology.add(node);\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(getClass().getSimpleName() + \".addDatanode: \"\n          + \"node \" + node + \" is added to datanodeMap.\");\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void addDatanode(final DatanodeDescriptor node) {\n    // To keep host2DatanodeMap consistent with datanodeMap,\n    // remove  from host2DatanodeMap the datanodeDescriptor removed\n    // from datanodeMap before adding node to host2DatanodeMap.\n    synchronized(datanodeMap) {\n      host2DatanodeMap.remove(datanodeMap.put(node.getStorageID(), node));\n    }\n\n    host2DatanodeMap.add(node);\n    networktopology.add(node);\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(getClass().getSimpleName() + \".addDatanode: \"\n          + \"node \" + node.getName() + \" is added to datanodeMap.\");\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void addDatanode(final DatanodeDescriptor node) {\n    // To keep host2DatanodeMap consistent with datanodeMap,\n    // remove  from host2DatanodeMap the datanodeDescriptor removed\n    // from datanodeMap before adding node to host2DatanodeMap.\n    synchronized(datanodeMap) {\n      host2DatanodeMap.remove(datanodeMap.put(node.getStorageID(), node));\n    }\n\n    host2DatanodeMap.add(node);\n    networktopology.add(node);\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(getClass().getSimpleName() + \".addDatanode: \"\n          + \"node \" + node.getName() + \" is added to datanodeMap.\");\n    }\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java"
      }
    },
    "969a263188f7015261719fe45fa1505121ebb80e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2191.  Move datanodeMap from FSNamesystem to DatanodeManager.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1151339 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/07/11 10:46 PM",
      "commitName": "969a263188f7015261719fe45fa1505121ebb80e",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "21/07/11 9:20 PM",
      "commitNameOld": "233a7aa34f37350bf7bcdd9c84b97d613e7344c9",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 5.06,
      "commitsBetweenForRepo": 16,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,16 @@\n   private void addDatanode(final DatanodeDescriptor node) {\n     // To keep host2DatanodeMap consistent with datanodeMap,\n     // remove  from host2DatanodeMap the datanodeDescriptor removed\n     // from datanodeMap before adding node to host2DatanodeMap.\n-    synchronized (namesystem.datanodeMap) {\n-      host2DatanodeMap.remove(\n-          namesystem.datanodeMap.put(node.getStorageID(), node));\n+    synchronized(datanodeMap) {\n+      host2DatanodeMap.remove(datanodeMap.put(node.getStorageID(), node));\n     }\n \n     host2DatanodeMap.add(node);\n     networktopology.add(node);\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(getClass().getSimpleName() + \".addDatanode: \"\n           + \"node \" + node.getName() + \" is added to datanodeMap.\");\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void addDatanode(final DatanodeDescriptor node) {\n    // To keep host2DatanodeMap consistent with datanodeMap,\n    // remove  from host2DatanodeMap the datanodeDescriptor removed\n    // from datanodeMap before adding node to host2DatanodeMap.\n    synchronized(datanodeMap) {\n      host2DatanodeMap.remove(datanodeMap.put(node.getStorageID(), node));\n    }\n\n    host2DatanodeMap.add(node);\n    networktopology.add(node);\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(getClass().getSimpleName() + \".addDatanode: \"\n          + \"node \" + node.getName() + \" is added to datanodeMap.\");\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "233a7aa34f37350bf7bcdd9c84b97d613e7344c9": {
      "type": "Ymodifierchange",
      "commitMessage": "HDFS-2167.  Move dnsToSwitchMapping and hostsReader from FSNamesystem to DatanodeManager.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1149455 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/07/11 9:20 PM",
      "commitName": "233a7aa34f37350bf7bcdd9c84b97d613e7344c9",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "18/07/11 5:26 PM",
      "commitNameOld": "c3f6575ca44e8ad803d0b46991472465b595cdeb",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 3.16,
      "commitsBetweenForRepo": 12,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n-  public void addDatanode(final DatanodeDescriptor node) {\n+  private void addDatanode(final DatanodeDescriptor node) {\n     // To keep host2DatanodeMap consistent with datanodeMap,\n     // remove  from host2DatanodeMap the datanodeDescriptor removed\n     // from datanodeMap before adding node to host2DatanodeMap.\n     synchronized (namesystem.datanodeMap) {\n       host2DatanodeMap.remove(\n           namesystem.datanodeMap.put(node.getStorageID(), node));\n     }\n \n     host2DatanodeMap.add(node);\n     networktopology.add(node);\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(getClass().getSimpleName() + \".addDatanode: \"\n           + \"node \" + node.getName() + \" is added to datanodeMap.\");\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void addDatanode(final DatanodeDescriptor node) {\n    // To keep host2DatanodeMap consistent with datanodeMap,\n    // remove  from host2DatanodeMap the datanodeDescriptor removed\n    // from datanodeMap before adding node to host2DatanodeMap.\n    synchronized (namesystem.datanodeMap) {\n      host2DatanodeMap.remove(\n          namesystem.datanodeMap.put(node.getStorageID(), node));\n    }\n\n    host2DatanodeMap.add(node);\n    networktopology.add(node);\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(getClass().getSimpleName() + \".addDatanode: \"\n          + \"node \" + node.getName() + \" is added to datanodeMap.\");\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {
        "oldValue": "[public]",
        "newValue": "[private]"
      }
    },
    "c3f6575ca44e8ad803d0b46991472465b595cdeb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2147. Move cluster network topology to block management and fix some javac warnings.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1148112 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/07/11 5:26 PM",
      "commitName": "c3f6575ca44e8ad803d0b46991472465b595cdeb",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "13/07/11 4:24 PM",
      "commitNameOld": "8327e70be87990c37ac14dcc1cb1a4d209c65593",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 5.04,
      "commitsBetweenForRepo": 17,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,17 @@\n   public void addDatanode(final DatanodeDescriptor node) {\n     // To keep host2DatanodeMap consistent with datanodeMap,\n     // remove  from host2DatanodeMap the datanodeDescriptor removed\n     // from datanodeMap before adding node to host2DatanodeMap.\n     synchronized (namesystem.datanodeMap) {\n       host2DatanodeMap.remove(\n           namesystem.datanodeMap.put(node.getStorageID(), node));\n     }\n+\n     host2DatanodeMap.add(node);\n+    networktopology.add(node);\n \n     if (LOG.isDebugEnabled()) {\n-      LOG.debug(getClass().getSimpleName() + \".unprotectedAddDatanode: \"\n+      LOG.debug(getClass().getSimpleName() + \".addDatanode: \"\n           + \"node \" + node.getName() + \" is added to datanodeMap.\");\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void addDatanode(final DatanodeDescriptor node) {\n    // To keep host2DatanodeMap consistent with datanodeMap,\n    // remove  from host2DatanodeMap the datanodeDescriptor removed\n    // from datanodeMap before adding node to host2DatanodeMap.\n    synchronized (namesystem.datanodeMap) {\n      host2DatanodeMap.remove(\n          namesystem.datanodeMap.put(node.getStorageID(), node));\n    }\n\n    host2DatanodeMap.add(node);\n    networktopology.add(node);\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(getClass().getSimpleName() + \".addDatanode: \"\n          + \"node \" + node.getName() + \" is added to datanodeMap.\");\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "8327e70be87990c37ac14dcc1cb1a4d209c65593": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-2140. Move Host2NodesMap to the blockmanagement package.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1146514 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/07/11 4:24 PM",
      "commitName": "8327e70be87990c37ac14dcc1cb1a4d209c65593",
      "commitAuthor": "Tsz-wo Sze",
      "diff": "@@ -0,0 +1,15 @@\n+  public void addDatanode(final DatanodeDescriptor node) {\n+    // To keep host2DatanodeMap consistent with datanodeMap,\n+    // remove  from host2DatanodeMap the datanodeDescriptor removed\n+    // from datanodeMap before adding node to host2DatanodeMap.\n+    synchronized (namesystem.datanodeMap) {\n+      host2DatanodeMap.remove(\n+          namesystem.datanodeMap.put(node.getStorageID(), node));\n+    }\n+    host2DatanodeMap.add(node);\n+\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(getClass().getSimpleName() + \".unprotectedAddDatanode: \"\n+          + \"node \" + node.getName() + \" is added to datanodeMap.\");\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void addDatanode(final DatanodeDescriptor node) {\n    // To keep host2DatanodeMap consistent with datanodeMap,\n    // remove  from host2DatanodeMap the datanodeDescriptor removed\n    // from datanodeMap before adding node to host2DatanodeMap.\n    synchronized (namesystem.datanodeMap) {\n      host2DatanodeMap.remove(\n          namesystem.datanodeMap.put(node.getStorageID(), node));\n    }\n    host2DatanodeMap.add(node);\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(getClass().getSimpleName() + \".unprotectedAddDatanode: \"\n          + \"node \" + node.getName() + \" is added to datanodeMap.\");\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java"
    }
  }
}