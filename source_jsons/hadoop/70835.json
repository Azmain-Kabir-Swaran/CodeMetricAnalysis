{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "PageBlobOutputStream.java",
  "functionName": "runInternal",
  "functionId": "runInternal",
  "sourceFilePath": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/PageBlobOutputStream.java",
  "functionStartLine": 278,
  "functionEndLine": 360,
  "numCommitsSeen": 8,
  "timeTaken": 1178,
  "changeHistory": [
    "f4b7e99f4ebac5b0295b7f7f42eb5705af41f079",
    "2217e2f8ff418b88eac6ad36cafe3a9795a11f40"
  ],
  "changeHistoryShort": {
    "f4b7e99f4ebac5b0295b7f7f42eb5705af41f079": "Ybodychange",
    "2217e2f8ff418b88eac6ad36cafe3a9795a11f40": "Yintroduced"
  },
  "changeHistoryDetails": {
    "f4b7e99f4ebac5b0295b7f7f42eb5705af41f079": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-11188. hadoop-azure: automatically expand page blobs when they become full. Contributed by Eric Hanson.\n",
      "commitDate": "10/10/14 3:05 PM",
      "commitName": "f4b7e99f4ebac5b0295b7f7f42eb5705af41f079",
      "commitAuthor": "cnauroth",
      "commitDateOld": "08/10/14 2:20 PM",
      "commitNameOld": "2217e2f8ff418b88eac6ad36cafe3a9795a11f40",
      "commitAuthorOld": "cnauroth",
      "daysBetweenCommits": 2.03,
      "commitsBetweenForRepo": 27,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,77 +1,83 @@\n     private void runInternal() {\n       if (lastError !\u003d null) {\n         // We\u0027re already in an error state, no point doing anything.\n         return;\n       }\n       if (dataPayload.length \u003d\u003d 0) {\n         // Nothing to do.\n         return;\n       }\n \n       // Since we have to rewrite the last request\u0027s last page\u0027s data\n       // (may be empty), total data size is our data plus whatever was\n       // left from there.\n       final int totalDataBytes \u003d dataPayload.length \n           + previousLastPageDataWritten.length;\n       // Calculate the total number of pages we\u0027re writing to the server.\n       final int numberOfPages \u003d (totalDataBytes / PAGE_DATA_SIZE) \n           + (totalDataBytes % PAGE_DATA_SIZE \u003d\u003d 0 ? 0 : 1);\n       // Fill up the raw bytes we\u0027re writing.\n       byte[] rawPayload \u003d new byte[numberOfPages * PAGE_SIZE];\n       // Keep track of the size of the last page we uploaded.\n       int currentLastPageDataSize \u003d -1;\n       for (int page \u003d 0; page \u003c numberOfPages; page++) {\n         // Our current byte offset in the data.\n         int dataOffset \u003d page * PAGE_DATA_SIZE;\n         // Our current byte offset in the raw buffer.\n         int rawOffset \u003d page * PAGE_SIZE;\n         // The size of the data in the current page.\n         final short currentPageDataSize \u003d (short) Math.min(PAGE_DATA_SIZE,\n             totalDataBytes - dataOffset);\n         // Save off this page\u0027s size as the potential last page\u0027s size.\n         currentLastPageDataSize \u003d currentPageDataSize;\n \n         // Write out the page size in the header.\n         final byte[] header \u003d fromShort(currentPageDataSize);\n         System.arraycopy(header, 0, rawPayload, rawOffset, header.length);\n         rawOffset +\u003d header.length;\n \n         int bytesToCopyFromDataPayload \u003d currentPageDataSize;\n         if (dataOffset \u003c previousLastPageDataWritten.length) {\n           // First write out the last page\u0027s data.\n           final int bytesToCopyFromLastPage \u003d Math.min(currentPageDataSize,\n               previousLastPageDataWritten.length - dataOffset);\n           System.arraycopy(previousLastPageDataWritten, dataOffset,\n               rawPayload, rawOffset, bytesToCopyFromLastPage);\n           bytesToCopyFromDataPayload -\u003d bytesToCopyFromLastPage;\n           rawOffset +\u003d bytesToCopyFromLastPage;\n           dataOffset +\u003d bytesToCopyFromLastPage;\n         }\n \n         if (dataOffset \u003e\u003d previousLastPageDataWritten.length) {\n           // Then write the current payload\u0027s data.\n           System.arraycopy(dataPayload, \n         \t  dataOffset - previousLastPageDataWritten.length,\n               rawPayload, rawOffset, bytesToCopyFromDataPayload);\n         }\n       }\n \n       // Raw payload constructed, ship it off to the server.\n       writePayloadToServer(rawPayload);\n \n       // Post-send bookkeeping.\n       currentBlobOffset +\u003d rawPayload.length;\n       if (currentLastPageDataSize \u003c PAGE_DATA_SIZE) {\n         // Partial page, save it off so it\u0027s overwritten in the next request.\n         final int startOffset \u003d (numberOfPages - 1) * PAGE_SIZE + PAGE_HEADER_SIZE;\n         previousLastPageDataWritten \u003d Arrays.copyOfRange(rawPayload,\n             startOffset,\n             startOffset + currentLastPageDataSize);\n         // Since we\u0027re rewriting this page, set our current offset in the server\n         // to that page\u0027s beginning.\n         currentBlobOffset -\u003d PAGE_SIZE;\n       } else {\n         // It wasn\u0027t a partial page, we won\u0027t need to rewrite it.\n         previousLastPageDataWritten \u003d new byte[0];\n       }\n+\n+      // Extend the file if we need more room in the file. This typically takes\n+      // less than 200 milliseconds if it has to actually be done,\n+      // so it is okay to include it in a write and won\u0027t cause a long pause.\n+      // Other writes can be queued behind this write in any case.\n+      conditionalExtendFile();\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void runInternal() {\n      if (lastError !\u003d null) {\n        // We\u0027re already in an error state, no point doing anything.\n        return;\n      }\n      if (dataPayload.length \u003d\u003d 0) {\n        // Nothing to do.\n        return;\n      }\n\n      // Since we have to rewrite the last request\u0027s last page\u0027s data\n      // (may be empty), total data size is our data plus whatever was\n      // left from there.\n      final int totalDataBytes \u003d dataPayload.length \n          + previousLastPageDataWritten.length;\n      // Calculate the total number of pages we\u0027re writing to the server.\n      final int numberOfPages \u003d (totalDataBytes / PAGE_DATA_SIZE) \n          + (totalDataBytes % PAGE_DATA_SIZE \u003d\u003d 0 ? 0 : 1);\n      // Fill up the raw bytes we\u0027re writing.\n      byte[] rawPayload \u003d new byte[numberOfPages * PAGE_SIZE];\n      // Keep track of the size of the last page we uploaded.\n      int currentLastPageDataSize \u003d -1;\n      for (int page \u003d 0; page \u003c numberOfPages; page++) {\n        // Our current byte offset in the data.\n        int dataOffset \u003d page * PAGE_DATA_SIZE;\n        // Our current byte offset in the raw buffer.\n        int rawOffset \u003d page * PAGE_SIZE;\n        // The size of the data in the current page.\n        final short currentPageDataSize \u003d (short) Math.min(PAGE_DATA_SIZE,\n            totalDataBytes - dataOffset);\n        // Save off this page\u0027s size as the potential last page\u0027s size.\n        currentLastPageDataSize \u003d currentPageDataSize;\n\n        // Write out the page size in the header.\n        final byte[] header \u003d fromShort(currentPageDataSize);\n        System.arraycopy(header, 0, rawPayload, rawOffset, header.length);\n        rawOffset +\u003d header.length;\n\n        int bytesToCopyFromDataPayload \u003d currentPageDataSize;\n        if (dataOffset \u003c previousLastPageDataWritten.length) {\n          // First write out the last page\u0027s data.\n          final int bytesToCopyFromLastPage \u003d Math.min(currentPageDataSize,\n              previousLastPageDataWritten.length - dataOffset);\n          System.arraycopy(previousLastPageDataWritten, dataOffset,\n              rawPayload, rawOffset, bytesToCopyFromLastPage);\n          bytesToCopyFromDataPayload -\u003d bytesToCopyFromLastPage;\n          rawOffset +\u003d bytesToCopyFromLastPage;\n          dataOffset +\u003d bytesToCopyFromLastPage;\n        }\n\n        if (dataOffset \u003e\u003d previousLastPageDataWritten.length) {\n          // Then write the current payload\u0027s data.\n          System.arraycopy(dataPayload, \n        \t  dataOffset - previousLastPageDataWritten.length,\n              rawPayload, rawOffset, bytesToCopyFromDataPayload);\n        }\n      }\n\n      // Raw payload constructed, ship it off to the server.\n      writePayloadToServer(rawPayload);\n\n      // Post-send bookkeeping.\n      currentBlobOffset +\u003d rawPayload.length;\n      if (currentLastPageDataSize \u003c PAGE_DATA_SIZE) {\n        // Partial page, save it off so it\u0027s overwritten in the next request.\n        final int startOffset \u003d (numberOfPages - 1) * PAGE_SIZE + PAGE_HEADER_SIZE;\n        previousLastPageDataWritten \u003d Arrays.copyOfRange(rawPayload,\n            startOffset,\n            startOffset + currentLastPageDataSize);\n        // Since we\u0027re rewriting this page, set our current offset in the server\n        // to that page\u0027s beginning.\n        currentBlobOffset -\u003d PAGE_SIZE;\n      } else {\n        // It wasn\u0027t a partial page, we won\u0027t need to rewrite it.\n        previousLastPageDataWritten \u003d new byte[0];\n      }\n\n      // Extend the file if we need more room in the file. This typically takes\n      // less than 200 milliseconds if it has to actually be done,\n      // so it is okay to include it in a write and won\u0027t cause a long pause.\n      // Other writes can be queued behind this write in any case.\n      conditionalExtendFile();\n    }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/PageBlobOutputStream.java",
      "extendedDetails": {}
    },
    "2217e2f8ff418b88eac6ad36cafe3a9795a11f40": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-10809. hadoop-azure: page blob support. Contributed by Dexter Bradshaw, Mostafa Elhemali, Eric Hanson, and Mike Liddell.\n",
      "commitDate": "08/10/14 2:20 PM",
      "commitName": "2217e2f8ff418b88eac6ad36cafe3a9795a11f40",
      "commitAuthor": "cnauroth",
      "diff": "@@ -0,0 +1,77 @@\n+    private void runInternal() {\n+      if (lastError !\u003d null) {\n+        // We\u0027re already in an error state, no point doing anything.\n+        return;\n+      }\n+      if (dataPayload.length \u003d\u003d 0) {\n+        // Nothing to do.\n+        return;\n+      }\n+\n+      // Since we have to rewrite the last request\u0027s last page\u0027s data\n+      // (may be empty), total data size is our data plus whatever was\n+      // left from there.\n+      final int totalDataBytes \u003d dataPayload.length \n+          + previousLastPageDataWritten.length;\n+      // Calculate the total number of pages we\u0027re writing to the server.\n+      final int numberOfPages \u003d (totalDataBytes / PAGE_DATA_SIZE) \n+          + (totalDataBytes % PAGE_DATA_SIZE \u003d\u003d 0 ? 0 : 1);\n+      // Fill up the raw bytes we\u0027re writing.\n+      byte[] rawPayload \u003d new byte[numberOfPages * PAGE_SIZE];\n+      // Keep track of the size of the last page we uploaded.\n+      int currentLastPageDataSize \u003d -1;\n+      for (int page \u003d 0; page \u003c numberOfPages; page++) {\n+        // Our current byte offset in the data.\n+        int dataOffset \u003d page * PAGE_DATA_SIZE;\n+        // Our current byte offset in the raw buffer.\n+        int rawOffset \u003d page * PAGE_SIZE;\n+        // The size of the data in the current page.\n+        final short currentPageDataSize \u003d (short) Math.min(PAGE_DATA_SIZE,\n+            totalDataBytes - dataOffset);\n+        // Save off this page\u0027s size as the potential last page\u0027s size.\n+        currentLastPageDataSize \u003d currentPageDataSize;\n+\n+        // Write out the page size in the header.\n+        final byte[] header \u003d fromShort(currentPageDataSize);\n+        System.arraycopy(header, 0, rawPayload, rawOffset, header.length);\n+        rawOffset +\u003d header.length;\n+\n+        int bytesToCopyFromDataPayload \u003d currentPageDataSize;\n+        if (dataOffset \u003c previousLastPageDataWritten.length) {\n+          // First write out the last page\u0027s data.\n+          final int bytesToCopyFromLastPage \u003d Math.min(currentPageDataSize,\n+              previousLastPageDataWritten.length - dataOffset);\n+          System.arraycopy(previousLastPageDataWritten, dataOffset,\n+              rawPayload, rawOffset, bytesToCopyFromLastPage);\n+          bytesToCopyFromDataPayload -\u003d bytesToCopyFromLastPage;\n+          rawOffset +\u003d bytesToCopyFromLastPage;\n+          dataOffset +\u003d bytesToCopyFromLastPage;\n+        }\n+\n+        if (dataOffset \u003e\u003d previousLastPageDataWritten.length) {\n+          // Then write the current payload\u0027s data.\n+          System.arraycopy(dataPayload, \n+        \t  dataOffset - previousLastPageDataWritten.length,\n+              rawPayload, rawOffset, bytesToCopyFromDataPayload);\n+        }\n+      }\n+\n+      // Raw payload constructed, ship it off to the server.\n+      writePayloadToServer(rawPayload);\n+\n+      // Post-send bookkeeping.\n+      currentBlobOffset +\u003d rawPayload.length;\n+      if (currentLastPageDataSize \u003c PAGE_DATA_SIZE) {\n+        // Partial page, save it off so it\u0027s overwritten in the next request.\n+        final int startOffset \u003d (numberOfPages - 1) * PAGE_SIZE + PAGE_HEADER_SIZE;\n+        previousLastPageDataWritten \u003d Arrays.copyOfRange(rawPayload,\n+            startOffset,\n+            startOffset + currentLastPageDataSize);\n+        // Since we\u0027re rewriting this page, set our current offset in the server\n+        // to that page\u0027s beginning.\n+        currentBlobOffset -\u003d PAGE_SIZE;\n+      } else {\n+        // It wasn\u0027t a partial page, we won\u0027t need to rewrite it.\n+        previousLastPageDataWritten \u003d new byte[0];\n+      }\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    private void runInternal() {\n      if (lastError !\u003d null) {\n        // We\u0027re already in an error state, no point doing anything.\n        return;\n      }\n      if (dataPayload.length \u003d\u003d 0) {\n        // Nothing to do.\n        return;\n      }\n\n      // Since we have to rewrite the last request\u0027s last page\u0027s data\n      // (may be empty), total data size is our data plus whatever was\n      // left from there.\n      final int totalDataBytes \u003d dataPayload.length \n          + previousLastPageDataWritten.length;\n      // Calculate the total number of pages we\u0027re writing to the server.\n      final int numberOfPages \u003d (totalDataBytes / PAGE_DATA_SIZE) \n          + (totalDataBytes % PAGE_DATA_SIZE \u003d\u003d 0 ? 0 : 1);\n      // Fill up the raw bytes we\u0027re writing.\n      byte[] rawPayload \u003d new byte[numberOfPages * PAGE_SIZE];\n      // Keep track of the size of the last page we uploaded.\n      int currentLastPageDataSize \u003d -1;\n      for (int page \u003d 0; page \u003c numberOfPages; page++) {\n        // Our current byte offset in the data.\n        int dataOffset \u003d page * PAGE_DATA_SIZE;\n        // Our current byte offset in the raw buffer.\n        int rawOffset \u003d page * PAGE_SIZE;\n        // The size of the data in the current page.\n        final short currentPageDataSize \u003d (short) Math.min(PAGE_DATA_SIZE,\n            totalDataBytes - dataOffset);\n        // Save off this page\u0027s size as the potential last page\u0027s size.\n        currentLastPageDataSize \u003d currentPageDataSize;\n\n        // Write out the page size in the header.\n        final byte[] header \u003d fromShort(currentPageDataSize);\n        System.arraycopy(header, 0, rawPayload, rawOffset, header.length);\n        rawOffset +\u003d header.length;\n\n        int bytesToCopyFromDataPayload \u003d currentPageDataSize;\n        if (dataOffset \u003c previousLastPageDataWritten.length) {\n          // First write out the last page\u0027s data.\n          final int bytesToCopyFromLastPage \u003d Math.min(currentPageDataSize,\n              previousLastPageDataWritten.length - dataOffset);\n          System.arraycopy(previousLastPageDataWritten, dataOffset,\n              rawPayload, rawOffset, bytesToCopyFromLastPage);\n          bytesToCopyFromDataPayload -\u003d bytesToCopyFromLastPage;\n          rawOffset +\u003d bytesToCopyFromLastPage;\n          dataOffset +\u003d bytesToCopyFromLastPage;\n        }\n\n        if (dataOffset \u003e\u003d previousLastPageDataWritten.length) {\n          // Then write the current payload\u0027s data.\n          System.arraycopy(dataPayload, \n        \t  dataOffset - previousLastPageDataWritten.length,\n              rawPayload, rawOffset, bytesToCopyFromDataPayload);\n        }\n      }\n\n      // Raw payload constructed, ship it off to the server.\n      writePayloadToServer(rawPayload);\n\n      // Post-send bookkeeping.\n      currentBlobOffset +\u003d rawPayload.length;\n      if (currentLastPageDataSize \u003c PAGE_DATA_SIZE) {\n        // Partial page, save it off so it\u0027s overwritten in the next request.\n        final int startOffset \u003d (numberOfPages - 1) * PAGE_SIZE + PAGE_HEADER_SIZE;\n        previousLastPageDataWritten \u003d Arrays.copyOfRange(rawPayload,\n            startOffset,\n            startOffset + currentLastPageDataSize);\n        // Since we\u0027re rewriting this page, set our current offset in the server\n        // to that page\u0027s beginning.\n        currentBlobOffset -\u003d PAGE_SIZE;\n      } else {\n        // It wasn\u0027t a partial page, we won\u0027t need to rewrite it.\n        previousLastPageDataWritten \u003d new byte[0];\n      }\n    }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/PageBlobOutputStream.java"
    }
  }
}