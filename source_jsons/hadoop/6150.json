{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSImageFormat.java",
  "functionName": "loadFullNameINodes",
  "functionId": "loadFullNameINodes___numFiles-long__in-DataInput__counter-Counter",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
  "functionStartLine": 615,
  "functionEndLine": 652,
  "numCommitsSeen": 180,
  "timeTaken": 3157,
  "changeHistory": [
    "e171254d56bfff467a67a6cf9160595c941f50c0",
    "b5935fab444491cbd1813d5390a68d9f23c8d27a",
    "da8e962e39bd41b73b53966826c82e741b08010b"
  ],
  "changeHistoryShort": {
    "e171254d56bfff467a67a6cf9160595c941f50c0": "Ybodychange",
    "b5935fab444491cbd1813d5390a68d9f23c8d27a": "Ybodychange",
    "da8e962e39bd41b73b53966826c82e741b08010b": "Ymultichange(Yparameterchange,Ybodychange)"
  },
  "changeHistoryDetails": {
    "e171254d56bfff467a67a6cf9160595c941f50c0": {
      "type": "Ybodychange",
      "commitMessage": "Name node cannot start if the path of a file under construction contains .snapshot. (wang)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1613329 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/07/14 4:42 PM",
      "commitName": "e171254d56bfff467a67a6cf9160595c941f50c0",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "07/07/14 5:08 PM",
      "commitNameOld": "76a621ffd2d66bf012a554f4400091a92a5b473e",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 16.98,
      "commitsBetweenForRepo": 140,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,38 @@\n   private void loadFullNameINodes(long numFiles, DataInput in, Counter counter)\n       throws IOException {\n     byte[][] pathComponents;\n     byte[][] parentPath \u003d {{}};      \n     FSDirectory fsDir \u003d namesystem.dir;\n     INodeDirectory parentINode \u003d fsDir.rootDir;\n     for (long i \u003d 0; i \u003c numFiles; i++) {\n       pathComponents \u003d FSImageSerialization.readPathComponents(in);\n+      for (int j\u003d0; j \u003c pathComponents.length; j++) {\n+        byte[] newComponent \u003d renameReservedComponentOnUpgrade\n+            (pathComponents[j], getLayoutVersion());\n+        if (!Arrays.equals(newComponent, pathComponents[j])) {\n+          String oldPath \u003d DFSUtil.byteArray2PathString(pathComponents);\n+          pathComponents[j] \u003d newComponent;\n+          String newPath \u003d DFSUtil.byteArray2PathString(pathComponents);\n+          LOG.info(\"Renaming reserved path \" + oldPath + \" to \" + newPath);\n+        }\n+      }\n       final INode newNode \u003d loadINode(\n           pathComponents[pathComponents.length-1], false, in, counter);\n \n       if (isRoot(pathComponents)) { // it is the root\n         // update the root\u0027s attributes\n         updateRootAttr(newNode.asDirectory());\n         continue;\n       }\n \n       namesystem.dir.addToInodeMap(newNode);\n       // check if the new inode belongs to the same parent\n       if(!isParent(pathComponents, parentPath)) {\n         parentINode \u003d getParentINodeDirectory(pathComponents);\n         parentPath \u003d getParent(pathComponents);\n       }\n \n       // add new inode\n       addToParent(parentINode, newNode);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void loadFullNameINodes(long numFiles, DataInput in, Counter counter)\n      throws IOException {\n    byte[][] pathComponents;\n    byte[][] parentPath \u003d {{}};      \n    FSDirectory fsDir \u003d namesystem.dir;\n    INodeDirectory parentINode \u003d fsDir.rootDir;\n    for (long i \u003d 0; i \u003c numFiles; i++) {\n      pathComponents \u003d FSImageSerialization.readPathComponents(in);\n      for (int j\u003d0; j \u003c pathComponents.length; j++) {\n        byte[] newComponent \u003d renameReservedComponentOnUpgrade\n            (pathComponents[j], getLayoutVersion());\n        if (!Arrays.equals(newComponent, pathComponents[j])) {\n          String oldPath \u003d DFSUtil.byteArray2PathString(pathComponents);\n          pathComponents[j] \u003d newComponent;\n          String newPath \u003d DFSUtil.byteArray2PathString(pathComponents);\n          LOG.info(\"Renaming reserved path \" + oldPath + \" to \" + newPath);\n        }\n      }\n      final INode newNode \u003d loadINode(\n          pathComponents[pathComponents.length-1], false, in, counter);\n\n      if (isRoot(pathComponents)) { // it is the root\n        // update the root\u0027s attributes\n        updateRootAttr(newNode.asDirectory());\n        continue;\n      }\n\n      namesystem.dir.addToInodeMap(newNode);\n      // check if the new inode belongs to the same parent\n      if(!isParent(pathComponents, parentPath)) {\n        parentINode \u003d getParentINodeDirectory(pathComponents);\n        parentPath \u003d getParent(pathComponents);\n      }\n\n      // add new inode\n      addToParent(parentINode, newNode);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "b5935fab444491cbd1813d5390a68d9f23c8d27a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6130. NPE when upgrading namenode from fsimages older than -32. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1581713 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/03/14 12:30 AM",
      "commitName": "b5935fab444491cbd1813d5390a68d9f23c8d27a",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "24/03/14 4:32 PM",
      "commitNameOld": "c2ef7e239eb0e81cf8a3e971378e9e696202de67",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 1.33,
      "commitsBetweenForRepo": 15,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,28 @@\n   private void loadFullNameINodes(long numFiles, DataInput in, Counter counter)\n       throws IOException {\n     byte[][] pathComponents;\n     byte[][] parentPath \u003d {{}};      \n     FSDirectory fsDir \u003d namesystem.dir;\n     INodeDirectory parentINode \u003d fsDir.rootDir;\n     for (long i \u003d 0; i \u003c numFiles; i++) {\n       pathComponents \u003d FSImageSerialization.readPathComponents(in);\n       final INode newNode \u003d loadINode(\n           pathComponents[pathComponents.length-1], false, in, counter);\n \n       if (isRoot(pathComponents)) { // it is the root\n         // update the root\u0027s attributes\n         updateRootAttr(newNode.asDirectory());\n         continue;\n       }\n+\n+      namesystem.dir.addToInodeMap(newNode);\n       // check if the new inode belongs to the same parent\n       if(!isParent(pathComponents, parentPath)) {\n         parentINode \u003d getParentINodeDirectory(pathComponents);\n         parentPath \u003d getParent(pathComponents);\n       }\n \n       // add new inode\n       addToParent(parentINode, newNode);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void loadFullNameINodes(long numFiles, DataInput in, Counter counter)\n      throws IOException {\n    byte[][] pathComponents;\n    byte[][] parentPath \u003d {{}};      \n    FSDirectory fsDir \u003d namesystem.dir;\n    INodeDirectory parentINode \u003d fsDir.rootDir;\n    for (long i \u003d 0; i \u003c numFiles; i++) {\n      pathComponents \u003d FSImageSerialization.readPathComponents(in);\n      final INode newNode \u003d loadINode(\n          pathComponents[pathComponents.length-1], false, in, counter);\n\n      if (isRoot(pathComponents)) { // it is the root\n        // update the root\u0027s attributes\n        updateRootAttr(newNode.asDirectory());\n        continue;\n      }\n\n      namesystem.dir.addToInodeMap(newNode);\n      // check if the new inode belongs to the same parent\n      if(!isParent(pathComponents, parentPath)) {\n        parentINode \u003d getParentINodeDirectory(pathComponents);\n        parentPath \u003d getParent(pathComponents);\n      }\n\n      // add new inode\n      addToParent(parentINode, newNode);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "da8e962e39bd41b73b53966826c82e741b08010b": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-4372. Track NameNode startup progress. Contributed by Chris Nauroth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1502120 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/07/13 10:35 PM",
      "commitName": "da8e962e39bd41b73b53966826c82e741b08010b",
      "commitAuthor": "Chris Nauroth",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-4372. Track NameNode startup progress. Contributed by Chris Nauroth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1502120 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "10/07/13 10:35 PM",
          "commitName": "da8e962e39bd41b73b53966826c82e741b08010b",
          "commitAuthor": "Chris Nauroth",
          "commitDateOld": "07/07/13 10:29 PM",
          "commitNameOld": "6770de7ec4f73e16740f1723f4e35d2fef2c22c8",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 3.0,
          "commitsBetweenForRepo": 22,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,26 +1,26 @@\n-  private void loadFullNameINodes(long numFiles,\n-      DataInput in) throws IOException {\n+  private void loadFullNameINodes(long numFiles, DataInput in, Counter counter)\n+      throws IOException {\n     byte[][] pathComponents;\n     byte[][] parentPath \u003d {{}};      \n     FSDirectory fsDir \u003d namesystem.dir;\n     INodeDirectory parentINode \u003d fsDir.rootDir;\n     for (long i \u003d 0; i \u003c numFiles; i++) {\n       pathComponents \u003d FSImageSerialization.readPathComponents(in);\n       final INode newNode \u003d loadINode(\n-          pathComponents[pathComponents.length-1], false, in);\n+          pathComponents[pathComponents.length-1], false, in, counter);\n \n       if (isRoot(pathComponents)) { // it is the root\n         // update the root\u0027s attributes\n         updateRootAttr(newNode.asDirectory());\n         continue;\n       }\n       // check if the new inode belongs to the same parent\n       if(!isParent(pathComponents, parentPath)) {\n         parentINode \u003d getParentINodeDirectory(pathComponents);\n         parentPath \u003d getParent(pathComponents);\n       }\n \n       // add new inode\n       addToParent(parentINode, newNode);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void loadFullNameINodes(long numFiles, DataInput in, Counter counter)\n      throws IOException {\n    byte[][] pathComponents;\n    byte[][] parentPath \u003d {{}};      \n    FSDirectory fsDir \u003d namesystem.dir;\n    INodeDirectory parentINode \u003d fsDir.rootDir;\n    for (long i \u003d 0; i \u003c numFiles; i++) {\n      pathComponents \u003d FSImageSerialization.readPathComponents(in);\n      final INode newNode \u003d loadINode(\n          pathComponents[pathComponents.length-1], false, in, counter);\n\n      if (isRoot(pathComponents)) { // it is the root\n        // update the root\u0027s attributes\n        updateRootAttr(newNode.asDirectory());\n        continue;\n      }\n      // check if the new inode belongs to the same parent\n      if(!isParent(pathComponents, parentPath)) {\n        parentINode \u003d getParentINodeDirectory(pathComponents);\n        parentPath \u003d getParent(pathComponents);\n      }\n\n      // add new inode\n      addToParent(parentINode, newNode);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
          "extendedDetails": {
            "oldValue": "[numFiles-long, in-DataInput]",
            "newValue": "[numFiles-long, in-DataInput, counter-Counter]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-4372. Track NameNode startup progress. Contributed by Chris Nauroth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1502120 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "10/07/13 10:35 PM",
          "commitName": "da8e962e39bd41b73b53966826c82e741b08010b",
          "commitAuthor": "Chris Nauroth",
          "commitDateOld": "07/07/13 10:29 PM",
          "commitNameOld": "6770de7ec4f73e16740f1723f4e35d2fef2c22c8",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 3.0,
          "commitsBetweenForRepo": 22,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,26 +1,26 @@\n-  private void loadFullNameINodes(long numFiles,\n-      DataInput in) throws IOException {\n+  private void loadFullNameINodes(long numFiles, DataInput in, Counter counter)\n+      throws IOException {\n     byte[][] pathComponents;\n     byte[][] parentPath \u003d {{}};      \n     FSDirectory fsDir \u003d namesystem.dir;\n     INodeDirectory parentINode \u003d fsDir.rootDir;\n     for (long i \u003d 0; i \u003c numFiles; i++) {\n       pathComponents \u003d FSImageSerialization.readPathComponents(in);\n       final INode newNode \u003d loadINode(\n-          pathComponents[pathComponents.length-1], false, in);\n+          pathComponents[pathComponents.length-1], false, in, counter);\n \n       if (isRoot(pathComponents)) { // it is the root\n         // update the root\u0027s attributes\n         updateRootAttr(newNode.asDirectory());\n         continue;\n       }\n       // check if the new inode belongs to the same parent\n       if(!isParent(pathComponents, parentPath)) {\n         parentINode \u003d getParentINodeDirectory(pathComponents);\n         parentPath \u003d getParent(pathComponents);\n       }\n \n       // add new inode\n       addToParent(parentINode, newNode);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void loadFullNameINodes(long numFiles, DataInput in, Counter counter)\n      throws IOException {\n    byte[][] pathComponents;\n    byte[][] parentPath \u003d {{}};      \n    FSDirectory fsDir \u003d namesystem.dir;\n    INodeDirectory parentINode \u003d fsDir.rootDir;\n    for (long i \u003d 0; i \u003c numFiles; i++) {\n      pathComponents \u003d FSImageSerialization.readPathComponents(in);\n      final INode newNode \u003d loadINode(\n          pathComponents[pathComponents.length-1], false, in, counter);\n\n      if (isRoot(pathComponents)) { // it is the root\n        // update the root\u0027s attributes\n        updateRootAttr(newNode.asDirectory());\n        continue;\n      }\n      // check if the new inode belongs to the same parent\n      if(!isParent(pathComponents, parentPath)) {\n        parentINode \u003d getParentINodeDirectory(pathComponents);\n        parentPath \u003d getParent(pathComponents);\n      }\n\n      // add new inode\n      addToParent(parentINode, newNode);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
          "extendedDetails": {}
        }
      ]
    }
  }
}