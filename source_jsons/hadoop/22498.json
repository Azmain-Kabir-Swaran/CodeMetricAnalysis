{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FileInputFormat.java",
  "functionName": "listStatus",
  "functionId": "listStatus___job-JobContext",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/input/FileInputFormat.java",
  "functionStartLine": 249,
  "functionEndLine": 302,
  "numCommitsSeen": 23,
  "timeTaken": 6726,
  "changeHistory": [
    "1921e94292f0820985a0cfbf8922a2a1a67fe921",
    "1babe50a2cbaae3c8165229347e743d0dc94e979",
    "a6ed4894b518351bf1b3290e725a475570a21296",
    "988639640024933448f822b48119dc832ebd2af3",
    "2eba7eb9aff5f7a1bf63ff1ebbe28d21fd37065b",
    "396c6c63a26b098fd0221e830f79be13b7e97432",
    "ec18984252731089ab5af12b3603dcfc3d4f4593",
    "e846c98397518838bba22f24df0f0d9ef4f3e1ad",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "1921e94292f0820985a0cfbf8922a2a1a67fe921": "Ybodychange",
    "1babe50a2cbaae3c8165229347e743d0dc94e979": "Ybodychange",
    "a6ed4894b518351bf1b3290e725a475570a21296": "Ybodychange",
    "988639640024933448f822b48119dc832ebd2af3": "Ybodychange",
    "2eba7eb9aff5f7a1bf63ff1ebbe28d21fd37065b": "Ybodychange",
    "396c6c63a26b098fd0221e830f79be13b7e97432": "Ybodychange",
    "ec18984252731089ab5af12b3603dcfc3d4f4593": "Ybodychange",
    "e846c98397518838bba22f24df0f0d9ef4f3e1ad": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "1921e94292f0820985a0cfbf8922a2a1a67fe921": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16458. LocatedFileStatusFetcher.getFileStatuses failing intermittently with S3\n\nContributed by Steve Loughran.\n\nIncludes\n-S3A glob scans don\u0027t bother trying to resolve symlinks\n-stack traces don\u0027t get lost in getFileStatuses() when exceptions are wrapped\n-debug level logging of what is up in Globber\n-Contains HADOOP-13373. Add S3A implementation of FSMainOperationsBaseTest.\n-ITestRestrictedReadAccess tests incomplete read access to files.\n\nThis adds a builder API for constructing globbers which other stores can use\nso that they too can skip symlink resolution when not needed.\n\nChange-Id: I23bcdb2783d6bd77cf168fdc165b1b4b334d91c7\n",
      "commitDate": "01/10/19 10:11 AM",
      "commitName": "1921e94292f0820985a0cfbf8922a2a1a67fe921",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "11/10/18 12:01 PM",
      "commitNameOld": "735a36afd528862d7690bee2d71b2f60dd282d21",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 354.92,
      "commitsBetweenForRepo": 2718,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,51 +1,54 @@\n   protected List\u003cFileStatus\u003e listStatus(JobContext job\n                                         ) throws IOException {\n     Path[] dirs \u003d getInputPaths(job);\n     if (dirs.length \u003d\u003d 0) {\n       throw new IOException(\"No input paths specified in job\");\n     }\n     \n     // get tokens for all the required FileSystems..\n     TokenCache.obtainTokensForNamenodes(job.getCredentials(), dirs, \n                                         job.getConfiguration());\n \n     // Whether we need to recursive look into the directory structure\n     boolean recursive \u003d getInputDirRecursive(job);\n \n     // creates a MultiPathFilter with the hiddenFileFilter and the\n     // user provided one (if any).\n     List\u003cPathFilter\u003e filters \u003d new ArrayList\u003cPathFilter\u003e();\n     filters.add(hiddenFileFilter);\n     PathFilter jobFilter \u003d getInputPathFilter(job);\n     if (jobFilter !\u003d null) {\n       filters.add(jobFilter);\n     }\n     PathFilter inputFilter \u003d new MultiPathFilter(filters);\n     \n     List\u003cFileStatus\u003e result \u003d null;\n \n     int numThreads \u003d job.getConfiguration().getInt(LIST_STATUS_NUM_THREADS,\n         DEFAULT_LIST_STATUS_NUM_THREADS);\n     StopWatch sw \u003d new StopWatch().start();\n     if (numThreads \u003d\u003d 1) {\n       result \u003d singleThreadedListStatus(job, dirs, inputFilter, recursive);\n     } else {\n       Iterable\u003cFileStatus\u003e locatedFiles \u003d null;\n       try {\n         LocatedFileStatusFetcher locatedFileStatusFetcher \u003d new LocatedFileStatusFetcher(\n             job.getConfiguration(), dirs, recursive, inputFilter, true);\n         locatedFiles \u003d locatedFileStatusFetcher.getFileStatuses();\n       } catch (InterruptedException e) {\n-        throw new IOException(\"Interrupted while getting file statuses\");\n+        throw (IOException)\n+            new InterruptedIOException(\n+                \"Interrupted while getting file statuses\")\n+                .initCause(e);\n       }\n       result \u003d Lists.newArrayList(locatedFiles);\n     }\n     \n     sw.stop();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"Time taken to get FileStatuses: \"\n           + sw.now(TimeUnit.MILLISECONDS));\n     }\n     LOG.info(\"Total input files to process : \" + result.size());\n     return result;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected List\u003cFileStatus\u003e listStatus(JobContext job\n                                        ) throws IOException {\n    Path[] dirs \u003d getInputPaths(job);\n    if (dirs.length \u003d\u003d 0) {\n      throw new IOException(\"No input paths specified in job\");\n    }\n    \n    // get tokens for all the required FileSystems..\n    TokenCache.obtainTokensForNamenodes(job.getCredentials(), dirs, \n                                        job.getConfiguration());\n\n    // Whether we need to recursive look into the directory structure\n    boolean recursive \u003d getInputDirRecursive(job);\n\n    // creates a MultiPathFilter with the hiddenFileFilter and the\n    // user provided one (if any).\n    List\u003cPathFilter\u003e filters \u003d new ArrayList\u003cPathFilter\u003e();\n    filters.add(hiddenFileFilter);\n    PathFilter jobFilter \u003d getInputPathFilter(job);\n    if (jobFilter !\u003d null) {\n      filters.add(jobFilter);\n    }\n    PathFilter inputFilter \u003d new MultiPathFilter(filters);\n    \n    List\u003cFileStatus\u003e result \u003d null;\n\n    int numThreads \u003d job.getConfiguration().getInt(LIST_STATUS_NUM_THREADS,\n        DEFAULT_LIST_STATUS_NUM_THREADS);\n    StopWatch sw \u003d new StopWatch().start();\n    if (numThreads \u003d\u003d 1) {\n      result \u003d singleThreadedListStatus(job, dirs, inputFilter, recursive);\n    } else {\n      Iterable\u003cFileStatus\u003e locatedFiles \u003d null;\n      try {\n        LocatedFileStatusFetcher locatedFileStatusFetcher \u003d new LocatedFileStatusFetcher(\n            job.getConfiguration(), dirs, recursive, inputFilter, true);\n        locatedFiles \u003d locatedFileStatusFetcher.getFileStatuses();\n      } catch (InterruptedException e) {\n        throw (IOException)\n            new InterruptedIOException(\n                \"Interrupted while getting file statuses\")\n                .initCause(e);\n      }\n      result \u003d Lists.newArrayList(locatedFiles);\n    }\n    \n    sw.stop();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Time taken to get FileStatuses: \"\n          + sw.now(TimeUnit.MILLISECONDS));\n    }\n    LOG.info(\"Total input files to process : \" + result.size());\n    return result;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/input/FileInputFormat.java",
      "extendedDetails": {}
    },
    "1babe50a2cbaae3c8165229347e743d0dc94e979": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6373. The logger reports total input paths but it is referring\nto input files. Contributed by Bibin A Chundatt.\n",
      "commitDate": "17/06/15 11:12 PM",
      "commitName": "1babe50a2cbaae3c8165229347e743d0dc94e979",
      "commitAuthor": "Devaraj K",
      "commitDateOld": "08/05/15 2:31 PM",
      "commitNameOld": "2edcf931d7843cddcf3da5666a73d6ee9a10d00d",
      "commitAuthorOld": "Chris Douglas",
      "daysBetweenCommits": 40.36,
      "commitsBetweenForRepo": 327,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,51 +1,51 @@\n   protected List\u003cFileStatus\u003e listStatus(JobContext job\n                                         ) throws IOException {\n     Path[] dirs \u003d getInputPaths(job);\n     if (dirs.length \u003d\u003d 0) {\n       throw new IOException(\"No input paths specified in job\");\n     }\n     \n     // get tokens for all the required FileSystems..\n     TokenCache.obtainTokensForNamenodes(job.getCredentials(), dirs, \n                                         job.getConfiguration());\n \n     // Whether we need to recursive look into the directory structure\n     boolean recursive \u003d getInputDirRecursive(job);\n \n     // creates a MultiPathFilter with the hiddenFileFilter and the\n     // user provided one (if any).\n     List\u003cPathFilter\u003e filters \u003d new ArrayList\u003cPathFilter\u003e();\n     filters.add(hiddenFileFilter);\n     PathFilter jobFilter \u003d getInputPathFilter(job);\n     if (jobFilter !\u003d null) {\n       filters.add(jobFilter);\n     }\n     PathFilter inputFilter \u003d new MultiPathFilter(filters);\n     \n     List\u003cFileStatus\u003e result \u003d null;\n \n     int numThreads \u003d job.getConfiguration().getInt(LIST_STATUS_NUM_THREADS,\n         DEFAULT_LIST_STATUS_NUM_THREADS);\n     StopWatch sw \u003d new StopWatch().start();\n     if (numThreads \u003d\u003d 1) {\n       result \u003d singleThreadedListStatus(job, dirs, inputFilter, recursive);\n     } else {\n       Iterable\u003cFileStatus\u003e locatedFiles \u003d null;\n       try {\n         LocatedFileStatusFetcher locatedFileStatusFetcher \u003d new LocatedFileStatusFetcher(\n             job.getConfiguration(), dirs, recursive, inputFilter, true);\n         locatedFiles \u003d locatedFileStatusFetcher.getFileStatuses();\n       } catch (InterruptedException e) {\n         throw new IOException(\"Interrupted while getting file statuses\");\n       }\n       result \u003d Lists.newArrayList(locatedFiles);\n     }\n     \n     sw.stop();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"Time taken to get FileStatuses: \"\n           + sw.now(TimeUnit.MILLISECONDS));\n     }\n-    LOG.info(\"Total input paths to process : \" + result.size()); \n+    LOG.info(\"Total input files to process : \" + result.size());\n     return result;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected List\u003cFileStatus\u003e listStatus(JobContext job\n                                        ) throws IOException {\n    Path[] dirs \u003d getInputPaths(job);\n    if (dirs.length \u003d\u003d 0) {\n      throw new IOException(\"No input paths specified in job\");\n    }\n    \n    // get tokens for all the required FileSystems..\n    TokenCache.obtainTokensForNamenodes(job.getCredentials(), dirs, \n                                        job.getConfiguration());\n\n    // Whether we need to recursive look into the directory structure\n    boolean recursive \u003d getInputDirRecursive(job);\n\n    // creates a MultiPathFilter with the hiddenFileFilter and the\n    // user provided one (if any).\n    List\u003cPathFilter\u003e filters \u003d new ArrayList\u003cPathFilter\u003e();\n    filters.add(hiddenFileFilter);\n    PathFilter jobFilter \u003d getInputPathFilter(job);\n    if (jobFilter !\u003d null) {\n      filters.add(jobFilter);\n    }\n    PathFilter inputFilter \u003d new MultiPathFilter(filters);\n    \n    List\u003cFileStatus\u003e result \u003d null;\n\n    int numThreads \u003d job.getConfiguration().getInt(LIST_STATUS_NUM_THREADS,\n        DEFAULT_LIST_STATUS_NUM_THREADS);\n    StopWatch sw \u003d new StopWatch().start();\n    if (numThreads \u003d\u003d 1) {\n      result \u003d singleThreadedListStatus(job, dirs, inputFilter, recursive);\n    } else {\n      Iterable\u003cFileStatus\u003e locatedFiles \u003d null;\n      try {\n        LocatedFileStatusFetcher locatedFileStatusFetcher \u003d new LocatedFileStatusFetcher(\n            job.getConfiguration(), dirs, recursive, inputFilter, true);\n        locatedFiles \u003d locatedFileStatusFetcher.getFileStatuses();\n      } catch (InterruptedException e) {\n        throw new IOException(\"Interrupted while getting file statuses\");\n      }\n      result \u003d Lists.newArrayList(locatedFiles);\n    }\n    \n    sw.stop();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Time taken to get FileStatuses: \"\n          + sw.now(TimeUnit.MILLISECONDS));\n    }\n    LOG.info(\"Total input files to process : \" + result.size());\n    return result;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/input/FileInputFormat.java",
      "extendedDetails": {}
    },
    "a6ed4894b518351bf1b3290e725a475570a21296": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-11032. Replace use of Guava\u0027s Stopwatch with Hadoop\u0027s StopWatch. (ozawa)\n",
      "commitDate": "07/01/15 9:51 PM",
      "commitName": "a6ed4894b518351bf1b3290e725a475570a21296",
      "commitAuthor": "Tsuyoshi Ozawa",
      "commitDateOld": "07/01/15 9:35 PM",
      "commitNameOld": "988639640024933448f822b48119dc832ebd2af3",
      "commitAuthorOld": "Tsuyoshi Ozawa",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,50 +1,51 @@\n   protected List\u003cFileStatus\u003e listStatus(JobContext job\n                                         ) throws IOException {\n     Path[] dirs \u003d getInputPaths(job);\n     if (dirs.length \u003d\u003d 0) {\n       throw new IOException(\"No input paths specified in job\");\n     }\n     \n     // get tokens for all the required FileSystems..\n     TokenCache.obtainTokensForNamenodes(job.getCredentials(), dirs, \n                                         job.getConfiguration());\n \n     // Whether we need to recursive look into the directory structure\n     boolean recursive \u003d getInputDirRecursive(job);\n \n     // creates a MultiPathFilter with the hiddenFileFilter and the\n     // user provided one (if any).\n     List\u003cPathFilter\u003e filters \u003d new ArrayList\u003cPathFilter\u003e();\n     filters.add(hiddenFileFilter);\n     PathFilter jobFilter \u003d getInputPathFilter(job);\n     if (jobFilter !\u003d null) {\n       filters.add(jobFilter);\n     }\n     PathFilter inputFilter \u003d new MultiPathFilter(filters);\n     \n     List\u003cFileStatus\u003e result \u003d null;\n \n     int numThreads \u003d job.getConfiguration().getInt(LIST_STATUS_NUM_THREADS,\n         DEFAULT_LIST_STATUS_NUM_THREADS);\n-    Stopwatch sw \u003d new Stopwatch().start();\n+    StopWatch sw \u003d new StopWatch().start();\n     if (numThreads \u003d\u003d 1) {\n       result \u003d singleThreadedListStatus(job, dirs, inputFilter, recursive);\n     } else {\n       Iterable\u003cFileStatus\u003e locatedFiles \u003d null;\n       try {\n         LocatedFileStatusFetcher locatedFileStatusFetcher \u003d new LocatedFileStatusFetcher(\n             job.getConfiguration(), dirs, recursive, inputFilter, true);\n         locatedFiles \u003d locatedFileStatusFetcher.getFileStatuses();\n       } catch (InterruptedException e) {\n         throw new IOException(\"Interrupted while getting file statuses\");\n       }\n       result \u003d Lists.newArrayList(locatedFiles);\n     }\n     \n     sw.stop();\n     if (LOG.isDebugEnabled()) {\n-      LOG.debug(\"Time taken to get FileStatuses: \" + sw.elapsedMillis());\n+      LOG.debug(\"Time taken to get FileStatuses: \"\n+          + sw.now(TimeUnit.MILLISECONDS));\n     }\n     LOG.info(\"Total input paths to process : \" + result.size()); \n     return result;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected List\u003cFileStatus\u003e listStatus(JobContext job\n                                        ) throws IOException {\n    Path[] dirs \u003d getInputPaths(job);\n    if (dirs.length \u003d\u003d 0) {\n      throw new IOException(\"No input paths specified in job\");\n    }\n    \n    // get tokens for all the required FileSystems..\n    TokenCache.obtainTokensForNamenodes(job.getCredentials(), dirs, \n                                        job.getConfiguration());\n\n    // Whether we need to recursive look into the directory structure\n    boolean recursive \u003d getInputDirRecursive(job);\n\n    // creates a MultiPathFilter with the hiddenFileFilter and the\n    // user provided one (if any).\n    List\u003cPathFilter\u003e filters \u003d new ArrayList\u003cPathFilter\u003e();\n    filters.add(hiddenFileFilter);\n    PathFilter jobFilter \u003d getInputPathFilter(job);\n    if (jobFilter !\u003d null) {\n      filters.add(jobFilter);\n    }\n    PathFilter inputFilter \u003d new MultiPathFilter(filters);\n    \n    List\u003cFileStatus\u003e result \u003d null;\n\n    int numThreads \u003d job.getConfiguration().getInt(LIST_STATUS_NUM_THREADS,\n        DEFAULT_LIST_STATUS_NUM_THREADS);\n    StopWatch sw \u003d new StopWatch().start();\n    if (numThreads \u003d\u003d 1) {\n      result \u003d singleThreadedListStatus(job, dirs, inputFilter, recursive);\n    } else {\n      Iterable\u003cFileStatus\u003e locatedFiles \u003d null;\n      try {\n        LocatedFileStatusFetcher locatedFileStatusFetcher \u003d new LocatedFileStatusFetcher(\n            job.getConfiguration(), dirs, recursive, inputFilter, true);\n        locatedFiles \u003d locatedFileStatusFetcher.getFileStatuses();\n      } catch (InterruptedException e) {\n        throw new IOException(\"Interrupted while getting file statuses\");\n      }\n      result \u003d Lists.newArrayList(locatedFiles);\n    }\n    \n    sw.stop();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Time taken to get FileStatuses: \"\n          + sw.now(TimeUnit.MILLISECONDS));\n    }\n    LOG.info(\"Total input paths to process : \" + result.size()); \n    return result;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/input/FileInputFormat.java",
      "extendedDetails": {}
    },
    "988639640024933448f822b48119dc832ebd2af3": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"Replace use of Guava\u0027s Stopwatch with Hadoop\u0027s StopWatch. (ozawa)\" because of missing JIRA\u0027s number.\n\nThis reverts commit 2eba7eb9aff5f7a1bf63ff1ebbe28d21fd37065b.\n",
      "commitDate": "07/01/15 9:35 PM",
      "commitName": "988639640024933448f822b48119dc832ebd2af3",
      "commitAuthor": "Tsuyoshi Ozawa",
      "commitDateOld": "07/01/15 9:21 PM",
      "commitNameOld": "2eba7eb9aff5f7a1bf63ff1ebbe28d21fd37065b",
      "commitAuthorOld": "Tsuyoshi Ozawa",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,51 +1,50 @@\n   protected List\u003cFileStatus\u003e listStatus(JobContext job\n                                         ) throws IOException {\n     Path[] dirs \u003d getInputPaths(job);\n     if (dirs.length \u003d\u003d 0) {\n       throw new IOException(\"No input paths specified in job\");\n     }\n     \n     // get tokens for all the required FileSystems..\n     TokenCache.obtainTokensForNamenodes(job.getCredentials(), dirs, \n                                         job.getConfiguration());\n \n     // Whether we need to recursive look into the directory structure\n     boolean recursive \u003d getInputDirRecursive(job);\n \n     // creates a MultiPathFilter with the hiddenFileFilter and the\n     // user provided one (if any).\n     List\u003cPathFilter\u003e filters \u003d new ArrayList\u003cPathFilter\u003e();\n     filters.add(hiddenFileFilter);\n     PathFilter jobFilter \u003d getInputPathFilter(job);\n     if (jobFilter !\u003d null) {\n       filters.add(jobFilter);\n     }\n     PathFilter inputFilter \u003d new MultiPathFilter(filters);\n     \n     List\u003cFileStatus\u003e result \u003d null;\n \n     int numThreads \u003d job.getConfiguration().getInt(LIST_STATUS_NUM_THREADS,\n         DEFAULT_LIST_STATUS_NUM_THREADS);\n-    StopWatch sw \u003d new StopWatch().start();\n+    Stopwatch sw \u003d new Stopwatch().start();\n     if (numThreads \u003d\u003d 1) {\n       result \u003d singleThreadedListStatus(job, dirs, inputFilter, recursive);\n     } else {\n       Iterable\u003cFileStatus\u003e locatedFiles \u003d null;\n       try {\n         LocatedFileStatusFetcher locatedFileStatusFetcher \u003d new LocatedFileStatusFetcher(\n             job.getConfiguration(), dirs, recursive, inputFilter, true);\n         locatedFiles \u003d locatedFileStatusFetcher.getFileStatuses();\n       } catch (InterruptedException e) {\n         throw new IOException(\"Interrupted while getting file statuses\");\n       }\n       result \u003d Lists.newArrayList(locatedFiles);\n     }\n     \n     sw.stop();\n     if (LOG.isDebugEnabled()) {\n-      LOG.debug(\"Time taken to get FileStatuses: \"\n-          + sw.now(TimeUnit.MILLISECONDS));\n+      LOG.debug(\"Time taken to get FileStatuses: \" + sw.elapsedMillis());\n     }\n     LOG.info(\"Total input paths to process : \" + result.size()); \n     return result;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected List\u003cFileStatus\u003e listStatus(JobContext job\n                                        ) throws IOException {\n    Path[] dirs \u003d getInputPaths(job);\n    if (dirs.length \u003d\u003d 0) {\n      throw new IOException(\"No input paths specified in job\");\n    }\n    \n    // get tokens for all the required FileSystems..\n    TokenCache.obtainTokensForNamenodes(job.getCredentials(), dirs, \n                                        job.getConfiguration());\n\n    // Whether we need to recursive look into the directory structure\n    boolean recursive \u003d getInputDirRecursive(job);\n\n    // creates a MultiPathFilter with the hiddenFileFilter and the\n    // user provided one (if any).\n    List\u003cPathFilter\u003e filters \u003d new ArrayList\u003cPathFilter\u003e();\n    filters.add(hiddenFileFilter);\n    PathFilter jobFilter \u003d getInputPathFilter(job);\n    if (jobFilter !\u003d null) {\n      filters.add(jobFilter);\n    }\n    PathFilter inputFilter \u003d new MultiPathFilter(filters);\n    \n    List\u003cFileStatus\u003e result \u003d null;\n\n    int numThreads \u003d job.getConfiguration().getInt(LIST_STATUS_NUM_THREADS,\n        DEFAULT_LIST_STATUS_NUM_THREADS);\n    Stopwatch sw \u003d new Stopwatch().start();\n    if (numThreads \u003d\u003d 1) {\n      result \u003d singleThreadedListStatus(job, dirs, inputFilter, recursive);\n    } else {\n      Iterable\u003cFileStatus\u003e locatedFiles \u003d null;\n      try {\n        LocatedFileStatusFetcher locatedFileStatusFetcher \u003d new LocatedFileStatusFetcher(\n            job.getConfiguration(), dirs, recursive, inputFilter, true);\n        locatedFiles \u003d locatedFileStatusFetcher.getFileStatuses();\n      } catch (InterruptedException e) {\n        throw new IOException(\"Interrupted while getting file statuses\");\n      }\n      result \u003d Lists.newArrayList(locatedFiles);\n    }\n    \n    sw.stop();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Time taken to get FileStatuses: \" + sw.elapsedMillis());\n    }\n    LOG.info(\"Total input paths to process : \" + result.size()); \n    return result;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/input/FileInputFormat.java",
      "extendedDetails": {}
    },
    "2eba7eb9aff5f7a1bf63ff1ebbe28d21fd37065b": {
      "type": "Ybodychange",
      "commitMessage": "Replace use of Guava\u0027s Stopwatch with Hadoop\u0027s StopWatch. (ozawa)\n",
      "commitDate": "07/01/15 9:21 PM",
      "commitName": "2eba7eb9aff5f7a1bf63ff1ebbe28d21fd37065b",
      "commitAuthor": "Tsuyoshi Ozawa",
      "commitDateOld": "18/06/14 4:28 PM",
      "commitNameOld": "bd23a2ff22dba8a5203e8e498244f985e728da51",
      "commitAuthorOld": "Karthik Kambatla",
      "daysBetweenCommits": 203.24,
      "commitsBetweenForRepo": 1722,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,50 +1,51 @@\n   protected List\u003cFileStatus\u003e listStatus(JobContext job\n                                         ) throws IOException {\n     Path[] dirs \u003d getInputPaths(job);\n     if (dirs.length \u003d\u003d 0) {\n       throw new IOException(\"No input paths specified in job\");\n     }\n     \n     // get tokens for all the required FileSystems..\n     TokenCache.obtainTokensForNamenodes(job.getCredentials(), dirs, \n                                         job.getConfiguration());\n \n     // Whether we need to recursive look into the directory structure\n     boolean recursive \u003d getInputDirRecursive(job);\n \n     // creates a MultiPathFilter with the hiddenFileFilter and the\n     // user provided one (if any).\n     List\u003cPathFilter\u003e filters \u003d new ArrayList\u003cPathFilter\u003e();\n     filters.add(hiddenFileFilter);\n     PathFilter jobFilter \u003d getInputPathFilter(job);\n     if (jobFilter !\u003d null) {\n       filters.add(jobFilter);\n     }\n     PathFilter inputFilter \u003d new MultiPathFilter(filters);\n     \n     List\u003cFileStatus\u003e result \u003d null;\n \n     int numThreads \u003d job.getConfiguration().getInt(LIST_STATUS_NUM_THREADS,\n         DEFAULT_LIST_STATUS_NUM_THREADS);\n-    Stopwatch sw \u003d new Stopwatch().start();\n+    StopWatch sw \u003d new StopWatch().start();\n     if (numThreads \u003d\u003d 1) {\n       result \u003d singleThreadedListStatus(job, dirs, inputFilter, recursive);\n     } else {\n       Iterable\u003cFileStatus\u003e locatedFiles \u003d null;\n       try {\n         LocatedFileStatusFetcher locatedFileStatusFetcher \u003d new LocatedFileStatusFetcher(\n             job.getConfiguration(), dirs, recursive, inputFilter, true);\n         locatedFiles \u003d locatedFileStatusFetcher.getFileStatuses();\n       } catch (InterruptedException e) {\n         throw new IOException(\"Interrupted while getting file statuses\");\n       }\n       result \u003d Lists.newArrayList(locatedFiles);\n     }\n     \n     sw.stop();\n     if (LOG.isDebugEnabled()) {\n-      LOG.debug(\"Time taken to get FileStatuses: \" + sw.elapsedMillis());\n+      LOG.debug(\"Time taken to get FileStatuses: \"\n+          + sw.now(TimeUnit.MILLISECONDS));\n     }\n     LOG.info(\"Total input paths to process : \" + result.size()); \n     return result;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected List\u003cFileStatus\u003e listStatus(JobContext job\n                                        ) throws IOException {\n    Path[] dirs \u003d getInputPaths(job);\n    if (dirs.length \u003d\u003d 0) {\n      throw new IOException(\"No input paths specified in job\");\n    }\n    \n    // get tokens for all the required FileSystems..\n    TokenCache.obtainTokensForNamenodes(job.getCredentials(), dirs, \n                                        job.getConfiguration());\n\n    // Whether we need to recursive look into the directory structure\n    boolean recursive \u003d getInputDirRecursive(job);\n\n    // creates a MultiPathFilter with the hiddenFileFilter and the\n    // user provided one (if any).\n    List\u003cPathFilter\u003e filters \u003d new ArrayList\u003cPathFilter\u003e();\n    filters.add(hiddenFileFilter);\n    PathFilter jobFilter \u003d getInputPathFilter(job);\n    if (jobFilter !\u003d null) {\n      filters.add(jobFilter);\n    }\n    PathFilter inputFilter \u003d new MultiPathFilter(filters);\n    \n    List\u003cFileStatus\u003e result \u003d null;\n\n    int numThreads \u003d job.getConfiguration().getInt(LIST_STATUS_NUM_THREADS,\n        DEFAULT_LIST_STATUS_NUM_THREADS);\n    StopWatch sw \u003d new StopWatch().start();\n    if (numThreads \u003d\u003d 1) {\n      result \u003d singleThreadedListStatus(job, dirs, inputFilter, recursive);\n    } else {\n      Iterable\u003cFileStatus\u003e locatedFiles \u003d null;\n      try {\n        LocatedFileStatusFetcher locatedFileStatusFetcher \u003d new LocatedFileStatusFetcher(\n            job.getConfiguration(), dirs, recursive, inputFilter, true);\n        locatedFiles \u003d locatedFileStatusFetcher.getFileStatuses();\n      } catch (InterruptedException e) {\n        throw new IOException(\"Interrupted while getting file statuses\");\n      }\n      result \u003d Lists.newArrayList(locatedFiles);\n    }\n    \n    sw.stop();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Time taken to get FileStatuses: \"\n          + sw.now(TimeUnit.MILLISECONDS));\n    }\n    LOG.info(\"Total input paths to process : \" + result.size()); \n    return result;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/input/FileInputFormat.java",
      "extendedDetails": {}
    },
    "396c6c63a26b098fd0221e830f79be13b7e97432": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2349. Modified FileInputFormat to be able to issue file and block location calls in parallel. Contributed by Siddharth Seth.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1579515 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/03/14 7:46 PM",
      "commitName": "396c6c63a26b098fd0221e830f79be13b7e97432",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "26/07/13 11:16 AM",
      "commitNameOld": "ec18984252731089ab5af12b3603dcfc3d4f4593",
      "commitAuthorOld": "Jason Darrell Lowe",
      "daysBetweenCommits": 236.35,
      "commitsBetweenForRepo": 1629,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,64 +1,50 @@\n   protected List\u003cFileStatus\u003e listStatus(JobContext job\n                                         ) throws IOException {\n-    List\u003cFileStatus\u003e result \u003d new ArrayList\u003cFileStatus\u003e();\n     Path[] dirs \u003d getInputPaths(job);\n     if (dirs.length \u003d\u003d 0) {\n       throw new IOException(\"No input paths specified in job\");\n     }\n     \n     // get tokens for all the required FileSystems..\n     TokenCache.obtainTokensForNamenodes(job.getCredentials(), dirs, \n                                         job.getConfiguration());\n \n     // Whether we need to recursive look into the directory structure\n     boolean recursive \u003d getInputDirRecursive(job);\n-    \n-    List\u003cIOException\u003e errors \u003d new ArrayList\u003cIOException\u003e();\n-    \n+\n     // creates a MultiPathFilter with the hiddenFileFilter and the\n     // user provided one (if any).\n     List\u003cPathFilter\u003e filters \u003d new ArrayList\u003cPathFilter\u003e();\n     filters.add(hiddenFileFilter);\n     PathFilter jobFilter \u003d getInputPathFilter(job);\n     if (jobFilter !\u003d null) {\n       filters.add(jobFilter);\n     }\n     PathFilter inputFilter \u003d new MultiPathFilter(filters);\n     \n-    for (int i\u003d0; i \u003c dirs.length; ++i) {\n-      Path p \u003d dirs[i];\n-      FileSystem fs \u003d p.getFileSystem(job.getConfiguration()); \n-      FileStatus[] matches \u003d fs.globStatus(p, inputFilter);\n-      if (matches \u003d\u003d null) {\n-        errors.add(new IOException(\"Input path does not exist: \" + p));\n-      } else if (matches.length \u003d\u003d 0) {\n-        errors.add(new IOException(\"Input Pattern \" + p + \" matches 0 files\"));\n-      } else {\n-        for (FileStatus globStat: matches) {\n-          if (globStat.isDirectory()) {\n-            RemoteIterator\u003cLocatedFileStatus\u003e iter \u003d\n-                fs.listLocatedStatus(globStat.getPath());\n-            while (iter.hasNext()) {\n-              LocatedFileStatus stat \u003d iter.next();\n-              if (inputFilter.accept(stat.getPath())) {\n-                if (recursive \u0026\u0026 stat.isDirectory()) {\n-                  addInputPathRecursively(result, fs, stat.getPath(),\n-                      inputFilter);\n-                } else {\n-                  result.add(stat);\n-                }\n-              }\n-            }\n-          } else {\n-            result.add(globStat);\n-          }\n-        }\n-      }\n-    }\n+    List\u003cFileStatus\u003e result \u003d null;\n \n-    if (!errors.isEmpty()) {\n-      throw new InvalidInputException(errors);\n+    int numThreads \u003d job.getConfiguration().getInt(LIST_STATUS_NUM_THREADS,\n+        DEFAULT_LIST_STATUS_NUM_THREADS);\n+    Stopwatch sw \u003d new Stopwatch().start();\n+    if (numThreads \u003d\u003d 1) {\n+      result \u003d singleThreadedListStatus(job, dirs, inputFilter, recursive);\n+    } else {\n+      Iterable\u003cFileStatus\u003e locatedFiles \u003d null;\n+      try {\n+        LocatedFileStatusFetcher locatedFileStatusFetcher \u003d new LocatedFileStatusFetcher(\n+            job.getConfiguration(), dirs, recursive, inputFilter, true);\n+        locatedFiles \u003d locatedFileStatusFetcher.getFileStatuses();\n+      } catch (InterruptedException e) {\n+        throw new IOException(\"Interrupted while getting file statuses\");\n+      }\n+      result \u003d Lists.newArrayList(locatedFiles);\n+    }\n+    \n+    sw.stop();\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"Time taken to get FileStatuses: \" + sw.elapsedMillis());\n     }\n     LOG.info(\"Total input paths to process : \" + result.size()); \n     return result;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected List\u003cFileStatus\u003e listStatus(JobContext job\n                                        ) throws IOException {\n    Path[] dirs \u003d getInputPaths(job);\n    if (dirs.length \u003d\u003d 0) {\n      throw new IOException(\"No input paths specified in job\");\n    }\n    \n    // get tokens for all the required FileSystems..\n    TokenCache.obtainTokensForNamenodes(job.getCredentials(), dirs, \n                                        job.getConfiguration());\n\n    // Whether we need to recursive look into the directory structure\n    boolean recursive \u003d getInputDirRecursive(job);\n\n    // creates a MultiPathFilter with the hiddenFileFilter and the\n    // user provided one (if any).\n    List\u003cPathFilter\u003e filters \u003d new ArrayList\u003cPathFilter\u003e();\n    filters.add(hiddenFileFilter);\n    PathFilter jobFilter \u003d getInputPathFilter(job);\n    if (jobFilter !\u003d null) {\n      filters.add(jobFilter);\n    }\n    PathFilter inputFilter \u003d new MultiPathFilter(filters);\n    \n    List\u003cFileStatus\u003e result \u003d null;\n\n    int numThreads \u003d job.getConfiguration().getInt(LIST_STATUS_NUM_THREADS,\n        DEFAULT_LIST_STATUS_NUM_THREADS);\n    Stopwatch sw \u003d new Stopwatch().start();\n    if (numThreads \u003d\u003d 1) {\n      result \u003d singleThreadedListStatus(job, dirs, inputFilter, recursive);\n    } else {\n      Iterable\u003cFileStatus\u003e locatedFiles \u003d null;\n      try {\n        LocatedFileStatusFetcher locatedFileStatusFetcher \u003d new LocatedFileStatusFetcher(\n            job.getConfiguration(), dirs, recursive, inputFilter, true);\n        locatedFiles \u003d locatedFileStatusFetcher.getFileStatuses();\n      } catch (InterruptedException e) {\n        throw new IOException(\"Interrupted while getting file statuses\");\n      }\n      result \u003d Lists.newArrayList(locatedFiles);\n    }\n    \n    sw.stop();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Time taken to get FileStatuses: \" + sw.elapsedMillis());\n    }\n    LOG.info(\"Total input paths to process : \" + result.size()); \n    return result;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/input/FileInputFormat.java",
      "extendedDetails": {}
    },
    "ec18984252731089ab5af12b3603dcfc3d4f4593": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-1981. Improve getSplits performance by using listLocatedStatus. Contributed by Hairong Kuang and Jason Lowe\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1507385 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/07/13 11:16 AM",
      "commitName": "ec18984252731089ab5af12b3603dcfc3d4f4593",
      "commitAuthor": "Jason Darrell Lowe",
      "commitDateOld": "02/07/13 2:47 PM",
      "commitNameOld": "e846c98397518838bba22f24df0f0d9ef4f3e1ad",
      "commitAuthorOld": "Jason Darrell Lowe",
      "daysBetweenCommits": 23.85,
      "commitsBetweenForRepo": 137,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,59 +1,64 @@\n   protected List\u003cFileStatus\u003e listStatus(JobContext job\n                                         ) throws IOException {\n     List\u003cFileStatus\u003e result \u003d new ArrayList\u003cFileStatus\u003e();\n     Path[] dirs \u003d getInputPaths(job);\n     if (dirs.length \u003d\u003d 0) {\n       throw new IOException(\"No input paths specified in job\");\n     }\n     \n     // get tokens for all the required FileSystems..\n     TokenCache.obtainTokensForNamenodes(job.getCredentials(), dirs, \n                                         job.getConfiguration());\n \n     // Whether we need to recursive look into the directory structure\n     boolean recursive \u003d getInputDirRecursive(job);\n     \n     List\u003cIOException\u003e errors \u003d new ArrayList\u003cIOException\u003e();\n     \n     // creates a MultiPathFilter with the hiddenFileFilter and the\n     // user provided one (if any).\n     List\u003cPathFilter\u003e filters \u003d new ArrayList\u003cPathFilter\u003e();\n     filters.add(hiddenFileFilter);\n     PathFilter jobFilter \u003d getInputPathFilter(job);\n     if (jobFilter !\u003d null) {\n       filters.add(jobFilter);\n     }\n     PathFilter inputFilter \u003d new MultiPathFilter(filters);\n     \n     for (int i\u003d0; i \u003c dirs.length; ++i) {\n       Path p \u003d dirs[i];\n       FileSystem fs \u003d p.getFileSystem(job.getConfiguration()); \n       FileStatus[] matches \u003d fs.globStatus(p, inputFilter);\n       if (matches \u003d\u003d null) {\n         errors.add(new IOException(\"Input path does not exist: \" + p));\n       } else if (matches.length \u003d\u003d 0) {\n         errors.add(new IOException(\"Input Pattern \" + p + \" matches 0 files\"));\n       } else {\n         for (FileStatus globStat: matches) {\n           if (globStat.isDirectory()) {\n-            for(FileStatus stat: fs.listStatus(globStat.getPath(),\n-                inputFilter)) {\n-              if (recursive \u0026\u0026 stat.isDirectory()) {\n-                addInputPathRecursively(result, fs, stat.getPath(), inputFilter);\n-              } else {\n-                result.add(stat);\n+            RemoteIterator\u003cLocatedFileStatus\u003e iter \u003d\n+                fs.listLocatedStatus(globStat.getPath());\n+            while (iter.hasNext()) {\n+              LocatedFileStatus stat \u003d iter.next();\n+              if (inputFilter.accept(stat.getPath())) {\n+                if (recursive \u0026\u0026 stat.isDirectory()) {\n+                  addInputPathRecursively(result, fs, stat.getPath(),\n+                      inputFilter);\n+                } else {\n+                  result.add(stat);\n+                }\n               }\n-            }          \n+            }\n           } else {\n             result.add(globStat);\n           }\n         }\n       }\n     }\n \n     if (!errors.isEmpty()) {\n       throw new InvalidInputException(errors);\n     }\n     LOG.info(\"Total input paths to process : \" + result.size()); \n     return result;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected List\u003cFileStatus\u003e listStatus(JobContext job\n                                        ) throws IOException {\n    List\u003cFileStatus\u003e result \u003d new ArrayList\u003cFileStatus\u003e();\n    Path[] dirs \u003d getInputPaths(job);\n    if (dirs.length \u003d\u003d 0) {\n      throw new IOException(\"No input paths specified in job\");\n    }\n    \n    // get tokens for all the required FileSystems..\n    TokenCache.obtainTokensForNamenodes(job.getCredentials(), dirs, \n                                        job.getConfiguration());\n\n    // Whether we need to recursive look into the directory structure\n    boolean recursive \u003d getInputDirRecursive(job);\n    \n    List\u003cIOException\u003e errors \u003d new ArrayList\u003cIOException\u003e();\n    \n    // creates a MultiPathFilter with the hiddenFileFilter and the\n    // user provided one (if any).\n    List\u003cPathFilter\u003e filters \u003d new ArrayList\u003cPathFilter\u003e();\n    filters.add(hiddenFileFilter);\n    PathFilter jobFilter \u003d getInputPathFilter(job);\n    if (jobFilter !\u003d null) {\n      filters.add(jobFilter);\n    }\n    PathFilter inputFilter \u003d new MultiPathFilter(filters);\n    \n    for (int i\u003d0; i \u003c dirs.length; ++i) {\n      Path p \u003d dirs[i];\n      FileSystem fs \u003d p.getFileSystem(job.getConfiguration()); \n      FileStatus[] matches \u003d fs.globStatus(p, inputFilter);\n      if (matches \u003d\u003d null) {\n        errors.add(new IOException(\"Input path does not exist: \" + p));\n      } else if (matches.length \u003d\u003d 0) {\n        errors.add(new IOException(\"Input Pattern \" + p + \" matches 0 files\"));\n      } else {\n        for (FileStatus globStat: matches) {\n          if (globStat.isDirectory()) {\n            RemoteIterator\u003cLocatedFileStatus\u003e iter \u003d\n                fs.listLocatedStatus(globStat.getPath());\n            while (iter.hasNext()) {\n              LocatedFileStatus stat \u003d iter.next();\n              if (inputFilter.accept(stat.getPath())) {\n                if (recursive \u0026\u0026 stat.isDirectory()) {\n                  addInputPathRecursively(result, fs, stat.getPath(),\n                      inputFilter);\n                } else {\n                  result.add(stat);\n                }\n              }\n            }\n          } else {\n            result.add(globStat);\n          }\n        }\n      }\n    }\n\n    if (!errors.isEmpty()) {\n      throw new InvalidInputException(errors);\n    }\n    LOG.info(\"Total input paths to process : \" + result.size()); \n    return result;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/input/FileInputFormat.java",
      "extendedDetails": {}
    },
    "e846c98397518838bba22f24df0f0d9ef4f3e1ad": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3193. FileInputFormat doesn\u0027t read files recursively in the input path dir. Contributed by Devaraj K\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1499125 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/07/13 2:47 PM",
      "commitName": "e846c98397518838bba22f24df0f0d9ef4f3e1ad",
      "commitAuthor": "Jason Darrell Lowe",
      "commitDateOld": "30/05/13 4:53 PM",
      "commitNameOld": "4394e5edb0e87879036b97da7db6a20be2e111d3",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 32.91,
      "commitsBetweenForRepo": 234,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,52 +1,59 @@\n   protected List\u003cFileStatus\u003e listStatus(JobContext job\n                                         ) throws IOException {\n     List\u003cFileStatus\u003e result \u003d new ArrayList\u003cFileStatus\u003e();\n     Path[] dirs \u003d getInputPaths(job);\n     if (dirs.length \u003d\u003d 0) {\n       throw new IOException(\"No input paths specified in job\");\n     }\n     \n     // get tokens for all the required FileSystems..\n     TokenCache.obtainTokensForNamenodes(job.getCredentials(), dirs, \n                                         job.getConfiguration());\n \n+    // Whether we need to recursive look into the directory structure\n+    boolean recursive \u003d getInputDirRecursive(job);\n+    \n     List\u003cIOException\u003e errors \u003d new ArrayList\u003cIOException\u003e();\n     \n     // creates a MultiPathFilter with the hiddenFileFilter and the\n     // user provided one (if any).\n     List\u003cPathFilter\u003e filters \u003d new ArrayList\u003cPathFilter\u003e();\n     filters.add(hiddenFileFilter);\n     PathFilter jobFilter \u003d getInputPathFilter(job);\n     if (jobFilter !\u003d null) {\n       filters.add(jobFilter);\n     }\n     PathFilter inputFilter \u003d new MultiPathFilter(filters);\n     \n     for (int i\u003d0; i \u003c dirs.length; ++i) {\n       Path p \u003d dirs[i];\n       FileSystem fs \u003d p.getFileSystem(job.getConfiguration()); \n       FileStatus[] matches \u003d fs.globStatus(p, inputFilter);\n       if (matches \u003d\u003d null) {\n         errors.add(new IOException(\"Input path does not exist: \" + p));\n       } else if (matches.length \u003d\u003d 0) {\n         errors.add(new IOException(\"Input Pattern \" + p + \" matches 0 files\"));\n       } else {\n         for (FileStatus globStat: matches) {\n           if (globStat.isDirectory()) {\n             for(FileStatus stat: fs.listStatus(globStat.getPath(),\n                 inputFilter)) {\n-              result.add(stat);\n+              if (recursive \u0026\u0026 stat.isDirectory()) {\n+                addInputPathRecursively(result, fs, stat.getPath(), inputFilter);\n+              } else {\n+                result.add(stat);\n+              }\n             }          \n           } else {\n             result.add(globStat);\n           }\n         }\n       }\n     }\n \n     if (!errors.isEmpty()) {\n       throw new InvalidInputException(errors);\n     }\n     LOG.info(\"Total input paths to process : \" + result.size()); \n     return result;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected List\u003cFileStatus\u003e listStatus(JobContext job\n                                        ) throws IOException {\n    List\u003cFileStatus\u003e result \u003d new ArrayList\u003cFileStatus\u003e();\n    Path[] dirs \u003d getInputPaths(job);\n    if (dirs.length \u003d\u003d 0) {\n      throw new IOException(\"No input paths specified in job\");\n    }\n    \n    // get tokens for all the required FileSystems..\n    TokenCache.obtainTokensForNamenodes(job.getCredentials(), dirs, \n                                        job.getConfiguration());\n\n    // Whether we need to recursive look into the directory structure\n    boolean recursive \u003d getInputDirRecursive(job);\n    \n    List\u003cIOException\u003e errors \u003d new ArrayList\u003cIOException\u003e();\n    \n    // creates a MultiPathFilter with the hiddenFileFilter and the\n    // user provided one (if any).\n    List\u003cPathFilter\u003e filters \u003d new ArrayList\u003cPathFilter\u003e();\n    filters.add(hiddenFileFilter);\n    PathFilter jobFilter \u003d getInputPathFilter(job);\n    if (jobFilter !\u003d null) {\n      filters.add(jobFilter);\n    }\n    PathFilter inputFilter \u003d new MultiPathFilter(filters);\n    \n    for (int i\u003d0; i \u003c dirs.length; ++i) {\n      Path p \u003d dirs[i];\n      FileSystem fs \u003d p.getFileSystem(job.getConfiguration()); \n      FileStatus[] matches \u003d fs.globStatus(p, inputFilter);\n      if (matches \u003d\u003d null) {\n        errors.add(new IOException(\"Input path does not exist: \" + p));\n      } else if (matches.length \u003d\u003d 0) {\n        errors.add(new IOException(\"Input Pattern \" + p + \" matches 0 files\"));\n      } else {\n        for (FileStatus globStat: matches) {\n          if (globStat.isDirectory()) {\n            for(FileStatus stat: fs.listStatus(globStat.getPath(),\n                inputFilter)) {\n              if (recursive \u0026\u0026 stat.isDirectory()) {\n                addInputPathRecursively(result, fs, stat.getPath(), inputFilter);\n              } else {\n                result.add(stat);\n              }\n            }          \n          } else {\n            result.add(globStat);\n          }\n        }\n      }\n    }\n\n    if (!errors.isEmpty()) {\n      throw new InvalidInputException(errors);\n    }\n    LOG.info(\"Total input paths to process : \" + result.size()); \n    return result;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/input/FileInputFormat.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  protected List\u003cFileStatus\u003e listStatus(JobContext job\n                                        ) throws IOException {\n    List\u003cFileStatus\u003e result \u003d new ArrayList\u003cFileStatus\u003e();\n    Path[] dirs \u003d getInputPaths(job);\n    if (dirs.length \u003d\u003d 0) {\n      throw new IOException(\"No input paths specified in job\");\n    }\n    \n    // get tokens for all the required FileSystems..\n    TokenCache.obtainTokensForNamenodes(job.getCredentials(), dirs, \n                                        job.getConfiguration());\n\n    List\u003cIOException\u003e errors \u003d new ArrayList\u003cIOException\u003e();\n    \n    // creates a MultiPathFilter with the hiddenFileFilter and the\n    // user provided one (if any).\n    List\u003cPathFilter\u003e filters \u003d new ArrayList\u003cPathFilter\u003e();\n    filters.add(hiddenFileFilter);\n    PathFilter jobFilter \u003d getInputPathFilter(job);\n    if (jobFilter !\u003d null) {\n      filters.add(jobFilter);\n    }\n    PathFilter inputFilter \u003d new MultiPathFilter(filters);\n    \n    for (int i\u003d0; i \u003c dirs.length; ++i) {\n      Path p \u003d dirs[i];\n      FileSystem fs \u003d p.getFileSystem(job.getConfiguration()); \n      FileStatus[] matches \u003d fs.globStatus(p, inputFilter);\n      if (matches \u003d\u003d null) {\n        errors.add(new IOException(\"Input path does not exist: \" + p));\n      } else if (matches.length \u003d\u003d 0) {\n        errors.add(new IOException(\"Input Pattern \" + p + \" matches 0 files\"));\n      } else {\n        for (FileStatus globStat: matches) {\n          if (globStat.isDirectory()) {\n            for(FileStatus stat: fs.listStatus(globStat.getPath(),\n                inputFilter)) {\n              result.add(stat);\n            }          \n          } else {\n            result.add(globStat);\n          }\n        }\n      }\n    }\n\n    if (!errors.isEmpty()) {\n      throw new InvalidInputException(errors);\n    }\n    LOG.info(\"Total input paths to process : \" + result.size()); \n    return result;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/input/FileInputFormat.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/input/FileInputFormat.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/input/FileInputFormat.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yfilerename",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "17/08/11 8:02 PM",
      "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.34,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  protected List\u003cFileStatus\u003e listStatus(JobContext job\n                                        ) throws IOException {\n    List\u003cFileStatus\u003e result \u003d new ArrayList\u003cFileStatus\u003e();\n    Path[] dirs \u003d getInputPaths(job);\n    if (dirs.length \u003d\u003d 0) {\n      throw new IOException(\"No input paths specified in job\");\n    }\n    \n    // get tokens for all the required FileSystems..\n    TokenCache.obtainTokensForNamenodes(job.getCredentials(), dirs, \n                                        job.getConfiguration());\n\n    List\u003cIOException\u003e errors \u003d new ArrayList\u003cIOException\u003e();\n    \n    // creates a MultiPathFilter with the hiddenFileFilter and the\n    // user provided one (if any).\n    List\u003cPathFilter\u003e filters \u003d new ArrayList\u003cPathFilter\u003e();\n    filters.add(hiddenFileFilter);\n    PathFilter jobFilter \u003d getInputPathFilter(job);\n    if (jobFilter !\u003d null) {\n      filters.add(jobFilter);\n    }\n    PathFilter inputFilter \u003d new MultiPathFilter(filters);\n    \n    for (int i\u003d0; i \u003c dirs.length; ++i) {\n      Path p \u003d dirs[i];\n      FileSystem fs \u003d p.getFileSystem(job.getConfiguration()); \n      FileStatus[] matches \u003d fs.globStatus(p, inputFilter);\n      if (matches \u003d\u003d null) {\n        errors.add(new IOException(\"Input path does not exist: \" + p));\n      } else if (matches.length \u003d\u003d 0) {\n        errors.add(new IOException(\"Input Pattern \" + p + \" matches 0 files\"));\n      } else {\n        for (FileStatus globStat: matches) {\n          if (globStat.isDirectory()) {\n            for(FileStatus stat: fs.listStatus(globStat.getPath(),\n                inputFilter)) {\n              result.add(stat);\n            }          \n          } else {\n            result.add(globStat);\n          }\n        }\n      }\n    }\n\n    if (!errors.isEmpty()) {\n      throw new InvalidInputException(errors);\n    }\n    LOG.info(\"Total input paths to process : \" + result.size()); \n    return result;\n  }",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/input/FileInputFormat.java",
      "extendedDetails": {
        "oldPath": "mapreduce/src/java/org/apache/hadoop/mapreduce/lib/input/FileInputFormat.java",
        "newPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/input/FileInputFormat.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,52 @@\n+  protected List\u003cFileStatus\u003e listStatus(JobContext job\n+                                        ) throws IOException {\n+    List\u003cFileStatus\u003e result \u003d new ArrayList\u003cFileStatus\u003e();\n+    Path[] dirs \u003d getInputPaths(job);\n+    if (dirs.length \u003d\u003d 0) {\n+      throw new IOException(\"No input paths specified in job\");\n+    }\n+    \n+    // get tokens for all the required FileSystems..\n+    TokenCache.obtainTokensForNamenodes(job.getCredentials(), dirs, \n+                                        job.getConfiguration());\n+\n+    List\u003cIOException\u003e errors \u003d new ArrayList\u003cIOException\u003e();\n+    \n+    // creates a MultiPathFilter with the hiddenFileFilter and the\n+    // user provided one (if any).\n+    List\u003cPathFilter\u003e filters \u003d new ArrayList\u003cPathFilter\u003e();\n+    filters.add(hiddenFileFilter);\n+    PathFilter jobFilter \u003d getInputPathFilter(job);\n+    if (jobFilter !\u003d null) {\n+      filters.add(jobFilter);\n+    }\n+    PathFilter inputFilter \u003d new MultiPathFilter(filters);\n+    \n+    for (int i\u003d0; i \u003c dirs.length; ++i) {\n+      Path p \u003d dirs[i];\n+      FileSystem fs \u003d p.getFileSystem(job.getConfiguration()); \n+      FileStatus[] matches \u003d fs.globStatus(p, inputFilter);\n+      if (matches \u003d\u003d null) {\n+        errors.add(new IOException(\"Input path does not exist: \" + p));\n+      } else if (matches.length \u003d\u003d 0) {\n+        errors.add(new IOException(\"Input Pattern \" + p + \" matches 0 files\"));\n+      } else {\n+        for (FileStatus globStat: matches) {\n+          if (globStat.isDirectory()) {\n+            for(FileStatus stat: fs.listStatus(globStat.getPath(),\n+                inputFilter)) {\n+              result.add(stat);\n+            }          \n+          } else {\n+            result.add(globStat);\n+          }\n+        }\n+      }\n+    }\n+\n+    if (!errors.isEmpty()) {\n+      throw new InvalidInputException(errors);\n+    }\n+    LOG.info(\"Total input paths to process : \" + result.size()); \n+    return result;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  protected List\u003cFileStatus\u003e listStatus(JobContext job\n                                        ) throws IOException {\n    List\u003cFileStatus\u003e result \u003d new ArrayList\u003cFileStatus\u003e();\n    Path[] dirs \u003d getInputPaths(job);\n    if (dirs.length \u003d\u003d 0) {\n      throw new IOException(\"No input paths specified in job\");\n    }\n    \n    // get tokens for all the required FileSystems..\n    TokenCache.obtainTokensForNamenodes(job.getCredentials(), dirs, \n                                        job.getConfiguration());\n\n    List\u003cIOException\u003e errors \u003d new ArrayList\u003cIOException\u003e();\n    \n    // creates a MultiPathFilter with the hiddenFileFilter and the\n    // user provided one (if any).\n    List\u003cPathFilter\u003e filters \u003d new ArrayList\u003cPathFilter\u003e();\n    filters.add(hiddenFileFilter);\n    PathFilter jobFilter \u003d getInputPathFilter(job);\n    if (jobFilter !\u003d null) {\n      filters.add(jobFilter);\n    }\n    PathFilter inputFilter \u003d new MultiPathFilter(filters);\n    \n    for (int i\u003d0; i \u003c dirs.length; ++i) {\n      Path p \u003d dirs[i];\n      FileSystem fs \u003d p.getFileSystem(job.getConfiguration()); \n      FileStatus[] matches \u003d fs.globStatus(p, inputFilter);\n      if (matches \u003d\u003d null) {\n        errors.add(new IOException(\"Input path does not exist: \" + p));\n      } else if (matches.length \u003d\u003d 0) {\n        errors.add(new IOException(\"Input Pattern \" + p + \" matches 0 files\"));\n      } else {\n        for (FileStatus globStat: matches) {\n          if (globStat.isDirectory()) {\n            for(FileStatus stat: fs.listStatus(globStat.getPath(),\n                inputFilter)) {\n              result.add(stat);\n            }          \n          } else {\n            result.add(globStat);\n          }\n        }\n      }\n    }\n\n    if (!errors.isEmpty()) {\n      throw new InvalidInputException(errors);\n    }\n    LOG.info(\"Total input paths to process : \" + result.size()); \n    return result;\n  }",
      "path": "mapreduce/src/java/org/apache/hadoop/mapreduce/lib/input/FileInputFormat.java"
    }
  }
}