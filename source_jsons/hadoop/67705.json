{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "RetriableFileCopyCommand.java",
  "functionName": "copyBytes",
  "functionId": "copyBytes___source2-CopyListingFileStatus__sourceOffset-long__outStream-OutputStream__bufferSize-int__context-Mapper.Context",
  "sourceFilePath": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/RetriableFileCopyCommand.java",
  "functionStartLine": 274,
  "functionEndLine": 314,
  "numCommitsSeen": 56,
  "timeTaken": 5924,
  "changeHistory": [
    "51c64b357d4bd1a0038e61df3d4b8ea0a3ad7449",
    "3e3963b035911703c61e6d9a2939eb894da5644c",
    "3bd6b1fd85c44354c777ef4fda6415231505b2a4",
    "bf3fb585aaf2b179836e139c041fc87920a3c886",
    "144f1cf76527e6c75aec77ef683a898580f3cc8d",
    "064c8b25eca9bc825dc07a54d9147d65c9290a03",
    "a1a0281e12ea96476e75b076f76d5b5eb5254eea",
    "3671a5e16fbddbe5a0516289ce98e1305e02291c",
    "9ea61e44153b938309841b1499488360e9abd176",
    "718f0f92a9074cb9574bc9ae629b042e60626d34",
    "d06948002fb0cabf72cc0d46bf2fa67d45370f67"
  ],
  "changeHistoryShort": {
    "51c64b357d4bd1a0038e61df3d4b8ea0a3ad7449": "Ybodychange",
    "3e3963b035911703c61e6d9a2939eb894da5644c": "Ybodychange",
    "3bd6b1fd85c44354c777ef4fda6415231505b2a4": "Ybodychange",
    "bf3fb585aaf2b179836e139c041fc87920a3c886": "Ybodychange",
    "144f1cf76527e6c75aec77ef683a898580f3cc8d": "Ybodychange",
    "064c8b25eca9bc825dc07a54d9147d65c9290a03": "Ybodychange",
    "a1a0281e12ea96476e75b076f76d5b5eb5254eea": "Ymultichange(Yparameterchange,Ybodychange)",
    "3671a5e16fbddbe5a0516289ce98e1305e02291c": "Ymultichange(Yparameterchange,Ybodychange)",
    "9ea61e44153b938309841b1499488360e9abd176": "Ymultichange(Ymodifierchange,Ybodychange)",
    "718f0f92a9074cb9574bc9ae629b042e60626d34": "Ymultichange(Yparameterchange,Ybodychange)",
    "d06948002fb0cabf72cc0d46bf2fa67d45370f67": "Yintroduced"
  },
  "changeHistoryDetails": {
    "51c64b357d4bd1a0038e61df3d4b8ea0a3ad7449": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13660. DistCp job fails when new data is appended in the file while the DistCp copy job is running\n\nThis uses the length of the file known at the start of the copy to determine the amount of data to copy.\n\n* If a file is appended to during the copy, the original bytes are copied.\n* If a file is truncated during a copy, or the attempt to read the data fails with a truncated stream,\n  distcp will now fail. Until now these failures were not detected.\n\nContributed by Mukund Thakur.\n\nChange-Id: I576a49d951fa48d37a45a7e4c82c47488aa8e884\n",
      "commitDate": "24/09/19 3:23 AM",
      "commitName": "51c64b357d4bd1a0038e61df3d4b8ea0a3ad7449",
      "commitAuthor": "Mukund Thakur",
      "commitDateOld": "18/08/19 6:46 PM",
      "commitNameOld": "c765584eb231f8482f5b90b7e8f61f9f7a931d09",
      "commitAuthorOld": "KAI XIE",
      "daysBetweenCommits": 36.36,
      "commitsBetweenForRepo": 313,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,41 @@\n   long copyBytes(CopyListingFileStatus source2, long sourceOffset,\n       OutputStream outStream, int bufferSize, Mapper.Context context)\n       throws IOException {\n     Path source \u003d source2.getPath();\n     byte buf[] \u003d new byte[bufferSize];\n     ThrottledInputStream inStream \u003d null;\n     long totalBytesRead \u003d 0;\n \n     long chunkLength \u003d source2.getChunkLength();\n     boolean finished \u003d false;\n     try {\n       inStream \u003d getInputStream(source, context.getConfiguration());\n+      long fileLength \u003d source2.getLen();\n+      int numBytesToRead  \u003d (int) getNumBytesToRead(fileLength, sourceOffset,\n+              bufferSize);\n       seekIfRequired(inStream, sourceOffset);\n-      int bytesRead \u003d readBytes(inStream, buf);\n-      while (bytesRead \u003e\u003d 0) {\n+      int bytesRead \u003d readBytes(inStream, buf, numBytesToRead);\n+      while (bytesRead \u003e 0) {\n         if (chunkLength \u003e 0 \u0026\u0026\n             (totalBytesRead + bytesRead) \u003e\u003d chunkLength) {\n           bytesRead \u003d (int)(chunkLength - totalBytesRead);\n           finished \u003d true;\n         }\n         totalBytesRead +\u003d bytesRead;\n-        if (action \u003d\u003d FileAction.APPEND) {\n-          sourceOffset +\u003d bytesRead;\n-        }\n+        sourceOffset +\u003d bytesRead;\n         outStream.write(buf, 0, bytesRead);\n         updateContextStatus(totalBytesRead, context, source2);\n         if (finished) {\n           break;\n         }\n-        bytesRead \u003d readBytes(inStream, buf);\n+        numBytesToRead  \u003d (int) getNumBytesToRead(fileLength, sourceOffset,\n+                bufferSize);\n+        bytesRead \u003d readBytes(inStream, buf, numBytesToRead);\n       }\n       outStream.close();\n       outStream \u003d null;\n     } finally {\n       IOUtils.cleanupWithLogger(LOG, outStream, inStream);\n     }\n     return totalBytesRead;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  long copyBytes(CopyListingFileStatus source2, long sourceOffset,\n      OutputStream outStream, int bufferSize, Mapper.Context context)\n      throws IOException {\n    Path source \u003d source2.getPath();\n    byte buf[] \u003d new byte[bufferSize];\n    ThrottledInputStream inStream \u003d null;\n    long totalBytesRead \u003d 0;\n\n    long chunkLength \u003d source2.getChunkLength();\n    boolean finished \u003d false;\n    try {\n      inStream \u003d getInputStream(source, context.getConfiguration());\n      long fileLength \u003d source2.getLen();\n      int numBytesToRead  \u003d (int) getNumBytesToRead(fileLength, sourceOffset,\n              bufferSize);\n      seekIfRequired(inStream, sourceOffset);\n      int bytesRead \u003d readBytes(inStream, buf, numBytesToRead);\n      while (bytesRead \u003e 0) {\n        if (chunkLength \u003e 0 \u0026\u0026\n            (totalBytesRead + bytesRead) \u003e\u003d chunkLength) {\n          bytesRead \u003d (int)(chunkLength - totalBytesRead);\n          finished \u003d true;\n        }\n        totalBytesRead +\u003d bytesRead;\n        sourceOffset +\u003d bytesRead;\n        outStream.write(buf, 0, bytesRead);\n        updateContextStatus(totalBytesRead, context, source2);\n        if (finished) {\n          break;\n        }\n        numBytesToRead  \u003d (int) getNumBytesToRead(fileLength, sourceOffset,\n                bufferSize);\n        bytesRead \u003d readBytes(inStream, buf, numBytesToRead);\n      }\n      outStream.close();\n      outStream \u003d null;\n    } finally {\n      IOUtils.cleanupWithLogger(LOG, outStream, inStream);\n    }\n    return totalBytesRead;\n  }",
      "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/RetriableFileCopyCommand.java",
      "extendedDetails": {}
    },
    "3e3963b035911703c61e6d9a2939eb894da5644c": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-15552. Move logging APIs over to slf4j in hadoop-tools - Part2. Contributed by Ian Pickering.\n",
      "commitDate": "15/08/18 8:31 AM",
      "commitName": "3e3963b035911703c61e6d9a2939eb894da5644c",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "08/03/18 3:24 AM",
      "commitNameOld": "7ef4d942dd96232b0743a40ed25f77065254f94d",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 160.17,
      "commitsBetweenForRepo": 1801,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,38 @@\n   long copyBytes(CopyListingFileStatus source2, long sourceOffset,\n       OutputStream outStream, int bufferSize, Mapper.Context context)\n       throws IOException {\n     Path source \u003d source2.getPath();\n     byte buf[] \u003d new byte[bufferSize];\n     ThrottledInputStream inStream \u003d null;\n     long totalBytesRead \u003d 0;\n \n     long chunkLength \u003d source2.getChunkLength();\n     boolean finished \u003d false;\n     try {\n       inStream \u003d getInputStream(source, context.getConfiguration());\n       seekIfRequired(inStream, sourceOffset);\n       int bytesRead \u003d readBytes(inStream, buf);\n       while (bytesRead \u003e\u003d 0) {\n         if (chunkLength \u003e 0 \u0026\u0026\n             (totalBytesRead + bytesRead) \u003e\u003d chunkLength) {\n           bytesRead \u003d (int)(chunkLength - totalBytesRead);\n           finished \u003d true;\n         }\n         totalBytesRead +\u003d bytesRead;\n         if (action \u003d\u003d FileAction.APPEND) {\n           sourceOffset +\u003d bytesRead;\n         }\n         outStream.write(buf, 0, bytesRead);\n         updateContextStatus(totalBytesRead, context, source2);\n         if (finished) {\n           break;\n         }\n         bytesRead \u003d readBytes(inStream, buf);\n       }\n       outStream.close();\n       outStream \u003d null;\n     } finally {\n-      IOUtils.cleanup(LOG, outStream, inStream);\n+      IOUtils.cleanupWithLogger(LOG, outStream, inStream);\n     }\n     return totalBytesRead;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  long copyBytes(CopyListingFileStatus source2, long sourceOffset,\n      OutputStream outStream, int bufferSize, Mapper.Context context)\n      throws IOException {\n    Path source \u003d source2.getPath();\n    byte buf[] \u003d new byte[bufferSize];\n    ThrottledInputStream inStream \u003d null;\n    long totalBytesRead \u003d 0;\n\n    long chunkLength \u003d source2.getChunkLength();\n    boolean finished \u003d false;\n    try {\n      inStream \u003d getInputStream(source, context.getConfiguration());\n      seekIfRequired(inStream, sourceOffset);\n      int bytesRead \u003d readBytes(inStream, buf);\n      while (bytesRead \u003e\u003d 0) {\n        if (chunkLength \u003e 0 \u0026\u0026\n            (totalBytesRead + bytesRead) \u003e\u003d chunkLength) {\n          bytesRead \u003d (int)(chunkLength - totalBytesRead);\n          finished \u003d true;\n        }\n        totalBytesRead +\u003d bytesRead;\n        if (action \u003d\u003d FileAction.APPEND) {\n          sourceOffset +\u003d bytesRead;\n        }\n        outStream.write(buf, 0, bytesRead);\n        updateContextStatus(totalBytesRead, context, source2);\n        if (finished) {\n          break;\n        }\n        bytesRead \u003d readBytes(inStream, buf);\n      }\n      outStream.close();\n      outStream \u003d null;\n    } finally {\n      IOUtils.cleanupWithLogger(LOG, outStream, inStream);\n    }\n    return totalBytesRead;\n  }",
      "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/RetriableFileCopyCommand.java",
      "extendedDetails": {}
    },
    "3bd6b1fd85c44354c777ef4fda6415231505b2a4": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-15292. Distcp\u0027s use of pread is slowing it down.\nContributed by Virajith Jalaparti.\n",
      "commitDate": "08/03/18 3:15 AM",
      "commitName": "3bd6b1fd85c44354c777ef4fda6415231505b2a4",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "18/05/17 3:35 PM",
      "commitNameOld": "b4adc8392c1314d6d6fbdd00f2afb306ef20a650",
      "commitAuthorOld": "Yongjun Zhang",
      "daysBetweenCommits": 293.53,
      "commitsBetweenForRepo": 2009,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,37 +1,38 @@\n   long copyBytes(CopyListingFileStatus source2, long sourceOffset,\n       OutputStream outStream, int bufferSize, Mapper.Context context)\n       throws IOException {\n     Path source \u003d source2.getPath();\n     byte buf[] \u003d new byte[bufferSize];\n     ThrottledInputStream inStream \u003d null;\n     long totalBytesRead \u003d 0;\n \n     long chunkLength \u003d source2.getChunkLength();\n     boolean finished \u003d false;\n     try {\n       inStream \u003d getInputStream(source, context.getConfiguration());\n-      int bytesRead \u003d readBytes(inStream, buf, sourceOffset);\n+      seekIfRequired(inStream, sourceOffset);\n+      int bytesRead \u003d readBytes(inStream, buf);\n       while (bytesRead \u003e\u003d 0) {\n         if (chunkLength \u003e 0 \u0026\u0026\n             (totalBytesRead + bytesRead) \u003e\u003d chunkLength) {\n           bytesRead \u003d (int)(chunkLength - totalBytesRead);\n           finished \u003d true;\n         }\n         totalBytesRead +\u003d bytesRead;\n         if (action \u003d\u003d FileAction.APPEND) {\n           sourceOffset +\u003d bytesRead;\n         }\n         outStream.write(buf, 0, bytesRead);\n         updateContextStatus(totalBytesRead, context, source2);\n         if (finished) {\n           break;\n         }\n-        bytesRead \u003d readBytes(inStream, buf, sourceOffset);\n+        bytesRead \u003d readBytes(inStream, buf);\n       }\n       outStream.close();\n       outStream \u003d null;\n     } finally {\n       IOUtils.cleanup(LOG, outStream, inStream);\n     }\n     return totalBytesRead;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  long copyBytes(CopyListingFileStatus source2, long sourceOffset,\n      OutputStream outStream, int bufferSize, Mapper.Context context)\n      throws IOException {\n    Path source \u003d source2.getPath();\n    byte buf[] \u003d new byte[bufferSize];\n    ThrottledInputStream inStream \u003d null;\n    long totalBytesRead \u003d 0;\n\n    long chunkLength \u003d source2.getChunkLength();\n    boolean finished \u003d false;\n    try {\n      inStream \u003d getInputStream(source, context.getConfiguration());\n      seekIfRequired(inStream, sourceOffset);\n      int bytesRead \u003d readBytes(inStream, buf);\n      while (bytesRead \u003e\u003d 0) {\n        if (chunkLength \u003e 0 \u0026\u0026\n            (totalBytesRead + bytesRead) \u003e\u003d chunkLength) {\n          bytesRead \u003d (int)(chunkLength - totalBytesRead);\n          finished \u003d true;\n        }\n        totalBytesRead +\u003d bytesRead;\n        if (action \u003d\u003d FileAction.APPEND) {\n          sourceOffset +\u003d bytesRead;\n        }\n        outStream.write(buf, 0, bytesRead);\n        updateContextStatus(totalBytesRead, context, source2);\n        if (finished) {\n          break;\n        }\n        bytesRead \u003d readBytes(inStream, buf);\n      }\n      outStream.close();\n      outStream \u003d null;\n    } finally {\n      IOUtils.cleanup(LOG, outStream, inStream);\n    }\n    return totalBytesRead;\n  }",
      "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/RetriableFileCopyCommand.java",
      "extendedDetails": {}
    },
    "bf3fb585aaf2b179836e139c041fc87920a3c886": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-11794. Enable distcp to copy blocks in parallel. Contributed by Yongjun Zhang, Wei-Chiu Chuang, Xiao Chen, Rosie Li.\n",
      "commitDate": "30/03/17 5:38 PM",
      "commitName": "bf3fb585aaf2b179836e139c041fc87920a3c886",
      "commitAuthor": "Yongjun Zhang",
      "commitDateOld": "30/03/17 5:38 PM",
      "commitNameOld": "144f1cf76527e6c75aec77ef683a898580f3cc8d",
      "commitAuthorOld": "Yongjun Zhang",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,27 +1,37 @@\n   long copyBytes(CopyListingFileStatus source2, long sourceOffset,\n       OutputStream outStream, int bufferSize, Mapper.Context context)\n       throws IOException {\n     Path source \u003d source2.getPath();\n     byte buf[] \u003d new byte[bufferSize];\n     ThrottledInputStream inStream \u003d null;\n     long totalBytesRead \u003d 0;\n \n+    long chunkLength \u003d source2.getChunkLength();\n+    boolean finished \u003d false;\n     try {\n       inStream \u003d getInputStream(source, context.getConfiguration());\n       int bytesRead \u003d readBytes(inStream, buf, sourceOffset);\n       while (bytesRead \u003e\u003d 0) {\n+        if (chunkLength \u003e 0 \u0026\u0026\n+            (totalBytesRead + bytesRead) \u003e\u003d chunkLength) {\n+          bytesRead \u003d (int)(chunkLength - totalBytesRead);\n+          finished \u003d true;\n+        }\n         totalBytesRead +\u003d bytesRead;\n         if (action \u003d\u003d FileAction.APPEND) {\n           sourceOffset +\u003d bytesRead;\n         }\n         outStream.write(buf, 0, bytesRead);\n         updateContextStatus(totalBytesRead, context, source2);\n+        if (finished) {\n+          break;\n+        }\n         bytesRead \u003d readBytes(inStream, buf, sourceOffset);\n       }\n       outStream.close();\n       outStream \u003d null;\n     } finally {\n       IOUtils.cleanup(LOG, outStream, inStream);\n     }\n     return totalBytesRead;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  long copyBytes(CopyListingFileStatus source2, long sourceOffset,\n      OutputStream outStream, int bufferSize, Mapper.Context context)\n      throws IOException {\n    Path source \u003d source2.getPath();\n    byte buf[] \u003d new byte[bufferSize];\n    ThrottledInputStream inStream \u003d null;\n    long totalBytesRead \u003d 0;\n\n    long chunkLength \u003d source2.getChunkLength();\n    boolean finished \u003d false;\n    try {\n      inStream \u003d getInputStream(source, context.getConfiguration());\n      int bytesRead \u003d readBytes(inStream, buf, sourceOffset);\n      while (bytesRead \u003e\u003d 0) {\n        if (chunkLength \u003e 0 \u0026\u0026\n            (totalBytesRead + bytesRead) \u003e\u003d chunkLength) {\n          bytesRead \u003d (int)(chunkLength - totalBytesRead);\n          finished \u003d true;\n        }\n        totalBytesRead +\u003d bytesRead;\n        if (action \u003d\u003d FileAction.APPEND) {\n          sourceOffset +\u003d bytesRead;\n        }\n        outStream.write(buf, 0, bytesRead);\n        updateContextStatus(totalBytesRead, context, source2);\n        if (finished) {\n          break;\n        }\n        bytesRead \u003d readBytes(inStream, buf, sourceOffset);\n      }\n      outStream.close();\n      outStream \u003d null;\n    } finally {\n      IOUtils.cleanup(LOG, outStream, inStream);\n    }\n    return totalBytesRead;\n  }",
      "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/RetriableFileCopyCommand.java",
      "extendedDetails": {}
    },
    "144f1cf76527e6c75aec77ef683a898580f3cc8d": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HADOOP-11794. Enable distcp to copy blocks in parallel. Contributed by Yongjun Zhang, Wei-Chiu Chuang, Xiao Chen.\"\n\nThis reverts commit 064c8b25eca9bc825dc07a54d9147d65c9290a03.\n",
      "commitDate": "30/03/17 5:38 PM",
      "commitName": "144f1cf76527e6c75aec77ef683a898580f3cc8d",
      "commitAuthor": "Yongjun Zhang",
      "commitDateOld": "30/03/17 5:01 PM",
      "commitNameOld": "064c8b25eca9bc825dc07a54d9147d65c9290a03",
      "commitAuthorOld": "Yongjun Zhang",
      "daysBetweenCommits": 0.03,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,37 +1,27 @@\n   long copyBytes(CopyListingFileStatus source2, long sourceOffset,\n       OutputStream outStream, int bufferSize, Mapper.Context context)\n       throws IOException {\n     Path source \u003d source2.getPath();\n     byte buf[] \u003d new byte[bufferSize];\n     ThrottledInputStream inStream \u003d null;\n     long totalBytesRead \u003d 0;\n \n-    long chunkLength \u003d source2.getChunkLength();\n-    boolean finished \u003d false;\n     try {\n       inStream \u003d getInputStream(source, context.getConfiguration());\n       int bytesRead \u003d readBytes(inStream, buf, sourceOffset);\n       while (bytesRead \u003e\u003d 0) {\n-        if (chunkLength \u003e 0 \u0026\u0026\n-            (totalBytesRead + bytesRead) \u003e\u003d chunkLength) {\n-          bytesRead \u003d (int)(chunkLength - totalBytesRead);\n-          finished \u003d true;\n-        }\n         totalBytesRead +\u003d bytesRead;\n         if (action \u003d\u003d FileAction.APPEND) {\n           sourceOffset +\u003d bytesRead;\n         }\n         outStream.write(buf, 0, bytesRead);\n         updateContextStatus(totalBytesRead, context, source2);\n-        if (finished) {\n-          break;\n-        }\n         bytesRead \u003d readBytes(inStream, buf, sourceOffset);\n       }\n       outStream.close();\n       outStream \u003d null;\n     } finally {\n       IOUtils.cleanup(LOG, outStream, inStream);\n     }\n     return totalBytesRead;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  long copyBytes(CopyListingFileStatus source2, long sourceOffset,\n      OutputStream outStream, int bufferSize, Mapper.Context context)\n      throws IOException {\n    Path source \u003d source2.getPath();\n    byte buf[] \u003d new byte[bufferSize];\n    ThrottledInputStream inStream \u003d null;\n    long totalBytesRead \u003d 0;\n\n    try {\n      inStream \u003d getInputStream(source, context.getConfiguration());\n      int bytesRead \u003d readBytes(inStream, buf, sourceOffset);\n      while (bytesRead \u003e\u003d 0) {\n        totalBytesRead +\u003d bytesRead;\n        if (action \u003d\u003d FileAction.APPEND) {\n          sourceOffset +\u003d bytesRead;\n        }\n        outStream.write(buf, 0, bytesRead);\n        updateContextStatus(totalBytesRead, context, source2);\n        bytesRead \u003d readBytes(inStream, buf, sourceOffset);\n      }\n      outStream.close();\n      outStream \u003d null;\n    } finally {\n      IOUtils.cleanup(LOG, outStream, inStream);\n    }\n    return totalBytesRead;\n  }",
      "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/RetriableFileCopyCommand.java",
      "extendedDetails": {}
    },
    "064c8b25eca9bc825dc07a54d9147d65c9290a03": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-11794. Enable distcp to copy blocks in parallel. Contributed by Yongjun Zhang, Wei-Chiu Chuang, Xiao Chen.\n",
      "commitDate": "30/03/17 5:01 PM",
      "commitName": "064c8b25eca9bc825dc07a54d9147d65c9290a03",
      "commitAuthor": "Yongjun Zhang",
      "commitDateOld": "28/03/17 10:14 PM",
      "commitNameOld": "0e6f8e4bc6642f90dc7b33848bfb1129ec20ee49",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 1.78,
      "commitsBetweenForRepo": 19,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,27 +1,37 @@\n   long copyBytes(CopyListingFileStatus source2, long sourceOffset,\n       OutputStream outStream, int bufferSize, Mapper.Context context)\n       throws IOException {\n     Path source \u003d source2.getPath();\n     byte buf[] \u003d new byte[bufferSize];\n     ThrottledInputStream inStream \u003d null;\n     long totalBytesRead \u003d 0;\n \n+    long chunkLength \u003d source2.getChunkLength();\n+    boolean finished \u003d false;\n     try {\n       inStream \u003d getInputStream(source, context.getConfiguration());\n       int bytesRead \u003d readBytes(inStream, buf, sourceOffset);\n       while (bytesRead \u003e\u003d 0) {\n+        if (chunkLength \u003e 0 \u0026\u0026\n+            (totalBytesRead + bytesRead) \u003e\u003d chunkLength) {\n+          bytesRead \u003d (int)(chunkLength - totalBytesRead);\n+          finished \u003d true;\n+        }\n         totalBytesRead +\u003d bytesRead;\n         if (action \u003d\u003d FileAction.APPEND) {\n           sourceOffset +\u003d bytesRead;\n         }\n         outStream.write(buf, 0, bytesRead);\n         updateContextStatus(totalBytesRead, context, source2);\n+        if (finished) {\n+          break;\n+        }\n         bytesRead \u003d readBytes(inStream, buf, sourceOffset);\n       }\n       outStream.close();\n       outStream \u003d null;\n     } finally {\n       IOUtils.cleanup(LOG, outStream, inStream);\n     }\n     return totalBytesRead;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  long copyBytes(CopyListingFileStatus source2, long sourceOffset,\n      OutputStream outStream, int bufferSize, Mapper.Context context)\n      throws IOException {\n    Path source \u003d source2.getPath();\n    byte buf[] \u003d new byte[bufferSize];\n    ThrottledInputStream inStream \u003d null;\n    long totalBytesRead \u003d 0;\n\n    long chunkLength \u003d source2.getChunkLength();\n    boolean finished \u003d false;\n    try {\n      inStream \u003d getInputStream(source, context.getConfiguration());\n      int bytesRead \u003d readBytes(inStream, buf, sourceOffset);\n      while (bytesRead \u003e\u003d 0) {\n        if (chunkLength \u003e 0 \u0026\u0026\n            (totalBytesRead + bytesRead) \u003e\u003d chunkLength) {\n          bytesRead \u003d (int)(chunkLength - totalBytesRead);\n          finished \u003d true;\n        }\n        totalBytesRead +\u003d bytesRead;\n        if (action \u003d\u003d FileAction.APPEND) {\n          sourceOffset +\u003d bytesRead;\n        }\n        outStream.write(buf, 0, bytesRead);\n        updateContextStatus(totalBytesRead, context, source2);\n        if (finished) {\n          break;\n        }\n        bytesRead \u003d readBytes(inStream, buf, sourceOffset);\n      }\n      outStream.close();\n      outStream \u003d null;\n    } finally {\n      IOUtils.cleanup(LOG, outStream, inStream);\n    }\n    return totalBytesRead;\n  }",
      "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/RetriableFileCopyCommand.java",
      "extendedDetails": {}
    },
    "a1a0281e12ea96476e75b076f76d5b5eb5254eea": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HADOOP-13626. Remove distcp dependency on FileStatus serialization\n",
      "commitDate": "24/10/16 12:46 PM",
      "commitName": "a1a0281e12ea96476e75b076f76d5b5eb5254eea",
      "commitAuthor": "Chris Douglas",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HADOOP-13626. Remove distcp dependency on FileStatus serialization\n",
          "commitDate": "24/10/16 12:46 PM",
          "commitName": "a1a0281e12ea96476e75b076f76d5b5eb5254eea",
          "commitAuthor": "Chris Douglas",
          "commitDateOld": "11/01/16 9:46 AM",
          "commitNameOld": "95f32015ad9273420299130a9f10acdbafe63556",
          "commitAuthorOld": "Zhe Zhang",
          "daysBetweenCommits": 287.08,
          "commitsBetweenForRepo": 2025,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,27 +1,27 @@\n-  long copyBytes(FileStatus sourceFileStatus, long sourceOffset,\n+  long copyBytes(CopyListingFileStatus source2, long sourceOffset,\n       OutputStream outStream, int bufferSize, Mapper.Context context)\n       throws IOException {\n-    Path source \u003d sourceFileStatus.getPath();\n+    Path source \u003d source2.getPath();\n     byte buf[] \u003d new byte[bufferSize];\n     ThrottledInputStream inStream \u003d null;\n     long totalBytesRead \u003d 0;\n \n     try {\n       inStream \u003d getInputStream(source, context.getConfiguration());\n       int bytesRead \u003d readBytes(inStream, buf, sourceOffset);\n       while (bytesRead \u003e\u003d 0) {\n         totalBytesRead +\u003d bytesRead;\n         if (action \u003d\u003d FileAction.APPEND) {\n           sourceOffset +\u003d bytesRead;\n         }\n         outStream.write(buf, 0, bytesRead);\n-        updateContextStatus(totalBytesRead, context, sourceFileStatus);\n+        updateContextStatus(totalBytesRead, context, source2);\n         bytesRead \u003d readBytes(inStream, buf, sourceOffset);\n       }\n       outStream.close();\n       outStream \u003d null;\n     } finally {\n       IOUtils.cleanup(LOG, outStream, inStream);\n     }\n     return totalBytesRead;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  long copyBytes(CopyListingFileStatus source2, long sourceOffset,\n      OutputStream outStream, int bufferSize, Mapper.Context context)\n      throws IOException {\n    Path source \u003d source2.getPath();\n    byte buf[] \u003d new byte[bufferSize];\n    ThrottledInputStream inStream \u003d null;\n    long totalBytesRead \u003d 0;\n\n    try {\n      inStream \u003d getInputStream(source, context.getConfiguration());\n      int bytesRead \u003d readBytes(inStream, buf, sourceOffset);\n      while (bytesRead \u003e\u003d 0) {\n        totalBytesRead +\u003d bytesRead;\n        if (action \u003d\u003d FileAction.APPEND) {\n          sourceOffset +\u003d bytesRead;\n        }\n        outStream.write(buf, 0, bytesRead);\n        updateContextStatus(totalBytesRead, context, source2);\n        bytesRead \u003d readBytes(inStream, buf, sourceOffset);\n      }\n      outStream.close();\n      outStream \u003d null;\n    } finally {\n      IOUtils.cleanup(LOG, outStream, inStream);\n    }\n    return totalBytesRead;\n  }",
          "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/RetriableFileCopyCommand.java",
          "extendedDetails": {
            "oldValue": "[sourceFileStatus-FileStatus, sourceOffset-long, outStream-OutputStream, bufferSize-int, context-Mapper.Context]",
            "newValue": "[source2-CopyListingFileStatus, sourceOffset-long, outStream-OutputStream, bufferSize-int, context-Mapper.Context]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-13626. Remove distcp dependency on FileStatus serialization\n",
          "commitDate": "24/10/16 12:46 PM",
          "commitName": "a1a0281e12ea96476e75b076f76d5b5eb5254eea",
          "commitAuthor": "Chris Douglas",
          "commitDateOld": "11/01/16 9:46 AM",
          "commitNameOld": "95f32015ad9273420299130a9f10acdbafe63556",
          "commitAuthorOld": "Zhe Zhang",
          "daysBetweenCommits": 287.08,
          "commitsBetweenForRepo": 2025,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,27 +1,27 @@\n-  long copyBytes(FileStatus sourceFileStatus, long sourceOffset,\n+  long copyBytes(CopyListingFileStatus source2, long sourceOffset,\n       OutputStream outStream, int bufferSize, Mapper.Context context)\n       throws IOException {\n-    Path source \u003d sourceFileStatus.getPath();\n+    Path source \u003d source2.getPath();\n     byte buf[] \u003d new byte[bufferSize];\n     ThrottledInputStream inStream \u003d null;\n     long totalBytesRead \u003d 0;\n \n     try {\n       inStream \u003d getInputStream(source, context.getConfiguration());\n       int bytesRead \u003d readBytes(inStream, buf, sourceOffset);\n       while (bytesRead \u003e\u003d 0) {\n         totalBytesRead +\u003d bytesRead;\n         if (action \u003d\u003d FileAction.APPEND) {\n           sourceOffset +\u003d bytesRead;\n         }\n         outStream.write(buf, 0, bytesRead);\n-        updateContextStatus(totalBytesRead, context, sourceFileStatus);\n+        updateContextStatus(totalBytesRead, context, source2);\n         bytesRead \u003d readBytes(inStream, buf, sourceOffset);\n       }\n       outStream.close();\n       outStream \u003d null;\n     } finally {\n       IOUtils.cleanup(LOG, outStream, inStream);\n     }\n     return totalBytesRead;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  long copyBytes(CopyListingFileStatus source2, long sourceOffset,\n      OutputStream outStream, int bufferSize, Mapper.Context context)\n      throws IOException {\n    Path source \u003d source2.getPath();\n    byte buf[] \u003d new byte[bufferSize];\n    ThrottledInputStream inStream \u003d null;\n    long totalBytesRead \u003d 0;\n\n    try {\n      inStream \u003d getInputStream(source, context.getConfiguration());\n      int bytesRead \u003d readBytes(inStream, buf, sourceOffset);\n      while (bytesRead \u003e\u003d 0) {\n        totalBytesRead +\u003d bytesRead;\n        if (action \u003d\u003d FileAction.APPEND) {\n          sourceOffset +\u003d bytesRead;\n        }\n        outStream.write(buf, 0, bytesRead);\n        updateContextStatus(totalBytesRead, context, source2);\n        bytesRead \u003d readBytes(inStream, buf, sourceOffset);\n      }\n      outStream.close();\n      outStream \u003d null;\n    } finally {\n      IOUtils.cleanup(LOG, outStream, inStream);\n    }\n    return totalBytesRead;\n  }",
          "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/RetriableFileCopyCommand.java",
          "extendedDetails": {}
        }
      ]
    },
    "3671a5e16fbddbe5a0516289ce98e1305e02291c": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "MAPREDUCE-5899. Support incremental data copy in DistCp. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1596931 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/05/14 11:17 AM",
      "commitName": "3671a5e16fbddbe5a0516289ce98e1305e02291c",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "MAPREDUCE-5899. Support incremental data copy in DistCp. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1596931 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "22/05/14 11:17 AM",
          "commitName": "3671a5e16fbddbe5a0516289ce98e1305e02291c",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "30/01/14 3:53 PM",
          "commitNameOld": "067d52b98c1d17a73b142bb53acc8aaa9c041f38",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 111.77,
          "commitsBetweenForRepo": 836,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,25 +1,27 @@\n-  long copyBytes(FileStatus sourceFileStatus, OutputStream outStream,\n-                         int bufferSize, Mapper.Context context)\n+  long copyBytes(FileStatus sourceFileStatus, long sourceOffset,\n+      OutputStream outStream, int bufferSize, Mapper.Context context)\n       throws IOException {\n     Path source \u003d sourceFileStatus.getPath();\n     byte buf[] \u003d new byte[bufferSize];\n     ThrottledInputStream inStream \u003d null;\n     long totalBytesRead \u003d 0;\n \n     try {\n       inStream \u003d getInputStream(source, context.getConfiguration());\n-      int bytesRead \u003d readBytes(inStream, buf);\n+      int bytesRead \u003d readBytes(inStream, buf, sourceOffset);\n       while (bytesRead \u003e\u003d 0) {\n         totalBytesRead +\u003d bytesRead;\n+        if (action \u003d\u003d FileAction.APPEND) {\n+          sourceOffset +\u003d bytesRead;\n+        }\n         outStream.write(buf, 0, bytesRead);\n         updateContextStatus(totalBytesRead, context, sourceFileStatus);\n-        bytesRead \u003d inStream.read(buf);\n+        bytesRead \u003d readBytes(inStream, buf, sourceOffset);\n       }\n       outStream.close();\n       outStream \u003d null;\n     } finally {\n       IOUtils.cleanup(LOG, outStream, inStream);\n     }\n-\n     return totalBytesRead;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  long copyBytes(FileStatus sourceFileStatus, long sourceOffset,\n      OutputStream outStream, int bufferSize, Mapper.Context context)\n      throws IOException {\n    Path source \u003d sourceFileStatus.getPath();\n    byte buf[] \u003d new byte[bufferSize];\n    ThrottledInputStream inStream \u003d null;\n    long totalBytesRead \u003d 0;\n\n    try {\n      inStream \u003d getInputStream(source, context.getConfiguration());\n      int bytesRead \u003d readBytes(inStream, buf, sourceOffset);\n      while (bytesRead \u003e\u003d 0) {\n        totalBytesRead +\u003d bytesRead;\n        if (action \u003d\u003d FileAction.APPEND) {\n          sourceOffset +\u003d bytesRead;\n        }\n        outStream.write(buf, 0, bytesRead);\n        updateContextStatus(totalBytesRead, context, sourceFileStatus);\n        bytesRead \u003d readBytes(inStream, buf, sourceOffset);\n      }\n      outStream.close();\n      outStream \u003d null;\n    } finally {\n      IOUtils.cleanup(LOG, outStream, inStream);\n    }\n    return totalBytesRead;\n  }",
          "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/RetriableFileCopyCommand.java",
          "extendedDetails": {
            "oldValue": "[sourceFileStatus-FileStatus, outStream-OutputStream, bufferSize-int, context-Mapper.Context]",
            "newValue": "[sourceFileStatus-FileStatus, sourceOffset-long, outStream-OutputStream, bufferSize-int, context-Mapper.Context]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-5899. Support incremental data copy in DistCp. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1596931 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "22/05/14 11:17 AM",
          "commitName": "3671a5e16fbddbe5a0516289ce98e1305e02291c",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "30/01/14 3:53 PM",
          "commitNameOld": "067d52b98c1d17a73b142bb53acc8aaa9c041f38",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 111.77,
          "commitsBetweenForRepo": 836,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,25 +1,27 @@\n-  long copyBytes(FileStatus sourceFileStatus, OutputStream outStream,\n-                         int bufferSize, Mapper.Context context)\n+  long copyBytes(FileStatus sourceFileStatus, long sourceOffset,\n+      OutputStream outStream, int bufferSize, Mapper.Context context)\n       throws IOException {\n     Path source \u003d sourceFileStatus.getPath();\n     byte buf[] \u003d new byte[bufferSize];\n     ThrottledInputStream inStream \u003d null;\n     long totalBytesRead \u003d 0;\n \n     try {\n       inStream \u003d getInputStream(source, context.getConfiguration());\n-      int bytesRead \u003d readBytes(inStream, buf);\n+      int bytesRead \u003d readBytes(inStream, buf, sourceOffset);\n       while (bytesRead \u003e\u003d 0) {\n         totalBytesRead +\u003d bytesRead;\n+        if (action \u003d\u003d FileAction.APPEND) {\n+          sourceOffset +\u003d bytesRead;\n+        }\n         outStream.write(buf, 0, bytesRead);\n         updateContextStatus(totalBytesRead, context, sourceFileStatus);\n-        bytesRead \u003d inStream.read(buf);\n+        bytesRead \u003d readBytes(inStream, buf, sourceOffset);\n       }\n       outStream.close();\n       outStream \u003d null;\n     } finally {\n       IOUtils.cleanup(LOG, outStream, inStream);\n     }\n-\n     return totalBytesRead;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  long copyBytes(FileStatus sourceFileStatus, long sourceOffset,\n      OutputStream outStream, int bufferSize, Mapper.Context context)\n      throws IOException {\n    Path source \u003d sourceFileStatus.getPath();\n    byte buf[] \u003d new byte[bufferSize];\n    ThrottledInputStream inStream \u003d null;\n    long totalBytesRead \u003d 0;\n\n    try {\n      inStream \u003d getInputStream(source, context.getConfiguration());\n      int bytesRead \u003d readBytes(inStream, buf, sourceOffset);\n      while (bytesRead \u003e\u003d 0) {\n        totalBytesRead +\u003d bytesRead;\n        if (action \u003d\u003d FileAction.APPEND) {\n          sourceOffset +\u003d bytesRead;\n        }\n        outStream.write(buf, 0, bytesRead);\n        updateContextStatus(totalBytesRead, context, sourceFileStatus);\n        bytesRead \u003d readBytes(inStream, buf, sourceOffset);\n      }\n      outStream.close();\n      outStream \u003d null;\n    } finally {\n      IOUtils.cleanup(LOG, outStream, inStream);\n    }\n    return totalBytesRead;\n  }",
          "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/RetriableFileCopyCommand.java",
          "extendedDetails": {}
        }
      ]
    },
    "9ea61e44153b938309841b1499488360e9abd176": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "HADOOP-10129. Distcp may succeed when it fails (daryn)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1548175 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "05/12/13 7:47 AM",
      "commitName": "9ea61e44153b938309841b1499488360e9abd176",
      "commitAuthor": "Daryn Sharp",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "HADOOP-10129. Distcp may succeed when it fails (daryn)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1548175 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "05/12/13 7:47 AM",
          "commitName": "9ea61e44153b938309841b1499488360e9abd176",
          "commitAuthor": "Daryn Sharp",
          "commitDateOld": "16/04/13 3:01 PM",
          "commitNameOld": "2e789dd9a6ec5784c98efcde17e9f64f410bcd53",
          "commitAuthorOld": "Kihwal Lee",
          "daysBetweenCommits": 232.74,
          "commitsBetweenForRepo": 1449,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,23 +1,25 @@\n-  private long copyBytes(FileStatus sourceFileStatus, OutputStream outStream,\n+  long copyBytes(FileStatus sourceFileStatus, OutputStream outStream,\n                          int bufferSize, Mapper.Context context)\n       throws IOException {\n     Path source \u003d sourceFileStatus.getPath();\n     byte buf[] \u003d new byte[bufferSize];\n     ThrottledInputStream inStream \u003d null;\n     long totalBytesRead \u003d 0;\n \n     try {\n       inStream \u003d getInputStream(source, context.getConfiguration());\n       int bytesRead \u003d readBytes(inStream, buf);\n       while (bytesRead \u003e\u003d 0) {\n         totalBytesRead +\u003d bytesRead;\n         outStream.write(buf, 0, bytesRead);\n         updateContextStatus(totalBytesRead, context, sourceFileStatus);\n         bytesRead \u003d inStream.read(buf);\n       }\n+      outStream.close();\n+      outStream \u003d null;\n     } finally {\n       IOUtils.cleanup(LOG, outStream, inStream);\n     }\n \n     return totalBytesRead;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  long copyBytes(FileStatus sourceFileStatus, OutputStream outStream,\n                         int bufferSize, Mapper.Context context)\n      throws IOException {\n    Path source \u003d sourceFileStatus.getPath();\n    byte buf[] \u003d new byte[bufferSize];\n    ThrottledInputStream inStream \u003d null;\n    long totalBytesRead \u003d 0;\n\n    try {\n      inStream \u003d getInputStream(source, context.getConfiguration());\n      int bytesRead \u003d readBytes(inStream, buf);\n      while (bytesRead \u003e\u003d 0) {\n        totalBytesRead +\u003d bytesRead;\n        outStream.write(buf, 0, bytesRead);\n        updateContextStatus(totalBytesRead, context, sourceFileStatus);\n        bytesRead \u003d inStream.read(buf);\n      }\n      outStream.close();\n      outStream \u003d null;\n    } finally {\n      IOUtils.cleanup(LOG, outStream, inStream);\n    }\n\n    return totalBytesRead;\n  }",
          "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/RetriableFileCopyCommand.java",
          "extendedDetails": {
            "oldValue": "[private]",
            "newValue": "[]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-10129. Distcp may succeed when it fails (daryn)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1548175 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "05/12/13 7:47 AM",
          "commitName": "9ea61e44153b938309841b1499488360e9abd176",
          "commitAuthor": "Daryn Sharp",
          "commitDateOld": "16/04/13 3:01 PM",
          "commitNameOld": "2e789dd9a6ec5784c98efcde17e9f64f410bcd53",
          "commitAuthorOld": "Kihwal Lee",
          "daysBetweenCommits": 232.74,
          "commitsBetweenForRepo": 1449,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,23 +1,25 @@\n-  private long copyBytes(FileStatus sourceFileStatus, OutputStream outStream,\n+  long copyBytes(FileStatus sourceFileStatus, OutputStream outStream,\n                          int bufferSize, Mapper.Context context)\n       throws IOException {\n     Path source \u003d sourceFileStatus.getPath();\n     byte buf[] \u003d new byte[bufferSize];\n     ThrottledInputStream inStream \u003d null;\n     long totalBytesRead \u003d 0;\n \n     try {\n       inStream \u003d getInputStream(source, context.getConfiguration());\n       int bytesRead \u003d readBytes(inStream, buf);\n       while (bytesRead \u003e\u003d 0) {\n         totalBytesRead +\u003d bytesRead;\n         outStream.write(buf, 0, bytesRead);\n         updateContextStatus(totalBytesRead, context, sourceFileStatus);\n         bytesRead \u003d inStream.read(buf);\n       }\n+      outStream.close();\n+      outStream \u003d null;\n     } finally {\n       IOUtils.cleanup(LOG, outStream, inStream);\n     }\n \n     return totalBytesRead;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  long copyBytes(FileStatus sourceFileStatus, OutputStream outStream,\n                         int bufferSize, Mapper.Context context)\n      throws IOException {\n    Path source \u003d sourceFileStatus.getPath();\n    byte buf[] \u003d new byte[bufferSize];\n    ThrottledInputStream inStream \u003d null;\n    long totalBytesRead \u003d 0;\n\n    try {\n      inStream \u003d getInputStream(source, context.getConfiguration());\n      int bytesRead \u003d readBytes(inStream, buf);\n      while (bytesRead \u003e\u003d 0) {\n        totalBytesRead +\u003d bytesRead;\n        outStream.write(buf, 0, bytesRead);\n        updateContextStatus(totalBytesRead, context, sourceFileStatus);\n        bytesRead \u003d inStream.read(buf);\n      }\n      outStream.close();\n      outStream \u003d null;\n    } finally {\n      IOUtils.cleanup(LOG, outStream, inStream);\n    }\n\n    return totalBytesRead;\n  }",
          "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/RetriableFileCopyCommand.java",
          "extendedDetails": {}
        }
      ]
    },
    "718f0f92a9074cb9574bc9ae629b042e60626d34": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "MAPREDUCE-5075. DistCp leaks input file handles since ThrottledInputStream does not close the wrapped InputStream.  Contributed by Chris Nauroth\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1458741 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/03/13 3:40 AM",
      "commitName": "718f0f92a9074cb9574bc9ae629b042e60626d34",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "MAPREDUCE-5075. DistCp leaks input file handles since ThrottledInputStream does not close the wrapped InputStream.  Contributed by Chris Nauroth\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1458741 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "20/03/13 3:40 AM",
          "commitName": "718f0f92a9074cb9574bc9ae629b042e60626d34",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "05/09/12 11:54 AM",
          "commitNameOld": "e57843e02a846e5b3bb19c4bf9c3f61675d3e8ff",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 195.66,
          "commitsBetweenForRepo": 950,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,23 @@\n   private long copyBytes(FileStatus sourceFileStatus, OutputStream outStream,\n-                         int bufferSize, boolean mustCloseStream,\n-                         Mapper.Context context) throws IOException {\n+                         int bufferSize, Mapper.Context context)\n+      throws IOException {\n     Path source \u003d sourceFileStatus.getPath();\n     byte buf[] \u003d new byte[bufferSize];\n     ThrottledInputStream inStream \u003d null;\n     long totalBytesRead \u003d 0;\n \n     try {\n       inStream \u003d getInputStream(source, context.getConfiguration());\n       int bytesRead \u003d readBytes(inStream, buf);\n       while (bytesRead \u003e\u003d 0) {\n         totalBytesRead +\u003d bytesRead;\n         outStream.write(buf, 0, bytesRead);\n         updateContextStatus(totalBytesRead, context, sourceFileStatus);\n         bytesRead \u003d inStream.read(buf);\n       }\n     } finally {\n-      if (mustCloseStream)\n-        IOUtils.cleanup(LOG, outStream, inStream);\n+      IOUtils.cleanup(LOG, outStream, inStream);\n     }\n \n     return totalBytesRead;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private long copyBytes(FileStatus sourceFileStatus, OutputStream outStream,\n                         int bufferSize, Mapper.Context context)\n      throws IOException {\n    Path source \u003d sourceFileStatus.getPath();\n    byte buf[] \u003d new byte[bufferSize];\n    ThrottledInputStream inStream \u003d null;\n    long totalBytesRead \u003d 0;\n\n    try {\n      inStream \u003d getInputStream(source, context.getConfiguration());\n      int bytesRead \u003d readBytes(inStream, buf);\n      while (bytesRead \u003e\u003d 0) {\n        totalBytesRead +\u003d bytesRead;\n        outStream.write(buf, 0, bytesRead);\n        updateContextStatus(totalBytesRead, context, sourceFileStatus);\n        bytesRead \u003d inStream.read(buf);\n      }\n    } finally {\n      IOUtils.cleanup(LOG, outStream, inStream);\n    }\n\n    return totalBytesRead;\n  }",
          "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/RetriableFileCopyCommand.java",
          "extendedDetails": {
            "oldValue": "[sourceFileStatus-FileStatus, outStream-OutputStream, bufferSize-int, mustCloseStream-boolean, context-Mapper.Context]",
            "newValue": "[sourceFileStatus-FileStatus, outStream-OutputStream, bufferSize-int, context-Mapper.Context]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-5075. DistCp leaks input file handles since ThrottledInputStream does not close the wrapped InputStream.  Contributed by Chris Nauroth\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1458741 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "20/03/13 3:40 AM",
          "commitName": "718f0f92a9074cb9574bc9ae629b042e60626d34",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "05/09/12 11:54 AM",
          "commitNameOld": "e57843e02a846e5b3bb19c4bf9c3f61675d3e8ff",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 195.66,
          "commitsBetweenForRepo": 950,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,23 @@\n   private long copyBytes(FileStatus sourceFileStatus, OutputStream outStream,\n-                         int bufferSize, boolean mustCloseStream,\n-                         Mapper.Context context) throws IOException {\n+                         int bufferSize, Mapper.Context context)\n+      throws IOException {\n     Path source \u003d sourceFileStatus.getPath();\n     byte buf[] \u003d new byte[bufferSize];\n     ThrottledInputStream inStream \u003d null;\n     long totalBytesRead \u003d 0;\n \n     try {\n       inStream \u003d getInputStream(source, context.getConfiguration());\n       int bytesRead \u003d readBytes(inStream, buf);\n       while (bytesRead \u003e\u003d 0) {\n         totalBytesRead +\u003d bytesRead;\n         outStream.write(buf, 0, bytesRead);\n         updateContextStatus(totalBytesRead, context, sourceFileStatus);\n         bytesRead \u003d inStream.read(buf);\n       }\n     } finally {\n-      if (mustCloseStream)\n-        IOUtils.cleanup(LOG, outStream, inStream);\n+      IOUtils.cleanup(LOG, outStream, inStream);\n     }\n \n     return totalBytesRead;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private long copyBytes(FileStatus sourceFileStatus, OutputStream outStream,\n                         int bufferSize, Mapper.Context context)\n      throws IOException {\n    Path source \u003d sourceFileStatus.getPath();\n    byte buf[] \u003d new byte[bufferSize];\n    ThrottledInputStream inStream \u003d null;\n    long totalBytesRead \u003d 0;\n\n    try {\n      inStream \u003d getInputStream(source, context.getConfiguration());\n      int bytesRead \u003d readBytes(inStream, buf);\n      while (bytesRead \u003e\u003d 0) {\n        totalBytesRead +\u003d bytesRead;\n        outStream.write(buf, 0, bytesRead);\n        updateContextStatus(totalBytesRead, context, sourceFileStatus);\n        bytesRead \u003d inStream.read(buf);\n      }\n    } finally {\n      IOUtils.cleanup(LOG, outStream, inStream);\n    }\n\n    return totalBytesRead;\n  }",
          "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/RetriableFileCopyCommand.java",
          "extendedDetails": {}
        }
      ]
    },
    "d06948002fb0cabf72cc0d46bf2fa67d45370f67": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-2765. DistCp Rewrite. (Mithun Radhakrishnan via mahadev)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1236045 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/01/12 10:36 PM",
      "commitName": "d06948002fb0cabf72cc0d46bf2fa67d45370f67",
      "commitAuthor": "Mahadev Konar",
      "diff": "@@ -0,0 +1,24 @@\n+  private long copyBytes(FileStatus sourceFileStatus, OutputStream outStream,\n+                         int bufferSize, boolean mustCloseStream,\n+                         Mapper.Context context) throws IOException {\n+    Path source \u003d sourceFileStatus.getPath();\n+    byte buf[] \u003d new byte[bufferSize];\n+    ThrottledInputStream inStream \u003d null;\n+    long totalBytesRead \u003d 0;\n+\n+    try {\n+      inStream \u003d getInputStream(source, context.getConfiguration());\n+      int bytesRead \u003d readBytes(inStream, buf);\n+      while (bytesRead \u003e\u003d 0) {\n+        totalBytesRead +\u003d bytesRead;\n+        outStream.write(buf, 0, bytesRead);\n+        updateContextStatus(totalBytesRead, context, sourceFileStatus);\n+        bytesRead \u003d inStream.read(buf);\n+      }\n+    } finally {\n+      if (mustCloseStream)\n+        IOUtils.cleanup(LOG, outStream, inStream);\n+    }\n+\n+    return totalBytesRead;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private long copyBytes(FileStatus sourceFileStatus, OutputStream outStream,\n                         int bufferSize, boolean mustCloseStream,\n                         Mapper.Context context) throws IOException {\n    Path source \u003d sourceFileStatus.getPath();\n    byte buf[] \u003d new byte[bufferSize];\n    ThrottledInputStream inStream \u003d null;\n    long totalBytesRead \u003d 0;\n\n    try {\n      inStream \u003d getInputStream(source, context.getConfiguration());\n      int bytesRead \u003d readBytes(inStream, buf);\n      while (bytesRead \u003e\u003d 0) {\n        totalBytesRead +\u003d bytesRead;\n        outStream.write(buf, 0, bytesRead);\n        updateContextStatus(totalBytesRead, context, sourceFileStatus);\n        bytesRead \u003d inStream.read(buf);\n      }\n    } finally {\n      if (mustCloseStream)\n        IOUtils.cleanup(LOG, outStream, inStream);\n    }\n\n    return totalBytesRead;\n  }",
      "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/RetriableFileCopyCommand.java"
    }
  }
}