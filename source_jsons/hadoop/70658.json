{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "AzureNativeFileSystemStore.java",
  "functionName": "configureAzureStorageSession",
  "functionId": "configureAzureStorageSession",
  "sourceFilePath": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/AzureNativeFileSystemStore.java",
  "functionStartLine": 724,
  "functionEndLine": 831,
  "numCommitsSeen": 53,
  "timeTaken": 3671,
  "changeHistory": [
    "45d9568aaaf532a6da11bd7c1844ff81bf66bab1",
    "778d4edd9adbe9519c3d6df65e45ddc8bb0ab2da",
    "d670c3a4da7dd80dccf6c6308603bb3bb013b3b0",
    "5f6edb30c2bb648d5564c951edc25645e17e6636",
    "cb8e69a80cecb95abdfc93a787bea0bedef275ed",
    "2217e2f8ff418b88eac6ad36cafe3a9795a11f40",
    "81bc395deb3ba00567dc067d6ca71bacf9e3bc82"
  ],
  "changeHistoryShort": {
    "45d9568aaaf532a6da11bd7c1844ff81bf66bab1": "Ybodychange",
    "778d4edd9adbe9519c3d6df65e45ddc8bb0ab2da": "Ybodychange",
    "d670c3a4da7dd80dccf6c6308603bb3bb013b3b0": "Ybodychange",
    "5f6edb30c2bb648d5564c951edc25645e17e6636": "Ybodychange",
    "cb8e69a80cecb95abdfc93a787bea0bedef275ed": "Ybodychange",
    "2217e2f8ff418b88eac6ad36cafe3a9795a11f40": "Ybodychange",
    "81bc395deb3ba00567dc067d6ca71bacf9e3bc82": "Yintroduced"
  },
  "changeHistoryDetails": {
    "45d9568aaaf532a6da11bd7c1844ff81bf66bab1": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-15547/ WASB: improve listStatus performance.\nContributed by Thomas Marquardt.\n\n(cherry picked from commit 749fff577ed9afb4ef8a54b8948f74be083cc620)\n",
      "commitDate": "19/07/18 12:31 PM",
      "commitName": "45d9568aaaf532a6da11bd7c1844ff81bf66bab1",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "27/06/18 10:37 PM",
      "commitNameOld": "2b2399d623539ab68e71a38fa9fbfc9a405bddb8",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 21.58,
      "commitsBetweenForRepo": 124,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,106 +1,108 @@\n   private void configureAzureStorageSession() throws AzureException {\n \n     // Assertion: Target session URI already should have been captured.\n     if (sessionUri \u003d\u003d null) {\n       throw new AssertionError(\n           \"Expected a non-null session URI when configuring storage session\");\n     }\n \n     // Assertion: A client session already should have been established with\n     // Azure.\n     if (storageInteractionLayer \u003d\u003d null) {\n       throw new AssertionError(String.format(\n           \"Cannot configure storage session for URI \u0027%s\u0027 \"\n               + \"if storage session has not been established.\",\n           sessionUri.toString()));\n     }\n \n     // Determine whether or not reads are allowed concurrent with OOB writes.\n     tolerateOobAppends \u003d sessionConfiguration.getBoolean(\n         KEY_READ_TOLERATE_CONCURRENT_APPEND,\n         DEFAULT_READ_TOLERATE_CONCURRENT_APPEND);\n \n     // Retrieve configuration for the minimum stream read and write block size.\n     //\n     this.downloadBlockSizeBytes \u003d sessionConfiguration.getInt(\n         KEY_STREAM_MIN_READ_SIZE, DEFAULT_DOWNLOAD_BLOCK_SIZE);\n     this.uploadBlockSizeBytes \u003d sessionConfiguration.getInt(\n         KEY_WRITE_BLOCK_SIZE, DEFAULT_UPLOAD_BLOCK_SIZE);\n+    this.hadoopBlockSize \u003d sessionConfiguration.getLong(\n+        HADOOP_BLOCK_SIZE_PROPERTY_NAME, DEFAULT_HADOOP_BLOCK_SIZE);\n \n     this.inputStreamVersion \u003d sessionConfiguration.getInt(\n         KEY_INPUT_STREAM_VERSION, DEFAULT_INPUT_STREAM_VERSION);\n \n     // The job may want to specify a timeout to use when engaging the\n     // storage service. The default is currently 90 seconds. It may\n     // be necessary to increase this value for long latencies in larger\n     // jobs. If the timeout specified is greater than zero seconds use\n     // it, otherwise use the default service client timeout.\n     int storageConnectionTimeout \u003d sessionConfiguration.getInt(\n         KEY_STORAGE_CONNECTION_TIMEOUT, 0);\n \n     if (0 \u003c storageConnectionTimeout) {\n       storageInteractionLayer.setTimeoutInMs(storageConnectionTimeout * 1000);\n     }\n \n     // Set the concurrency values equal to the that specified in the\n     // configuration file. If it does not exist, set it to the default\n     // value calculated as double the number of CPU cores on the client\n     // machine. The concurrency value is minimum of double the cores and\n     // the read/write property.\n     int cpuCores \u003d 2 * Runtime.getRuntime().availableProcessors();\n \n     concurrentWrites \u003d sessionConfiguration.getInt(\n         KEY_CONCURRENT_CONNECTION_VALUE_OUT,\n         Math.min(cpuCores, DEFAULT_CONCURRENT_WRITES));\n \n     // Set up the exponential retry policy.\n     //\n     minBackoff \u003d sessionConfiguration.getInt(\n         KEY_MIN_BACKOFF_INTERVAL, DEFAULT_MIN_BACKOFF_INTERVAL);\n \n     maxBackoff \u003d sessionConfiguration.getInt(\n         KEY_MAX_BACKOFF_INTERVAL, DEFAULT_MAX_BACKOFF_INTERVAL);\n \n     deltaBackoff \u003d sessionConfiguration.getInt(\n         KEY_BACKOFF_INTERVAL, DEFAULT_BACKOFF_INTERVAL);\n \n     maxRetries \u003d sessionConfiguration.getInt(\n         KEY_MAX_IO_RETRIES, DEFAULT_MAX_RETRY_ATTEMPTS);\n \n     storageInteractionLayer.setRetryPolicyFactory(\n           new RetryExponentialRetry(minBackoff, deltaBackoff, maxBackoff, maxRetries));\n \n \n     // read the self-throttling config.\n     selfThrottlingEnabled \u003d sessionConfiguration.getBoolean(\n         KEY_SELF_THROTTLE_ENABLE, DEFAULT_SELF_THROTTLE_ENABLE);\n \n     selfThrottlingReadFactor \u003d sessionConfiguration.getFloat(\n         KEY_SELF_THROTTLE_READ_FACTOR, DEFAULT_SELF_THROTTLE_READ_FACTOR);\n \n     selfThrottlingWriteFactor \u003d sessionConfiguration.getFloat(\n         KEY_SELF_THROTTLE_WRITE_FACTOR, DEFAULT_SELF_THROTTLE_WRITE_FACTOR);\n \n     if (!selfThrottlingEnabled) {\n       autoThrottlingEnabled \u003d sessionConfiguration.getBoolean(\n           KEY_AUTO_THROTTLE_ENABLE,\n           DEFAULT_AUTO_THROTTLE_ENABLE);\n       if (autoThrottlingEnabled) {\n         ClientThrottlingIntercept.initializeSingleton();\n       }\n     } else {\n       // cannot enable both self-throttling and client-throttling\n       autoThrottlingEnabled \u003d false;\n     }\n \n     OperationContext.setLoggingEnabledByDefault(sessionConfiguration.\n         getBoolean(KEY_ENABLE_STORAGE_CLIENT_LOGGING, false));\n \n     LOG.debug(\n         \"AzureNativeFileSystemStore init. Settings\u003d{},{},{},{{},{},{},{}},{{},{},{}}\",\n         concurrentWrites, tolerateOobAppends,\n         ((storageConnectionTimeout \u003e 0) ? storageConnectionTimeout\n           : STORAGE_CONNECTION_TIMEOUT_DEFAULT), minBackoff,\n         deltaBackoff, maxBackoff, maxRetries, selfThrottlingEnabled,\n         selfThrottlingReadFactor, selfThrottlingWriteFactor);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void configureAzureStorageSession() throws AzureException {\n\n    // Assertion: Target session URI already should have been captured.\n    if (sessionUri \u003d\u003d null) {\n      throw new AssertionError(\n          \"Expected a non-null session URI when configuring storage session\");\n    }\n\n    // Assertion: A client session already should have been established with\n    // Azure.\n    if (storageInteractionLayer \u003d\u003d null) {\n      throw new AssertionError(String.format(\n          \"Cannot configure storage session for URI \u0027%s\u0027 \"\n              + \"if storage session has not been established.\",\n          sessionUri.toString()));\n    }\n\n    // Determine whether or not reads are allowed concurrent with OOB writes.\n    tolerateOobAppends \u003d sessionConfiguration.getBoolean(\n        KEY_READ_TOLERATE_CONCURRENT_APPEND,\n        DEFAULT_READ_TOLERATE_CONCURRENT_APPEND);\n\n    // Retrieve configuration for the minimum stream read and write block size.\n    //\n    this.downloadBlockSizeBytes \u003d sessionConfiguration.getInt(\n        KEY_STREAM_MIN_READ_SIZE, DEFAULT_DOWNLOAD_BLOCK_SIZE);\n    this.uploadBlockSizeBytes \u003d sessionConfiguration.getInt(\n        KEY_WRITE_BLOCK_SIZE, DEFAULT_UPLOAD_BLOCK_SIZE);\n    this.hadoopBlockSize \u003d sessionConfiguration.getLong(\n        HADOOP_BLOCK_SIZE_PROPERTY_NAME, DEFAULT_HADOOP_BLOCK_SIZE);\n\n    this.inputStreamVersion \u003d sessionConfiguration.getInt(\n        KEY_INPUT_STREAM_VERSION, DEFAULT_INPUT_STREAM_VERSION);\n\n    // The job may want to specify a timeout to use when engaging the\n    // storage service. The default is currently 90 seconds. It may\n    // be necessary to increase this value for long latencies in larger\n    // jobs. If the timeout specified is greater than zero seconds use\n    // it, otherwise use the default service client timeout.\n    int storageConnectionTimeout \u003d sessionConfiguration.getInt(\n        KEY_STORAGE_CONNECTION_TIMEOUT, 0);\n\n    if (0 \u003c storageConnectionTimeout) {\n      storageInteractionLayer.setTimeoutInMs(storageConnectionTimeout * 1000);\n    }\n\n    // Set the concurrency values equal to the that specified in the\n    // configuration file. If it does not exist, set it to the default\n    // value calculated as double the number of CPU cores on the client\n    // machine. The concurrency value is minimum of double the cores and\n    // the read/write property.\n    int cpuCores \u003d 2 * Runtime.getRuntime().availableProcessors();\n\n    concurrentWrites \u003d sessionConfiguration.getInt(\n        KEY_CONCURRENT_CONNECTION_VALUE_OUT,\n        Math.min(cpuCores, DEFAULT_CONCURRENT_WRITES));\n\n    // Set up the exponential retry policy.\n    //\n    minBackoff \u003d sessionConfiguration.getInt(\n        KEY_MIN_BACKOFF_INTERVAL, DEFAULT_MIN_BACKOFF_INTERVAL);\n\n    maxBackoff \u003d sessionConfiguration.getInt(\n        KEY_MAX_BACKOFF_INTERVAL, DEFAULT_MAX_BACKOFF_INTERVAL);\n\n    deltaBackoff \u003d sessionConfiguration.getInt(\n        KEY_BACKOFF_INTERVAL, DEFAULT_BACKOFF_INTERVAL);\n\n    maxRetries \u003d sessionConfiguration.getInt(\n        KEY_MAX_IO_RETRIES, DEFAULT_MAX_RETRY_ATTEMPTS);\n\n    storageInteractionLayer.setRetryPolicyFactory(\n          new RetryExponentialRetry(minBackoff, deltaBackoff, maxBackoff, maxRetries));\n\n\n    // read the self-throttling config.\n    selfThrottlingEnabled \u003d sessionConfiguration.getBoolean(\n        KEY_SELF_THROTTLE_ENABLE, DEFAULT_SELF_THROTTLE_ENABLE);\n\n    selfThrottlingReadFactor \u003d sessionConfiguration.getFloat(\n        KEY_SELF_THROTTLE_READ_FACTOR, DEFAULT_SELF_THROTTLE_READ_FACTOR);\n\n    selfThrottlingWriteFactor \u003d sessionConfiguration.getFloat(\n        KEY_SELF_THROTTLE_WRITE_FACTOR, DEFAULT_SELF_THROTTLE_WRITE_FACTOR);\n\n    if (!selfThrottlingEnabled) {\n      autoThrottlingEnabled \u003d sessionConfiguration.getBoolean(\n          KEY_AUTO_THROTTLE_ENABLE,\n          DEFAULT_AUTO_THROTTLE_ENABLE);\n      if (autoThrottlingEnabled) {\n        ClientThrottlingIntercept.initializeSingleton();\n      }\n    } else {\n      // cannot enable both self-throttling and client-throttling\n      autoThrottlingEnabled \u003d false;\n    }\n\n    OperationContext.setLoggingEnabledByDefault(sessionConfiguration.\n        getBoolean(KEY_ENABLE_STORAGE_CLIENT_LOGGING, false));\n\n    LOG.debug(\n        \"AzureNativeFileSystemStore init. Settings\u003d{},{},{},{{},{},{},{}},{{},{},{}}\",\n        concurrentWrites, tolerateOobAppends,\n        ((storageConnectionTimeout \u003e 0) ? storageConnectionTimeout\n          : STORAGE_CONNECTION_TIMEOUT_DEFAULT), minBackoff,\n        deltaBackoff, maxBackoff, maxRetries, selfThrottlingEnabled,\n        selfThrottlingReadFactor, selfThrottlingWriteFactor);\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/AzureNativeFileSystemStore.java",
      "extendedDetails": {}
    },
    "778d4edd9adbe9519c3d6df65e45ddc8bb0ab2da": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-14660 wasb: improve throughput by 34% when account limit exceeded.\nContributed by Thomas Marquardt.\n",
      "commitDate": "01/08/17 1:36 PM",
      "commitName": "778d4edd9adbe9519c3d6df65e45ddc8bb0ab2da",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "24/07/17 11:01 PM",
      "commitNameOld": "f2921e51f0fe613abce0a9f415a0d8ab6144aa6e",
      "commitAuthorOld": "Jitendra Pandey",
      "daysBetweenCommits": 7.61,
      "commitsBetweenForRepo": 46,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,94 +1,106 @@\n   private void configureAzureStorageSession() throws AzureException {\n \n     // Assertion: Target session URI already should have been captured.\n     if (sessionUri \u003d\u003d null) {\n       throw new AssertionError(\n           \"Expected a non-null session URI when configuring storage session\");\n     }\n \n     // Assertion: A client session already should have been established with\n     // Azure.\n     if (storageInteractionLayer \u003d\u003d null) {\n       throw new AssertionError(String.format(\n           \"Cannot configure storage session for URI \u0027%s\u0027 \"\n               + \"if storage session has not been established.\",\n           sessionUri.toString()));\n     }\n \n     // Determine whether or not reads are allowed concurrent with OOB writes.\n     tolerateOobAppends \u003d sessionConfiguration.getBoolean(\n         KEY_READ_TOLERATE_CONCURRENT_APPEND,\n         DEFAULT_READ_TOLERATE_CONCURRENT_APPEND);\n \n     // Retrieve configuration for the minimum stream read and write block size.\n     //\n     this.downloadBlockSizeBytes \u003d sessionConfiguration.getInt(\n         KEY_STREAM_MIN_READ_SIZE, DEFAULT_DOWNLOAD_BLOCK_SIZE);\n     this.uploadBlockSizeBytes \u003d sessionConfiguration.getInt(\n         KEY_WRITE_BLOCK_SIZE, DEFAULT_UPLOAD_BLOCK_SIZE);\n \n     this.inputStreamVersion \u003d sessionConfiguration.getInt(\n         KEY_INPUT_STREAM_VERSION, DEFAULT_INPUT_STREAM_VERSION);\n \n     // The job may want to specify a timeout to use when engaging the\n     // storage service. The default is currently 90 seconds. It may\n     // be necessary to increase this value for long latencies in larger\n     // jobs. If the timeout specified is greater than zero seconds use\n     // it, otherwise use the default service client timeout.\n     int storageConnectionTimeout \u003d sessionConfiguration.getInt(\n         KEY_STORAGE_CONNECTION_TIMEOUT, 0);\n \n     if (0 \u003c storageConnectionTimeout) {\n       storageInteractionLayer.setTimeoutInMs(storageConnectionTimeout * 1000);\n     }\n \n     // Set the concurrency values equal to the that specified in the\n     // configuration file. If it does not exist, set it to the default\n     // value calculated as double the number of CPU cores on the client\n     // machine. The concurrency value is minimum of double the cores and\n     // the read/write property.\n     int cpuCores \u003d 2 * Runtime.getRuntime().availableProcessors();\n \n     concurrentWrites \u003d sessionConfiguration.getInt(\n         KEY_CONCURRENT_CONNECTION_VALUE_OUT,\n         Math.min(cpuCores, DEFAULT_CONCURRENT_WRITES));\n \n     // Set up the exponential retry policy.\n     //\n     minBackoff \u003d sessionConfiguration.getInt(\n         KEY_MIN_BACKOFF_INTERVAL, DEFAULT_MIN_BACKOFF_INTERVAL);\n \n     maxBackoff \u003d sessionConfiguration.getInt(\n         KEY_MAX_BACKOFF_INTERVAL, DEFAULT_MAX_BACKOFF_INTERVAL);\n \n     deltaBackoff \u003d sessionConfiguration.getInt(\n         KEY_BACKOFF_INTERVAL, DEFAULT_BACKOFF_INTERVAL);\n \n     maxRetries \u003d sessionConfiguration.getInt(\n         KEY_MAX_IO_RETRIES, DEFAULT_MAX_RETRY_ATTEMPTS);\n \n     storageInteractionLayer.setRetryPolicyFactory(\n           new RetryExponentialRetry(minBackoff, deltaBackoff, maxBackoff, maxRetries));\n \n \n     // read the self-throttling config.\n     selfThrottlingEnabled \u003d sessionConfiguration.getBoolean(\n         KEY_SELF_THROTTLE_ENABLE, DEFAULT_SELF_THROTTLE_ENABLE);\n \n     selfThrottlingReadFactor \u003d sessionConfiguration.getFloat(\n         KEY_SELF_THROTTLE_READ_FACTOR, DEFAULT_SELF_THROTTLE_READ_FACTOR);\n \n     selfThrottlingWriteFactor \u003d sessionConfiguration.getFloat(\n         KEY_SELF_THROTTLE_WRITE_FACTOR, DEFAULT_SELF_THROTTLE_WRITE_FACTOR);\n \n+    if (!selfThrottlingEnabled) {\n+      autoThrottlingEnabled \u003d sessionConfiguration.getBoolean(\n+          KEY_AUTO_THROTTLE_ENABLE,\n+          DEFAULT_AUTO_THROTTLE_ENABLE);\n+      if (autoThrottlingEnabled) {\n+        ClientThrottlingIntercept.initializeSingleton();\n+      }\n+    } else {\n+      // cannot enable both self-throttling and client-throttling\n+      autoThrottlingEnabled \u003d false;\n+    }\n+\n     OperationContext.setLoggingEnabledByDefault(sessionConfiguration.\n         getBoolean(KEY_ENABLE_STORAGE_CLIENT_LOGGING, false));\n \n     LOG.debug(\n         \"AzureNativeFileSystemStore init. Settings\u003d{},{},{},{{},{},{},{}},{{},{},{}}\",\n         concurrentWrites, tolerateOobAppends,\n         ((storageConnectionTimeout \u003e 0) ? storageConnectionTimeout\n           : STORAGE_CONNECTION_TIMEOUT_DEFAULT), minBackoff,\n         deltaBackoff, maxBackoff, maxRetries, selfThrottlingEnabled,\n         selfThrottlingReadFactor, selfThrottlingWriteFactor);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void configureAzureStorageSession() throws AzureException {\n\n    // Assertion: Target session URI already should have been captured.\n    if (sessionUri \u003d\u003d null) {\n      throw new AssertionError(\n          \"Expected a non-null session URI when configuring storage session\");\n    }\n\n    // Assertion: A client session already should have been established with\n    // Azure.\n    if (storageInteractionLayer \u003d\u003d null) {\n      throw new AssertionError(String.format(\n          \"Cannot configure storage session for URI \u0027%s\u0027 \"\n              + \"if storage session has not been established.\",\n          sessionUri.toString()));\n    }\n\n    // Determine whether or not reads are allowed concurrent with OOB writes.\n    tolerateOobAppends \u003d sessionConfiguration.getBoolean(\n        KEY_READ_TOLERATE_CONCURRENT_APPEND,\n        DEFAULT_READ_TOLERATE_CONCURRENT_APPEND);\n\n    // Retrieve configuration for the minimum stream read and write block size.\n    //\n    this.downloadBlockSizeBytes \u003d sessionConfiguration.getInt(\n        KEY_STREAM_MIN_READ_SIZE, DEFAULT_DOWNLOAD_BLOCK_SIZE);\n    this.uploadBlockSizeBytes \u003d sessionConfiguration.getInt(\n        KEY_WRITE_BLOCK_SIZE, DEFAULT_UPLOAD_BLOCK_SIZE);\n\n    this.inputStreamVersion \u003d sessionConfiguration.getInt(\n        KEY_INPUT_STREAM_VERSION, DEFAULT_INPUT_STREAM_VERSION);\n\n    // The job may want to specify a timeout to use when engaging the\n    // storage service. The default is currently 90 seconds. It may\n    // be necessary to increase this value for long latencies in larger\n    // jobs. If the timeout specified is greater than zero seconds use\n    // it, otherwise use the default service client timeout.\n    int storageConnectionTimeout \u003d sessionConfiguration.getInt(\n        KEY_STORAGE_CONNECTION_TIMEOUT, 0);\n\n    if (0 \u003c storageConnectionTimeout) {\n      storageInteractionLayer.setTimeoutInMs(storageConnectionTimeout * 1000);\n    }\n\n    // Set the concurrency values equal to the that specified in the\n    // configuration file. If it does not exist, set it to the default\n    // value calculated as double the number of CPU cores on the client\n    // machine. The concurrency value is minimum of double the cores and\n    // the read/write property.\n    int cpuCores \u003d 2 * Runtime.getRuntime().availableProcessors();\n\n    concurrentWrites \u003d sessionConfiguration.getInt(\n        KEY_CONCURRENT_CONNECTION_VALUE_OUT,\n        Math.min(cpuCores, DEFAULT_CONCURRENT_WRITES));\n\n    // Set up the exponential retry policy.\n    //\n    minBackoff \u003d sessionConfiguration.getInt(\n        KEY_MIN_BACKOFF_INTERVAL, DEFAULT_MIN_BACKOFF_INTERVAL);\n\n    maxBackoff \u003d sessionConfiguration.getInt(\n        KEY_MAX_BACKOFF_INTERVAL, DEFAULT_MAX_BACKOFF_INTERVAL);\n\n    deltaBackoff \u003d sessionConfiguration.getInt(\n        KEY_BACKOFF_INTERVAL, DEFAULT_BACKOFF_INTERVAL);\n\n    maxRetries \u003d sessionConfiguration.getInt(\n        KEY_MAX_IO_RETRIES, DEFAULT_MAX_RETRY_ATTEMPTS);\n\n    storageInteractionLayer.setRetryPolicyFactory(\n          new RetryExponentialRetry(minBackoff, deltaBackoff, maxBackoff, maxRetries));\n\n\n    // read the self-throttling config.\n    selfThrottlingEnabled \u003d sessionConfiguration.getBoolean(\n        KEY_SELF_THROTTLE_ENABLE, DEFAULT_SELF_THROTTLE_ENABLE);\n\n    selfThrottlingReadFactor \u003d sessionConfiguration.getFloat(\n        KEY_SELF_THROTTLE_READ_FACTOR, DEFAULT_SELF_THROTTLE_READ_FACTOR);\n\n    selfThrottlingWriteFactor \u003d sessionConfiguration.getFloat(\n        KEY_SELF_THROTTLE_WRITE_FACTOR, DEFAULT_SELF_THROTTLE_WRITE_FACTOR);\n\n    if (!selfThrottlingEnabled) {\n      autoThrottlingEnabled \u003d sessionConfiguration.getBoolean(\n          KEY_AUTO_THROTTLE_ENABLE,\n          DEFAULT_AUTO_THROTTLE_ENABLE);\n      if (autoThrottlingEnabled) {\n        ClientThrottlingIntercept.initializeSingleton();\n      }\n    } else {\n      // cannot enable both self-throttling and client-throttling\n      autoThrottlingEnabled \u003d false;\n    }\n\n    OperationContext.setLoggingEnabledByDefault(sessionConfiguration.\n        getBoolean(KEY_ENABLE_STORAGE_CLIENT_LOGGING, false));\n\n    LOG.debug(\n        \"AzureNativeFileSystemStore init. Settings\u003d{},{},{},{{},{},{},{}},{{},{},{}}\",\n        concurrentWrites, tolerateOobAppends,\n        ((storageConnectionTimeout \u003e 0) ? storageConnectionTimeout\n          : STORAGE_CONNECTION_TIMEOUT_DEFAULT), minBackoff,\n        deltaBackoff, maxBackoff, maxRetries, selfThrottlingEnabled,\n        selfThrottlingReadFactor, selfThrottlingWriteFactor);\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/AzureNativeFileSystemStore.java",
      "extendedDetails": {}
    },
    "d670c3a4da7dd80dccf6c6308603bb3bb013b3b0": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-14535 wasb: implement high-performance random access and seek of block blobs.\nContributed by Thomas Marquardt\n",
      "commitDate": "11/07/17 1:34 PM",
      "commitName": "d670c3a4da7dd80dccf6c6308603bb3bb013b3b0",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "28/06/17 2:18 PM",
      "commitNameOld": "990aa34de23c625163745ebc338483065d955bbe",
      "commitAuthorOld": "Mingliang Liu",
      "daysBetweenCommits": 12.97,
      "commitsBetweenForRepo": 50,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,91 +1,94 @@\n   private void configureAzureStorageSession() throws AzureException {\n \n     // Assertion: Target session URI already should have been captured.\n     if (sessionUri \u003d\u003d null) {\n       throw new AssertionError(\n           \"Expected a non-null session URI when configuring storage session\");\n     }\n \n     // Assertion: A client session already should have been established with\n     // Azure.\n     if (storageInteractionLayer \u003d\u003d null) {\n       throw new AssertionError(String.format(\n           \"Cannot configure storage session for URI \u0027%s\u0027 \"\n               + \"if storage session has not been established.\",\n           sessionUri.toString()));\n     }\n \n     // Determine whether or not reads are allowed concurrent with OOB writes.\n     tolerateOobAppends \u003d sessionConfiguration.getBoolean(\n         KEY_READ_TOLERATE_CONCURRENT_APPEND,\n         DEFAULT_READ_TOLERATE_CONCURRENT_APPEND);\n \n     // Retrieve configuration for the minimum stream read and write block size.\n     //\n     this.downloadBlockSizeBytes \u003d sessionConfiguration.getInt(\n         KEY_STREAM_MIN_READ_SIZE, DEFAULT_DOWNLOAD_BLOCK_SIZE);\n     this.uploadBlockSizeBytes \u003d sessionConfiguration.getInt(\n         KEY_WRITE_BLOCK_SIZE, DEFAULT_UPLOAD_BLOCK_SIZE);\n \n+    this.inputStreamVersion \u003d sessionConfiguration.getInt(\n+        KEY_INPUT_STREAM_VERSION, DEFAULT_INPUT_STREAM_VERSION);\n+\n     // The job may want to specify a timeout to use when engaging the\n     // storage service. The default is currently 90 seconds. It may\n     // be necessary to increase this value for long latencies in larger\n     // jobs. If the timeout specified is greater than zero seconds use\n     // it, otherwise use the default service client timeout.\n     int storageConnectionTimeout \u003d sessionConfiguration.getInt(\n         KEY_STORAGE_CONNECTION_TIMEOUT, 0);\n \n     if (0 \u003c storageConnectionTimeout) {\n       storageInteractionLayer.setTimeoutInMs(storageConnectionTimeout * 1000);\n     }\n \n     // Set the concurrency values equal to the that specified in the\n     // configuration file. If it does not exist, set it to the default\n     // value calculated as double the number of CPU cores on the client\n     // machine. The concurrency value is minimum of double the cores and\n     // the read/write property.\n     int cpuCores \u003d 2 * Runtime.getRuntime().availableProcessors();\n \n     concurrentWrites \u003d sessionConfiguration.getInt(\n         KEY_CONCURRENT_CONNECTION_VALUE_OUT,\n         Math.min(cpuCores, DEFAULT_CONCURRENT_WRITES));\n \n     // Set up the exponential retry policy.\n     //\n     minBackoff \u003d sessionConfiguration.getInt(\n         KEY_MIN_BACKOFF_INTERVAL, DEFAULT_MIN_BACKOFF_INTERVAL);\n \n     maxBackoff \u003d sessionConfiguration.getInt(\n         KEY_MAX_BACKOFF_INTERVAL, DEFAULT_MAX_BACKOFF_INTERVAL);\n \n     deltaBackoff \u003d sessionConfiguration.getInt(\n         KEY_BACKOFF_INTERVAL, DEFAULT_BACKOFF_INTERVAL);\n \n     maxRetries \u003d sessionConfiguration.getInt(\n         KEY_MAX_IO_RETRIES, DEFAULT_MAX_RETRY_ATTEMPTS);\n \n     storageInteractionLayer.setRetryPolicyFactory(\n           new RetryExponentialRetry(minBackoff, deltaBackoff, maxBackoff, maxRetries));\n \n \n     // read the self-throttling config.\n     selfThrottlingEnabled \u003d sessionConfiguration.getBoolean(\n         KEY_SELF_THROTTLE_ENABLE, DEFAULT_SELF_THROTTLE_ENABLE);\n \n     selfThrottlingReadFactor \u003d sessionConfiguration.getFloat(\n         KEY_SELF_THROTTLE_READ_FACTOR, DEFAULT_SELF_THROTTLE_READ_FACTOR);\n \n     selfThrottlingWriteFactor \u003d sessionConfiguration.getFloat(\n         KEY_SELF_THROTTLE_WRITE_FACTOR, DEFAULT_SELF_THROTTLE_WRITE_FACTOR);\n \n     OperationContext.setLoggingEnabledByDefault(sessionConfiguration.\n         getBoolean(KEY_ENABLE_STORAGE_CLIENT_LOGGING, false));\n \n     LOG.debug(\n         \"AzureNativeFileSystemStore init. Settings\u003d{},{},{},{{},{},{},{}},{{},{},{}}\",\n         concurrentWrites, tolerateOobAppends,\n         ((storageConnectionTimeout \u003e 0) ? storageConnectionTimeout\n           : STORAGE_CONNECTION_TIMEOUT_DEFAULT), minBackoff,\n         deltaBackoff, maxBackoff, maxRetries, selfThrottlingEnabled,\n         selfThrottlingReadFactor, selfThrottlingWriteFactor);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void configureAzureStorageSession() throws AzureException {\n\n    // Assertion: Target session URI already should have been captured.\n    if (sessionUri \u003d\u003d null) {\n      throw new AssertionError(\n          \"Expected a non-null session URI when configuring storage session\");\n    }\n\n    // Assertion: A client session already should have been established with\n    // Azure.\n    if (storageInteractionLayer \u003d\u003d null) {\n      throw new AssertionError(String.format(\n          \"Cannot configure storage session for URI \u0027%s\u0027 \"\n              + \"if storage session has not been established.\",\n          sessionUri.toString()));\n    }\n\n    // Determine whether or not reads are allowed concurrent with OOB writes.\n    tolerateOobAppends \u003d sessionConfiguration.getBoolean(\n        KEY_READ_TOLERATE_CONCURRENT_APPEND,\n        DEFAULT_READ_TOLERATE_CONCURRENT_APPEND);\n\n    // Retrieve configuration for the minimum stream read and write block size.\n    //\n    this.downloadBlockSizeBytes \u003d sessionConfiguration.getInt(\n        KEY_STREAM_MIN_READ_SIZE, DEFAULT_DOWNLOAD_BLOCK_SIZE);\n    this.uploadBlockSizeBytes \u003d sessionConfiguration.getInt(\n        KEY_WRITE_BLOCK_SIZE, DEFAULT_UPLOAD_BLOCK_SIZE);\n\n    this.inputStreamVersion \u003d sessionConfiguration.getInt(\n        KEY_INPUT_STREAM_VERSION, DEFAULT_INPUT_STREAM_VERSION);\n\n    // The job may want to specify a timeout to use when engaging the\n    // storage service. The default is currently 90 seconds. It may\n    // be necessary to increase this value for long latencies in larger\n    // jobs. If the timeout specified is greater than zero seconds use\n    // it, otherwise use the default service client timeout.\n    int storageConnectionTimeout \u003d sessionConfiguration.getInt(\n        KEY_STORAGE_CONNECTION_TIMEOUT, 0);\n\n    if (0 \u003c storageConnectionTimeout) {\n      storageInteractionLayer.setTimeoutInMs(storageConnectionTimeout * 1000);\n    }\n\n    // Set the concurrency values equal to the that specified in the\n    // configuration file. If it does not exist, set it to the default\n    // value calculated as double the number of CPU cores on the client\n    // machine. The concurrency value is minimum of double the cores and\n    // the read/write property.\n    int cpuCores \u003d 2 * Runtime.getRuntime().availableProcessors();\n\n    concurrentWrites \u003d sessionConfiguration.getInt(\n        KEY_CONCURRENT_CONNECTION_VALUE_OUT,\n        Math.min(cpuCores, DEFAULT_CONCURRENT_WRITES));\n\n    // Set up the exponential retry policy.\n    //\n    minBackoff \u003d sessionConfiguration.getInt(\n        KEY_MIN_BACKOFF_INTERVAL, DEFAULT_MIN_BACKOFF_INTERVAL);\n\n    maxBackoff \u003d sessionConfiguration.getInt(\n        KEY_MAX_BACKOFF_INTERVAL, DEFAULT_MAX_BACKOFF_INTERVAL);\n\n    deltaBackoff \u003d sessionConfiguration.getInt(\n        KEY_BACKOFF_INTERVAL, DEFAULT_BACKOFF_INTERVAL);\n\n    maxRetries \u003d sessionConfiguration.getInt(\n        KEY_MAX_IO_RETRIES, DEFAULT_MAX_RETRY_ATTEMPTS);\n\n    storageInteractionLayer.setRetryPolicyFactory(\n          new RetryExponentialRetry(minBackoff, deltaBackoff, maxBackoff, maxRetries));\n\n\n    // read the self-throttling config.\n    selfThrottlingEnabled \u003d sessionConfiguration.getBoolean(\n        KEY_SELF_THROTTLE_ENABLE, DEFAULT_SELF_THROTTLE_ENABLE);\n\n    selfThrottlingReadFactor \u003d sessionConfiguration.getFloat(\n        KEY_SELF_THROTTLE_READ_FACTOR, DEFAULT_SELF_THROTTLE_READ_FACTOR);\n\n    selfThrottlingWriteFactor \u003d sessionConfiguration.getFloat(\n        KEY_SELF_THROTTLE_WRITE_FACTOR, DEFAULT_SELF_THROTTLE_WRITE_FACTOR);\n\n    OperationContext.setLoggingEnabledByDefault(sessionConfiguration.\n        getBoolean(KEY_ENABLE_STORAGE_CLIENT_LOGGING, false));\n\n    LOG.debug(\n        \"AzureNativeFileSystemStore init. Settings\u003d{},{},{},{{},{},{},{}},{{},{},{}}\",\n        concurrentWrites, tolerateOobAppends,\n        ((storageConnectionTimeout \u003e 0) ? storageConnectionTimeout\n          : STORAGE_CONNECTION_TIMEOUT_DEFAULT), minBackoff,\n        deltaBackoff, maxBackoff, maxRetries, selfThrottlingEnabled,\n        selfThrottlingReadFactor, selfThrottlingWriteFactor);\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/AzureNativeFileSystemStore.java",
      "extendedDetails": {}
    },
    "5f6edb30c2bb648d5564c951edc25645e17e6636": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-12350. WASB Logging: Improve WASB Logging around deletes, reads and writes. Contributed by Dushyanth.\n",
      "commitDate": "05/10/15 8:11 PM",
      "commitName": "5f6edb30c2bb648d5564c951edc25645e17e6636",
      "commitAuthor": "cnauroth",
      "commitDateOld": "08/06/15 10:42 PM",
      "commitNameOld": "c45784bc9031353b938f4756473937cca759b3dc",
      "commitAuthorOld": "cnauroth",
      "daysBetweenCommits": 118.9,
      "commitsBetweenForRepo": 778,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,94 +1,91 @@\n   private void configureAzureStorageSession() throws AzureException {\n \n     // Assertion: Target session URI already should have been captured.\n     if (sessionUri \u003d\u003d null) {\n       throw new AssertionError(\n           \"Expected a non-null session URI when configuring storage session\");\n     }\n \n     // Assertion: A client session already should have been established with\n     // Azure.\n     if (storageInteractionLayer \u003d\u003d null) {\n       throw new AssertionError(String.format(\n           \"Cannot configure storage session for URI \u0027%s\u0027 \"\n               + \"if storage session has not been established.\",\n           sessionUri.toString()));\n     }\n \n     // Determine whether or not reads are allowed concurrent with OOB writes.\n     tolerateOobAppends \u003d sessionConfiguration.getBoolean(\n         KEY_READ_TOLERATE_CONCURRENT_APPEND,\n         DEFAULT_READ_TOLERATE_CONCURRENT_APPEND);\n \n     // Retrieve configuration for the minimum stream read and write block size.\n     //\n     this.downloadBlockSizeBytes \u003d sessionConfiguration.getInt(\n         KEY_STREAM_MIN_READ_SIZE, DEFAULT_DOWNLOAD_BLOCK_SIZE);\n     this.uploadBlockSizeBytes \u003d sessionConfiguration.getInt(\n         KEY_WRITE_BLOCK_SIZE, DEFAULT_UPLOAD_BLOCK_SIZE);\n \n     // The job may want to specify a timeout to use when engaging the\n     // storage service. The default is currently 90 seconds. It may\n     // be necessary to increase this value for long latencies in larger\n     // jobs. If the timeout specified is greater than zero seconds use\n     // it, otherwise use the default service client timeout.\n     int storageConnectionTimeout \u003d sessionConfiguration.getInt(\n         KEY_STORAGE_CONNECTION_TIMEOUT, 0);\n \n     if (0 \u003c storageConnectionTimeout) {\n       storageInteractionLayer.setTimeoutInMs(storageConnectionTimeout * 1000);\n     }\n \n     // Set the concurrency values equal to the that specified in the\n     // configuration file. If it does not exist, set it to the default\n     // value calculated as double the number of CPU cores on the client\n     // machine. The concurrency value is minimum of double the cores and\n     // the read/write property.\n     int cpuCores \u003d 2 * Runtime.getRuntime().availableProcessors();\n \n     concurrentWrites \u003d sessionConfiguration.getInt(\n         KEY_CONCURRENT_CONNECTION_VALUE_OUT,\n         Math.min(cpuCores, DEFAULT_CONCURRENT_WRITES));\n \n     // Set up the exponential retry policy.\n     //\n     minBackoff \u003d sessionConfiguration.getInt(\n         KEY_MIN_BACKOFF_INTERVAL, DEFAULT_MIN_BACKOFF_INTERVAL);\n \n     maxBackoff \u003d sessionConfiguration.getInt(\n         KEY_MAX_BACKOFF_INTERVAL, DEFAULT_MAX_BACKOFF_INTERVAL);\n \n     deltaBackoff \u003d sessionConfiguration.getInt(\n         KEY_BACKOFF_INTERVAL, DEFAULT_BACKOFF_INTERVAL);\n \n     maxRetries \u003d sessionConfiguration.getInt(\n         KEY_MAX_IO_RETRIES, DEFAULT_MAX_RETRY_ATTEMPTS);\n \n     storageInteractionLayer.setRetryPolicyFactory(\n           new RetryExponentialRetry(minBackoff, deltaBackoff, maxBackoff, maxRetries));\n \n \n     // read the self-throttling config.\n     selfThrottlingEnabled \u003d sessionConfiguration.getBoolean(\n         KEY_SELF_THROTTLE_ENABLE, DEFAULT_SELF_THROTTLE_ENABLE);\n \n     selfThrottlingReadFactor \u003d sessionConfiguration.getFloat(\n         KEY_SELF_THROTTLE_READ_FACTOR, DEFAULT_SELF_THROTTLE_READ_FACTOR);\n \n     selfThrottlingWriteFactor \u003d sessionConfiguration.getFloat(\n         KEY_SELF_THROTTLE_WRITE_FACTOR, DEFAULT_SELF_THROTTLE_WRITE_FACTOR);\n \n     OperationContext.setLoggingEnabledByDefault(sessionConfiguration.\n         getBoolean(KEY_ENABLE_STORAGE_CLIENT_LOGGING, false));\n \n-    if (LOG.isDebugEnabled()) {\n-      LOG.debug(String\n-          .format(\n-              \"AzureNativeFileSystemStore init. Settings\u003d%d,%b,%d,{%d,%d,%d,%d},{%b,%f,%f}\",\n-              concurrentWrites, tolerateOobAppends,\n-              ((storageConnectionTimeout \u003e 0) ? storageConnectionTimeout\n-                  : STORAGE_CONNECTION_TIMEOUT_DEFAULT), minBackoff,\n-              deltaBackoff, maxBackoff, maxRetries, selfThrottlingEnabled,\n-              selfThrottlingReadFactor, selfThrottlingWriteFactor));\n-    }\n+    LOG.debug(\n+        \"AzureNativeFileSystemStore init. Settings\u003d{},{},{},{{},{},{},{}},{{},{},{}}\",\n+        concurrentWrites, tolerateOobAppends,\n+        ((storageConnectionTimeout \u003e 0) ? storageConnectionTimeout\n+          : STORAGE_CONNECTION_TIMEOUT_DEFAULT), minBackoff,\n+        deltaBackoff, maxBackoff, maxRetries, selfThrottlingEnabled,\n+        selfThrottlingReadFactor, selfThrottlingWriteFactor);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void configureAzureStorageSession() throws AzureException {\n\n    // Assertion: Target session URI already should have been captured.\n    if (sessionUri \u003d\u003d null) {\n      throw new AssertionError(\n          \"Expected a non-null session URI when configuring storage session\");\n    }\n\n    // Assertion: A client session already should have been established with\n    // Azure.\n    if (storageInteractionLayer \u003d\u003d null) {\n      throw new AssertionError(String.format(\n          \"Cannot configure storage session for URI \u0027%s\u0027 \"\n              + \"if storage session has not been established.\",\n          sessionUri.toString()));\n    }\n\n    // Determine whether or not reads are allowed concurrent with OOB writes.\n    tolerateOobAppends \u003d sessionConfiguration.getBoolean(\n        KEY_READ_TOLERATE_CONCURRENT_APPEND,\n        DEFAULT_READ_TOLERATE_CONCURRENT_APPEND);\n\n    // Retrieve configuration for the minimum stream read and write block size.\n    //\n    this.downloadBlockSizeBytes \u003d sessionConfiguration.getInt(\n        KEY_STREAM_MIN_READ_SIZE, DEFAULT_DOWNLOAD_BLOCK_SIZE);\n    this.uploadBlockSizeBytes \u003d sessionConfiguration.getInt(\n        KEY_WRITE_BLOCK_SIZE, DEFAULT_UPLOAD_BLOCK_SIZE);\n\n    // The job may want to specify a timeout to use when engaging the\n    // storage service. The default is currently 90 seconds. It may\n    // be necessary to increase this value for long latencies in larger\n    // jobs. If the timeout specified is greater than zero seconds use\n    // it, otherwise use the default service client timeout.\n    int storageConnectionTimeout \u003d sessionConfiguration.getInt(\n        KEY_STORAGE_CONNECTION_TIMEOUT, 0);\n\n    if (0 \u003c storageConnectionTimeout) {\n      storageInteractionLayer.setTimeoutInMs(storageConnectionTimeout * 1000);\n    }\n\n    // Set the concurrency values equal to the that specified in the\n    // configuration file. If it does not exist, set it to the default\n    // value calculated as double the number of CPU cores on the client\n    // machine. The concurrency value is minimum of double the cores and\n    // the read/write property.\n    int cpuCores \u003d 2 * Runtime.getRuntime().availableProcessors();\n\n    concurrentWrites \u003d sessionConfiguration.getInt(\n        KEY_CONCURRENT_CONNECTION_VALUE_OUT,\n        Math.min(cpuCores, DEFAULT_CONCURRENT_WRITES));\n\n    // Set up the exponential retry policy.\n    //\n    minBackoff \u003d sessionConfiguration.getInt(\n        KEY_MIN_BACKOFF_INTERVAL, DEFAULT_MIN_BACKOFF_INTERVAL);\n\n    maxBackoff \u003d sessionConfiguration.getInt(\n        KEY_MAX_BACKOFF_INTERVAL, DEFAULT_MAX_BACKOFF_INTERVAL);\n\n    deltaBackoff \u003d sessionConfiguration.getInt(\n        KEY_BACKOFF_INTERVAL, DEFAULT_BACKOFF_INTERVAL);\n\n    maxRetries \u003d sessionConfiguration.getInt(\n        KEY_MAX_IO_RETRIES, DEFAULT_MAX_RETRY_ATTEMPTS);\n\n    storageInteractionLayer.setRetryPolicyFactory(\n          new RetryExponentialRetry(minBackoff, deltaBackoff, maxBackoff, maxRetries));\n\n\n    // read the self-throttling config.\n    selfThrottlingEnabled \u003d sessionConfiguration.getBoolean(\n        KEY_SELF_THROTTLE_ENABLE, DEFAULT_SELF_THROTTLE_ENABLE);\n\n    selfThrottlingReadFactor \u003d sessionConfiguration.getFloat(\n        KEY_SELF_THROTTLE_READ_FACTOR, DEFAULT_SELF_THROTTLE_READ_FACTOR);\n\n    selfThrottlingWriteFactor \u003d sessionConfiguration.getFloat(\n        KEY_SELF_THROTTLE_WRITE_FACTOR, DEFAULT_SELF_THROTTLE_WRITE_FACTOR);\n\n    OperationContext.setLoggingEnabledByDefault(sessionConfiguration.\n        getBoolean(KEY_ENABLE_STORAGE_CLIENT_LOGGING, false));\n\n    LOG.debug(\n        \"AzureNativeFileSystemStore init. Settings\u003d{},{},{},{{},{},{},{}},{{},{},{}}\",\n        concurrentWrites, tolerateOobAppends,\n        ((storageConnectionTimeout \u003e 0) ? storageConnectionTimeout\n          : STORAGE_CONNECTION_TIMEOUT_DEFAULT), minBackoff,\n        deltaBackoff, maxBackoff, maxRetries, selfThrottlingEnabled,\n        selfThrottlingReadFactor, selfThrottlingWriteFactor);\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/AzureNativeFileSystemStore.java",
      "extendedDetails": {}
    },
    "cb8e69a80cecb95abdfc93a787bea0bedef275ed": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-11960. Enable Azure-Storage Client Side logging. Contributed by Dushyanth.\n",
      "commitDate": "14/05/15 10:22 PM",
      "commitName": "cb8e69a80cecb95abdfc93a787bea0bedef275ed",
      "commitAuthor": "cnauroth",
      "commitDateOld": "17/03/15 12:09 AM",
      "commitNameOld": "ef9946cd52d54200c658987c1dbc3e6fce133f77",
      "commitAuthorOld": "Tsuyoshi Ozawa",
      "daysBetweenCommits": 58.93,
      "commitsBetweenForRepo": 614,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,91 +1,94 @@\n   private void configureAzureStorageSession() throws AzureException {\n \n     // Assertion: Target session URI already should have been captured.\n     if (sessionUri \u003d\u003d null) {\n       throw new AssertionError(\n           \"Expected a non-null session URI when configuring storage session\");\n     }\n \n     // Assertion: A client session already should have been established with\n     // Azure.\n     if (storageInteractionLayer \u003d\u003d null) {\n       throw new AssertionError(String.format(\n           \"Cannot configure storage session for URI \u0027%s\u0027 \"\n               + \"if storage session has not been established.\",\n           sessionUri.toString()));\n     }\n \n     // Determine whether or not reads are allowed concurrent with OOB writes.\n     tolerateOobAppends \u003d sessionConfiguration.getBoolean(\n         KEY_READ_TOLERATE_CONCURRENT_APPEND,\n         DEFAULT_READ_TOLERATE_CONCURRENT_APPEND);\n \n     // Retrieve configuration for the minimum stream read and write block size.\n     //\n     this.downloadBlockSizeBytes \u003d sessionConfiguration.getInt(\n         KEY_STREAM_MIN_READ_SIZE, DEFAULT_DOWNLOAD_BLOCK_SIZE);\n     this.uploadBlockSizeBytes \u003d sessionConfiguration.getInt(\n         KEY_WRITE_BLOCK_SIZE, DEFAULT_UPLOAD_BLOCK_SIZE);\n \n     // The job may want to specify a timeout to use when engaging the\n     // storage service. The default is currently 90 seconds. It may\n     // be necessary to increase this value for long latencies in larger\n     // jobs. If the timeout specified is greater than zero seconds use\n     // it, otherwise use the default service client timeout.\n     int storageConnectionTimeout \u003d sessionConfiguration.getInt(\n         KEY_STORAGE_CONNECTION_TIMEOUT, 0);\n \n     if (0 \u003c storageConnectionTimeout) {\n       storageInteractionLayer.setTimeoutInMs(storageConnectionTimeout * 1000);\n     }\n \n     // Set the concurrency values equal to the that specified in the\n     // configuration file. If it does not exist, set it to the default\n     // value calculated as double the number of CPU cores on the client\n     // machine. The concurrency value is minimum of double the cores and\n     // the read/write property.\n     int cpuCores \u003d 2 * Runtime.getRuntime().availableProcessors();\n \n     concurrentWrites \u003d sessionConfiguration.getInt(\n         KEY_CONCURRENT_CONNECTION_VALUE_OUT,\n         Math.min(cpuCores, DEFAULT_CONCURRENT_WRITES));\n \n     // Set up the exponential retry policy.\n     //\n     minBackoff \u003d sessionConfiguration.getInt(\n         KEY_MIN_BACKOFF_INTERVAL, DEFAULT_MIN_BACKOFF_INTERVAL);\n \n     maxBackoff \u003d sessionConfiguration.getInt(\n         KEY_MAX_BACKOFF_INTERVAL, DEFAULT_MAX_BACKOFF_INTERVAL);\n \n     deltaBackoff \u003d sessionConfiguration.getInt(\n         KEY_BACKOFF_INTERVAL, DEFAULT_BACKOFF_INTERVAL);\n \n     maxRetries \u003d sessionConfiguration.getInt(\n         KEY_MAX_IO_RETRIES, DEFAULT_MAX_RETRY_ATTEMPTS);\n \n     storageInteractionLayer.setRetryPolicyFactory(\n           new RetryExponentialRetry(minBackoff, deltaBackoff, maxBackoff, maxRetries));\n \n \n     // read the self-throttling config.\n     selfThrottlingEnabled \u003d sessionConfiguration.getBoolean(\n         KEY_SELF_THROTTLE_ENABLE, DEFAULT_SELF_THROTTLE_ENABLE);\n \n     selfThrottlingReadFactor \u003d sessionConfiguration.getFloat(\n         KEY_SELF_THROTTLE_READ_FACTOR, DEFAULT_SELF_THROTTLE_READ_FACTOR);\n \n     selfThrottlingWriteFactor \u003d sessionConfiguration.getFloat(\n         KEY_SELF_THROTTLE_WRITE_FACTOR, DEFAULT_SELF_THROTTLE_WRITE_FACTOR);\n \n+    OperationContext.setLoggingEnabledByDefault(sessionConfiguration.\n+        getBoolean(KEY_ENABLE_STORAGE_CLIENT_LOGGING, false));\n+\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(String\n           .format(\n               \"AzureNativeFileSystemStore init. Settings\u003d%d,%b,%d,{%d,%d,%d,%d},{%b,%f,%f}\",\n               concurrentWrites, tolerateOobAppends,\n               ((storageConnectionTimeout \u003e 0) ? storageConnectionTimeout\n                   : STORAGE_CONNECTION_TIMEOUT_DEFAULT), minBackoff,\n               deltaBackoff, maxBackoff, maxRetries, selfThrottlingEnabled,\n               selfThrottlingReadFactor, selfThrottlingWriteFactor));\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void configureAzureStorageSession() throws AzureException {\n\n    // Assertion: Target session URI already should have been captured.\n    if (sessionUri \u003d\u003d null) {\n      throw new AssertionError(\n          \"Expected a non-null session URI when configuring storage session\");\n    }\n\n    // Assertion: A client session already should have been established with\n    // Azure.\n    if (storageInteractionLayer \u003d\u003d null) {\n      throw new AssertionError(String.format(\n          \"Cannot configure storage session for URI \u0027%s\u0027 \"\n              + \"if storage session has not been established.\",\n          sessionUri.toString()));\n    }\n\n    // Determine whether or not reads are allowed concurrent with OOB writes.\n    tolerateOobAppends \u003d sessionConfiguration.getBoolean(\n        KEY_READ_TOLERATE_CONCURRENT_APPEND,\n        DEFAULT_READ_TOLERATE_CONCURRENT_APPEND);\n\n    // Retrieve configuration for the minimum stream read and write block size.\n    //\n    this.downloadBlockSizeBytes \u003d sessionConfiguration.getInt(\n        KEY_STREAM_MIN_READ_SIZE, DEFAULT_DOWNLOAD_BLOCK_SIZE);\n    this.uploadBlockSizeBytes \u003d sessionConfiguration.getInt(\n        KEY_WRITE_BLOCK_SIZE, DEFAULT_UPLOAD_BLOCK_SIZE);\n\n    // The job may want to specify a timeout to use when engaging the\n    // storage service. The default is currently 90 seconds. It may\n    // be necessary to increase this value for long latencies in larger\n    // jobs. If the timeout specified is greater than zero seconds use\n    // it, otherwise use the default service client timeout.\n    int storageConnectionTimeout \u003d sessionConfiguration.getInt(\n        KEY_STORAGE_CONNECTION_TIMEOUT, 0);\n\n    if (0 \u003c storageConnectionTimeout) {\n      storageInteractionLayer.setTimeoutInMs(storageConnectionTimeout * 1000);\n    }\n\n    // Set the concurrency values equal to the that specified in the\n    // configuration file. If it does not exist, set it to the default\n    // value calculated as double the number of CPU cores on the client\n    // machine. The concurrency value is minimum of double the cores and\n    // the read/write property.\n    int cpuCores \u003d 2 * Runtime.getRuntime().availableProcessors();\n\n    concurrentWrites \u003d sessionConfiguration.getInt(\n        KEY_CONCURRENT_CONNECTION_VALUE_OUT,\n        Math.min(cpuCores, DEFAULT_CONCURRENT_WRITES));\n\n    // Set up the exponential retry policy.\n    //\n    minBackoff \u003d sessionConfiguration.getInt(\n        KEY_MIN_BACKOFF_INTERVAL, DEFAULT_MIN_BACKOFF_INTERVAL);\n\n    maxBackoff \u003d sessionConfiguration.getInt(\n        KEY_MAX_BACKOFF_INTERVAL, DEFAULT_MAX_BACKOFF_INTERVAL);\n\n    deltaBackoff \u003d sessionConfiguration.getInt(\n        KEY_BACKOFF_INTERVAL, DEFAULT_BACKOFF_INTERVAL);\n\n    maxRetries \u003d sessionConfiguration.getInt(\n        KEY_MAX_IO_RETRIES, DEFAULT_MAX_RETRY_ATTEMPTS);\n\n    storageInteractionLayer.setRetryPolicyFactory(\n          new RetryExponentialRetry(minBackoff, deltaBackoff, maxBackoff, maxRetries));\n\n\n    // read the self-throttling config.\n    selfThrottlingEnabled \u003d sessionConfiguration.getBoolean(\n        KEY_SELF_THROTTLE_ENABLE, DEFAULT_SELF_THROTTLE_ENABLE);\n\n    selfThrottlingReadFactor \u003d sessionConfiguration.getFloat(\n        KEY_SELF_THROTTLE_READ_FACTOR, DEFAULT_SELF_THROTTLE_READ_FACTOR);\n\n    selfThrottlingWriteFactor \u003d sessionConfiguration.getFloat(\n        KEY_SELF_THROTTLE_WRITE_FACTOR, DEFAULT_SELF_THROTTLE_WRITE_FACTOR);\n\n    OperationContext.setLoggingEnabledByDefault(sessionConfiguration.\n        getBoolean(KEY_ENABLE_STORAGE_CLIENT_LOGGING, false));\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(String\n          .format(\n              \"AzureNativeFileSystemStore init. Settings\u003d%d,%b,%d,{%d,%d,%d,%d},{%b,%f,%f}\",\n              concurrentWrites, tolerateOobAppends,\n              ((storageConnectionTimeout \u003e 0) ? storageConnectionTimeout\n                  : STORAGE_CONNECTION_TIMEOUT_DEFAULT), minBackoff,\n              deltaBackoff, maxBackoff, maxRetries, selfThrottlingEnabled,\n              selfThrottlingReadFactor, selfThrottlingWriteFactor));\n    }\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/AzureNativeFileSystemStore.java",
      "extendedDetails": {}
    },
    "2217e2f8ff418b88eac6ad36cafe3a9795a11f40": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-10809. hadoop-azure: page blob support. Contributed by Dexter Bradshaw, Mostafa Elhemali, Eric Hanson, and Mike Liddell.\n",
      "commitDate": "08/10/14 2:20 PM",
      "commitName": "2217e2f8ff418b88eac6ad36cafe3a9795a11f40",
      "commitAuthor": "cnauroth",
      "commitDateOld": "24/06/14 1:52 PM",
      "commitNameOld": "0d91576ec31f63402f2db6107a04155368e2632d",
      "commitAuthorOld": "Chris Nauroth",
      "daysBetweenCommits": 106.02,
      "commitsBetweenForRepo": 1005,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,89 +1,91 @@\n   private void configureAzureStorageSession() throws AzureException {\n \n     // Assertion: Target session URI already should have been captured.\n     if (sessionUri \u003d\u003d null) {\n       throw new AssertionError(\n           \"Expected a non-null session URI when configuring storage session\");\n     }\n \n     // Assertion: A client session already should have been established with\n     // Azure.\n     if (storageInteractionLayer \u003d\u003d null) {\n       throw new AssertionError(String.format(\n           \"Cannot configure storage session for URI \u0027%s\u0027 \"\n               + \"if storage session has not been established.\",\n           sessionUri.toString()));\n     }\n \n     // Determine whether or not reads are allowed concurrent with OOB writes.\n     tolerateOobAppends \u003d sessionConfiguration.getBoolean(\n         KEY_READ_TOLERATE_CONCURRENT_APPEND,\n         DEFAULT_READ_TOLERATE_CONCURRENT_APPEND);\n \n     // Retrieve configuration for the minimum stream read and write block size.\n     //\n     this.downloadBlockSizeBytes \u003d sessionConfiguration.getInt(\n         KEY_STREAM_MIN_READ_SIZE, DEFAULT_DOWNLOAD_BLOCK_SIZE);\n     this.uploadBlockSizeBytes \u003d sessionConfiguration.getInt(\n         KEY_WRITE_BLOCK_SIZE, DEFAULT_UPLOAD_BLOCK_SIZE);\n \n     // The job may want to specify a timeout to use when engaging the\n     // storage service. The default is currently 90 seconds. It may\n     // be necessary to increase this value for long latencies in larger\n     // jobs. If the timeout specified is greater than zero seconds use\n     // it, otherwise use the default service client timeout.\n     int storageConnectionTimeout \u003d sessionConfiguration.getInt(\n         KEY_STORAGE_CONNECTION_TIMEOUT, 0);\n \n     if (0 \u003c storageConnectionTimeout) {\n       storageInteractionLayer.setTimeoutInMs(storageConnectionTimeout * 1000);\n     }\n \n     // Set the concurrency values equal to the that specified in the\n     // configuration file. If it does not exist, set it to the default\n     // value calculated as double the number of CPU cores on the client\n     // machine. The concurrency value is minimum of double the cores and\n     // the read/write property.\n     int cpuCores \u003d 2 * Runtime.getRuntime().availableProcessors();\n \n     concurrentWrites \u003d sessionConfiguration.getInt(\n         KEY_CONCURRENT_CONNECTION_VALUE_OUT,\n         Math.min(cpuCores, DEFAULT_CONCURRENT_WRITES));\n \n     // Set up the exponential retry policy.\n-    minBackoff \u003d sessionConfiguration.getInt(KEY_MIN_BACKOFF_INTERVAL,\n-        DEFAULT_MIN_BACKOFF_INTERVAL);\n+    //\n+    minBackoff \u003d sessionConfiguration.getInt(\n+        KEY_MIN_BACKOFF_INTERVAL, DEFAULT_MIN_BACKOFF_INTERVAL);\n \n-    maxBackoff \u003d sessionConfiguration.getInt(KEY_MAX_BACKOFF_INTERVAL,\n-        DEFAULT_MAX_BACKOFF_INTERVAL);\n+    maxBackoff \u003d sessionConfiguration.getInt(\n+        KEY_MAX_BACKOFF_INTERVAL, DEFAULT_MAX_BACKOFF_INTERVAL);\n \n-    deltaBackoff \u003d sessionConfiguration.getInt(KEY_BACKOFF_INTERVAL,\n-        DEFAULT_BACKOFF_INTERVAL);\n+    deltaBackoff \u003d sessionConfiguration.getInt(\n+        KEY_BACKOFF_INTERVAL, DEFAULT_BACKOFF_INTERVAL);\n \n-    maxRetries \u003d sessionConfiguration.getInt(KEY_MAX_IO_RETRIES,\n-        DEFAULT_MAX_RETRY_ATTEMPTS);\n+    maxRetries \u003d sessionConfiguration.getInt(\n+        KEY_MAX_IO_RETRIES, DEFAULT_MAX_RETRY_ATTEMPTS);\n \n-    storageInteractionLayer.setRetryPolicyFactory(new RetryExponentialRetry(\n-        minBackoff, deltaBackoff, maxBackoff, maxRetries));\n+    storageInteractionLayer.setRetryPolicyFactory(\n+          new RetryExponentialRetry(minBackoff, deltaBackoff, maxBackoff, maxRetries));\n+\n \n     // read the self-throttling config.\n     selfThrottlingEnabled \u003d sessionConfiguration.getBoolean(\n         KEY_SELF_THROTTLE_ENABLE, DEFAULT_SELF_THROTTLE_ENABLE);\n \n     selfThrottlingReadFactor \u003d sessionConfiguration.getFloat(\n         KEY_SELF_THROTTLE_READ_FACTOR, DEFAULT_SELF_THROTTLE_READ_FACTOR);\n \n     selfThrottlingWriteFactor \u003d sessionConfiguration.getFloat(\n         KEY_SELF_THROTTLE_WRITE_FACTOR, DEFAULT_SELF_THROTTLE_WRITE_FACTOR);\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(String\n           .format(\n               \"AzureNativeFileSystemStore init. Settings\u003d%d,%b,%d,{%d,%d,%d,%d},{%b,%f,%f}\",\n               concurrentWrites, tolerateOobAppends,\n               ((storageConnectionTimeout \u003e 0) ? storageConnectionTimeout\n                   : STORAGE_CONNECTION_TIMEOUT_DEFAULT), minBackoff,\n               deltaBackoff, maxBackoff, maxRetries, selfThrottlingEnabled,\n               selfThrottlingReadFactor, selfThrottlingWriteFactor));\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void configureAzureStorageSession() throws AzureException {\n\n    // Assertion: Target session URI already should have been captured.\n    if (sessionUri \u003d\u003d null) {\n      throw new AssertionError(\n          \"Expected a non-null session URI when configuring storage session\");\n    }\n\n    // Assertion: A client session already should have been established with\n    // Azure.\n    if (storageInteractionLayer \u003d\u003d null) {\n      throw new AssertionError(String.format(\n          \"Cannot configure storage session for URI \u0027%s\u0027 \"\n              + \"if storage session has not been established.\",\n          sessionUri.toString()));\n    }\n\n    // Determine whether or not reads are allowed concurrent with OOB writes.\n    tolerateOobAppends \u003d sessionConfiguration.getBoolean(\n        KEY_READ_TOLERATE_CONCURRENT_APPEND,\n        DEFAULT_READ_TOLERATE_CONCURRENT_APPEND);\n\n    // Retrieve configuration for the minimum stream read and write block size.\n    //\n    this.downloadBlockSizeBytes \u003d sessionConfiguration.getInt(\n        KEY_STREAM_MIN_READ_SIZE, DEFAULT_DOWNLOAD_BLOCK_SIZE);\n    this.uploadBlockSizeBytes \u003d sessionConfiguration.getInt(\n        KEY_WRITE_BLOCK_SIZE, DEFAULT_UPLOAD_BLOCK_SIZE);\n\n    // The job may want to specify a timeout to use when engaging the\n    // storage service. The default is currently 90 seconds. It may\n    // be necessary to increase this value for long latencies in larger\n    // jobs. If the timeout specified is greater than zero seconds use\n    // it, otherwise use the default service client timeout.\n    int storageConnectionTimeout \u003d sessionConfiguration.getInt(\n        KEY_STORAGE_CONNECTION_TIMEOUT, 0);\n\n    if (0 \u003c storageConnectionTimeout) {\n      storageInteractionLayer.setTimeoutInMs(storageConnectionTimeout * 1000);\n    }\n\n    // Set the concurrency values equal to the that specified in the\n    // configuration file. If it does not exist, set it to the default\n    // value calculated as double the number of CPU cores on the client\n    // machine. The concurrency value is minimum of double the cores and\n    // the read/write property.\n    int cpuCores \u003d 2 * Runtime.getRuntime().availableProcessors();\n\n    concurrentWrites \u003d sessionConfiguration.getInt(\n        KEY_CONCURRENT_CONNECTION_VALUE_OUT,\n        Math.min(cpuCores, DEFAULT_CONCURRENT_WRITES));\n\n    // Set up the exponential retry policy.\n    //\n    minBackoff \u003d sessionConfiguration.getInt(\n        KEY_MIN_BACKOFF_INTERVAL, DEFAULT_MIN_BACKOFF_INTERVAL);\n\n    maxBackoff \u003d sessionConfiguration.getInt(\n        KEY_MAX_BACKOFF_INTERVAL, DEFAULT_MAX_BACKOFF_INTERVAL);\n\n    deltaBackoff \u003d sessionConfiguration.getInt(\n        KEY_BACKOFF_INTERVAL, DEFAULT_BACKOFF_INTERVAL);\n\n    maxRetries \u003d sessionConfiguration.getInt(\n        KEY_MAX_IO_RETRIES, DEFAULT_MAX_RETRY_ATTEMPTS);\n\n    storageInteractionLayer.setRetryPolicyFactory(\n          new RetryExponentialRetry(minBackoff, deltaBackoff, maxBackoff, maxRetries));\n\n\n    // read the self-throttling config.\n    selfThrottlingEnabled \u003d sessionConfiguration.getBoolean(\n        KEY_SELF_THROTTLE_ENABLE, DEFAULT_SELF_THROTTLE_ENABLE);\n\n    selfThrottlingReadFactor \u003d sessionConfiguration.getFloat(\n        KEY_SELF_THROTTLE_READ_FACTOR, DEFAULT_SELF_THROTTLE_READ_FACTOR);\n\n    selfThrottlingWriteFactor \u003d sessionConfiguration.getFloat(\n        KEY_SELF_THROTTLE_WRITE_FACTOR, DEFAULT_SELF_THROTTLE_WRITE_FACTOR);\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(String\n          .format(\n              \"AzureNativeFileSystemStore init. Settings\u003d%d,%b,%d,{%d,%d,%d,%d},{%b,%f,%f}\",\n              concurrentWrites, tolerateOobAppends,\n              ((storageConnectionTimeout \u003e 0) ? storageConnectionTimeout\n                  : STORAGE_CONNECTION_TIMEOUT_DEFAULT), minBackoff,\n              deltaBackoff, maxBackoff, maxRetries, selfThrottlingEnabled,\n              selfThrottlingReadFactor, selfThrottlingWriteFactor));\n    }\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/AzureNativeFileSystemStore.java",
      "extendedDetails": {}
    },
    "81bc395deb3ba00567dc067d6ca71bacf9e3bc82": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-9629. Support Windows Azure Storage - Blob as a file system in Hadoop. Contributed by Dexter Bradshaw, Mostafa Elhemali, Xi Fang, Johannes Klein, David Lao, Mike Liddell, Chuan Liu, Lengning Liu, Ivan Mitic, Michael Rys, Alexander Stojanovic, Brian Swan, and Min Wei.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1601781 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/06/14 3:26 PM",
      "commitName": "81bc395deb3ba00567dc067d6ca71bacf9e3bc82",
      "commitAuthor": "Chris Nauroth",
      "diff": "@@ -0,0 +1,89 @@\n+  private void configureAzureStorageSession() throws AzureException {\n+\n+    // Assertion: Target session URI already should have been captured.\n+    if (sessionUri \u003d\u003d null) {\n+      throw new AssertionError(\n+          \"Expected a non-null session URI when configuring storage session\");\n+    }\n+\n+    // Assertion: A client session already should have been established with\n+    // Azure.\n+    if (storageInteractionLayer \u003d\u003d null) {\n+      throw new AssertionError(String.format(\n+          \"Cannot configure storage session for URI \u0027%s\u0027 \"\n+              + \"if storage session has not been established.\",\n+          sessionUri.toString()));\n+    }\n+\n+    // Determine whether or not reads are allowed concurrent with OOB writes.\n+    tolerateOobAppends \u003d sessionConfiguration.getBoolean(\n+        KEY_READ_TOLERATE_CONCURRENT_APPEND,\n+        DEFAULT_READ_TOLERATE_CONCURRENT_APPEND);\n+\n+    // Retrieve configuration for the minimum stream read and write block size.\n+    //\n+    this.downloadBlockSizeBytes \u003d sessionConfiguration.getInt(\n+        KEY_STREAM_MIN_READ_SIZE, DEFAULT_DOWNLOAD_BLOCK_SIZE);\n+    this.uploadBlockSizeBytes \u003d sessionConfiguration.getInt(\n+        KEY_WRITE_BLOCK_SIZE, DEFAULT_UPLOAD_BLOCK_SIZE);\n+\n+    // The job may want to specify a timeout to use when engaging the\n+    // storage service. The default is currently 90 seconds. It may\n+    // be necessary to increase this value for long latencies in larger\n+    // jobs. If the timeout specified is greater than zero seconds use\n+    // it, otherwise use the default service client timeout.\n+    int storageConnectionTimeout \u003d sessionConfiguration.getInt(\n+        KEY_STORAGE_CONNECTION_TIMEOUT, 0);\n+\n+    if (0 \u003c storageConnectionTimeout) {\n+      storageInteractionLayer.setTimeoutInMs(storageConnectionTimeout * 1000);\n+    }\n+\n+    // Set the concurrency values equal to the that specified in the\n+    // configuration file. If it does not exist, set it to the default\n+    // value calculated as double the number of CPU cores on the client\n+    // machine. The concurrency value is minimum of double the cores and\n+    // the read/write property.\n+    int cpuCores \u003d 2 * Runtime.getRuntime().availableProcessors();\n+\n+    concurrentWrites \u003d sessionConfiguration.getInt(\n+        KEY_CONCURRENT_CONNECTION_VALUE_OUT,\n+        Math.min(cpuCores, DEFAULT_CONCURRENT_WRITES));\n+\n+    // Set up the exponential retry policy.\n+    minBackoff \u003d sessionConfiguration.getInt(KEY_MIN_BACKOFF_INTERVAL,\n+        DEFAULT_MIN_BACKOFF_INTERVAL);\n+\n+    maxBackoff \u003d sessionConfiguration.getInt(KEY_MAX_BACKOFF_INTERVAL,\n+        DEFAULT_MAX_BACKOFF_INTERVAL);\n+\n+    deltaBackoff \u003d sessionConfiguration.getInt(KEY_BACKOFF_INTERVAL,\n+        DEFAULT_BACKOFF_INTERVAL);\n+\n+    maxRetries \u003d sessionConfiguration.getInt(KEY_MAX_IO_RETRIES,\n+        DEFAULT_MAX_RETRY_ATTEMPTS);\n+\n+    storageInteractionLayer.setRetryPolicyFactory(new RetryExponentialRetry(\n+        minBackoff, deltaBackoff, maxBackoff, maxRetries));\n+\n+    // read the self-throttling config.\n+    selfThrottlingEnabled \u003d sessionConfiguration.getBoolean(\n+        KEY_SELF_THROTTLE_ENABLE, DEFAULT_SELF_THROTTLE_ENABLE);\n+\n+    selfThrottlingReadFactor \u003d sessionConfiguration.getFloat(\n+        KEY_SELF_THROTTLE_READ_FACTOR, DEFAULT_SELF_THROTTLE_READ_FACTOR);\n+\n+    selfThrottlingWriteFactor \u003d sessionConfiguration.getFloat(\n+        KEY_SELF_THROTTLE_WRITE_FACTOR, DEFAULT_SELF_THROTTLE_WRITE_FACTOR);\n+\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(String\n+          .format(\n+              \"AzureNativeFileSystemStore init. Settings\u003d%d,%b,%d,{%d,%d,%d,%d},{%b,%f,%f}\",\n+              concurrentWrites, tolerateOobAppends,\n+              ((storageConnectionTimeout \u003e 0) ? storageConnectionTimeout\n+                  : STORAGE_CONNECTION_TIMEOUT_DEFAULT), minBackoff,\n+              deltaBackoff, maxBackoff, maxRetries, selfThrottlingEnabled,\n+              selfThrottlingReadFactor, selfThrottlingWriteFactor));\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void configureAzureStorageSession() throws AzureException {\n\n    // Assertion: Target session URI already should have been captured.\n    if (sessionUri \u003d\u003d null) {\n      throw new AssertionError(\n          \"Expected a non-null session URI when configuring storage session\");\n    }\n\n    // Assertion: A client session already should have been established with\n    // Azure.\n    if (storageInteractionLayer \u003d\u003d null) {\n      throw new AssertionError(String.format(\n          \"Cannot configure storage session for URI \u0027%s\u0027 \"\n              + \"if storage session has not been established.\",\n          sessionUri.toString()));\n    }\n\n    // Determine whether or not reads are allowed concurrent with OOB writes.\n    tolerateOobAppends \u003d sessionConfiguration.getBoolean(\n        KEY_READ_TOLERATE_CONCURRENT_APPEND,\n        DEFAULT_READ_TOLERATE_CONCURRENT_APPEND);\n\n    // Retrieve configuration for the minimum stream read and write block size.\n    //\n    this.downloadBlockSizeBytes \u003d sessionConfiguration.getInt(\n        KEY_STREAM_MIN_READ_SIZE, DEFAULT_DOWNLOAD_BLOCK_SIZE);\n    this.uploadBlockSizeBytes \u003d sessionConfiguration.getInt(\n        KEY_WRITE_BLOCK_SIZE, DEFAULT_UPLOAD_BLOCK_SIZE);\n\n    // The job may want to specify a timeout to use when engaging the\n    // storage service. The default is currently 90 seconds. It may\n    // be necessary to increase this value for long latencies in larger\n    // jobs. If the timeout specified is greater than zero seconds use\n    // it, otherwise use the default service client timeout.\n    int storageConnectionTimeout \u003d sessionConfiguration.getInt(\n        KEY_STORAGE_CONNECTION_TIMEOUT, 0);\n\n    if (0 \u003c storageConnectionTimeout) {\n      storageInteractionLayer.setTimeoutInMs(storageConnectionTimeout * 1000);\n    }\n\n    // Set the concurrency values equal to the that specified in the\n    // configuration file. If it does not exist, set it to the default\n    // value calculated as double the number of CPU cores on the client\n    // machine. The concurrency value is minimum of double the cores and\n    // the read/write property.\n    int cpuCores \u003d 2 * Runtime.getRuntime().availableProcessors();\n\n    concurrentWrites \u003d sessionConfiguration.getInt(\n        KEY_CONCURRENT_CONNECTION_VALUE_OUT,\n        Math.min(cpuCores, DEFAULT_CONCURRENT_WRITES));\n\n    // Set up the exponential retry policy.\n    minBackoff \u003d sessionConfiguration.getInt(KEY_MIN_BACKOFF_INTERVAL,\n        DEFAULT_MIN_BACKOFF_INTERVAL);\n\n    maxBackoff \u003d sessionConfiguration.getInt(KEY_MAX_BACKOFF_INTERVAL,\n        DEFAULT_MAX_BACKOFF_INTERVAL);\n\n    deltaBackoff \u003d sessionConfiguration.getInt(KEY_BACKOFF_INTERVAL,\n        DEFAULT_BACKOFF_INTERVAL);\n\n    maxRetries \u003d sessionConfiguration.getInt(KEY_MAX_IO_RETRIES,\n        DEFAULT_MAX_RETRY_ATTEMPTS);\n\n    storageInteractionLayer.setRetryPolicyFactory(new RetryExponentialRetry(\n        minBackoff, deltaBackoff, maxBackoff, maxRetries));\n\n    // read the self-throttling config.\n    selfThrottlingEnabled \u003d sessionConfiguration.getBoolean(\n        KEY_SELF_THROTTLE_ENABLE, DEFAULT_SELF_THROTTLE_ENABLE);\n\n    selfThrottlingReadFactor \u003d sessionConfiguration.getFloat(\n        KEY_SELF_THROTTLE_READ_FACTOR, DEFAULT_SELF_THROTTLE_READ_FACTOR);\n\n    selfThrottlingWriteFactor \u003d sessionConfiguration.getFloat(\n        KEY_SELF_THROTTLE_WRITE_FACTOR, DEFAULT_SELF_THROTTLE_WRITE_FACTOR);\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(String\n          .format(\n              \"AzureNativeFileSystemStore init. Settings\u003d%d,%b,%d,{%d,%d,%d,%d},{%b,%f,%f}\",\n              concurrentWrites, tolerateOobAppends,\n              ((storageConnectionTimeout \u003e 0) ? storageConnectionTimeout\n                  : STORAGE_CONNECTION_TIMEOUT_DEFAULT), minBackoff,\n              deltaBackoff, maxBackoff, maxRetries, selfThrottlingEnabled,\n              selfThrottlingReadFactor, selfThrottlingWriteFactor));\n    }\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/AzureNativeFileSystemStore.java"
    }
  }
}