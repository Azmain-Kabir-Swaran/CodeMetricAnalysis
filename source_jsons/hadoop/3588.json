{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DFSInputStream.java",
  "functionName": "blockSeekTo",
  "functionId": "blockSeekTo___target-long",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
  "functionStartLine": 639,
  "functionEndLine": 713,
  "numCommitsSeen": 143,
  "timeTaken": 11404,
  "changeHistory": [
    "d10f77e3c91225f86ed9c0f0e6a9adf2e1434674",
    "b3119b9ab60a19d624db476c4e1c53410870c7a6",
    "c95b9b5c077c5b95649d195bd7385a76604863c1",
    "a9d3412b4ce40f5ab5a18756ede7e0606b653171",
    "70fc6746b326b9a913e8bebca5f5afaf01ab9e11",
    "be34e85e682880f46eee0310bf00ecc7d39cd5bd",
    "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93",
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
    "bff5999d07e9416a22846c849487e509ede55040",
    "b75df697e0f101f86788ad23a338ab3545b8d702",
    "439614b0c8a3df3d8b7967451c5331a0e034e13a",
    "caa42adf208bfb5625d1b3ef665fbf334ffcccd9",
    "a9dc5cd7069f721e8c55794b877026ba02537167",
    "7caa3bc98e6880f98c5c32c486a0c539f9fd3f5f",
    "463aec11718e47d4aabb86a7a539cb973460aae6",
    "17db74a1c1972392a5aba48a3e0334dcd6c76487",
    "beb0d25d2a7ba5004c6aabd105546ba9a9fec9be",
    "90122f25e142ff5ae9e2610b6b8968ac5fee8f79",
    "a31a3a68ead2773f8daa5b3ac1041e271b442789",
    "8373c4134afef0b7fb08a63b44ef0131faacec00",
    "a18fd620d070cf8e84aaf80d93807ac9ee207a0f",
    "bbb24fbf5d220fbe137d43651ba3802a9806b1a3",
    "9a4030e0e84a688c12daa21fe9a165808c3eca70",
    "c9db06f2e4d1c1f71f021d5070323f9fc194cdd7",
    "837e17b2eac1471d93e2eff395272063b265fee7",
    "239b2742d0e80d13c970fd062af4930e672fe903",
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de",
    "9b4a7900c7dfc0590316eedaa97144f938885651",
    "2ab10e29d9cca5018064be46a40e3c74423615a8",
    "3ab2e79ad7786623798c5c8816fcdb4173b09da1",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "d10f77e3c91225f86ed9c0f0e6a9adf2e1434674": "Ybodychange",
    "b3119b9ab60a19d624db476c4e1c53410870c7a6": "Ybodychange",
    "c95b9b5c077c5b95649d195bd7385a76604863c1": "Ybodychange",
    "a9d3412b4ce40f5ab5a18756ede7e0606b653171": "Ybodychange",
    "70fc6746b326b9a913e8bebca5f5afaf01ab9e11": "Ybodychange",
    "be34e85e682880f46eee0310bf00ecc7d39cd5bd": "Ybodychange",
    "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93": "Ybodychange",
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": "Yfilerename",
    "bff5999d07e9416a22846c849487e509ede55040": "Ybodychange",
    "b75df697e0f101f86788ad23a338ab3545b8d702": "Ybodychange",
    "439614b0c8a3df3d8b7967451c5331a0e034e13a": "Ybodychange",
    "caa42adf208bfb5625d1b3ef665fbf334ffcccd9": "Ybodychange",
    "a9dc5cd7069f721e8c55794b877026ba02537167": "Ybodychange",
    "7caa3bc98e6880f98c5c32c486a0c539f9fd3f5f": "Ybodychange",
    "463aec11718e47d4aabb86a7a539cb973460aae6": "Ybodychange",
    "17db74a1c1972392a5aba48a3e0334dcd6c76487": "Ybodychange",
    "beb0d25d2a7ba5004c6aabd105546ba9a9fec9be": "Ybodychange",
    "90122f25e142ff5ae9e2610b6b8968ac5fee8f79": "Ybodychange",
    "a31a3a68ead2773f8daa5b3ac1041e271b442789": "Ybodychange",
    "8373c4134afef0b7fb08a63b44ef0131faacec00": "Ybodychange",
    "a18fd620d070cf8e84aaf80d93807ac9ee207a0f": "Ybodychange",
    "bbb24fbf5d220fbe137d43651ba3802a9806b1a3": "Ybodychange",
    "9a4030e0e84a688c12daa21fe9a165808c3eca70": "Ybodychange",
    "c9db06f2e4d1c1f71f021d5070323f9fc194cdd7": "Ybodychange",
    "837e17b2eac1471d93e2eff395272063b265fee7": "Ybodychange",
    "239b2742d0e80d13c970fd062af4930e672fe903": "Ybodychange",
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de": "Ybodychange",
    "9b4a7900c7dfc0590316eedaa97144f938885651": "Ybodychange",
    "2ab10e29d9cca5018064be46a40e3c74423615a8": "Ybodychange",
    "3ab2e79ad7786623798c5c8816fcdb4173b09da1": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "d10f77e3c91225f86ed9c0f0e6a9adf2e1434674": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-15119. Allow expiration of cached locations in DFSInputStream.\nContributed by Ahmed Hussein.\n",
      "commitDate": "24/01/20 7:15 AM",
      "commitName": "d10f77e3c91225f86ed9c0f0e6a9adf2e1434674",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "12/12/19 2:23 AM",
      "commitNameOld": "0e28cd8f63615dddded2f1183f27efb5c2aaf6aa",
      "commitAuthorOld": "He Xiaoqiao",
      "daysBetweenCommits": 43.2,
      "commitsBetweenForRepo": 139,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,72 +1,75 @@\n   private synchronized DatanodeInfo blockSeekTo(long target)\n       throws IOException {\n     if (target \u003e\u003d getFileLength()) {\n       throw new IOException(\"Attempted to read past end of file\");\n     }\n-\n     // Will be getting a new BlockReader.\n     closeCurrentBlockReaders();\n \n     //\n     // Connect to best DataNode for desired Block, with potential offset\n     //\n     DatanodeInfo chosenNode;\n     int refetchToken \u003d 1; // only need to get a new access token once\n     int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n \n     boolean connectFailedOnce \u003d false;\n \n     while (true) {\n+      // Re-fetch the locatedBlocks from NN if the timestamp has expired.\n+      updateBlockLocationsStamp();\n+\n       //\n       // Compute desired block\n       //\n+\n       LocatedBlock targetBlock \u003d getBlockAt(target);\n \n       // update current position\n       this.pos \u003d target;\n       this.blockEnd \u003d targetBlock.getStartOffset() +\n             targetBlock.getBlockSize() - 1;\n       this.currentLocatedBlock \u003d targetBlock;\n \n       long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n \n       DNAddrPair retval \u003d chooseDataNode(targetBlock, null);\n       chosenNode \u003d retval.info;\n       InetSocketAddress targetAddr \u003d retval.addr;\n       StorageType storageType \u003d retval.storageType;\n       // Latest block if refreshed by chooseDatanode()\n       targetBlock \u003d retval.block;\n \n       try {\n         blockReader \u003d getBlockReader(targetBlock, offsetIntoBlock,\n             targetBlock.getBlockSize() - offsetIntoBlock, targetAddr,\n             storageType, chosenNode);\n         if(connectFailedOnce) {\n           DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                              \" for \" + targetBlock.getBlock());\n         }\n         return chosenNode;\n       } catch (IOException ex) {\n         checkInterrupted(ex);\n         if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n           DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \"\n               + \"encryption key was invalid when connecting to \" + targetAddr\n               + \" : \" + ex);\n           // The encryption key used is invalid.\n           refetchEncryptionKey--;\n           dfsClient.clearDataEncryptionKey();\n         } else if (refetchToken \u003e 0 \u0026\u0026 tokenRefetchNeeded(ex, targetAddr)) {\n           refetchToken--;\n           fetchBlockAt(target);\n         } else {\n           connectFailedOnce \u003d true;\n           DFSClient.LOG.warn(\"Failed to connect to {} for file {} for block \"\n                   + \"{}, add to deadNodes and continue. \", targetAddr, src,\n               targetBlock.getBlock(), ex);\n           // Put chosen node into dead list, continue\n           addToLocalDeadNodes(chosenNode);\n           dfsClient.addNodeToDeadNodeDetector(this, chosenNode);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized DatanodeInfo blockSeekTo(long target)\n      throws IOException {\n    if (target \u003e\u003d getFileLength()) {\n      throw new IOException(\"Attempted to read past end of file\");\n    }\n    // Will be getting a new BlockReader.\n    closeCurrentBlockReaders();\n\n    //\n    // Connect to best DataNode for desired Block, with potential offset\n    //\n    DatanodeInfo chosenNode;\n    int refetchToken \u003d 1; // only need to get a new access token once\n    int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n\n    boolean connectFailedOnce \u003d false;\n\n    while (true) {\n      // Re-fetch the locatedBlocks from NN if the timestamp has expired.\n      updateBlockLocationsStamp();\n\n      //\n      // Compute desired block\n      //\n\n      LocatedBlock targetBlock \u003d getBlockAt(target);\n\n      // update current position\n      this.pos \u003d target;\n      this.blockEnd \u003d targetBlock.getStartOffset() +\n            targetBlock.getBlockSize() - 1;\n      this.currentLocatedBlock \u003d targetBlock;\n\n      long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n\n      DNAddrPair retval \u003d chooseDataNode(targetBlock, null);\n      chosenNode \u003d retval.info;\n      InetSocketAddress targetAddr \u003d retval.addr;\n      StorageType storageType \u003d retval.storageType;\n      // Latest block if refreshed by chooseDatanode()\n      targetBlock \u003d retval.block;\n\n      try {\n        blockReader \u003d getBlockReader(targetBlock, offsetIntoBlock,\n            targetBlock.getBlockSize() - offsetIntoBlock, targetAddr,\n            storageType, chosenNode);\n        if(connectFailedOnce) {\n          DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                             \" for \" + targetBlock.getBlock());\n        }\n        return chosenNode;\n      } catch (IOException ex) {\n        checkInterrupted(ex);\n        if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \"\n              + \"encryption key was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          // The encryption key used is invalid.\n          refetchEncryptionKey--;\n          dfsClient.clearDataEncryptionKey();\n        } else if (refetchToken \u003e 0 \u0026\u0026 tokenRefetchNeeded(ex, targetAddr)) {\n          refetchToken--;\n          fetchBlockAt(target);\n        } else {\n          connectFailedOnce \u003d true;\n          DFSClient.LOG.warn(\"Failed to connect to {} for file {} for block \"\n                  + \"{}, add to deadNodes and continue. \", targetAddr, src,\n              targetBlock.getBlock(), ex);\n          // Put chosen node into dead list, continue\n          addToLocalDeadNodes(chosenNode);\n          dfsClient.addNodeToDeadNodeDetector(this, chosenNode);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "b3119b9ab60a19d624db476c4e1c53410870c7a6": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14648. Implement DeadNodeDetector basic model. Contributed by Lisheng Sun.\n",
      "commitDate": "15/11/19 7:32 PM",
      "commitName": "b3119b9ab60a19d624db476c4e1c53410870c7a6",
      "commitAuthor": "Yiqun Lin",
      "commitDateOld": "06/11/19 5:58 AM",
      "commitNameOld": "c36014165c212b26d75268ee3659aa2cadcff349",
      "commitAuthorOld": "Surendra Singh Lilhore",
      "daysBetweenCommits": 9.57,
      "commitsBetweenForRepo": 36,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,71 +1,72 @@\n   private synchronized DatanodeInfo blockSeekTo(long target)\n       throws IOException {\n     if (target \u003e\u003d getFileLength()) {\n       throw new IOException(\"Attempted to read past end of file\");\n     }\n \n     // Will be getting a new BlockReader.\n     closeCurrentBlockReaders();\n \n     //\n     // Connect to best DataNode for desired Block, with potential offset\n     //\n     DatanodeInfo chosenNode;\n     int refetchToken \u003d 1; // only need to get a new access token once\n     int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n \n     boolean connectFailedOnce \u003d false;\n \n     while (true) {\n       //\n       // Compute desired block\n       //\n       LocatedBlock targetBlock \u003d getBlockAt(target);\n \n       // update current position\n       this.pos \u003d target;\n       this.blockEnd \u003d targetBlock.getStartOffset() +\n             targetBlock.getBlockSize() - 1;\n       this.currentLocatedBlock \u003d targetBlock;\n \n       long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n \n       DNAddrPair retval \u003d chooseDataNode(targetBlock, null);\n       chosenNode \u003d retval.info;\n       InetSocketAddress targetAddr \u003d retval.addr;\n       StorageType storageType \u003d retval.storageType;\n       // Latest block if refreshed by chooseDatanode()\n       targetBlock \u003d retval.block;\n \n       try {\n         blockReader \u003d getBlockReader(targetBlock, offsetIntoBlock,\n             targetBlock.getBlockSize() - offsetIntoBlock, targetAddr,\n             storageType, chosenNode);\n         if(connectFailedOnce) {\n           DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                              \" for \" + targetBlock.getBlock());\n         }\n         return chosenNode;\n       } catch (IOException ex) {\n         checkInterrupted(ex);\n         if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n           DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \"\n               + \"encryption key was invalid when connecting to \" + targetAddr\n               + \" : \" + ex);\n           // The encryption key used is invalid.\n           refetchEncryptionKey--;\n           dfsClient.clearDataEncryptionKey();\n         } else if (refetchToken \u003e 0 \u0026\u0026 tokenRefetchNeeded(ex, targetAddr)) {\n           refetchToken--;\n           fetchBlockAt(target);\n         } else {\n           connectFailedOnce \u003d true;\n           DFSClient.LOG.warn(\"Failed to connect to {} for file {} for block \"\n                   + \"{}, add to deadNodes and continue. \", targetAddr, src,\n               targetBlock.getBlock(), ex);\n           // Put chosen node into dead list, continue\n-          addToDeadNodes(chosenNode);\n+          addToLocalDeadNodes(chosenNode);\n+          dfsClient.addNodeToDeadNodeDetector(this, chosenNode);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized DatanodeInfo blockSeekTo(long target)\n      throws IOException {\n    if (target \u003e\u003d getFileLength()) {\n      throw new IOException(\"Attempted to read past end of file\");\n    }\n\n    // Will be getting a new BlockReader.\n    closeCurrentBlockReaders();\n\n    //\n    // Connect to best DataNode for desired Block, with potential offset\n    //\n    DatanodeInfo chosenNode;\n    int refetchToken \u003d 1; // only need to get a new access token once\n    int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n\n    boolean connectFailedOnce \u003d false;\n\n    while (true) {\n      //\n      // Compute desired block\n      //\n      LocatedBlock targetBlock \u003d getBlockAt(target);\n\n      // update current position\n      this.pos \u003d target;\n      this.blockEnd \u003d targetBlock.getStartOffset() +\n            targetBlock.getBlockSize() - 1;\n      this.currentLocatedBlock \u003d targetBlock;\n\n      long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n\n      DNAddrPair retval \u003d chooseDataNode(targetBlock, null);\n      chosenNode \u003d retval.info;\n      InetSocketAddress targetAddr \u003d retval.addr;\n      StorageType storageType \u003d retval.storageType;\n      // Latest block if refreshed by chooseDatanode()\n      targetBlock \u003d retval.block;\n\n      try {\n        blockReader \u003d getBlockReader(targetBlock, offsetIntoBlock,\n            targetBlock.getBlockSize() - offsetIntoBlock, targetAddr,\n            storageType, chosenNode);\n        if(connectFailedOnce) {\n          DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                             \" for \" + targetBlock.getBlock());\n        }\n        return chosenNode;\n      } catch (IOException ex) {\n        checkInterrupted(ex);\n        if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \"\n              + \"encryption key was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          // The encryption key used is invalid.\n          refetchEncryptionKey--;\n          dfsClient.clearDataEncryptionKey();\n        } else if (refetchToken \u003e 0 \u0026\u0026 tokenRefetchNeeded(ex, targetAddr)) {\n          refetchToken--;\n          fetchBlockAt(target);\n        } else {\n          connectFailedOnce \u003d true;\n          DFSClient.LOG.warn(\"Failed to connect to {} for file {} for block \"\n                  + \"{}, add to deadNodes and continue. \", targetAddr, src,\n              targetBlock.getBlock(), ex);\n          // Put chosen node into dead list, continue\n          addToLocalDeadNodes(chosenNode);\n          dfsClient.addNodeToDeadNodeDetector(this, chosenNode);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "c95b9b5c077c5b95649d195bd7385a76604863c1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13440. Log HDFS file name when client fails to connect.  Contributed by Gabor Bota.\n",
      "commitDate": "31/05/18 3:20 PM",
      "commitName": "c95b9b5c077c5b95649d195bd7385a76604863c1",
      "commitAuthor": "Wei-Chiu Chuang",
      "commitDateOld": "14/05/18 9:28 AM",
      "commitNameOld": "960940e0e08f7839775f2d8a352b444d104d36b4",
      "commitAuthorOld": "Xiao Chen",
      "daysBetweenCommits": 17.24,
      "commitsBetweenForRepo": 150,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,71 +1,71 @@\n   private synchronized DatanodeInfo blockSeekTo(long target)\n       throws IOException {\n     if (target \u003e\u003d getFileLength()) {\n       throw new IOException(\"Attempted to read past end of file\");\n     }\n \n     // Will be getting a new BlockReader.\n     closeCurrentBlockReaders();\n \n     //\n     // Connect to best DataNode for desired Block, with potential offset\n     //\n     DatanodeInfo chosenNode;\n     int refetchToken \u003d 1; // only need to get a new access token once\n     int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n \n     boolean connectFailedOnce \u003d false;\n \n     while (true) {\n       //\n       // Compute desired block\n       //\n       LocatedBlock targetBlock \u003d getBlockAt(target);\n \n       // update current position\n       this.pos \u003d target;\n       this.blockEnd \u003d targetBlock.getStartOffset() +\n             targetBlock.getBlockSize() - 1;\n       this.currentLocatedBlock \u003d targetBlock;\n \n       long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n \n       DNAddrPair retval \u003d chooseDataNode(targetBlock, null);\n       chosenNode \u003d retval.info;\n       InetSocketAddress targetAddr \u003d retval.addr;\n       StorageType storageType \u003d retval.storageType;\n       // Latest block if refreshed by chooseDatanode()\n       targetBlock \u003d retval.block;\n \n       try {\n         blockReader \u003d getBlockReader(targetBlock, offsetIntoBlock,\n             targetBlock.getBlockSize() - offsetIntoBlock, targetAddr,\n             storageType, chosenNode);\n         if(connectFailedOnce) {\n           DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                              \" for \" + targetBlock.getBlock());\n         }\n         return chosenNode;\n       } catch (IOException ex) {\n         checkInterrupted(ex);\n         if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n           DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \"\n               + \"encryption key was invalid when connecting to \" + targetAddr\n               + \" : \" + ex);\n           // The encryption key used is invalid.\n           refetchEncryptionKey--;\n           dfsClient.clearDataEncryptionKey();\n         } else if (refetchToken \u003e 0 \u0026\u0026 tokenRefetchNeeded(ex, targetAddr)) {\n           refetchToken--;\n           fetchBlockAt(target);\n         } else {\n           connectFailedOnce \u003d true;\n-          DFSClient.LOG.warn(\"Failed to connect to {} for block {}, \" +\n-              \"add to deadNodes and continue. \", targetAddr,\n+          DFSClient.LOG.warn(\"Failed to connect to {} for file {} for block \"\n+                  + \"{}, add to deadNodes and continue. \", targetAddr, src,\n               targetBlock.getBlock(), ex);\n           // Put chosen node into dead list, continue\n           addToDeadNodes(chosenNode);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized DatanodeInfo blockSeekTo(long target)\n      throws IOException {\n    if (target \u003e\u003d getFileLength()) {\n      throw new IOException(\"Attempted to read past end of file\");\n    }\n\n    // Will be getting a new BlockReader.\n    closeCurrentBlockReaders();\n\n    //\n    // Connect to best DataNode for desired Block, with potential offset\n    //\n    DatanodeInfo chosenNode;\n    int refetchToken \u003d 1; // only need to get a new access token once\n    int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n\n    boolean connectFailedOnce \u003d false;\n\n    while (true) {\n      //\n      // Compute desired block\n      //\n      LocatedBlock targetBlock \u003d getBlockAt(target);\n\n      // update current position\n      this.pos \u003d target;\n      this.blockEnd \u003d targetBlock.getStartOffset() +\n            targetBlock.getBlockSize() - 1;\n      this.currentLocatedBlock \u003d targetBlock;\n\n      long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n\n      DNAddrPair retval \u003d chooseDataNode(targetBlock, null);\n      chosenNode \u003d retval.info;\n      InetSocketAddress targetAddr \u003d retval.addr;\n      StorageType storageType \u003d retval.storageType;\n      // Latest block if refreshed by chooseDatanode()\n      targetBlock \u003d retval.block;\n\n      try {\n        blockReader \u003d getBlockReader(targetBlock, offsetIntoBlock,\n            targetBlock.getBlockSize() - offsetIntoBlock, targetAddr,\n            storageType, chosenNode);\n        if(connectFailedOnce) {\n          DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                             \" for \" + targetBlock.getBlock());\n        }\n        return chosenNode;\n      } catch (IOException ex) {\n        checkInterrupted(ex);\n        if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \"\n              + \"encryption key was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          // The encryption key used is invalid.\n          refetchEncryptionKey--;\n          dfsClient.clearDataEncryptionKey();\n        } else if (refetchToken \u003e 0 \u0026\u0026 tokenRefetchNeeded(ex, targetAddr)) {\n          refetchToken--;\n          fetchBlockAt(target);\n        } else {\n          connectFailedOnce \u003d true;\n          DFSClient.LOG.warn(\"Failed to connect to {} for file {} for block \"\n                  + \"{}, add to deadNodes and continue. \", targetAddr, src,\n              targetBlock.getBlock(), ex);\n          // Put chosen node into dead list, continue\n          addToDeadNodes(chosenNode);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "a9d3412b4ce40f5ab5a18756ede7e0606b653171": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11993. Add log info when connect to datanode socket address failed. Contributed by chencan\n",
      "commitDate": "26/06/17 1:24 PM",
      "commitName": "a9d3412b4ce40f5ab5a18756ede7e0606b653171",
      "commitAuthor": "Ravi Prakash",
      "commitDateOld": "06/06/17 10:25 PM",
      "commitNameOld": "70fc6746b326b9a913e8bebca5f5afaf01ab9e11",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 19.62,
      "commitsBetweenForRepo": 86,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,70 +1,71 @@\n   private synchronized DatanodeInfo blockSeekTo(long target)\n       throws IOException {\n     if (target \u003e\u003d getFileLength()) {\n       throw new IOException(\"Attempted to read past end of file\");\n     }\n \n     // Will be getting a new BlockReader.\n     closeCurrentBlockReaders();\n \n     //\n     // Connect to best DataNode for desired Block, with potential offset\n     //\n     DatanodeInfo chosenNode;\n     int refetchToken \u003d 1; // only need to get a new access token once\n     int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n \n     boolean connectFailedOnce \u003d false;\n \n     while (true) {\n       //\n       // Compute desired block\n       //\n       LocatedBlock targetBlock \u003d getBlockAt(target);\n \n       // update current position\n       this.pos \u003d target;\n       this.blockEnd \u003d targetBlock.getStartOffset() +\n             targetBlock.getBlockSize() - 1;\n       this.currentLocatedBlock \u003d targetBlock;\n \n       long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n \n       DNAddrPair retval \u003d chooseDataNode(targetBlock, null);\n       chosenNode \u003d retval.info;\n       InetSocketAddress targetAddr \u003d retval.addr;\n       StorageType storageType \u003d retval.storageType;\n       // Latest block if refreshed by chooseDatanode()\n       targetBlock \u003d retval.block;\n \n       try {\n         blockReader \u003d getBlockReader(targetBlock, offsetIntoBlock,\n             targetBlock.getBlockSize() - offsetIntoBlock, targetAddr,\n             storageType, chosenNode);\n         if(connectFailedOnce) {\n           DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                              \" for \" + targetBlock.getBlock());\n         }\n         return chosenNode;\n       } catch (IOException ex) {\n         checkInterrupted(ex);\n         if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n           DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \"\n               + \"encryption key was invalid when connecting to \" + targetAddr\n               + \" : \" + ex);\n           // The encryption key used is invalid.\n           refetchEncryptionKey--;\n           dfsClient.clearDataEncryptionKey();\n         } else if (refetchToken \u003e 0 \u0026\u0026 tokenRefetchNeeded(ex, targetAddr)) {\n           refetchToken--;\n           fetchBlockAt(target);\n         } else {\n           connectFailedOnce \u003d true;\n-          DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n-              + \", add to deadNodes and continue. \" + ex, ex);\n+          DFSClient.LOG.warn(\"Failed to connect to {} for block {}, \" +\n+              \"add to deadNodes and continue. \", targetAddr,\n+              targetBlock.getBlock(), ex);\n           // Put chosen node into dead list, continue\n           addToDeadNodes(chosenNode);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized DatanodeInfo blockSeekTo(long target)\n      throws IOException {\n    if (target \u003e\u003d getFileLength()) {\n      throw new IOException(\"Attempted to read past end of file\");\n    }\n\n    // Will be getting a new BlockReader.\n    closeCurrentBlockReaders();\n\n    //\n    // Connect to best DataNode for desired Block, with potential offset\n    //\n    DatanodeInfo chosenNode;\n    int refetchToken \u003d 1; // only need to get a new access token once\n    int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n\n    boolean connectFailedOnce \u003d false;\n\n    while (true) {\n      //\n      // Compute desired block\n      //\n      LocatedBlock targetBlock \u003d getBlockAt(target);\n\n      // update current position\n      this.pos \u003d target;\n      this.blockEnd \u003d targetBlock.getStartOffset() +\n            targetBlock.getBlockSize() - 1;\n      this.currentLocatedBlock \u003d targetBlock;\n\n      long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n\n      DNAddrPair retval \u003d chooseDataNode(targetBlock, null);\n      chosenNode \u003d retval.info;\n      InetSocketAddress targetAddr \u003d retval.addr;\n      StorageType storageType \u003d retval.storageType;\n      // Latest block if refreshed by chooseDatanode()\n      targetBlock \u003d retval.block;\n\n      try {\n        blockReader \u003d getBlockReader(targetBlock, offsetIntoBlock,\n            targetBlock.getBlockSize() - offsetIntoBlock, targetAddr,\n            storageType, chosenNode);\n        if(connectFailedOnce) {\n          DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                             \" for \" + targetBlock.getBlock());\n        }\n        return chosenNode;\n      } catch (IOException ex) {\n        checkInterrupted(ex);\n        if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \"\n              + \"encryption key was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          // The encryption key used is invalid.\n          refetchEncryptionKey--;\n          dfsClient.clearDataEncryptionKey();\n        } else if (refetchToken \u003e 0 \u0026\u0026 tokenRefetchNeeded(ex, targetAddr)) {\n          refetchToken--;\n          fetchBlockAt(target);\n        } else {\n          connectFailedOnce \u003d true;\n          DFSClient.LOG.warn(\"Failed to connect to {} for block {}, \" +\n              \"add to deadNodes and continue. \", targetAddr,\n              targetBlock.getBlock(), ex);\n          // Put chosen node into dead list, continue\n          addToDeadNodes(chosenNode);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "70fc6746b326b9a913e8bebca5f5afaf01ab9e11": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11708. Positional read will fail if replicas moved to different DNs after stream is opened. Contributed by Vinayakumar B.\n",
      "commitDate": "06/06/17 10:25 PM",
      "commitName": "70fc6746b326b9a913e8bebca5f5afaf01ab9e11",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "03/04/17 8:13 PM",
      "commitNameOld": "6eba79232f36b36e0196163adc8fe4219a6b6bf9",
      "commitAuthorOld": "Chris Douglas",
      "daysBetweenCommits": 64.09,
      "commitsBetweenForRepo": 349,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,68 +1,70 @@\n   private synchronized DatanodeInfo blockSeekTo(long target)\n       throws IOException {\n     if (target \u003e\u003d getFileLength()) {\n       throw new IOException(\"Attempted to read past end of file\");\n     }\n \n     // Will be getting a new BlockReader.\n     closeCurrentBlockReaders();\n \n     //\n     // Connect to best DataNode for desired Block, with potential offset\n     //\n     DatanodeInfo chosenNode;\n     int refetchToken \u003d 1; // only need to get a new access token once\n     int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n \n     boolean connectFailedOnce \u003d false;\n \n     while (true) {\n       //\n       // Compute desired block\n       //\n       LocatedBlock targetBlock \u003d getBlockAt(target);\n \n       // update current position\n       this.pos \u003d target;\n       this.blockEnd \u003d targetBlock.getStartOffset() +\n             targetBlock.getBlockSize() - 1;\n       this.currentLocatedBlock \u003d targetBlock;\n \n       long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n \n       DNAddrPair retval \u003d chooseDataNode(targetBlock, null);\n       chosenNode \u003d retval.info;\n       InetSocketAddress targetAddr \u003d retval.addr;\n       StorageType storageType \u003d retval.storageType;\n+      // Latest block if refreshed by chooseDatanode()\n+      targetBlock \u003d retval.block;\n \n       try {\n         blockReader \u003d getBlockReader(targetBlock, offsetIntoBlock,\n             targetBlock.getBlockSize() - offsetIntoBlock, targetAddr,\n             storageType, chosenNode);\n         if(connectFailedOnce) {\n           DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                              \" for \" + targetBlock.getBlock());\n         }\n         return chosenNode;\n       } catch (IOException ex) {\n         checkInterrupted(ex);\n         if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n           DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \"\n               + \"encryption key was invalid when connecting to \" + targetAddr\n               + \" : \" + ex);\n           // The encryption key used is invalid.\n           refetchEncryptionKey--;\n           dfsClient.clearDataEncryptionKey();\n         } else if (refetchToken \u003e 0 \u0026\u0026 tokenRefetchNeeded(ex, targetAddr)) {\n           refetchToken--;\n           fetchBlockAt(target);\n         } else {\n           connectFailedOnce \u003d true;\n           DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n               + \", add to deadNodes and continue. \" + ex, ex);\n           // Put chosen node into dead list, continue\n           addToDeadNodes(chosenNode);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized DatanodeInfo blockSeekTo(long target)\n      throws IOException {\n    if (target \u003e\u003d getFileLength()) {\n      throw new IOException(\"Attempted to read past end of file\");\n    }\n\n    // Will be getting a new BlockReader.\n    closeCurrentBlockReaders();\n\n    //\n    // Connect to best DataNode for desired Block, with potential offset\n    //\n    DatanodeInfo chosenNode;\n    int refetchToken \u003d 1; // only need to get a new access token once\n    int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n\n    boolean connectFailedOnce \u003d false;\n\n    while (true) {\n      //\n      // Compute desired block\n      //\n      LocatedBlock targetBlock \u003d getBlockAt(target);\n\n      // update current position\n      this.pos \u003d target;\n      this.blockEnd \u003d targetBlock.getStartOffset() +\n            targetBlock.getBlockSize() - 1;\n      this.currentLocatedBlock \u003d targetBlock;\n\n      long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n\n      DNAddrPair retval \u003d chooseDataNode(targetBlock, null);\n      chosenNode \u003d retval.info;\n      InetSocketAddress targetAddr \u003d retval.addr;\n      StorageType storageType \u003d retval.storageType;\n      // Latest block if refreshed by chooseDatanode()\n      targetBlock \u003d retval.block;\n\n      try {\n        blockReader \u003d getBlockReader(targetBlock, offsetIntoBlock,\n            targetBlock.getBlockSize() - offsetIntoBlock, targetAddr,\n            storageType, chosenNode);\n        if(connectFailedOnce) {\n          DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                             \" for \" + targetBlock.getBlock());\n        }\n        return chosenNode;\n      } catch (IOException ex) {\n        checkInterrupted(ex);\n        if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \"\n              + \"encryption key was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          // The encryption key used is invalid.\n          refetchEncryptionKey--;\n          dfsClient.clearDataEncryptionKey();\n        } else if (refetchToken \u003e 0 \u0026\u0026 tokenRefetchNeeded(ex, targetAddr)) {\n          refetchToken--;\n          fetchBlockAt(target);\n        } else {\n          connectFailedOnce \u003d true;\n          DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n              + \", add to deadNodes and continue. \" + ex, ex);\n          // Put chosen node into dead list, continue\n          addToDeadNodes(chosenNode);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "be34e85e682880f46eee0310bf00ecc7d39cd5bd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10468. HDFS read ends up ignoring an interrupt. Contributed by Jing Zhao\n",
      "commitDate": "07/06/16 10:48 AM",
      "commitName": "be34e85e682880f46eee0310bf00ecc7d39cd5bd",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "25/04/16 12:01 PM",
      "commitNameOld": "f308561f1d885491b88db73ac63003202056d661",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 42.95,
      "commitsBetweenForRepo": 291,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,66 +1,67 @@\n   private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n     if (target \u003e\u003d getFileLength()) {\n       throw new IOException(\"Attempted to read past end of file\");\n     }\n \n     // Will be getting a new BlockReader.\n     closeCurrentBlockReaders();\n \n     //\n     // Connect to best DataNode for desired Block, with potential offset\n     //\n     DatanodeInfo chosenNode;\n     int refetchToken \u003d 1; // only need to get a new access token once\n     int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n \n     boolean connectFailedOnce \u003d false;\n \n     while (true) {\n       //\n       // Compute desired block\n       //\n       LocatedBlock targetBlock \u003d getBlockAt(target);\n \n       // update current position\n       this.pos \u003d target;\n       this.blockEnd \u003d targetBlock.getStartOffset() +\n             targetBlock.getBlockSize() - 1;\n       this.currentLocatedBlock \u003d targetBlock;\n \n       long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n \n       DNAddrPair retval \u003d chooseDataNode(targetBlock, null);\n       chosenNode \u003d retval.info;\n       InetSocketAddress targetAddr \u003d retval.addr;\n       StorageType storageType \u003d retval.storageType;\n \n       try {\n         blockReader \u003d getBlockReader(targetBlock, offsetIntoBlock,\n             targetBlock.getBlockSize() - offsetIntoBlock, targetAddr,\n             storageType, chosenNode);\n         if(connectFailedOnce) {\n           DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                              \" for \" + targetBlock.getBlock());\n         }\n         return chosenNode;\n       } catch (IOException ex) {\n+        checkInterrupted(ex);\n         if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n           DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \"\n               + \"encryption key was invalid when connecting to \" + targetAddr\n               + \" : \" + ex);\n           // The encryption key used is invalid.\n           refetchEncryptionKey--;\n           dfsClient.clearDataEncryptionKey();\n         } else if (refetchToken \u003e 0 \u0026\u0026 tokenRefetchNeeded(ex, targetAddr)) {\n           refetchToken--;\n           fetchBlockAt(target);\n         } else {\n           connectFailedOnce \u003d true;\n           DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n               + \", add to deadNodes and continue. \" + ex, ex);\n           // Put chosen node into dead list, continue\n           addToDeadNodes(chosenNode);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n    if (target \u003e\u003d getFileLength()) {\n      throw new IOException(\"Attempted to read past end of file\");\n    }\n\n    // Will be getting a new BlockReader.\n    closeCurrentBlockReaders();\n\n    //\n    // Connect to best DataNode for desired Block, with potential offset\n    //\n    DatanodeInfo chosenNode;\n    int refetchToken \u003d 1; // only need to get a new access token once\n    int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n\n    boolean connectFailedOnce \u003d false;\n\n    while (true) {\n      //\n      // Compute desired block\n      //\n      LocatedBlock targetBlock \u003d getBlockAt(target);\n\n      // update current position\n      this.pos \u003d target;\n      this.blockEnd \u003d targetBlock.getStartOffset() +\n            targetBlock.getBlockSize() - 1;\n      this.currentLocatedBlock \u003d targetBlock;\n\n      long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n\n      DNAddrPair retval \u003d chooseDataNode(targetBlock, null);\n      chosenNode \u003d retval.info;\n      InetSocketAddress targetAddr \u003d retval.addr;\n      StorageType storageType \u003d retval.storageType;\n\n      try {\n        blockReader \u003d getBlockReader(targetBlock, offsetIntoBlock,\n            targetBlock.getBlockSize() - offsetIntoBlock, targetAddr,\n            storageType, chosenNode);\n        if(connectFailedOnce) {\n          DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                             \" for \" + targetBlock.getBlock());\n        }\n        return chosenNode;\n      } catch (IOException ex) {\n        checkInterrupted(ex);\n        if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \"\n              + \"encryption key was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          // The encryption key used is invalid.\n          refetchEncryptionKey--;\n          dfsClient.clearDataEncryptionKey();\n        } else if (refetchToken \u003e 0 \u0026\u0026 tokenRefetchNeeded(ex, targetAddr)) {\n          refetchToken--;\n          fetchBlockAt(target);\n        } else {\n          connectFailedOnce \u003d true;\n          DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n              + \", add to deadNodes and continue. \" + ex, ex);\n          // Put chosen node into dead list, continue\n          addToDeadNodes(chosenNode);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8979. Clean up checkstyle warnings in hadoop-hdfs-client module. Contributed by Mingliang Liu.\n",
      "commitDate": "03/10/15 11:38 AM",
      "commitName": "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "30/09/15 8:39 AM",
      "commitNameOld": "6c17d315287020368689fa078a40a1eaedf89d5b",
      "commitAuthorOld": "",
      "daysBetweenCommits": 3.12,
      "commitsBetweenForRepo": 16,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,66 +1,66 @@\n   private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n     if (target \u003e\u003d getFileLength()) {\n       throw new IOException(\"Attempted to read past end of file\");\n     }\n \n     // Will be getting a new BlockReader.\n     closeCurrentBlockReaders();\n \n     //\n     // Connect to best DataNode for desired Block, with potential offset\n     //\n-    DatanodeInfo chosenNode \u003d null;\n+    DatanodeInfo chosenNode;\n     int refetchToken \u003d 1; // only need to get a new access token once\n     int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n-    \n+\n     boolean connectFailedOnce \u003d false;\n \n     while (true) {\n       //\n       // Compute desired block\n       //\n       LocatedBlock targetBlock \u003d getBlockAt(target);\n \n       // update current position\n       this.pos \u003d target;\n       this.blockEnd \u003d targetBlock.getStartOffset() +\n             targetBlock.getBlockSize() - 1;\n       this.currentLocatedBlock \u003d targetBlock;\n \n       long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n \n       DNAddrPair retval \u003d chooseDataNode(targetBlock, null);\n       chosenNode \u003d retval.info;\n       InetSocketAddress targetAddr \u003d retval.addr;\n       StorageType storageType \u003d retval.storageType;\n \n       try {\n         blockReader \u003d getBlockReader(targetBlock, offsetIntoBlock,\n             targetBlock.getBlockSize() - offsetIntoBlock, targetAddr,\n             storageType, chosenNode);\n         if(connectFailedOnce) {\n           DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                              \" for \" + targetBlock.getBlock());\n         }\n         return chosenNode;\n       } catch (IOException ex) {\n         if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n           DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \"\n               + \"encryption key was invalid when connecting to \" + targetAddr\n               + \" : \" + ex);\n           // The encryption key used is invalid.\n           refetchEncryptionKey--;\n           dfsClient.clearDataEncryptionKey();\n         } else if (refetchToken \u003e 0 \u0026\u0026 tokenRefetchNeeded(ex, targetAddr)) {\n           refetchToken--;\n           fetchBlockAt(target);\n         } else {\n           connectFailedOnce \u003d true;\n           DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n-            + \", add to deadNodes and continue. \" + ex, ex);\n+              + \", add to deadNodes and continue. \" + ex, ex);\n           // Put chosen node into dead list, continue\n           addToDeadNodes(chosenNode);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n    if (target \u003e\u003d getFileLength()) {\n      throw new IOException(\"Attempted to read past end of file\");\n    }\n\n    // Will be getting a new BlockReader.\n    closeCurrentBlockReaders();\n\n    //\n    // Connect to best DataNode for desired Block, with potential offset\n    //\n    DatanodeInfo chosenNode;\n    int refetchToken \u003d 1; // only need to get a new access token once\n    int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n\n    boolean connectFailedOnce \u003d false;\n\n    while (true) {\n      //\n      // Compute desired block\n      //\n      LocatedBlock targetBlock \u003d getBlockAt(target);\n\n      // update current position\n      this.pos \u003d target;\n      this.blockEnd \u003d targetBlock.getStartOffset() +\n            targetBlock.getBlockSize() - 1;\n      this.currentLocatedBlock \u003d targetBlock;\n\n      long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n\n      DNAddrPair retval \u003d chooseDataNode(targetBlock, null);\n      chosenNode \u003d retval.info;\n      InetSocketAddress targetAddr \u003d retval.addr;\n      StorageType storageType \u003d retval.storageType;\n\n      try {\n        blockReader \u003d getBlockReader(targetBlock, offsetIntoBlock,\n            targetBlock.getBlockSize() - offsetIntoBlock, targetAddr,\n            storageType, chosenNode);\n        if(connectFailedOnce) {\n          DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                             \" for \" + targetBlock.getBlock());\n        }\n        return chosenNode;\n      } catch (IOException ex) {\n        if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \"\n              + \"encryption key was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          // The encryption key used is invalid.\n          refetchEncryptionKey--;\n          dfsClient.clearDataEncryptionKey();\n        } else if (refetchToken \u003e 0 \u0026\u0026 tokenRefetchNeeded(ex, targetAddr)) {\n          refetchToken--;\n          fetchBlockAt(target);\n        } else {\n          connectFailedOnce \u003d true;\n          DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n              + \", add to deadNodes and continue. \" + ex, ex);\n          // Put chosen node into dead list, continue\n          addToDeadNodes(chosenNode);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8053. Move DFSIn/OutputStream and related classes to hadoop-hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "26/09/15 11:08 AM",
      "commitName": "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "26/09/15 9:06 AM",
      "commitNameOld": "861b52db242f238d7e36ad75c158025be959a696",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 0.08,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n    if (target \u003e\u003d getFileLength()) {\n      throw new IOException(\"Attempted to read past end of file\");\n    }\n\n    // Will be getting a new BlockReader.\n    closeCurrentBlockReaders();\n\n    //\n    // Connect to best DataNode for desired Block, with potential offset\n    //\n    DatanodeInfo chosenNode \u003d null;\n    int refetchToken \u003d 1; // only need to get a new access token once\n    int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n    \n    boolean connectFailedOnce \u003d false;\n\n    while (true) {\n      //\n      // Compute desired block\n      //\n      LocatedBlock targetBlock \u003d getBlockAt(target);\n\n      // update current position\n      this.pos \u003d target;\n      this.blockEnd \u003d targetBlock.getStartOffset() +\n            targetBlock.getBlockSize() - 1;\n      this.currentLocatedBlock \u003d targetBlock;\n\n      long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n\n      DNAddrPair retval \u003d chooseDataNode(targetBlock, null);\n      chosenNode \u003d retval.info;\n      InetSocketAddress targetAddr \u003d retval.addr;\n      StorageType storageType \u003d retval.storageType;\n\n      try {\n        blockReader \u003d getBlockReader(targetBlock, offsetIntoBlock,\n            targetBlock.getBlockSize() - offsetIntoBlock, targetAddr,\n            storageType, chosenNode);\n        if(connectFailedOnce) {\n          DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                             \" for \" + targetBlock.getBlock());\n        }\n        return chosenNode;\n      } catch (IOException ex) {\n        if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \"\n              + \"encryption key was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          // The encryption key used is invalid.\n          refetchEncryptionKey--;\n          dfsClient.clearDataEncryptionKey();\n        } else if (refetchToken \u003e 0 \u0026\u0026 tokenRefetchNeeded(ex, targetAddr)) {\n          refetchToken--;\n          fetchBlockAt(target);\n        } else {\n          connectFailedOnce \u003d true;\n          DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n            + \", add to deadNodes and continue. \" + ex, ex);\n          // Put chosen node into dead list, continue\n          addToDeadNodes(chosenNode);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java"
      }
    },
    "bff5999d07e9416a22846c849487e509ede55040": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8703. Merge refactor of DFSInputStream from ErasureCoding branch (Contributed by Vinayakumar B)\n",
      "commitDate": "02/07/15 3:41 AM",
      "commitName": "bff5999d07e9416a22846c849487e509ede55040",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "04/06/15 10:51 AM",
      "commitNameOld": "ade6d9a61eb2e57a975f0efcdf8828d51ffec5fd",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 27.7,
      "commitsBetweenForRepo": 196,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,66 +1,66 @@\n   private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n     if (target \u003e\u003d getFileLength()) {\n       throw new IOException(\"Attempted to read past end of file\");\n     }\n \n     // Will be getting a new BlockReader.\n-    closeCurrentBlockReader();\n+    closeCurrentBlockReaders();\n \n     //\n     // Connect to best DataNode for desired Block, with potential offset\n     //\n     DatanodeInfo chosenNode \u003d null;\n     int refetchToken \u003d 1; // only need to get a new access token once\n     int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n     \n     boolean connectFailedOnce \u003d false;\n \n     while (true) {\n       //\n       // Compute desired block\n       //\n       LocatedBlock targetBlock \u003d getBlockAt(target);\n \n       // update current position\n       this.pos \u003d target;\n       this.blockEnd \u003d targetBlock.getStartOffset() +\n             targetBlock.getBlockSize() - 1;\n       this.currentLocatedBlock \u003d targetBlock;\n \n       long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n \n       DNAddrPair retval \u003d chooseDataNode(targetBlock, null);\n       chosenNode \u003d retval.info;\n       InetSocketAddress targetAddr \u003d retval.addr;\n       StorageType storageType \u003d retval.storageType;\n \n       try {\n         blockReader \u003d getBlockReader(targetBlock, offsetIntoBlock,\n             targetBlock.getBlockSize() - offsetIntoBlock, targetAddr,\n             storageType, chosenNode);\n         if(connectFailedOnce) {\n           DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                              \" for \" + targetBlock.getBlock());\n         }\n         return chosenNode;\n       } catch (IOException ex) {\n         if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n-          DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n+          DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \"\n               + \"encryption key was invalid when connecting to \" + targetAddr\n               + \" : \" + ex);\n           // The encryption key used is invalid.\n           refetchEncryptionKey--;\n           dfsClient.clearDataEncryptionKey();\n         } else if (refetchToken \u003e 0 \u0026\u0026 tokenRefetchNeeded(ex, targetAddr)) {\n           refetchToken--;\n           fetchBlockAt(target);\n         } else {\n           connectFailedOnce \u003d true;\n-          DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block \"\n-            +targetBlock.getBlock()+ \", add to deadNodes and continue. \" + ex, ex);\n+          DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n+            + \", add to deadNodes and continue. \" + ex, ex);\n           // Put chosen node into dead list, continue\n           addToDeadNodes(chosenNode);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n    if (target \u003e\u003d getFileLength()) {\n      throw new IOException(\"Attempted to read past end of file\");\n    }\n\n    // Will be getting a new BlockReader.\n    closeCurrentBlockReaders();\n\n    //\n    // Connect to best DataNode for desired Block, with potential offset\n    //\n    DatanodeInfo chosenNode \u003d null;\n    int refetchToken \u003d 1; // only need to get a new access token once\n    int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n    \n    boolean connectFailedOnce \u003d false;\n\n    while (true) {\n      //\n      // Compute desired block\n      //\n      LocatedBlock targetBlock \u003d getBlockAt(target);\n\n      // update current position\n      this.pos \u003d target;\n      this.blockEnd \u003d targetBlock.getStartOffset() +\n            targetBlock.getBlockSize() - 1;\n      this.currentLocatedBlock \u003d targetBlock;\n\n      long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n\n      DNAddrPair retval \u003d chooseDataNode(targetBlock, null);\n      chosenNode \u003d retval.info;\n      InetSocketAddress targetAddr \u003d retval.addr;\n      StorageType storageType \u003d retval.storageType;\n\n      try {\n        blockReader \u003d getBlockReader(targetBlock, offsetIntoBlock,\n            targetBlock.getBlockSize() - offsetIntoBlock, targetAddr,\n            storageType, chosenNode);\n        if(connectFailedOnce) {\n          DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                             \" for \" + targetBlock.getBlock());\n        }\n        return chosenNode;\n      } catch (IOException ex) {\n        if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \"\n              + \"encryption key was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          // The encryption key used is invalid.\n          refetchEncryptionKey--;\n          dfsClient.clearDataEncryptionKey();\n        } else if (refetchToken \u003e 0 \u0026\u0026 tokenRefetchNeeded(ex, targetAddr)) {\n          refetchToken--;\n          fetchBlockAt(target);\n        } else {\n          connectFailedOnce \u003d true;\n          DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n            + \", add to deadNodes and continue. \" + ex, ex);\n          // Put chosen node into dead list, continue\n          addToDeadNodes(chosenNode);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "b75df697e0f101f86788ad23a338ab3545b8d702": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7401. Add block info to DFSInputStream\u0027 WARN message when it adds node to deadNodes (Contributed by Arshad Mohammad)\n",
      "commitDate": "29/05/15 4:06 AM",
      "commitName": "b75df697e0f101f86788ad23a338ab3545b8d702",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "19/05/15 10:50 AM",
      "commitNameOld": "470c87dbc6c24dd3b370f1ad9e7ab1f6dabd2080",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 9.72,
      "commitsBetweenForRepo": 78,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,66 +1,66 @@\n   private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n     if (target \u003e\u003d getFileLength()) {\n       throw new IOException(\"Attempted to read past end of file\");\n     }\n \n     // Will be getting a new BlockReader.\n     closeCurrentBlockReader();\n \n     //\n     // Connect to best DataNode for desired Block, with potential offset\n     //\n     DatanodeInfo chosenNode \u003d null;\n     int refetchToken \u003d 1; // only need to get a new access token once\n     int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n     \n     boolean connectFailedOnce \u003d false;\n \n     while (true) {\n       //\n       // Compute desired block\n       //\n       LocatedBlock targetBlock \u003d getBlockAt(target);\n \n       // update current position\n       this.pos \u003d target;\n       this.blockEnd \u003d targetBlock.getStartOffset() +\n             targetBlock.getBlockSize() - 1;\n       this.currentLocatedBlock \u003d targetBlock;\n \n       long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n \n       DNAddrPair retval \u003d chooseDataNode(targetBlock, null);\n       chosenNode \u003d retval.info;\n       InetSocketAddress targetAddr \u003d retval.addr;\n       StorageType storageType \u003d retval.storageType;\n \n       try {\n         blockReader \u003d getBlockReader(targetBlock, offsetIntoBlock,\n             targetBlock.getBlockSize() - offsetIntoBlock, targetAddr,\n             storageType, chosenNode);\n         if(connectFailedOnce) {\n           DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                              \" for \" + targetBlock.getBlock());\n         }\n         return chosenNode;\n       } catch (IOException ex) {\n         if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n           DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n               + \"encryption key was invalid when connecting to \" + targetAddr\n               + \" : \" + ex);\n           // The encryption key used is invalid.\n           refetchEncryptionKey--;\n           dfsClient.clearDataEncryptionKey();\n         } else if (refetchToken \u003e 0 \u0026\u0026 tokenRefetchNeeded(ex, targetAddr)) {\n           refetchToken--;\n           fetchBlockAt(target);\n         } else {\n           connectFailedOnce \u003d true;\n-          DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n-            + \", add to deadNodes and continue. \" + ex, ex);\n+          DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block \"\n+            +targetBlock.getBlock()+ \", add to deadNodes and continue. \" + ex, ex);\n           // Put chosen node into dead list, continue\n           addToDeadNodes(chosenNode);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n    if (target \u003e\u003d getFileLength()) {\n      throw new IOException(\"Attempted to read past end of file\");\n    }\n\n    // Will be getting a new BlockReader.\n    closeCurrentBlockReader();\n\n    //\n    // Connect to best DataNode for desired Block, with potential offset\n    //\n    DatanodeInfo chosenNode \u003d null;\n    int refetchToken \u003d 1; // only need to get a new access token once\n    int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n    \n    boolean connectFailedOnce \u003d false;\n\n    while (true) {\n      //\n      // Compute desired block\n      //\n      LocatedBlock targetBlock \u003d getBlockAt(target);\n\n      // update current position\n      this.pos \u003d target;\n      this.blockEnd \u003d targetBlock.getStartOffset() +\n            targetBlock.getBlockSize() - 1;\n      this.currentLocatedBlock \u003d targetBlock;\n\n      long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n\n      DNAddrPair retval \u003d chooseDataNode(targetBlock, null);\n      chosenNode \u003d retval.info;\n      InetSocketAddress targetAddr \u003d retval.addr;\n      StorageType storageType \u003d retval.storageType;\n\n      try {\n        blockReader \u003d getBlockReader(targetBlock, offsetIntoBlock,\n            targetBlock.getBlockSize() - offsetIntoBlock, targetAddr,\n            storageType, chosenNode);\n        if(connectFailedOnce) {\n          DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                             \" for \" + targetBlock.getBlock());\n        }\n        return chosenNode;\n      } catch (IOException ex) {\n        if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n              + \"encryption key was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          // The encryption key used is invalid.\n          refetchEncryptionKey--;\n          dfsClient.clearDataEncryptionKey();\n        } else if (refetchToken \u003e 0 \u0026\u0026 tokenRefetchNeeded(ex, targetAddr)) {\n          refetchToken--;\n          fetchBlockAt(target);\n        } else {\n          connectFailedOnce \u003d true;\n          DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block \"\n            +targetBlock.getBlock()+ \", add to deadNodes and continue. \" + ex, ex);\n          // Put chosen node into dead list, continue\n          addToDeadNodes(chosenNode);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "439614b0c8a3df3d8b7967451c5331a0e034e13a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8280. Code Cleanup in DFSInputStream. Contributed by Jing Zhao.\n",
      "commitDate": "28/04/15 6:11 PM",
      "commitName": "439614b0c8a3df3d8b7967451c5331a0e034e13a",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "16/04/15 1:22 PM",
      "commitNameOld": "75bbcc8bf3fa1daf54f56868dae737f6da12ab1f",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 12.2,
      "commitsBetweenForRepo": 109,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,90 +1,66 @@\n   private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n     if (target \u003e\u003d getFileLength()) {\n       throw new IOException(\"Attempted to read past end of file\");\n     }\n \n     // Will be getting a new BlockReader.\n     closeCurrentBlockReader();\n \n     //\n     // Connect to best DataNode for desired Block, with potential offset\n     //\n     DatanodeInfo chosenNode \u003d null;\n     int refetchToken \u003d 1; // only need to get a new access token once\n     int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n     \n     boolean connectFailedOnce \u003d false;\n \n     while (true) {\n       //\n       // Compute desired block\n       //\n       LocatedBlock targetBlock \u003d getBlockAt(target);\n \n       // update current position\n       this.pos \u003d target;\n       this.blockEnd \u003d targetBlock.getStartOffset() +\n             targetBlock.getBlockSize() - 1;\n       this.currentLocatedBlock \u003d targetBlock;\n \n-      assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n       long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n \n       DNAddrPair retval \u003d chooseDataNode(targetBlock, null);\n       chosenNode \u003d retval.info;\n       InetSocketAddress targetAddr \u003d retval.addr;\n       StorageType storageType \u003d retval.storageType;\n \n       try {\n-        ExtendedBlock blk \u003d targetBlock.getBlock();\n-        Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n-        CachingStrategy curCachingStrategy;\n-        boolean shortCircuitForbidden;\n-        synchronized(infoLock) {\n-          curCachingStrategy \u003d cachingStrategy;\n-          shortCircuitForbidden \u003d shortCircuitForbidden();\n-        }\n-        blockReader \u003d new BlockReaderFactory(dfsClient.getConf()).\n-            setInetSocketAddress(targetAddr).\n-            setRemotePeerFactory(dfsClient).\n-            setDatanodeInfo(chosenNode).\n-            setStorageType(storageType).\n-            setFileName(src).\n-            setBlock(blk).\n-            setBlockToken(accessToken).\n-            setStartOffset(offsetIntoBlock).\n-            setVerifyChecksum(verifyChecksum).\n-            setClientName(dfsClient.clientName).\n-            setLength(blk.getNumBytes() - offsetIntoBlock).\n-            setCachingStrategy(curCachingStrategy).\n-            setAllowShortCircuitLocalReads(!shortCircuitForbidden).\n-            setClientCacheContext(dfsClient.getClientContext()).\n-            setUserGroupInformation(dfsClient.ugi).\n-            setConfiguration(dfsClient.getConfiguration()).\n-            build();\n+        blockReader \u003d getBlockReader(targetBlock, offsetIntoBlock,\n+            targetBlock.getBlockSize() - offsetIntoBlock, targetAddr,\n+            storageType, chosenNode);\n         if(connectFailedOnce) {\n           DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n-                             \" for \" + blk);\n+                             \" for \" + targetBlock.getBlock());\n         }\n         return chosenNode;\n       } catch (IOException ex) {\n         if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n           DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n               + \"encryption key was invalid when connecting to \" + targetAddr\n               + \" : \" + ex);\n           // The encryption key used is invalid.\n           refetchEncryptionKey--;\n           dfsClient.clearDataEncryptionKey();\n         } else if (refetchToken \u003e 0 \u0026\u0026 tokenRefetchNeeded(ex, targetAddr)) {\n           refetchToken--;\n           fetchBlockAt(target);\n         } else {\n           connectFailedOnce \u003d true;\n           DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n             + \", add to deadNodes and continue. \" + ex, ex);\n           // Put chosen node into dead list, continue\n           addToDeadNodes(chosenNode);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n    if (target \u003e\u003d getFileLength()) {\n      throw new IOException(\"Attempted to read past end of file\");\n    }\n\n    // Will be getting a new BlockReader.\n    closeCurrentBlockReader();\n\n    //\n    // Connect to best DataNode for desired Block, with potential offset\n    //\n    DatanodeInfo chosenNode \u003d null;\n    int refetchToken \u003d 1; // only need to get a new access token once\n    int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n    \n    boolean connectFailedOnce \u003d false;\n\n    while (true) {\n      //\n      // Compute desired block\n      //\n      LocatedBlock targetBlock \u003d getBlockAt(target);\n\n      // update current position\n      this.pos \u003d target;\n      this.blockEnd \u003d targetBlock.getStartOffset() +\n            targetBlock.getBlockSize() - 1;\n      this.currentLocatedBlock \u003d targetBlock;\n\n      long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n\n      DNAddrPair retval \u003d chooseDataNode(targetBlock, null);\n      chosenNode \u003d retval.info;\n      InetSocketAddress targetAddr \u003d retval.addr;\n      StorageType storageType \u003d retval.storageType;\n\n      try {\n        blockReader \u003d getBlockReader(targetBlock, offsetIntoBlock,\n            targetBlock.getBlockSize() - offsetIntoBlock, targetAddr,\n            storageType, chosenNode);\n        if(connectFailedOnce) {\n          DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                             \" for \" + targetBlock.getBlock());\n        }\n        return chosenNode;\n      } catch (IOException ex) {\n        if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n              + \"encryption key was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          // The encryption key used is invalid.\n          refetchEncryptionKey--;\n          dfsClient.clearDataEncryptionKey();\n        } else if (refetchToken \u003e 0 \u0026\u0026 tokenRefetchNeeded(ex, targetAddr)) {\n          refetchToken--;\n          fetchBlockAt(target);\n        } else {\n          connectFailedOnce \u003d true;\n          DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n            + \", add to deadNodes and continue. \" + ex, ex);\n          // Put chosen node into dead list, continue\n          addToDeadNodes(chosenNode);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "caa42adf208bfb5625d1b3ef665fbf334ffcccd9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7495. Remove updatePosition argument from DFSInputStream#getBlockAt() (cmccabe)\n",
      "commitDate": "25/02/15 1:30 PM",
      "commitName": "caa42adf208bfb5625d1b3ef665fbf334ffcccd9",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "21/02/15 3:38 PM",
      "commitNameOld": "8b465b4b8caed31ca9daeaae108f9a868a30a455",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 3.91,
      "commitsBetweenForRepo": 26,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,83 +1,90 @@\n   private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n     if (target \u003e\u003d getFileLength()) {\n       throw new IOException(\"Attempted to read past end of file\");\n     }\n \n     // Will be getting a new BlockReader.\n     closeCurrentBlockReader();\n \n     //\n     // Connect to best DataNode for desired Block, with potential offset\n     //\n     DatanodeInfo chosenNode \u003d null;\n     int refetchToken \u003d 1; // only need to get a new access token once\n     int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n     \n     boolean connectFailedOnce \u003d false;\n \n     while (true) {\n       //\n       // Compute desired block\n       //\n-      LocatedBlock targetBlock \u003d getBlockAt(target, true);\n+      LocatedBlock targetBlock \u003d getBlockAt(target);\n+\n+      // update current position\n+      this.pos \u003d target;\n+      this.blockEnd \u003d targetBlock.getStartOffset() +\n+            targetBlock.getBlockSize() - 1;\n+      this.currentLocatedBlock \u003d targetBlock;\n+\n       assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n       long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n \n       DNAddrPair retval \u003d chooseDataNode(targetBlock, null);\n       chosenNode \u003d retval.info;\n       InetSocketAddress targetAddr \u003d retval.addr;\n       StorageType storageType \u003d retval.storageType;\n \n       try {\n         ExtendedBlock blk \u003d targetBlock.getBlock();\n         Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n         CachingStrategy curCachingStrategy;\n         boolean shortCircuitForbidden;\n         synchronized(infoLock) {\n           curCachingStrategy \u003d cachingStrategy;\n           shortCircuitForbidden \u003d shortCircuitForbidden();\n         }\n         blockReader \u003d new BlockReaderFactory(dfsClient.getConf()).\n             setInetSocketAddress(targetAddr).\n             setRemotePeerFactory(dfsClient).\n             setDatanodeInfo(chosenNode).\n             setStorageType(storageType).\n             setFileName(src).\n             setBlock(blk).\n             setBlockToken(accessToken).\n             setStartOffset(offsetIntoBlock).\n             setVerifyChecksum(verifyChecksum).\n             setClientName(dfsClient.clientName).\n             setLength(blk.getNumBytes() - offsetIntoBlock).\n             setCachingStrategy(curCachingStrategy).\n             setAllowShortCircuitLocalReads(!shortCircuitForbidden).\n             setClientCacheContext(dfsClient.getClientContext()).\n             setUserGroupInformation(dfsClient.ugi).\n             setConfiguration(dfsClient.getConfiguration()).\n             build();\n         if(connectFailedOnce) {\n           DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                              \" for \" + blk);\n         }\n         return chosenNode;\n       } catch (IOException ex) {\n         if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n           DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n               + \"encryption key was invalid when connecting to \" + targetAddr\n               + \" : \" + ex);\n           // The encryption key used is invalid.\n           refetchEncryptionKey--;\n           dfsClient.clearDataEncryptionKey();\n         } else if (refetchToken \u003e 0 \u0026\u0026 tokenRefetchNeeded(ex, targetAddr)) {\n           refetchToken--;\n           fetchBlockAt(target);\n         } else {\n           connectFailedOnce \u003d true;\n           DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n             + \", add to deadNodes and continue. \" + ex, ex);\n           // Put chosen node into dead list, continue\n           addToDeadNodes(chosenNode);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n    if (target \u003e\u003d getFileLength()) {\n      throw new IOException(\"Attempted to read past end of file\");\n    }\n\n    // Will be getting a new BlockReader.\n    closeCurrentBlockReader();\n\n    //\n    // Connect to best DataNode for desired Block, with potential offset\n    //\n    DatanodeInfo chosenNode \u003d null;\n    int refetchToken \u003d 1; // only need to get a new access token once\n    int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n    \n    boolean connectFailedOnce \u003d false;\n\n    while (true) {\n      //\n      // Compute desired block\n      //\n      LocatedBlock targetBlock \u003d getBlockAt(target);\n\n      // update current position\n      this.pos \u003d target;\n      this.blockEnd \u003d targetBlock.getStartOffset() +\n            targetBlock.getBlockSize() - 1;\n      this.currentLocatedBlock \u003d targetBlock;\n\n      assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n      long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n\n      DNAddrPair retval \u003d chooseDataNode(targetBlock, null);\n      chosenNode \u003d retval.info;\n      InetSocketAddress targetAddr \u003d retval.addr;\n      StorageType storageType \u003d retval.storageType;\n\n      try {\n        ExtendedBlock blk \u003d targetBlock.getBlock();\n        Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n        CachingStrategy curCachingStrategy;\n        boolean shortCircuitForbidden;\n        synchronized(infoLock) {\n          curCachingStrategy \u003d cachingStrategy;\n          shortCircuitForbidden \u003d shortCircuitForbidden();\n        }\n        blockReader \u003d new BlockReaderFactory(dfsClient.getConf()).\n            setInetSocketAddress(targetAddr).\n            setRemotePeerFactory(dfsClient).\n            setDatanodeInfo(chosenNode).\n            setStorageType(storageType).\n            setFileName(src).\n            setBlock(blk).\n            setBlockToken(accessToken).\n            setStartOffset(offsetIntoBlock).\n            setVerifyChecksum(verifyChecksum).\n            setClientName(dfsClient.clientName).\n            setLength(blk.getNumBytes() - offsetIntoBlock).\n            setCachingStrategy(curCachingStrategy).\n            setAllowShortCircuitLocalReads(!shortCircuitForbidden).\n            setClientCacheContext(dfsClient.getClientContext()).\n            setUserGroupInformation(dfsClient.ugi).\n            setConfiguration(dfsClient.getConfiguration()).\n            build();\n        if(connectFailedOnce) {\n          DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                             \" for \" + blk);\n        }\n        return chosenNode;\n      } catch (IOException ex) {\n        if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n              + \"encryption key was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          // The encryption key used is invalid.\n          refetchEncryptionKey--;\n          dfsClient.clearDataEncryptionKey();\n        } else if (refetchToken \u003e 0 \u0026\u0026 tokenRefetchNeeded(ex, targetAddr)) {\n          refetchToken--;\n          fetchBlockAt(target);\n        } else {\n          connectFailedOnce \u003d true;\n          DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n            + \", add to deadNodes and continue. \" + ex, ex);\n          // Put chosen node into dead list, continue\n          addToDeadNodes(chosenNode);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "a9dc5cd7069f721e8c55794b877026ba02537167": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7744. Fix potential NPE in DFSInputStream after setDropBehind or setReadahead is called (cmccabe)\n",
      "commitDate": "09/02/15 8:16 PM",
      "commitName": "a9dc5cd7069f721e8c55794b877026ba02537167",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "05/02/15 7:56 AM",
      "commitNameOld": "45ea53f9388e6bff1ac0aa3989a1dad56a611fd3",
      "commitAuthorOld": "yliu",
      "daysBetweenCommits": 4.51,
      "commitsBetweenForRepo": 37,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,86 +1,83 @@\n   private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n     if (target \u003e\u003d getFileLength()) {\n       throw new IOException(\"Attempted to read past end of file\");\n     }\n \n     // Will be getting a new BlockReader.\n-    if (blockReader !\u003d null) {\n-      blockReader.close();\n-      blockReader \u003d null;\n-    }\n+    closeCurrentBlockReader();\n \n     //\n     // Connect to best DataNode for desired Block, with potential offset\n     //\n     DatanodeInfo chosenNode \u003d null;\n     int refetchToken \u003d 1; // only need to get a new access token once\n     int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n     \n     boolean connectFailedOnce \u003d false;\n \n     while (true) {\n       //\n       // Compute desired block\n       //\n       LocatedBlock targetBlock \u003d getBlockAt(target, true);\n       assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n       long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n \n       DNAddrPair retval \u003d chooseDataNode(targetBlock, null);\n       chosenNode \u003d retval.info;\n       InetSocketAddress targetAddr \u003d retval.addr;\n       StorageType storageType \u003d retval.storageType;\n \n       try {\n         ExtendedBlock blk \u003d targetBlock.getBlock();\n         Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n         CachingStrategy curCachingStrategy;\n         boolean shortCircuitForbidden;\n         synchronized(infoLock) {\n           curCachingStrategy \u003d cachingStrategy;\n           shortCircuitForbidden \u003d shortCircuitForbidden();\n         }\n         blockReader \u003d new BlockReaderFactory(dfsClient.getConf()).\n             setInetSocketAddress(targetAddr).\n             setRemotePeerFactory(dfsClient).\n             setDatanodeInfo(chosenNode).\n             setStorageType(storageType).\n             setFileName(src).\n             setBlock(blk).\n             setBlockToken(accessToken).\n             setStartOffset(offsetIntoBlock).\n             setVerifyChecksum(verifyChecksum).\n             setClientName(dfsClient.clientName).\n             setLength(blk.getNumBytes() - offsetIntoBlock).\n             setCachingStrategy(curCachingStrategy).\n             setAllowShortCircuitLocalReads(!shortCircuitForbidden).\n             setClientCacheContext(dfsClient.getClientContext()).\n             setUserGroupInformation(dfsClient.ugi).\n             setConfiguration(dfsClient.getConfiguration()).\n             build();\n         if(connectFailedOnce) {\n           DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                              \" for \" + blk);\n         }\n         return chosenNode;\n       } catch (IOException ex) {\n         if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n           DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n               + \"encryption key was invalid when connecting to \" + targetAddr\n               + \" : \" + ex);\n           // The encryption key used is invalid.\n           refetchEncryptionKey--;\n           dfsClient.clearDataEncryptionKey();\n         } else if (refetchToken \u003e 0 \u0026\u0026 tokenRefetchNeeded(ex, targetAddr)) {\n           refetchToken--;\n           fetchBlockAt(target);\n         } else {\n           connectFailedOnce \u003d true;\n           DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n             + \", add to deadNodes and continue. \" + ex, ex);\n           // Put chosen node into dead list, continue\n           addToDeadNodes(chosenNode);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n    if (target \u003e\u003d getFileLength()) {\n      throw new IOException(\"Attempted to read past end of file\");\n    }\n\n    // Will be getting a new BlockReader.\n    closeCurrentBlockReader();\n\n    //\n    // Connect to best DataNode for desired Block, with potential offset\n    //\n    DatanodeInfo chosenNode \u003d null;\n    int refetchToken \u003d 1; // only need to get a new access token once\n    int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n    \n    boolean connectFailedOnce \u003d false;\n\n    while (true) {\n      //\n      // Compute desired block\n      //\n      LocatedBlock targetBlock \u003d getBlockAt(target, true);\n      assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n      long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n\n      DNAddrPair retval \u003d chooseDataNode(targetBlock, null);\n      chosenNode \u003d retval.info;\n      InetSocketAddress targetAddr \u003d retval.addr;\n      StorageType storageType \u003d retval.storageType;\n\n      try {\n        ExtendedBlock blk \u003d targetBlock.getBlock();\n        Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n        CachingStrategy curCachingStrategy;\n        boolean shortCircuitForbidden;\n        synchronized(infoLock) {\n          curCachingStrategy \u003d cachingStrategy;\n          shortCircuitForbidden \u003d shortCircuitForbidden();\n        }\n        blockReader \u003d new BlockReaderFactory(dfsClient.getConf()).\n            setInetSocketAddress(targetAddr).\n            setRemotePeerFactory(dfsClient).\n            setDatanodeInfo(chosenNode).\n            setStorageType(storageType).\n            setFileName(src).\n            setBlock(blk).\n            setBlockToken(accessToken).\n            setStartOffset(offsetIntoBlock).\n            setVerifyChecksum(verifyChecksum).\n            setClientName(dfsClient.clientName).\n            setLength(blk.getNumBytes() - offsetIntoBlock).\n            setCachingStrategy(curCachingStrategy).\n            setAllowShortCircuitLocalReads(!shortCircuitForbidden).\n            setClientCacheContext(dfsClient.getClientContext()).\n            setUserGroupInformation(dfsClient.ugi).\n            setConfiguration(dfsClient.getConfiguration()).\n            build();\n        if(connectFailedOnce) {\n          DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                             \" for \" + blk);\n        }\n        return chosenNode;\n      } catch (IOException ex) {\n        if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n              + \"encryption key was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          // The encryption key used is invalid.\n          refetchEncryptionKey--;\n          dfsClient.clearDataEncryptionKey();\n        } else if (refetchToken \u003e 0 \u0026\u0026 tokenRefetchNeeded(ex, targetAddr)) {\n          refetchToken--;\n          fetchBlockAt(target);\n        } else {\n          connectFailedOnce \u003d true;\n          DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n            + \", add to deadNodes and continue. \" + ex, ex);\n          // Put chosen node into dead list, continue\n          addToDeadNodes(chosenNode);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "7caa3bc98e6880f98c5c32c486a0c539f9fd3f5f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6735. A minor optimization to avoid pread() be blocked by read() inside the same DFSInputStream (Lars Hofhansl via stack)\n",
      "commitDate": "02/12/14 8:57 PM",
      "commitName": "7caa3bc98e6880f98c5c32c486a0c539f9fd3f5f",
      "commitAuthor": "stack",
      "commitDateOld": "05/11/14 9:00 PM",
      "commitNameOld": "80d7d183cd4052d6e6d412ff6588d26471c85d6d",
      "commitAuthorOld": "Milan Desai",
      "daysBetweenCommits": 27.0,
      "commitsBetweenForRepo": 189,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,80 +1,86 @@\n   private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n     if (target \u003e\u003d getFileLength()) {\n       throw new IOException(\"Attempted to read past end of file\");\n     }\n \n     // Will be getting a new BlockReader.\n     if (blockReader !\u003d null) {\n       blockReader.close();\n       blockReader \u003d null;\n     }\n \n     //\n     // Connect to best DataNode for desired Block, with potential offset\n     //\n     DatanodeInfo chosenNode \u003d null;\n     int refetchToken \u003d 1; // only need to get a new access token once\n     int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n     \n     boolean connectFailedOnce \u003d false;\n \n     while (true) {\n       //\n       // Compute desired block\n       //\n       LocatedBlock targetBlock \u003d getBlockAt(target, true);\n       assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n       long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n \n       DNAddrPair retval \u003d chooseDataNode(targetBlock, null);\n       chosenNode \u003d retval.info;\n       InetSocketAddress targetAddr \u003d retval.addr;\n       StorageType storageType \u003d retval.storageType;\n \n       try {\n         ExtendedBlock blk \u003d targetBlock.getBlock();\n         Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n+        CachingStrategy curCachingStrategy;\n+        boolean shortCircuitForbidden;\n+        synchronized(infoLock) {\n+          curCachingStrategy \u003d cachingStrategy;\n+          shortCircuitForbidden \u003d shortCircuitForbidden();\n+        }\n         blockReader \u003d new BlockReaderFactory(dfsClient.getConf()).\n             setInetSocketAddress(targetAddr).\n             setRemotePeerFactory(dfsClient).\n             setDatanodeInfo(chosenNode).\n             setStorageType(storageType).\n             setFileName(src).\n             setBlock(blk).\n             setBlockToken(accessToken).\n             setStartOffset(offsetIntoBlock).\n             setVerifyChecksum(verifyChecksum).\n             setClientName(dfsClient.clientName).\n             setLength(blk.getNumBytes() - offsetIntoBlock).\n-            setCachingStrategy(cachingStrategy).\n-            setAllowShortCircuitLocalReads(!shortCircuitForbidden()).\n+            setCachingStrategy(curCachingStrategy).\n+            setAllowShortCircuitLocalReads(!shortCircuitForbidden).\n             setClientCacheContext(dfsClient.getClientContext()).\n             setUserGroupInformation(dfsClient.ugi).\n             setConfiguration(dfsClient.getConfiguration()).\n             build();\n         if(connectFailedOnce) {\n           DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                              \" for \" + blk);\n         }\n         return chosenNode;\n       } catch (IOException ex) {\n         if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n           DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n               + \"encryption key was invalid when connecting to \" + targetAddr\n               + \" : \" + ex);\n           // The encryption key used is invalid.\n           refetchEncryptionKey--;\n           dfsClient.clearDataEncryptionKey();\n         } else if (refetchToken \u003e 0 \u0026\u0026 tokenRefetchNeeded(ex, targetAddr)) {\n           refetchToken--;\n           fetchBlockAt(target);\n         } else {\n           connectFailedOnce \u003d true;\n           DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n             + \", add to deadNodes and continue. \" + ex, ex);\n           // Put chosen node into dead list, continue\n           addToDeadNodes(chosenNode);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n    if (target \u003e\u003d getFileLength()) {\n      throw new IOException(\"Attempted to read past end of file\");\n    }\n\n    // Will be getting a new BlockReader.\n    if (blockReader !\u003d null) {\n      blockReader.close();\n      blockReader \u003d null;\n    }\n\n    //\n    // Connect to best DataNode for desired Block, with potential offset\n    //\n    DatanodeInfo chosenNode \u003d null;\n    int refetchToken \u003d 1; // only need to get a new access token once\n    int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n    \n    boolean connectFailedOnce \u003d false;\n\n    while (true) {\n      //\n      // Compute desired block\n      //\n      LocatedBlock targetBlock \u003d getBlockAt(target, true);\n      assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n      long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n\n      DNAddrPair retval \u003d chooseDataNode(targetBlock, null);\n      chosenNode \u003d retval.info;\n      InetSocketAddress targetAddr \u003d retval.addr;\n      StorageType storageType \u003d retval.storageType;\n\n      try {\n        ExtendedBlock blk \u003d targetBlock.getBlock();\n        Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n        CachingStrategy curCachingStrategy;\n        boolean shortCircuitForbidden;\n        synchronized(infoLock) {\n          curCachingStrategy \u003d cachingStrategy;\n          shortCircuitForbidden \u003d shortCircuitForbidden();\n        }\n        blockReader \u003d new BlockReaderFactory(dfsClient.getConf()).\n            setInetSocketAddress(targetAddr).\n            setRemotePeerFactory(dfsClient).\n            setDatanodeInfo(chosenNode).\n            setStorageType(storageType).\n            setFileName(src).\n            setBlock(blk).\n            setBlockToken(accessToken).\n            setStartOffset(offsetIntoBlock).\n            setVerifyChecksum(verifyChecksum).\n            setClientName(dfsClient.clientName).\n            setLength(blk.getNumBytes() - offsetIntoBlock).\n            setCachingStrategy(curCachingStrategy).\n            setAllowShortCircuitLocalReads(!shortCircuitForbidden).\n            setClientCacheContext(dfsClient.getClientContext()).\n            setUserGroupInformation(dfsClient.ugi).\n            setConfiguration(dfsClient.getConfiguration()).\n            build();\n        if(connectFailedOnce) {\n          DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                             \" for \" + blk);\n        }\n        return chosenNode;\n      } catch (IOException ex) {\n        if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n              + \"encryption key was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          // The encryption key used is invalid.\n          refetchEncryptionKey--;\n          dfsClient.clearDataEncryptionKey();\n        } else if (refetchToken \u003e 0 \u0026\u0026 tokenRefetchNeeded(ex, targetAddr)) {\n          refetchToken--;\n          fetchBlockAt(target);\n        } else {\n          connectFailedOnce \u003d true;\n          DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n            + \", add to deadNodes and continue. \" + ex, ex);\n          // Put chosen node into dead list, continue\n          addToDeadNodes(chosenNode);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "463aec11718e47d4aabb86a7a539cb973460aae6": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6934. Move checksum computation off the hot path when writing to RAM disk. Contributed by Chris Nauroth.\n",
      "commitDate": "27/10/14 9:38 AM",
      "commitName": "463aec11718e47d4aabb86a7a539cb973460aae6",
      "commitAuthor": "cnauroth",
      "commitDateOld": "03/10/14 1:35 PM",
      "commitNameOld": "7f6ed7fe365166e8075359f1d0ad035fa876c70f",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 23.84,
      "commitsBetweenForRepo": 188,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,78 +1,80 @@\n   private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n     if (target \u003e\u003d getFileLength()) {\n       throw new IOException(\"Attempted to read past end of file\");\n     }\n \n     // Will be getting a new BlockReader.\n     if (blockReader !\u003d null) {\n       blockReader.close();\n       blockReader \u003d null;\n     }\n \n     //\n     // Connect to best DataNode for desired Block, with potential offset\n     //\n     DatanodeInfo chosenNode \u003d null;\n     int refetchToken \u003d 1; // only need to get a new access token once\n     int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n     \n     boolean connectFailedOnce \u003d false;\n \n     while (true) {\n       //\n       // Compute desired block\n       //\n       LocatedBlock targetBlock \u003d getBlockAt(target, true);\n       assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n       long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n \n       DNAddrPair retval \u003d chooseDataNode(targetBlock, null);\n       chosenNode \u003d retval.info;\n       InetSocketAddress targetAddr \u003d retval.addr;\n+      StorageType storageType \u003d retval.storageType;\n \n       try {\n         ExtendedBlock blk \u003d targetBlock.getBlock();\n         Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n         blockReader \u003d new BlockReaderFactory(dfsClient.getConf()).\n             setInetSocketAddress(targetAddr).\n             setRemotePeerFactory(dfsClient).\n             setDatanodeInfo(chosenNode).\n+            setStorageType(storageType).\n             setFileName(src).\n             setBlock(blk).\n             setBlockToken(accessToken).\n             setStartOffset(offsetIntoBlock).\n             setVerifyChecksum(verifyChecksum).\n             setClientName(dfsClient.clientName).\n             setLength(blk.getNumBytes() - offsetIntoBlock).\n             setCachingStrategy(cachingStrategy).\n             setAllowShortCircuitLocalReads(!shortCircuitForbidden()).\n             setClientCacheContext(dfsClient.getClientContext()).\n             setUserGroupInformation(dfsClient.ugi).\n             setConfiguration(dfsClient.getConfiguration()).\n             build();\n         if(connectFailedOnce) {\n           DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                              \" for \" + blk);\n         }\n         return chosenNode;\n       } catch (IOException ex) {\n         if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n           DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n               + \"encryption key was invalid when connecting to \" + targetAddr\n               + \" : \" + ex);\n           // The encryption key used is invalid.\n           refetchEncryptionKey--;\n           dfsClient.clearDataEncryptionKey();\n         } else if (refetchToken \u003e 0 \u0026\u0026 tokenRefetchNeeded(ex, targetAddr)) {\n           refetchToken--;\n           fetchBlockAt(target);\n         } else {\n           connectFailedOnce \u003d true;\n           DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n             + \", add to deadNodes and continue. \" + ex, ex);\n           // Put chosen node into dead list, continue\n           addToDeadNodes(chosenNode);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n    if (target \u003e\u003d getFileLength()) {\n      throw new IOException(\"Attempted to read past end of file\");\n    }\n\n    // Will be getting a new BlockReader.\n    if (blockReader !\u003d null) {\n      blockReader.close();\n      blockReader \u003d null;\n    }\n\n    //\n    // Connect to best DataNode for desired Block, with potential offset\n    //\n    DatanodeInfo chosenNode \u003d null;\n    int refetchToken \u003d 1; // only need to get a new access token once\n    int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n    \n    boolean connectFailedOnce \u003d false;\n\n    while (true) {\n      //\n      // Compute desired block\n      //\n      LocatedBlock targetBlock \u003d getBlockAt(target, true);\n      assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n      long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n\n      DNAddrPair retval \u003d chooseDataNode(targetBlock, null);\n      chosenNode \u003d retval.info;\n      InetSocketAddress targetAddr \u003d retval.addr;\n      StorageType storageType \u003d retval.storageType;\n\n      try {\n        ExtendedBlock blk \u003d targetBlock.getBlock();\n        Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n        blockReader \u003d new BlockReaderFactory(dfsClient.getConf()).\n            setInetSocketAddress(targetAddr).\n            setRemotePeerFactory(dfsClient).\n            setDatanodeInfo(chosenNode).\n            setStorageType(storageType).\n            setFileName(src).\n            setBlock(blk).\n            setBlockToken(accessToken).\n            setStartOffset(offsetIntoBlock).\n            setVerifyChecksum(verifyChecksum).\n            setClientName(dfsClient.clientName).\n            setLength(blk.getNumBytes() - offsetIntoBlock).\n            setCachingStrategy(cachingStrategy).\n            setAllowShortCircuitLocalReads(!shortCircuitForbidden()).\n            setClientCacheContext(dfsClient.getClientContext()).\n            setUserGroupInformation(dfsClient.ugi).\n            setConfiguration(dfsClient.getConfiguration()).\n            build();\n        if(connectFailedOnce) {\n          DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                             \" for \" + blk);\n        }\n        return chosenNode;\n      } catch (IOException ex) {\n        if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n              + \"encryption key was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          // The encryption key used is invalid.\n          refetchEncryptionKey--;\n          dfsClient.clearDataEncryptionKey();\n        } else if (refetchToken \u003e 0 \u0026\u0026 tokenRefetchNeeded(ex, targetAddr)) {\n          refetchToken--;\n          fetchBlockAt(target);\n        } else {\n          connectFailedOnce \u003d true;\n          DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n            + \", add to deadNodes and continue. \" + ex, ex);\n          // Put chosen node into dead list, continue\n          addToDeadNodes(chosenNode);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "17db74a1c1972392a5aba48a3e0334dcd6c76487": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5776 Support \u0027hedged\u0027 reads in DFSClient\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1571466 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/02/14 2:34 PM",
      "commitName": "17db74a1c1972392a5aba48a3e0334dcd6c76487",
      "commitAuthor": "Michael Stack",
      "commitDateOld": "12/02/14 11:08 AM",
      "commitNameOld": "beb0d25d2a7ba5004c6aabd105546ba9a9fec9be",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 12.14,
      "commitsBetweenForRepo": 95,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,78 +1,78 @@\n   private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n     if (target \u003e\u003d getFileLength()) {\n       throw new IOException(\"Attempted to read past end of file\");\n     }\n \n     // Will be getting a new BlockReader.\n     if (blockReader !\u003d null) {\n       blockReader.close();\n       blockReader \u003d null;\n     }\n \n     //\n     // Connect to best DataNode for desired Block, with potential offset\n     //\n     DatanodeInfo chosenNode \u003d null;\n     int refetchToken \u003d 1; // only need to get a new access token once\n     int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n     \n     boolean connectFailedOnce \u003d false;\n \n     while (true) {\n       //\n       // Compute desired block\n       //\n       LocatedBlock targetBlock \u003d getBlockAt(target, true);\n       assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n       long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n \n-      DNAddrPair retval \u003d chooseDataNode(targetBlock);\n+      DNAddrPair retval \u003d chooseDataNode(targetBlock, null);\n       chosenNode \u003d retval.info;\n       InetSocketAddress targetAddr \u003d retval.addr;\n \n       try {\n         ExtendedBlock blk \u003d targetBlock.getBlock();\n         Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n         blockReader \u003d new BlockReaderFactory(dfsClient.getConf()).\n             setInetSocketAddress(targetAddr).\n             setRemotePeerFactory(dfsClient).\n             setDatanodeInfo(chosenNode).\n             setFileName(src).\n             setBlock(blk).\n             setBlockToken(accessToken).\n             setStartOffset(offsetIntoBlock).\n             setVerifyChecksum(verifyChecksum).\n             setClientName(dfsClient.clientName).\n             setLength(blk.getNumBytes() - offsetIntoBlock).\n             setCachingStrategy(cachingStrategy).\n             setAllowShortCircuitLocalReads(!shortCircuitForbidden()).\n             setClientCacheContext(dfsClient.getClientContext()).\n             setUserGroupInformation(dfsClient.ugi).\n             setConfiguration(dfsClient.getConfiguration()).\n             build();\n         if(connectFailedOnce) {\n           DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                              \" for \" + blk);\n         }\n         return chosenNode;\n       } catch (IOException ex) {\n         if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n           DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n               + \"encryption key was invalid when connecting to \" + targetAddr\n               + \" : \" + ex);\n           // The encryption key used is invalid.\n           refetchEncryptionKey--;\n           dfsClient.clearDataEncryptionKey();\n         } else if (refetchToken \u003e 0 \u0026\u0026 tokenRefetchNeeded(ex, targetAddr)) {\n           refetchToken--;\n           fetchBlockAt(target);\n         } else {\n           connectFailedOnce \u003d true;\n           DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n             + \", add to deadNodes and continue. \" + ex, ex);\n           // Put chosen node into dead list, continue\n           addToDeadNodes(chosenNode);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n    if (target \u003e\u003d getFileLength()) {\n      throw new IOException(\"Attempted to read past end of file\");\n    }\n\n    // Will be getting a new BlockReader.\n    if (blockReader !\u003d null) {\n      blockReader.close();\n      blockReader \u003d null;\n    }\n\n    //\n    // Connect to best DataNode for desired Block, with potential offset\n    //\n    DatanodeInfo chosenNode \u003d null;\n    int refetchToken \u003d 1; // only need to get a new access token once\n    int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n    \n    boolean connectFailedOnce \u003d false;\n\n    while (true) {\n      //\n      // Compute desired block\n      //\n      LocatedBlock targetBlock \u003d getBlockAt(target, true);\n      assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n      long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n\n      DNAddrPair retval \u003d chooseDataNode(targetBlock, null);\n      chosenNode \u003d retval.info;\n      InetSocketAddress targetAddr \u003d retval.addr;\n\n      try {\n        ExtendedBlock blk \u003d targetBlock.getBlock();\n        Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n        blockReader \u003d new BlockReaderFactory(dfsClient.getConf()).\n            setInetSocketAddress(targetAddr).\n            setRemotePeerFactory(dfsClient).\n            setDatanodeInfo(chosenNode).\n            setFileName(src).\n            setBlock(blk).\n            setBlockToken(accessToken).\n            setStartOffset(offsetIntoBlock).\n            setVerifyChecksum(verifyChecksum).\n            setClientName(dfsClient.clientName).\n            setLength(blk.getNumBytes() - offsetIntoBlock).\n            setCachingStrategy(cachingStrategy).\n            setAllowShortCircuitLocalReads(!shortCircuitForbidden()).\n            setClientCacheContext(dfsClient.getClientContext()).\n            setUserGroupInformation(dfsClient.ugi).\n            setConfiguration(dfsClient.getConfiguration()).\n            build();\n        if(connectFailedOnce) {\n          DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                             \" for \" + blk);\n        }\n        return chosenNode;\n      } catch (IOException ex) {\n        if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n              + \"encryption key was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          // The encryption key used is invalid.\n          refetchEncryptionKey--;\n          dfsClient.clearDataEncryptionKey();\n        } else if (refetchToken \u003e 0 \u0026\u0026 tokenRefetchNeeded(ex, targetAddr)) {\n          refetchToken--;\n          fetchBlockAt(target);\n        } else {\n          connectFailedOnce \u003d true;\n          DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n            + \", add to deadNodes and continue. \" + ex, ex);\n          // Put chosen node into dead list, continue\n          addToDeadNodes(chosenNode);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "beb0d25d2a7ba5004c6aabd105546ba9a9fec9be": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5810. Unify mmap cache and short-circuit file descriptor cache (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1567720 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/02/14 11:08 AM",
      "commitName": "beb0d25d2a7ba5004c6aabd105546ba9a9fec9be",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "06/02/14 7:45 AM",
      "commitNameOld": "ab96a0838dafbfea77382135914feadbfd03cf53",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 6.14,
      "commitsBetweenForRepo": 45,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,68 +1,78 @@\n   private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n     if (target \u003e\u003d getFileLength()) {\n       throw new IOException(\"Attempted to read past end of file\");\n     }\n \n     // Will be getting a new BlockReader.\n     if (blockReader !\u003d null) {\n       blockReader.close();\n       blockReader \u003d null;\n     }\n \n     //\n     // Connect to best DataNode for desired Block, with potential offset\n     //\n     DatanodeInfo chosenNode \u003d null;\n     int refetchToken \u003d 1; // only need to get a new access token once\n     int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n     \n     boolean connectFailedOnce \u003d false;\n \n     while (true) {\n       //\n       // Compute desired block\n       //\n       LocatedBlock targetBlock \u003d getBlockAt(target, true);\n       assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n       long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n \n       DNAddrPair retval \u003d chooseDataNode(targetBlock);\n       chosenNode \u003d retval.info;\n       InetSocketAddress targetAddr \u003d retval.addr;\n \n       try {\n         ExtendedBlock blk \u003d targetBlock.getBlock();\n         Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n-        blockReader \u003d getBlockReader(targetAddr, chosenNode, src, blk,\n-            accessToken, offsetIntoBlock, blk.getNumBytes() - offsetIntoBlock,\n-            buffersize, verifyChecksum, dfsClient.clientName, cachingStrategy);\n+        blockReader \u003d new BlockReaderFactory(dfsClient.getConf()).\n+            setInetSocketAddress(targetAddr).\n+            setRemotePeerFactory(dfsClient).\n+            setDatanodeInfo(chosenNode).\n+            setFileName(src).\n+            setBlock(blk).\n+            setBlockToken(accessToken).\n+            setStartOffset(offsetIntoBlock).\n+            setVerifyChecksum(verifyChecksum).\n+            setClientName(dfsClient.clientName).\n+            setLength(blk.getNumBytes() - offsetIntoBlock).\n+            setCachingStrategy(cachingStrategy).\n+            setAllowShortCircuitLocalReads(!shortCircuitForbidden()).\n+            setClientCacheContext(dfsClient.getClientContext()).\n+            setUserGroupInformation(dfsClient.ugi).\n+            setConfiguration(dfsClient.getConfiguration()).\n+            build();\n         if(connectFailedOnce) {\n           DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                              \" for \" + blk);\n         }\n         return chosenNode;\n-      } catch (AccessControlException ex) {\n-        DFSClient.LOG.warn(\"Short circuit access failed \" + ex);\n-        dfsClient.disableLegacyBlockReaderLocal();\n-        continue;\n       } catch (IOException ex) {\n         if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n           DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n               + \"encryption key was invalid when connecting to \" + targetAddr\n               + \" : \" + ex);\n           // The encryption key used is invalid.\n           refetchEncryptionKey--;\n           dfsClient.clearDataEncryptionKey();\n         } else if (refetchToken \u003e 0 \u0026\u0026 tokenRefetchNeeded(ex, targetAddr)) {\n           refetchToken--;\n           fetchBlockAt(target);\n         } else {\n           connectFailedOnce \u003d true;\n           DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n             + \", add to deadNodes and continue. \" + ex, ex);\n           // Put chosen node into dead list, continue\n           addToDeadNodes(chosenNode);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n    if (target \u003e\u003d getFileLength()) {\n      throw new IOException(\"Attempted to read past end of file\");\n    }\n\n    // Will be getting a new BlockReader.\n    if (blockReader !\u003d null) {\n      blockReader.close();\n      blockReader \u003d null;\n    }\n\n    //\n    // Connect to best DataNode for desired Block, with potential offset\n    //\n    DatanodeInfo chosenNode \u003d null;\n    int refetchToken \u003d 1; // only need to get a new access token once\n    int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n    \n    boolean connectFailedOnce \u003d false;\n\n    while (true) {\n      //\n      // Compute desired block\n      //\n      LocatedBlock targetBlock \u003d getBlockAt(target, true);\n      assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n      long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n\n      DNAddrPair retval \u003d chooseDataNode(targetBlock);\n      chosenNode \u003d retval.info;\n      InetSocketAddress targetAddr \u003d retval.addr;\n\n      try {\n        ExtendedBlock blk \u003d targetBlock.getBlock();\n        Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n        blockReader \u003d new BlockReaderFactory(dfsClient.getConf()).\n            setInetSocketAddress(targetAddr).\n            setRemotePeerFactory(dfsClient).\n            setDatanodeInfo(chosenNode).\n            setFileName(src).\n            setBlock(blk).\n            setBlockToken(accessToken).\n            setStartOffset(offsetIntoBlock).\n            setVerifyChecksum(verifyChecksum).\n            setClientName(dfsClient.clientName).\n            setLength(blk.getNumBytes() - offsetIntoBlock).\n            setCachingStrategy(cachingStrategy).\n            setAllowShortCircuitLocalReads(!shortCircuitForbidden()).\n            setClientCacheContext(dfsClient.getClientContext()).\n            setUserGroupInformation(dfsClient.ugi).\n            setConfiguration(dfsClient.getConfiguration()).\n            build();\n        if(connectFailedOnce) {\n          DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                             \" for \" + blk);\n        }\n        return chosenNode;\n      } catch (IOException ex) {\n        if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n              + \"encryption key was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          // The encryption key used is invalid.\n          refetchEncryptionKey--;\n          dfsClient.clearDataEncryptionKey();\n        } else if (refetchToken \u003e 0 \u0026\u0026 tokenRefetchNeeded(ex, targetAddr)) {\n          refetchToken--;\n          fetchBlockAt(target);\n        } else {\n          connectFailedOnce \u003d true;\n          DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n            + \", add to deadNodes and continue. \" + ex, ex);\n          // Put chosen node into dead list, continue\n          addToDeadNodes(chosenNode);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "90122f25e142ff5ae9e2610b6b8968ac5fee8f79": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5676. fix inconsistent synchronization of CachingStrategy (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1552162 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/12/13 3:29 PM",
      "commitName": "90122f25e142ff5ae9e2610b6b8968ac5fee8f79",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "17/12/13 12:57 PM",
      "commitNameOld": "124e507674c0d396f8494585e64226957199097b",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 1.11,
      "commitsBetweenForRepo": 12,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,68 +1,68 @@\n   private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n     if (target \u003e\u003d getFileLength()) {\n       throw new IOException(\"Attempted to read past end of file\");\n     }\n \n     // Will be getting a new BlockReader.\n     if (blockReader !\u003d null) {\n       blockReader.close();\n       blockReader \u003d null;\n     }\n \n     //\n     // Connect to best DataNode for desired Block, with potential offset\n     //\n     DatanodeInfo chosenNode \u003d null;\n     int refetchToken \u003d 1; // only need to get a new access token once\n     int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n     \n     boolean connectFailedOnce \u003d false;\n \n     while (true) {\n       //\n       // Compute desired block\n       //\n       LocatedBlock targetBlock \u003d getBlockAt(target, true);\n       assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n       long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n \n       DNAddrPair retval \u003d chooseDataNode(targetBlock);\n       chosenNode \u003d retval.info;\n       InetSocketAddress targetAddr \u003d retval.addr;\n \n       try {\n         ExtendedBlock blk \u003d targetBlock.getBlock();\n         Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n         blockReader \u003d getBlockReader(targetAddr, chosenNode, src, blk,\n             accessToken, offsetIntoBlock, blk.getNumBytes() - offsetIntoBlock,\n-            buffersize, verifyChecksum, dfsClient.clientName);\n+            buffersize, verifyChecksum, dfsClient.clientName, cachingStrategy);\n         if(connectFailedOnce) {\n           DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                              \" for \" + blk);\n         }\n         return chosenNode;\n       } catch (AccessControlException ex) {\n         DFSClient.LOG.warn(\"Short circuit access failed \" + ex);\n         dfsClient.disableLegacyBlockReaderLocal();\n         continue;\n       } catch (IOException ex) {\n         if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n           DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n               + \"encryption key was invalid when connecting to \" + targetAddr\n               + \" : \" + ex);\n           // The encryption key used is invalid.\n           refetchEncryptionKey--;\n           dfsClient.clearDataEncryptionKey();\n         } else if (refetchToken \u003e 0 \u0026\u0026 tokenRefetchNeeded(ex, targetAddr)) {\n           refetchToken--;\n           fetchBlockAt(target);\n         } else {\n           connectFailedOnce \u003d true;\n           DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n             + \", add to deadNodes and continue. \" + ex, ex);\n           // Put chosen node into dead list, continue\n           addToDeadNodes(chosenNode);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n    if (target \u003e\u003d getFileLength()) {\n      throw new IOException(\"Attempted to read past end of file\");\n    }\n\n    // Will be getting a new BlockReader.\n    if (blockReader !\u003d null) {\n      blockReader.close();\n      blockReader \u003d null;\n    }\n\n    //\n    // Connect to best DataNode for desired Block, with potential offset\n    //\n    DatanodeInfo chosenNode \u003d null;\n    int refetchToken \u003d 1; // only need to get a new access token once\n    int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n    \n    boolean connectFailedOnce \u003d false;\n\n    while (true) {\n      //\n      // Compute desired block\n      //\n      LocatedBlock targetBlock \u003d getBlockAt(target, true);\n      assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n      long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n\n      DNAddrPair retval \u003d chooseDataNode(targetBlock);\n      chosenNode \u003d retval.info;\n      InetSocketAddress targetAddr \u003d retval.addr;\n\n      try {\n        ExtendedBlock blk \u003d targetBlock.getBlock();\n        Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n        blockReader \u003d getBlockReader(targetAddr, chosenNode, src, blk,\n            accessToken, offsetIntoBlock, blk.getNumBytes() - offsetIntoBlock,\n            buffersize, verifyChecksum, dfsClient.clientName, cachingStrategy);\n        if(connectFailedOnce) {\n          DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                             \" for \" + blk);\n        }\n        return chosenNode;\n      } catch (AccessControlException ex) {\n        DFSClient.LOG.warn(\"Short circuit access failed \" + ex);\n        dfsClient.disableLegacyBlockReaderLocal();\n        continue;\n      } catch (IOException ex) {\n        if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n              + \"encryption key was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          // The encryption key used is invalid.\n          refetchEncryptionKey--;\n          dfsClient.clearDataEncryptionKey();\n        } else if (refetchToken \u003e 0 \u0026\u0026 tokenRefetchNeeded(ex, targetAddr)) {\n          refetchToken--;\n          fetchBlockAt(target);\n        } else {\n          connectFailedOnce \u003d true;\n          DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n            + \", add to deadNodes and continue. \" + ex, ex);\n          // Put chosen node into dead list, continue\n          addToDeadNodes(chosenNode);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "a31a3a68ead2773f8daa5b3ac1041e271b442789": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5652. Refactor invalid block token exception handling in DFSInputStream. (Liang Xie via junping_du)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1550620 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/12/13 6:47 PM",
      "commitName": "a31a3a68ead2773f8daa5b3ac1041e271b442789",
      "commitAuthor": "Junping Du",
      "commitDateOld": "11/12/13 10:51 PM",
      "commitNameOld": "c656562556d98323396043421b30cef800c850fd",
      "commitAuthorOld": "",
      "daysBetweenCommits": 0.83,
      "commitsBetweenForRepo": 13,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,82 +1,68 @@\n   private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n     if (target \u003e\u003d getFileLength()) {\n       throw new IOException(\"Attempted to read past end of file\");\n     }\n \n     // Will be getting a new BlockReader.\n     if (blockReader !\u003d null) {\n       blockReader.close();\n       blockReader \u003d null;\n     }\n \n     //\n     // Connect to best DataNode for desired Block, with potential offset\n     //\n     DatanodeInfo chosenNode \u003d null;\n     int refetchToken \u003d 1; // only need to get a new access token once\n     int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n     \n     boolean connectFailedOnce \u003d false;\n \n     while (true) {\n       //\n       // Compute desired block\n       //\n       LocatedBlock targetBlock \u003d getBlockAt(target, true);\n       assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n       long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n \n       DNAddrPair retval \u003d chooseDataNode(targetBlock);\n       chosenNode \u003d retval.info;\n       InetSocketAddress targetAddr \u003d retval.addr;\n \n       try {\n         ExtendedBlock blk \u003d targetBlock.getBlock();\n         Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n         blockReader \u003d getBlockReader(targetAddr, chosenNode, src, blk,\n             accessToken, offsetIntoBlock, blk.getNumBytes() - offsetIntoBlock,\n             buffersize, verifyChecksum, dfsClient.clientName);\n         if(connectFailedOnce) {\n           DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                              \" for \" + blk);\n         }\n         return chosenNode;\n       } catch (AccessControlException ex) {\n         DFSClient.LOG.warn(\"Short circuit access failed \" + ex);\n         dfsClient.disableLegacyBlockReaderLocal();\n         continue;\n       } catch (IOException ex) {\n         if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n           DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n               + \"encryption key was invalid when connecting to \" + targetAddr\n               + \" : \" + ex);\n           // The encryption key used is invalid.\n           refetchEncryptionKey--;\n           dfsClient.clearDataEncryptionKey();\n-        } else if ((ex instanceof InvalidBlockTokenException || ex instanceof InvalidToken)\n-            \u0026\u0026 refetchToken \u003e 0) {\n-          DFSClient.LOG.info(\"Will fetch a new access token and retry, \" \n-              + \"access token was invalid when connecting to \" + targetAddr\n-              + \" : \" + ex);\n-          /*\n-           * Get a new access token and retry. Retry is needed in 2 cases. 1)\n-           * When both NN and DN re-started while DFSClient holding a cached\n-           * access token. 2) In the case that NN fails to update its\n-           * access key at pre-set interval (by a wide margin) and\n-           * subsequently restarts. In this case, DN re-registers itself with\n-           * NN and receives a new access key, but DN will delete the old\n-           * access key from its memory since it\u0027s considered expired based on\n-           * the estimated expiration date.\n-           */\n+        } else if (refetchToken \u003e 0 \u0026\u0026 tokenRefetchNeeded(ex, targetAddr)) {\n           refetchToken--;\n           fetchBlockAt(target);\n         } else {\n           connectFailedOnce \u003d true;\n           DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n             + \", add to deadNodes and continue. \" + ex, ex);\n           // Put chosen node into dead list, continue\n           addToDeadNodes(chosenNode);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n    if (target \u003e\u003d getFileLength()) {\n      throw new IOException(\"Attempted to read past end of file\");\n    }\n\n    // Will be getting a new BlockReader.\n    if (blockReader !\u003d null) {\n      blockReader.close();\n      blockReader \u003d null;\n    }\n\n    //\n    // Connect to best DataNode for desired Block, with potential offset\n    //\n    DatanodeInfo chosenNode \u003d null;\n    int refetchToken \u003d 1; // only need to get a new access token once\n    int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n    \n    boolean connectFailedOnce \u003d false;\n\n    while (true) {\n      //\n      // Compute desired block\n      //\n      LocatedBlock targetBlock \u003d getBlockAt(target, true);\n      assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n      long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n\n      DNAddrPair retval \u003d chooseDataNode(targetBlock);\n      chosenNode \u003d retval.info;\n      InetSocketAddress targetAddr \u003d retval.addr;\n\n      try {\n        ExtendedBlock blk \u003d targetBlock.getBlock();\n        Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n        blockReader \u003d getBlockReader(targetAddr, chosenNode, src, blk,\n            accessToken, offsetIntoBlock, blk.getNumBytes() - offsetIntoBlock,\n            buffersize, verifyChecksum, dfsClient.clientName);\n        if(connectFailedOnce) {\n          DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                             \" for \" + blk);\n        }\n        return chosenNode;\n      } catch (AccessControlException ex) {\n        DFSClient.LOG.warn(\"Short circuit access failed \" + ex);\n        dfsClient.disableLegacyBlockReaderLocal();\n        continue;\n      } catch (IOException ex) {\n        if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n              + \"encryption key was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          // The encryption key used is invalid.\n          refetchEncryptionKey--;\n          dfsClient.clearDataEncryptionKey();\n        } else if (refetchToken \u003e 0 \u0026\u0026 tokenRefetchNeeded(ex, targetAddr)) {\n          refetchToken--;\n          fetchBlockAt(target);\n        } else {\n          connectFailedOnce \u003d true;\n          DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n            + \", add to deadNodes and continue. \" + ex, ex);\n          // Put chosen node into dead list, continue\n          addToDeadNodes(chosenNode);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "8373c4134afef0b7fb08a63b44ef0131faacec00": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5637. Try to refeatchToken while local read InvalidToken occurred. (Liang Xie via junping_du)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1550335 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/12/13 7:04 PM",
      "commitName": "8373c4134afef0b7fb08a63b44ef0131faacec00",
      "commitAuthor": "Junping Du",
      "commitDateOld": "20/11/13 6:43 AM",
      "commitNameOld": "f26d2adbf98890cfe350c17241f5049b89a11e3c",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 21.51,
      "commitsBetweenForRepo": 113,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,81 +1,82 @@\n   private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n     if (target \u003e\u003d getFileLength()) {\n       throw new IOException(\"Attempted to read past end of file\");\n     }\n \n     // Will be getting a new BlockReader.\n     if (blockReader !\u003d null) {\n       blockReader.close();\n       blockReader \u003d null;\n     }\n \n     //\n     // Connect to best DataNode for desired Block, with potential offset\n     //\n     DatanodeInfo chosenNode \u003d null;\n     int refetchToken \u003d 1; // only need to get a new access token once\n     int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n     \n     boolean connectFailedOnce \u003d false;\n \n     while (true) {\n       //\n       // Compute desired block\n       //\n       LocatedBlock targetBlock \u003d getBlockAt(target, true);\n       assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n       long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n \n       DNAddrPair retval \u003d chooseDataNode(targetBlock);\n       chosenNode \u003d retval.info;\n       InetSocketAddress targetAddr \u003d retval.addr;\n \n       try {\n         ExtendedBlock blk \u003d targetBlock.getBlock();\n         Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n         blockReader \u003d getBlockReader(targetAddr, chosenNode, src, blk,\n             accessToken, offsetIntoBlock, blk.getNumBytes() - offsetIntoBlock,\n             buffersize, verifyChecksum, dfsClient.clientName);\n         if(connectFailedOnce) {\n           DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                              \" for \" + blk);\n         }\n         return chosenNode;\n       } catch (AccessControlException ex) {\n         DFSClient.LOG.warn(\"Short circuit access failed \" + ex);\n         dfsClient.disableLegacyBlockReaderLocal();\n         continue;\n       } catch (IOException ex) {\n         if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n           DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n               + \"encryption key was invalid when connecting to \" + targetAddr\n               + \" : \" + ex);\n           // The encryption key used is invalid.\n           refetchEncryptionKey--;\n           dfsClient.clearDataEncryptionKey();\n-        } else if (ex instanceof InvalidBlockTokenException \u0026\u0026 refetchToken \u003e 0) {\n+        } else if ((ex instanceof InvalidBlockTokenException || ex instanceof InvalidToken)\n+            \u0026\u0026 refetchToken \u003e 0) {\n           DFSClient.LOG.info(\"Will fetch a new access token and retry, \" \n               + \"access token was invalid when connecting to \" + targetAddr\n               + \" : \" + ex);\n           /*\n            * Get a new access token and retry. Retry is needed in 2 cases. 1)\n            * When both NN and DN re-started while DFSClient holding a cached\n            * access token. 2) In the case that NN fails to update its\n            * access key at pre-set interval (by a wide margin) and\n            * subsequently restarts. In this case, DN re-registers itself with\n            * NN and receives a new access key, but DN will delete the old\n            * access key from its memory since it\u0027s considered expired based on\n            * the estimated expiration date.\n            */\n           refetchToken--;\n           fetchBlockAt(target);\n         } else {\n           connectFailedOnce \u003d true;\n           DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n             + \", add to deadNodes and continue. \" + ex, ex);\n           // Put chosen node into dead list, continue\n           addToDeadNodes(chosenNode);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n    if (target \u003e\u003d getFileLength()) {\n      throw new IOException(\"Attempted to read past end of file\");\n    }\n\n    // Will be getting a new BlockReader.\n    if (blockReader !\u003d null) {\n      blockReader.close();\n      blockReader \u003d null;\n    }\n\n    //\n    // Connect to best DataNode for desired Block, with potential offset\n    //\n    DatanodeInfo chosenNode \u003d null;\n    int refetchToken \u003d 1; // only need to get a new access token once\n    int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n    \n    boolean connectFailedOnce \u003d false;\n\n    while (true) {\n      //\n      // Compute desired block\n      //\n      LocatedBlock targetBlock \u003d getBlockAt(target, true);\n      assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n      long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n\n      DNAddrPair retval \u003d chooseDataNode(targetBlock);\n      chosenNode \u003d retval.info;\n      InetSocketAddress targetAddr \u003d retval.addr;\n\n      try {\n        ExtendedBlock blk \u003d targetBlock.getBlock();\n        Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n        blockReader \u003d getBlockReader(targetAddr, chosenNode, src, blk,\n            accessToken, offsetIntoBlock, blk.getNumBytes() - offsetIntoBlock,\n            buffersize, verifyChecksum, dfsClient.clientName);\n        if(connectFailedOnce) {\n          DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                             \" for \" + blk);\n        }\n        return chosenNode;\n      } catch (AccessControlException ex) {\n        DFSClient.LOG.warn(\"Short circuit access failed \" + ex);\n        dfsClient.disableLegacyBlockReaderLocal();\n        continue;\n      } catch (IOException ex) {\n        if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n              + \"encryption key was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          // The encryption key used is invalid.\n          refetchEncryptionKey--;\n          dfsClient.clearDataEncryptionKey();\n        } else if ((ex instanceof InvalidBlockTokenException || ex instanceof InvalidToken)\n            \u0026\u0026 refetchToken \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new access token and retry, \" \n              + \"access token was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          /*\n           * Get a new access token and retry. Retry is needed in 2 cases. 1)\n           * When both NN and DN re-started while DFSClient holding a cached\n           * access token. 2) In the case that NN fails to update its\n           * access key at pre-set interval (by a wide margin) and\n           * subsequently restarts. In this case, DN re-registers itself with\n           * NN and receives a new access key, but DN will delete the old\n           * access key from its memory since it\u0027s considered expired based on\n           * the estimated expiration date.\n           */\n          refetchToken--;\n          fetchBlockAt(target);\n        } else {\n          connectFailedOnce \u003d true;\n          DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n            + \", add to deadNodes and continue. \" + ex, ex);\n          // Put chosen node into dead list, continue\n          addToDeadNodes(chosenNode);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "a18fd620d070cf8e84aaf80d93807ac9ee207a0f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4661. A few little code cleanups of some HDFS-347-related code. Contributed by Colin Patrick McCabe.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1480839 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/05/13 5:03 PM",
      "commitName": "a18fd620d070cf8e84aaf80d93807ac9ee207a0f",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "29/03/13 2:33 PM",
      "commitNameOld": "bbb24fbf5d220fbe137d43651ba3802a9806b1a3",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 41.1,
      "commitsBetweenForRepo": 266,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,81 +1,81 @@\n   private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n     if (target \u003e\u003d getFileLength()) {\n       throw new IOException(\"Attempted to read past end of file\");\n     }\n \n     // Will be getting a new BlockReader.\n     if (blockReader !\u003d null) {\n-      blockReader.close(peerCache, fileInputStreamCache);\n+      blockReader.close();\n       blockReader \u003d null;\n     }\n \n     //\n     // Connect to best DataNode for desired Block, with potential offset\n     //\n     DatanodeInfo chosenNode \u003d null;\n     int refetchToken \u003d 1; // only need to get a new access token once\n     int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n     \n     boolean connectFailedOnce \u003d false;\n \n     while (true) {\n       //\n       // Compute desired block\n       //\n       LocatedBlock targetBlock \u003d getBlockAt(target, true);\n       assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n       long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n \n       DNAddrPair retval \u003d chooseDataNode(targetBlock);\n       chosenNode \u003d retval.info;\n       InetSocketAddress targetAddr \u003d retval.addr;\n \n       try {\n         ExtendedBlock blk \u003d targetBlock.getBlock();\n         Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n         blockReader \u003d getBlockReader(targetAddr, chosenNode, src, blk,\n             accessToken, offsetIntoBlock, blk.getNumBytes() - offsetIntoBlock,\n             buffersize, verifyChecksum, dfsClient.clientName);\n         if(connectFailedOnce) {\n           DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                              \" for \" + blk);\n         }\n         return chosenNode;\n       } catch (AccessControlException ex) {\n         DFSClient.LOG.warn(\"Short circuit access failed \" + ex);\n         dfsClient.disableLegacyBlockReaderLocal();\n         continue;\n       } catch (IOException ex) {\n         if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n           DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n               + \"encryption key was invalid when connecting to \" + targetAddr\n               + \" : \" + ex);\n           // The encryption key used is invalid.\n           refetchEncryptionKey--;\n           dfsClient.clearDataEncryptionKey();\n         } else if (ex instanceof InvalidBlockTokenException \u0026\u0026 refetchToken \u003e 0) {\n           DFSClient.LOG.info(\"Will fetch a new access token and retry, \" \n               + \"access token was invalid when connecting to \" + targetAddr\n               + \" : \" + ex);\n           /*\n            * Get a new access token and retry. Retry is needed in 2 cases. 1)\n            * When both NN and DN re-started while DFSClient holding a cached\n            * access token. 2) In the case that NN fails to update its\n            * access key at pre-set interval (by a wide margin) and\n            * subsequently restarts. In this case, DN re-registers itself with\n            * NN and receives a new access key, but DN will delete the old\n            * access key from its memory since it\u0027s considered expired based on\n            * the estimated expiration date.\n            */\n           refetchToken--;\n           fetchBlockAt(target);\n         } else {\n           connectFailedOnce \u003d true;\n           DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n             + \", add to deadNodes and continue. \" + ex, ex);\n           // Put chosen node into dead list, continue\n           addToDeadNodes(chosenNode);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n    if (target \u003e\u003d getFileLength()) {\n      throw new IOException(\"Attempted to read past end of file\");\n    }\n\n    // Will be getting a new BlockReader.\n    if (blockReader !\u003d null) {\n      blockReader.close();\n      blockReader \u003d null;\n    }\n\n    //\n    // Connect to best DataNode for desired Block, with potential offset\n    //\n    DatanodeInfo chosenNode \u003d null;\n    int refetchToken \u003d 1; // only need to get a new access token once\n    int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n    \n    boolean connectFailedOnce \u003d false;\n\n    while (true) {\n      //\n      // Compute desired block\n      //\n      LocatedBlock targetBlock \u003d getBlockAt(target, true);\n      assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n      long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n\n      DNAddrPair retval \u003d chooseDataNode(targetBlock);\n      chosenNode \u003d retval.info;\n      InetSocketAddress targetAddr \u003d retval.addr;\n\n      try {\n        ExtendedBlock blk \u003d targetBlock.getBlock();\n        Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n        blockReader \u003d getBlockReader(targetAddr, chosenNode, src, blk,\n            accessToken, offsetIntoBlock, blk.getNumBytes() - offsetIntoBlock,\n            buffersize, verifyChecksum, dfsClient.clientName);\n        if(connectFailedOnce) {\n          DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                             \" for \" + blk);\n        }\n        return chosenNode;\n      } catch (AccessControlException ex) {\n        DFSClient.LOG.warn(\"Short circuit access failed \" + ex);\n        dfsClient.disableLegacyBlockReaderLocal();\n        continue;\n      } catch (IOException ex) {\n        if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n              + \"encryption key was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          // The encryption key used is invalid.\n          refetchEncryptionKey--;\n          dfsClient.clearDataEncryptionKey();\n        } else if (ex instanceof InvalidBlockTokenException \u0026\u0026 refetchToken \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new access token and retry, \" \n              + \"access token was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          /*\n           * Get a new access token and retry. Retry is needed in 2 cases. 1)\n           * When both NN and DN re-started while DFSClient holding a cached\n           * access token. 2) In the case that NN fails to update its\n           * access key at pre-set interval (by a wide margin) and\n           * subsequently restarts. In this case, DN re-registers itself with\n           * NN and receives a new access key, but DN will delete the old\n           * access key from its memory since it\u0027s considered expired based on\n           * the estimated expiration date.\n           */\n          refetchToken--;\n          fetchBlockAt(target);\n        } else {\n          connectFailedOnce \u003d true;\n          DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n            + \", add to deadNodes and continue. \" + ex, ex);\n          // Put chosen node into dead list, continue\n          addToDeadNodes(chosenNode);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "bbb24fbf5d220fbe137d43651ba3802a9806b1a3": {
      "type": "Ybodychange",
      "commitMessage": "Merge trunk into branch.\n\nConflicts resolved:\nC       hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestShortCircuitLocalRead.java\n!     C hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/SocketCache.java\nC       hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java\nC       hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java\nC       hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java\nC       hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java\n\n(thanks to Colin for help resolving)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-347@1462652 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/03/13 2:33 PM",
      "commitName": "bbb24fbf5d220fbe137d43651ba3802a9806b1a3",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "27/03/13 12:28 PM",
      "commitNameOld": "694a6721316aea14c1244447974231abc8dff0cb",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 2.09,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,77 +1,81 @@\n   private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n     if (target \u003e\u003d getFileLength()) {\n       throw new IOException(\"Attempted to read past end of file\");\n     }\n \n     // Will be getting a new BlockReader.\n     if (blockReader !\u003d null) {\n       blockReader.close(peerCache, fileInputStreamCache);\n       blockReader \u003d null;\n     }\n \n     //\n     // Connect to best DataNode for desired Block, with potential offset\n     //\n     DatanodeInfo chosenNode \u003d null;\n     int refetchToken \u003d 1; // only need to get a new access token once\n     int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n     \n     boolean connectFailedOnce \u003d false;\n \n     while (true) {\n       //\n       // Compute desired block\n       //\n       LocatedBlock targetBlock \u003d getBlockAt(target, true);\n       assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n       long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n \n       DNAddrPair retval \u003d chooseDataNode(targetBlock);\n       chosenNode \u003d retval.info;\n       InetSocketAddress targetAddr \u003d retval.addr;\n \n       try {\n         ExtendedBlock blk \u003d targetBlock.getBlock();\n         Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n         blockReader \u003d getBlockReader(targetAddr, chosenNode, src, blk,\n             accessToken, offsetIntoBlock, blk.getNumBytes() - offsetIntoBlock,\n             buffersize, verifyChecksum, dfsClient.clientName);\n         if(connectFailedOnce) {\n           DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                              \" for \" + blk);\n         }\n         return chosenNode;\n+      } catch (AccessControlException ex) {\n+        DFSClient.LOG.warn(\"Short circuit access failed \" + ex);\n+        dfsClient.disableLegacyBlockReaderLocal();\n+        continue;\n       } catch (IOException ex) {\n         if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n           DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n               + \"encryption key was invalid when connecting to \" + targetAddr\n               + \" : \" + ex);\n           // The encryption key used is invalid.\n           refetchEncryptionKey--;\n           dfsClient.clearDataEncryptionKey();\n         } else if (ex instanceof InvalidBlockTokenException \u0026\u0026 refetchToken \u003e 0) {\n           DFSClient.LOG.info(\"Will fetch a new access token and retry, \" \n               + \"access token was invalid when connecting to \" + targetAddr\n               + \" : \" + ex);\n           /*\n            * Get a new access token and retry. Retry is needed in 2 cases. 1)\n            * When both NN and DN re-started while DFSClient holding a cached\n            * access token. 2) In the case that NN fails to update its\n            * access key at pre-set interval (by a wide margin) and\n            * subsequently restarts. In this case, DN re-registers itself with\n            * NN and receives a new access key, but DN will delete the old\n            * access key from its memory since it\u0027s considered expired based on\n            * the estimated expiration date.\n            */\n           refetchToken--;\n           fetchBlockAt(target);\n         } else {\n           connectFailedOnce \u003d true;\n           DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n             + \", add to deadNodes and continue. \" + ex, ex);\n           // Put chosen node into dead list, continue\n           addToDeadNodes(chosenNode);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n    if (target \u003e\u003d getFileLength()) {\n      throw new IOException(\"Attempted to read past end of file\");\n    }\n\n    // Will be getting a new BlockReader.\n    if (blockReader !\u003d null) {\n      blockReader.close(peerCache, fileInputStreamCache);\n      blockReader \u003d null;\n    }\n\n    //\n    // Connect to best DataNode for desired Block, with potential offset\n    //\n    DatanodeInfo chosenNode \u003d null;\n    int refetchToken \u003d 1; // only need to get a new access token once\n    int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n    \n    boolean connectFailedOnce \u003d false;\n\n    while (true) {\n      //\n      // Compute desired block\n      //\n      LocatedBlock targetBlock \u003d getBlockAt(target, true);\n      assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n      long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n\n      DNAddrPair retval \u003d chooseDataNode(targetBlock);\n      chosenNode \u003d retval.info;\n      InetSocketAddress targetAddr \u003d retval.addr;\n\n      try {\n        ExtendedBlock blk \u003d targetBlock.getBlock();\n        Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n        blockReader \u003d getBlockReader(targetAddr, chosenNode, src, blk,\n            accessToken, offsetIntoBlock, blk.getNumBytes() - offsetIntoBlock,\n            buffersize, verifyChecksum, dfsClient.clientName);\n        if(connectFailedOnce) {\n          DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                             \" for \" + blk);\n        }\n        return chosenNode;\n      } catch (AccessControlException ex) {\n        DFSClient.LOG.warn(\"Short circuit access failed \" + ex);\n        dfsClient.disableLegacyBlockReaderLocal();\n        continue;\n      } catch (IOException ex) {\n        if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n              + \"encryption key was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          // The encryption key used is invalid.\n          refetchEncryptionKey--;\n          dfsClient.clearDataEncryptionKey();\n        } else if (ex instanceof InvalidBlockTokenException \u0026\u0026 refetchToken \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new access token and retry, \" \n              + \"access token was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          /*\n           * Get a new access token and retry. Retry is needed in 2 cases. 1)\n           * When both NN and DN re-started while DFSClient holding a cached\n           * access token. 2) In the case that NN fails to update its\n           * access key at pre-set interval (by a wide margin) and\n           * subsequently restarts. In this case, DN re-registers itself with\n           * NN and receives a new access key, but DN will delete the old\n           * access key from its memory since it\u0027s considered expired based on\n           * the estimated expiration date.\n           */\n          refetchToken--;\n          fetchBlockAt(target);\n        } else {\n          connectFailedOnce \u003d true;\n          DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n            + \", add to deadNodes and continue. \" + ex, ex);\n          // Put chosen node into dead list, continue\n          addToDeadNodes(chosenNode);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "9a4030e0e84a688c12daa21fe9a165808c3eca70": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4356. BlockReaderLocal should use passed file descriptors rather than paths. Contributed by Colin Patrick McCabe.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-347@1432335 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/01/13 3:52 PM",
      "commitName": "9a4030e0e84a688c12daa21fe9a165808c3eca70",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "09/01/13 1:34 PM",
      "commitNameOld": "c9db06f2e4d1c1f71f021d5070323f9fc194cdd7",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 2.1,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,77 +1,77 @@\n   private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n     if (target \u003e\u003d getFileLength()) {\n       throw new IOException(\"Attempted to read past end of file\");\n     }\n \n     // Will be getting a new BlockReader.\n     if (blockReader !\u003d null) {\n-      blockReader.close(peerCache);\n+      blockReader.close(peerCache, fileInputStreamCache);\n       blockReader \u003d null;\n     }\n \n     //\n     // Connect to best DataNode for desired Block, with potential offset\n     //\n     DatanodeInfo chosenNode \u003d null;\n     int refetchToken \u003d 1; // only need to get a new access token once\n     int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n     \n     boolean connectFailedOnce \u003d false;\n \n     while (true) {\n       //\n       // Compute desired block\n       //\n       LocatedBlock targetBlock \u003d getBlockAt(target, true);\n       assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n       long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n \n       DNAddrPair retval \u003d chooseDataNode(targetBlock);\n       chosenNode \u003d retval.info;\n       InetSocketAddress targetAddr \u003d retval.addr;\n \n       try {\n         ExtendedBlock blk \u003d targetBlock.getBlock();\n         Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n         blockReader \u003d getBlockReader(targetAddr, chosenNode, src, blk,\n             accessToken, offsetIntoBlock, blk.getNumBytes() - offsetIntoBlock,\n             buffersize, verifyChecksum, dfsClient.clientName);\n         if(connectFailedOnce) {\n           DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                              \" for \" + blk);\n         }\n         return chosenNode;\n       } catch (IOException ex) {\n         if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n           DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n               + \"encryption key was invalid when connecting to \" + targetAddr\n               + \" : \" + ex);\n           // The encryption key used is invalid.\n           refetchEncryptionKey--;\n           dfsClient.clearDataEncryptionKey();\n         } else if (ex instanceof InvalidBlockTokenException \u0026\u0026 refetchToken \u003e 0) {\n           DFSClient.LOG.info(\"Will fetch a new access token and retry, \" \n               + \"access token was invalid when connecting to \" + targetAddr\n               + \" : \" + ex);\n           /*\n            * Get a new access token and retry. Retry is needed in 2 cases. 1)\n            * When both NN and DN re-started while DFSClient holding a cached\n            * access token. 2) In the case that NN fails to update its\n            * access key at pre-set interval (by a wide margin) and\n            * subsequently restarts. In this case, DN re-registers itself with\n            * NN and receives a new access key, but DN will delete the old\n            * access key from its memory since it\u0027s considered expired based on\n            * the estimated expiration date.\n            */\n           refetchToken--;\n           fetchBlockAt(target);\n         } else {\n           connectFailedOnce \u003d true;\n           DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n             + \", add to deadNodes and continue. \" + ex, ex);\n           // Put chosen node into dead list, continue\n           addToDeadNodes(chosenNode);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n    if (target \u003e\u003d getFileLength()) {\n      throw new IOException(\"Attempted to read past end of file\");\n    }\n\n    // Will be getting a new BlockReader.\n    if (blockReader !\u003d null) {\n      blockReader.close(peerCache, fileInputStreamCache);\n      blockReader \u003d null;\n    }\n\n    //\n    // Connect to best DataNode for desired Block, with potential offset\n    //\n    DatanodeInfo chosenNode \u003d null;\n    int refetchToken \u003d 1; // only need to get a new access token once\n    int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n    \n    boolean connectFailedOnce \u003d false;\n\n    while (true) {\n      //\n      // Compute desired block\n      //\n      LocatedBlock targetBlock \u003d getBlockAt(target, true);\n      assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n      long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n\n      DNAddrPair retval \u003d chooseDataNode(targetBlock);\n      chosenNode \u003d retval.info;\n      InetSocketAddress targetAddr \u003d retval.addr;\n\n      try {\n        ExtendedBlock blk \u003d targetBlock.getBlock();\n        Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n        blockReader \u003d getBlockReader(targetAddr, chosenNode, src, blk,\n            accessToken, offsetIntoBlock, blk.getNumBytes() - offsetIntoBlock,\n            buffersize, verifyChecksum, dfsClient.clientName);\n        if(connectFailedOnce) {\n          DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                             \" for \" + blk);\n        }\n        return chosenNode;\n      } catch (IOException ex) {\n        if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n              + \"encryption key was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          // The encryption key used is invalid.\n          refetchEncryptionKey--;\n          dfsClient.clearDataEncryptionKey();\n        } else if (ex instanceof InvalidBlockTokenException \u0026\u0026 refetchToken \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new access token and retry, \" \n              + \"access token was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          /*\n           * Get a new access token and retry. Retry is needed in 2 cases. 1)\n           * When both NN and DN re-started while DFSClient holding a cached\n           * access token. 2) In the case that NN fails to update its\n           * access key at pre-set interval (by a wide margin) and\n           * subsequently restarts. In this case, DN re-registers itself with\n           * NN and receives a new access key, but DN will delete the old\n           * access key from its memory since it\u0027s considered expired based on\n           * the estimated expiration date.\n           */\n          refetchToken--;\n          fetchBlockAt(target);\n        } else {\n          connectFailedOnce \u003d true;\n          DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n            + \", add to deadNodes and continue. \" + ex, ex);\n          // Put chosen node into dead list, continue\n          addToDeadNodes(chosenNode);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "c9db06f2e4d1c1f71f021d5070323f9fc194cdd7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4353. Encapsulate connections to peers in Peer and PeerServer classes. Contributed by Colin Patrick McCabe.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-347@1431097 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/01/13 1:34 PM",
      "commitName": "c9db06f2e4d1c1f71f021d5070323f9fc194cdd7",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "08/01/13 6:41 PM",
      "commitNameOld": "fab2cbc2c1fa7b592e27a186411dcc4a67ea2bc2",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 0.79,
      "commitsBetweenForRepo": 7,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,77 +1,77 @@\n   private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n     if (target \u003e\u003d getFileLength()) {\n       throw new IOException(\"Attempted to read past end of file\");\n     }\n \n     // Will be getting a new BlockReader.\n     if (blockReader !\u003d null) {\n-      closeBlockReader(blockReader);\n+      blockReader.close(peerCache);\n       blockReader \u003d null;\n     }\n \n     //\n     // Connect to best DataNode for desired Block, with potential offset\n     //\n     DatanodeInfo chosenNode \u003d null;\n     int refetchToken \u003d 1; // only need to get a new access token once\n     int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n     \n     boolean connectFailedOnce \u003d false;\n \n     while (true) {\n       //\n       // Compute desired block\n       //\n       LocatedBlock targetBlock \u003d getBlockAt(target, true);\n       assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n       long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n \n       DNAddrPair retval \u003d chooseDataNode(targetBlock);\n       chosenNode \u003d retval.info;\n       InetSocketAddress targetAddr \u003d retval.addr;\n \n       try {\n         ExtendedBlock blk \u003d targetBlock.getBlock();\n         Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n         blockReader \u003d getBlockReader(targetAddr, chosenNode, src, blk,\n             accessToken, offsetIntoBlock, blk.getNumBytes() - offsetIntoBlock,\n             buffersize, verifyChecksum, dfsClient.clientName);\n         if(connectFailedOnce) {\n           DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                              \" for \" + blk);\n         }\n         return chosenNode;\n       } catch (IOException ex) {\n         if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n           DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n               + \"encryption key was invalid when connecting to \" + targetAddr\n               + \" : \" + ex);\n           // The encryption key used is invalid.\n           refetchEncryptionKey--;\n           dfsClient.clearDataEncryptionKey();\n         } else if (ex instanceof InvalidBlockTokenException \u0026\u0026 refetchToken \u003e 0) {\n           DFSClient.LOG.info(\"Will fetch a new access token and retry, \" \n               + \"access token was invalid when connecting to \" + targetAddr\n               + \" : \" + ex);\n           /*\n            * Get a new access token and retry. Retry is needed in 2 cases. 1)\n            * When both NN and DN re-started while DFSClient holding a cached\n            * access token. 2) In the case that NN fails to update its\n            * access key at pre-set interval (by a wide margin) and\n            * subsequently restarts. In this case, DN re-registers itself with\n            * NN and receives a new access key, but DN will delete the old\n            * access key from its memory since it\u0027s considered expired based on\n            * the estimated expiration date.\n            */\n           refetchToken--;\n           fetchBlockAt(target);\n         } else {\n           connectFailedOnce \u003d true;\n           DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n             + \", add to deadNodes and continue. \" + ex, ex);\n           // Put chosen node into dead list, continue\n           addToDeadNodes(chosenNode);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n    if (target \u003e\u003d getFileLength()) {\n      throw new IOException(\"Attempted to read past end of file\");\n    }\n\n    // Will be getting a new BlockReader.\n    if (blockReader !\u003d null) {\n      blockReader.close(peerCache);\n      blockReader \u003d null;\n    }\n\n    //\n    // Connect to best DataNode for desired Block, with potential offset\n    //\n    DatanodeInfo chosenNode \u003d null;\n    int refetchToken \u003d 1; // only need to get a new access token once\n    int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n    \n    boolean connectFailedOnce \u003d false;\n\n    while (true) {\n      //\n      // Compute desired block\n      //\n      LocatedBlock targetBlock \u003d getBlockAt(target, true);\n      assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n      long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n\n      DNAddrPair retval \u003d chooseDataNode(targetBlock);\n      chosenNode \u003d retval.info;\n      InetSocketAddress targetAddr \u003d retval.addr;\n\n      try {\n        ExtendedBlock blk \u003d targetBlock.getBlock();\n        Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n        blockReader \u003d getBlockReader(targetAddr, chosenNode, src, blk,\n            accessToken, offsetIntoBlock, blk.getNumBytes() - offsetIntoBlock,\n            buffersize, verifyChecksum, dfsClient.clientName);\n        if(connectFailedOnce) {\n          DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                             \" for \" + blk);\n        }\n        return chosenNode;\n      } catch (IOException ex) {\n        if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n              + \"encryption key was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          // The encryption key used is invalid.\n          refetchEncryptionKey--;\n          dfsClient.clearDataEncryptionKey();\n        } else if (ex instanceof InvalidBlockTokenException \u0026\u0026 refetchToken \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new access token and retry, \" \n              + \"access token was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          /*\n           * Get a new access token and retry. Retry is needed in 2 cases. 1)\n           * When both NN and DN re-started while DFSClient holding a cached\n           * access token. 2) In the case that NN fails to update its\n           * access key at pre-set interval (by a wide margin) and\n           * subsequently restarts. In this case, DN re-registers itself with\n           * NN and receives a new access key, but DN will delete the old\n           * access key from its memory since it\u0027s considered expired based on\n           * the estimated expiration date.\n           */\n          refetchToken--;\n          fetchBlockAt(target);\n        } else {\n          connectFailedOnce \u003d true;\n          DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n            + \", add to deadNodes and continue. \" + ex, ex);\n          // Put chosen node into dead list, continue\n          addToDeadNodes(chosenNode);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "837e17b2eac1471d93e2eff395272063b265fee7": {
      "type": "Ybodychange",
      "commitMessage": "svn merge -c -1430507 . for reverting HDFS-4353. Encapsulate connections to peers in Peer and PeerServer classes\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1430662 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/01/13 6:39 PM",
      "commitName": "837e17b2eac1471d93e2eff395272063b265fee7",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "08/01/13 12:44 PM",
      "commitNameOld": "239b2742d0e80d13c970fd062af4930e672fe903",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.25,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,77 +1,77 @@\n   private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n     if (target \u003e\u003d getFileLength()) {\n       throw new IOException(\"Attempted to read past end of file\");\n     }\n \n     // Will be getting a new BlockReader.\n     if (blockReader !\u003d null) {\n-      blockReader.close(peerCache);\n+      closeBlockReader(blockReader);\n       blockReader \u003d null;\n     }\n \n     //\n     // Connect to best DataNode for desired Block, with potential offset\n     //\n     DatanodeInfo chosenNode \u003d null;\n     int refetchToken \u003d 1; // only need to get a new access token once\n     int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n     \n     boolean connectFailedOnce \u003d false;\n \n     while (true) {\n       //\n       // Compute desired block\n       //\n       LocatedBlock targetBlock \u003d getBlockAt(target, true);\n       assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n       long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n \n       DNAddrPair retval \u003d chooseDataNode(targetBlock);\n       chosenNode \u003d retval.info;\n       InetSocketAddress targetAddr \u003d retval.addr;\n \n       try {\n         ExtendedBlock blk \u003d targetBlock.getBlock();\n         Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n         blockReader \u003d getBlockReader(targetAddr, chosenNode, src, blk,\n             accessToken, offsetIntoBlock, blk.getNumBytes() - offsetIntoBlock,\n             buffersize, verifyChecksum, dfsClient.clientName);\n         if(connectFailedOnce) {\n           DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                              \" for \" + blk);\n         }\n         return chosenNode;\n       } catch (IOException ex) {\n         if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n           DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n               + \"encryption key was invalid when connecting to \" + targetAddr\n               + \" : \" + ex);\n           // The encryption key used is invalid.\n           refetchEncryptionKey--;\n           dfsClient.clearDataEncryptionKey();\n         } else if (ex instanceof InvalidBlockTokenException \u0026\u0026 refetchToken \u003e 0) {\n           DFSClient.LOG.info(\"Will fetch a new access token and retry, \" \n               + \"access token was invalid when connecting to \" + targetAddr\n               + \" : \" + ex);\n           /*\n            * Get a new access token and retry. Retry is needed in 2 cases. 1)\n            * When both NN and DN re-started while DFSClient holding a cached\n            * access token. 2) In the case that NN fails to update its\n            * access key at pre-set interval (by a wide margin) and\n            * subsequently restarts. In this case, DN re-registers itself with\n            * NN and receives a new access key, but DN will delete the old\n            * access key from its memory since it\u0027s considered expired based on\n            * the estimated expiration date.\n            */\n           refetchToken--;\n           fetchBlockAt(target);\n         } else {\n           connectFailedOnce \u003d true;\n           DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n             + \", add to deadNodes and continue. \" + ex, ex);\n           // Put chosen node into dead list, continue\n           addToDeadNodes(chosenNode);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n    if (target \u003e\u003d getFileLength()) {\n      throw new IOException(\"Attempted to read past end of file\");\n    }\n\n    // Will be getting a new BlockReader.\n    if (blockReader !\u003d null) {\n      closeBlockReader(blockReader);\n      blockReader \u003d null;\n    }\n\n    //\n    // Connect to best DataNode for desired Block, with potential offset\n    //\n    DatanodeInfo chosenNode \u003d null;\n    int refetchToken \u003d 1; // only need to get a new access token once\n    int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n    \n    boolean connectFailedOnce \u003d false;\n\n    while (true) {\n      //\n      // Compute desired block\n      //\n      LocatedBlock targetBlock \u003d getBlockAt(target, true);\n      assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n      long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n\n      DNAddrPair retval \u003d chooseDataNode(targetBlock);\n      chosenNode \u003d retval.info;\n      InetSocketAddress targetAddr \u003d retval.addr;\n\n      try {\n        ExtendedBlock blk \u003d targetBlock.getBlock();\n        Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n        blockReader \u003d getBlockReader(targetAddr, chosenNode, src, blk,\n            accessToken, offsetIntoBlock, blk.getNumBytes() - offsetIntoBlock,\n            buffersize, verifyChecksum, dfsClient.clientName);\n        if(connectFailedOnce) {\n          DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                             \" for \" + blk);\n        }\n        return chosenNode;\n      } catch (IOException ex) {\n        if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n              + \"encryption key was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          // The encryption key used is invalid.\n          refetchEncryptionKey--;\n          dfsClient.clearDataEncryptionKey();\n        } else if (ex instanceof InvalidBlockTokenException \u0026\u0026 refetchToken \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new access token and retry, \" \n              + \"access token was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          /*\n           * Get a new access token and retry. Retry is needed in 2 cases. 1)\n           * When both NN and DN re-started while DFSClient holding a cached\n           * access token. 2) In the case that NN fails to update its\n           * access key at pre-set interval (by a wide margin) and\n           * subsequently restarts. In this case, DN re-registers itself with\n           * NN and receives a new access key, but DN will delete the old\n           * access key from its memory since it\u0027s considered expired based on\n           * the estimated expiration date.\n           */\n          refetchToken--;\n          fetchBlockAt(target);\n        } else {\n          connectFailedOnce \u003d true;\n          DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n            + \", add to deadNodes and continue. \" + ex, ex);\n          // Put chosen node into dead list, continue\n          addToDeadNodes(chosenNode);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "239b2742d0e80d13c970fd062af4930e672fe903": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4353. Encapsulate connections to peers in Peer and PeerServer classes. Contributed by Colin Patrick McCabe.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1430507 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/01/13 12:44 PM",
      "commitName": "239b2742d0e80d13c970fd062af4930e672fe903",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "03/01/13 10:59 PM",
      "commitNameOld": "32052a1e3a8007b5348dc42415861aeb859ebc5a",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 4.57,
      "commitsBetweenForRepo": 24,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,77 +1,77 @@\n   private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n     if (target \u003e\u003d getFileLength()) {\n       throw new IOException(\"Attempted to read past end of file\");\n     }\n \n     // Will be getting a new BlockReader.\n     if (blockReader !\u003d null) {\n-      closeBlockReader(blockReader);\n+      blockReader.close(peerCache);\n       blockReader \u003d null;\n     }\n \n     //\n     // Connect to best DataNode for desired Block, with potential offset\n     //\n     DatanodeInfo chosenNode \u003d null;\n     int refetchToken \u003d 1; // only need to get a new access token once\n     int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n     \n     boolean connectFailedOnce \u003d false;\n \n     while (true) {\n       //\n       // Compute desired block\n       //\n       LocatedBlock targetBlock \u003d getBlockAt(target, true);\n       assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n       long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n \n       DNAddrPair retval \u003d chooseDataNode(targetBlock);\n       chosenNode \u003d retval.info;\n       InetSocketAddress targetAddr \u003d retval.addr;\n \n       try {\n         ExtendedBlock blk \u003d targetBlock.getBlock();\n         Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n         blockReader \u003d getBlockReader(targetAddr, chosenNode, src, blk,\n             accessToken, offsetIntoBlock, blk.getNumBytes() - offsetIntoBlock,\n             buffersize, verifyChecksum, dfsClient.clientName);\n         if(connectFailedOnce) {\n           DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                              \" for \" + blk);\n         }\n         return chosenNode;\n       } catch (IOException ex) {\n         if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n           DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n               + \"encryption key was invalid when connecting to \" + targetAddr\n               + \" : \" + ex);\n           // The encryption key used is invalid.\n           refetchEncryptionKey--;\n           dfsClient.clearDataEncryptionKey();\n         } else if (ex instanceof InvalidBlockTokenException \u0026\u0026 refetchToken \u003e 0) {\n           DFSClient.LOG.info(\"Will fetch a new access token and retry, \" \n               + \"access token was invalid when connecting to \" + targetAddr\n               + \" : \" + ex);\n           /*\n            * Get a new access token and retry. Retry is needed in 2 cases. 1)\n            * When both NN and DN re-started while DFSClient holding a cached\n            * access token. 2) In the case that NN fails to update its\n            * access key at pre-set interval (by a wide margin) and\n            * subsequently restarts. In this case, DN re-registers itself with\n            * NN and receives a new access key, but DN will delete the old\n            * access key from its memory since it\u0027s considered expired based on\n            * the estimated expiration date.\n            */\n           refetchToken--;\n           fetchBlockAt(target);\n         } else {\n           connectFailedOnce \u003d true;\n           DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n             + \", add to deadNodes and continue. \" + ex, ex);\n           // Put chosen node into dead list, continue\n           addToDeadNodes(chosenNode);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n    if (target \u003e\u003d getFileLength()) {\n      throw new IOException(\"Attempted to read past end of file\");\n    }\n\n    // Will be getting a new BlockReader.\n    if (blockReader !\u003d null) {\n      blockReader.close(peerCache);\n      blockReader \u003d null;\n    }\n\n    //\n    // Connect to best DataNode for desired Block, with potential offset\n    //\n    DatanodeInfo chosenNode \u003d null;\n    int refetchToken \u003d 1; // only need to get a new access token once\n    int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n    \n    boolean connectFailedOnce \u003d false;\n\n    while (true) {\n      //\n      // Compute desired block\n      //\n      LocatedBlock targetBlock \u003d getBlockAt(target, true);\n      assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n      long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n\n      DNAddrPair retval \u003d chooseDataNode(targetBlock);\n      chosenNode \u003d retval.info;\n      InetSocketAddress targetAddr \u003d retval.addr;\n\n      try {\n        ExtendedBlock blk \u003d targetBlock.getBlock();\n        Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n        blockReader \u003d getBlockReader(targetAddr, chosenNode, src, blk,\n            accessToken, offsetIntoBlock, blk.getNumBytes() - offsetIntoBlock,\n            buffersize, verifyChecksum, dfsClient.clientName);\n        if(connectFailedOnce) {\n          DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                             \" for \" + blk);\n        }\n        return chosenNode;\n      } catch (IOException ex) {\n        if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n              + \"encryption key was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          // The encryption key used is invalid.\n          refetchEncryptionKey--;\n          dfsClient.clearDataEncryptionKey();\n        } else if (ex instanceof InvalidBlockTokenException \u0026\u0026 refetchToken \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new access token and retry, \" \n              + \"access token was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          /*\n           * Get a new access token and retry. Retry is needed in 2 cases. 1)\n           * When both NN and DN re-started while DFSClient holding a cached\n           * access token. 2) In the case that NN fails to update its\n           * access key at pre-set interval (by a wide margin) and\n           * subsequently restarts. In this case, DN re-registers itself with\n           * NN and receives a new access key, but DN will delete the old\n           * access key from its memory since it\u0027s considered expired based on\n           * the estimated expiration date.\n           */\n          refetchToken--;\n          fetchBlockAt(target);\n        } else {\n          connectFailedOnce \u003d true;\n          DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n            + \", add to deadNodes and continue. \" + ex, ex);\n          // Put chosen node into dead list, continue\n          addToDeadNodes(chosenNode);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4122. Cleanup HDFS logs and reduce the size of logged messages. Contributed by Suresh Srinivas.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1403120 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/10/12 4:10 PM",
      "commitName": "cea7bbc630deede93dbe6a1bbda56ad49de4f3de",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "08/09/12 11:37 PM",
      "commitNameOld": "3a4dcfba573ecfe2e776cea437d70c18adfeaeb9",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 49.69,
      "commitsBetweenForRepo": 280,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,77 +1,77 @@\n   private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n     if (target \u003e\u003d getFileLength()) {\n       throw new IOException(\"Attempted to read past end of file\");\n     }\n \n     // Will be getting a new BlockReader.\n     if (blockReader !\u003d null) {\n       closeBlockReader(blockReader);\n       blockReader \u003d null;\n     }\n \n     //\n     // Connect to best DataNode for desired Block, with potential offset\n     //\n     DatanodeInfo chosenNode \u003d null;\n     int refetchToken \u003d 1; // only need to get a new access token once\n     int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n     \n     boolean connectFailedOnce \u003d false;\n \n     while (true) {\n       //\n       // Compute desired block\n       //\n       LocatedBlock targetBlock \u003d getBlockAt(target, true);\n       assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n       long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n \n       DNAddrPair retval \u003d chooseDataNode(targetBlock);\n       chosenNode \u003d retval.info;\n       InetSocketAddress targetAddr \u003d retval.addr;\n \n       try {\n         ExtendedBlock blk \u003d targetBlock.getBlock();\n         Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n         blockReader \u003d getBlockReader(targetAddr, chosenNode, src, blk,\n             accessToken, offsetIntoBlock, blk.getNumBytes() - offsetIntoBlock,\n             buffersize, verifyChecksum, dfsClient.clientName);\n         if(connectFailedOnce) {\n           DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n-                             \" for block \" + blk.getBlockId());\n+                             \" for \" + blk);\n         }\n         return chosenNode;\n       } catch (IOException ex) {\n         if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n           DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n               + \"encryption key was invalid when connecting to \" + targetAddr\n               + \" : \" + ex);\n           // The encryption key used is invalid.\n           refetchEncryptionKey--;\n           dfsClient.clearDataEncryptionKey();\n         } else if (ex instanceof InvalidBlockTokenException \u0026\u0026 refetchToken \u003e 0) {\n           DFSClient.LOG.info(\"Will fetch a new access token and retry, \" \n               + \"access token was invalid when connecting to \" + targetAddr\n               + \" : \" + ex);\n           /*\n            * Get a new access token and retry. Retry is needed in 2 cases. 1)\n            * When both NN and DN re-started while DFSClient holding a cached\n            * access token. 2) In the case that NN fails to update its\n            * access key at pre-set interval (by a wide margin) and\n            * subsequently restarts. In this case, DN re-registers itself with\n            * NN and receives a new access key, but DN will delete the old\n            * access key from its memory since it\u0027s considered expired based on\n            * the estimated expiration date.\n            */\n           refetchToken--;\n           fetchBlockAt(target);\n         } else {\n           connectFailedOnce \u003d true;\n           DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n             + \", add to deadNodes and continue. \" + ex, ex);\n           // Put chosen node into dead list, continue\n           addToDeadNodes(chosenNode);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n    if (target \u003e\u003d getFileLength()) {\n      throw new IOException(\"Attempted to read past end of file\");\n    }\n\n    // Will be getting a new BlockReader.\n    if (blockReader !\u003d null) {\n      closeBlockReader(blockReader);\n      blockReader \u003d null;\n    }\n\n    //\n    // Connect to best DataNode for desired Block, with potential offset\n    //\n    DatanodeInfo chosenNode \u003d null;\n    int refetchToken \u003d 1; // only need to get a new access token once\n    int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n    \n    boolean connectFailedOnce \u003d false;\n\n    while (true) {\n      //\n      // Compute desired block\n      //\n      LocatedBlock targetBlock \u003d getBlockAt(target, true);\n      assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n      long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n\n      DNAddrPair retval \u003d chooseDataNode(targetBlock);\n      chosenNode \u003d retval.info;\n      InetSocketAddress targetAddr \u003d retval.addr;\n\n      try {\n        ExtendedBlock blk \u003d targetBlock.getBlock();\n        Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n        blockReader \u003d getBlockReader(targetAddr, chosenNode, src, blk,\n            accessToken, offsetIntoBlock, blk.getNumBytes() - offsetIntoBlock,\n            buffersize, verifyChecksum, dfsClient.clientName);\n        if(connectFailedOnce) {\n          DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                             \" for \" + blk);\n        }\n        return chosenNode;\n      } catch (IOException ex) {\n        if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n              + \"encryption key was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          // The encryption key used is invalid.\n          refetchEncryptionKey--;\n          dfsClient.clearDataEncryptionKey();\n        } else if (ex instanceof InvalidBlockTokenException \u0026\u0026 refetchToken \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new access token and retry, \" \n              + \"access token was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          /*\n           * Get a new access token and retry. Retry is needed in 2 cases. 1)\n           * When both NN and DN re-started while DFSClient holding a cached\n           * access token. 2) In the case that NN fails to update its\n           * access key at pre-set interval (by a wide margin) and\n           * subsequently restarts. In this case, DN re-registers itself with\n           * NN and receives a new access key, but DN will delete the old\n           * access key from its memory since it\u0027s considered expired based on\n           * the estimated expiration date.\n           */\n          refetchToken--;\n          fetchBlockAt(target);\n        } else {\n          connectFailedOnce \u003d true;\n          DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n            + \", add to deadNodes and continue. \" + ex, ex);\n          // Put chosen node into dead list, continue\n          addToDeadNodes(chosenNode);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "9b4a7900c7dfc0590316eedaa97144f938885651": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3637. Add support for encrypting the DataTransferProtocol. Contributed by Aaron T. Myers.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1370354 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/08/12 9:40 AM",
      "commitName": "9b4a7900c7dfc0590316eedaa97144f938885651",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "06/07/12 11:59 AM",
      "commitNameOld": "fb95fce24056c0b0aa5b77683c684fe1b68c4f76",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 31.9,
      "commitsBetweenForRepo": 179,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,69 +1,77 @@\n   private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n     if (target \u003e\u003d getFileLength()) {\n       throw new IOException(\"Attempted to read past end of file\");\n     }\n \n     // Will be getting a new BlockReader.\n     if (blockReader !\u003d null) {\n       closeBlockReader(blockReader);\n       blockReader \u003d null;\n     }\n \n     //\n     // Connect to best DataNode for desired Block, with potential offset\n     //\n     DatanodeInfo chosenNode \u003d null;\n     int refetchToken \u003d 1; // only need to get a new access token once\n+    int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n     \n     boolean connectFailedOnce \u003d false;\n \n     while (true) {\n       //\n       // Compute desired block\n       //\n       LocatedBlock targetBlock \u003d getBlockAt(target, true);\n       assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n       long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n \n       DNAddrPair retval \u003d chooseDataNode(targetBlock);\n       chosenNode \u003d retval.info;\n       InetSocketAddress targetAddr \u003d retval.addr;\n \n       try {\n         ExtendedBlock blk \u003d targetBlock.getBlock();\n         Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n         blockReader \u003d getBlockReader(targetAddr, chosenNode, src, blk,\n             accessToken, offsetIntoBlock, blk.getNumBytes() - offsetIntoBlock,\n             buffersize, verifyChecksum, dfsClient.clientName);\n         if(connectFailedOnce) {\n           DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                              \" for block \" + blk.getBlockId());\n         }\n         return chosenNode;\n       } catch (IOException ex) {\n-        if (ex instanceof InvalidBlockTokenException \u0026\u0026 refetchToken \u003e 0) {\n+        if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n+          DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n+              + \"encryption key was invalid when connecting to \" + targetAddr\n+              + \" : \" + ex);\n+          // The encryption key used is invalid.\n+          refetchEncryptionKey--;\n+          dfsClient.clearDataEncryptionKey();\n+        } else if (ex instanceof InvalidBlockTokenException \u0026\u0026 refetchToken \u003e 0) {\n           DFSClient.LOG.info(\"Will fetch a new access token and retry, \" \n               + \"access token was invalid when connecting to \" + targetAddr\n               + \" : \" + ex);\n           /*\n            * Get a new access token and retry. Retry is needed in 2 cases. 1)\n            * When both NN and DN re-started while DFSClient holding a cached\n            * access token. 2) In the case that NN fails to update its\n            * access key at pre-set interval (by a wide margin) and\n            * subsequently restarts. In this case, DN re-registers itself with\n            * NN and receives a new access key, but DN will delete the old\n            * access key from its memory since it\u0027s considered expired based on\n            * the estimated expiration date.\n            */\n           refetchToken--;\n           fetchBlockAt(target);\n         } else {\n           connectFailedOnce \u003d true;\n           DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n             + \", add to deadNodes and continue. \" + ex, ex);\n           // Put chosen node into dead list, continue\n           addToDeadNodes(chosenNode);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n    if (target \u003e\u003d getFileLength()) {\n      throw new IOException(\"Attempted to read past end of file\");\n    }\n\n    // Will be getting a new BlockReader.\n    if (blockReader !\u003d null) {\n      closeBlockReader(blockReader);\n      blockReader \u003d null;\n    }\n\n    //\n    // Connect to best DataNode for desired Block, with potential offset\n    //\n    DatanodeInfo chosenNode \u003d null;\n    int refetchToken \u003d 1; // only need to get a new access token once\n    int refetchEncryptionKey \u003d 1; // only need to get a new encryption key once\n    \n    boolean connectFailedOnce \u003d false;\n\n    while (true) {\n      //\n      // Compute desired block\n      //\n      LocatedBlock targetBlock \u003d getBlockAt(target, true);\n      assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n      long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n\n      DNAddrPair retval \u003d chooseDataNode(targetBlock);\n      chosenNode \u003d retval.info;\n      InetSocketAddress targetAddr \u003d retval.addr;\n\n      try {\n        ExtendedBlock blk \u003d targetBlock.getBlock();\n        Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n        blockReader \u003d getBlockReader(targetAddr, chosenNode, src, blk,\n            accessToken, offsetIntoBlock, blk.getNumBytes() - offsetIntoBlock,\n            buffersize, verifyChecksum, dfsClient.clientName);\n        if(connectFailedOnce) {\n          DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                             \" for block \" + blk.getBlockId());\n        }\n        return chosenNode;\n      } catch (IOException ex) {\n        if (ex instanceof InvalidEncryptionKeyException \u0026\u0026 refetchEncryptionKey \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new encryption key and retry, \" \n              + \"encryption key was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          // The encryption key used is invalid.\n          refetchEncryptionKey--;\n          dfsClient.clearDataEncryptionKey();\n        } else if (ex instanceof InvalidBlockTokenException \u0026\u0026 refetchToken \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new access token and retry, \" \n              + \"access token was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          /*\n           * Get a new access token and retry. Retry is needed in 2 cases. 1)\n           * When both NN and DN re-started while DFSClient holding a cached\n           * access token. 2) In the case that NN fails to update its\n           * access key at pre-set interval (by a wide margin) and\n           * subsequently restarts. In this case, DN re-registers itself with\n           * NN and receives a new access key, but DN will delete the old\n           * access key from its memory since it\u0027s considered expired based on\n           * the estimated expiration date.\n           */\n          refetchToken--;\n          fetchBlockAt(target);\n        } else {\n          connectFailedOnce \u003d true;\n          DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n            + \", add to deadNodes and continue. \" + ex, ex);\n          // Put chosen node into dead list, continue\n          addToDeadNodes(chosenNode);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "2ab10e29d9cca5018064be46a40e3c74423615a8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2246. Enable reading a block directly from local file system for a client on the same node as the block file.  Contributed by Andrew Purtell, Suresh Srinivas and Jitendra Nath Pandey\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1204792 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/11/11 6:57 PM",
      "commitName": "2ab10e29d9cca5018064be46a40e3c74423615a8",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "18/11/11 6:34 PM",
      "commitNameOld": "b7cd8c0f865e88e40eee75fd2690b1fdc4155071",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 3.02,
      "commitsBetweenForRepo": 27,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,72 +1,69 @@\n   private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n     if (target \u003e\u003d getFileLength()) {\n       throw new IOException(\"Attempted to read past end of file\");\n     }\n \n     // Will be getting a new BlockReader.\n     if (blockReader !\u003d null) {\n       closeBlockReader(blockReader);\n       blockReader \u003d null;\n     }\n \n     //\n     // Connect to best DataNode for desired Block, with potential offset\n     //\n     DatanodeInfo chosenNode \u003d null;\n     int refetchToken \u003d 1; // only need to get a new access token once\n     \n     boolean connectFailedOnce \u003d false;\n \n     while (true) {\n       //\n       // Compute desired block\n       //\n       LocatedBlock targetBlock \u003d getBlockAt(target, true);\n       assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n       long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n \n       DNAddrPair retval \u003d chooseDataNode(targetBlock);\n       chosenNode \u003d retval.info;\n       InetSocketAddress targetAddr \u003d retval.addr;\n \n       try {\n         ExtendedBlock blk \u003d targetBlock.getBlock();\n         Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n-        \n-        blockReader \u003d getBlockReader(\n-            targetAddr, src, blk,\n-            accessToken,\n-            offsetIntoBlock, blk.getNumBytes() - offsetIntoBlock,\n+        blockReader \u003d getBlockReader(targetAddr, chosenNode, src, blk,\n+            accessToken, offsetIntoBlock, blk.getNumBytes() - offsetIntoBlock,\n             buffersize, verifyChecksum, dfsClient.clientName);\n         if(connectFailedOnce) {\n           DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                              \" for block \" + blk.getBlockId());\n         }\n         return chosenNode;\n       } catch (IOException ex) {\n         if (ex instanceof InvalidBlockTokenException \u0026\u0026 refetchToken \u003e 0) {\n           DFSClient.LOG.info(\"Will fetch a new access token and retry, \" \n               + \"access token was invalid when connecting to \" + targetAddr\n               + \" : \" + ex);\n           /*\n            * Get a new access token and retry. Retry is needed in 2 cases. 1)\n            * When both NN and DN re-started while DFSClient holding a cached\n            * access token. 2) In the case that NN fails to update its\n            * access key at pre-set interval (by a wide margin) and\n            * subsequently restarts. In this case, DN re-registers itself with\n            * NN and receives a new access key, but DN will delete the old\n            * access key from its memory since it\u0027s considered expired based on\n            * the estimated expiration date.\n            */\n           refetchToken--;\n           fetchBlockAt(target);\n         } else {\n           connectFailedOnce \u003d true;\n           DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n             + \", add to deadNodes and continue. \" + ex, ex);\n           // Put chosen node into dead list, continue\n           addToDeadNodes(chosenNode);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n    if (target \u003e\u003d getFileLength()) {\n      throw new IOException(\"Attempted to read past end of file\");\n    }\n\n    // Will be getting a new BlockReader.\n    if (blockReader !\u003d null) {\n      closeBlockReader(blockReader);\n      blockReader \u003d null;\n    }\n\n    //\n    // Connect to best DataNode for desired Block, with potential offset\n    //\n    DatanodeInfo chosenNode \u003d null;\n    int refetchToken \u003d 1; // only need to get a new access token once\n    \n    boolean connectFailedOnce \u003d false;\n\n    while (true) {\n      //\n      // Compute desired block\n      //\n      LocatedBlock targetBlock \u003d getBlockAt(target, true);\n      assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n      long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n\n      DNAddrPair retval \u003d chooseDataNode(targetBlock);\n      chosenNode \u003d retval.info;\n      InetSocketAddress targetAddr \u003d retval.addr;\n\n      try {\n        ExtendedBlock blk \u003d targetBlock.getBlock();\n        Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n        blockReader \u003d getBlockReader(targetAddr, chosenNode, src, blk,\n            accessToken, offsetIntoBlock, blk.getNumBytes() - offsetIntoBlock,\n            buffersize, verifyChecksum, dfsClient.clientName);\n        if(connectFailedOnce) {\n          DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                             \" for block \" + blk.getBlockId());\n        }\n        return chosenNode;\n      } catch (IOException ex) {\n        if (ex instanceof InvalidBlockTokenException \u0026\u0026 refetchToken \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new access token and retry, \" \n              + \"access token was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          /*\n           * Get a new access token and retry. Retry is needed in 2 cases. 1)\n           * When both NN and DN re-started while DFSClient holding a cached\n           * access token. 2) In the case that NN fails to update its\n           * access key at pre-set interval (by a wide margin) and\n           * subsequently restarts. In this case, DN re-registers itself with\n           * NN and receives a new access key, but DN will delete the old\n           * access key from its memory since it\u0027s considered expired based on\n           * the estimated expiration date.\n           */\n          refetchToken--;\n          fetchBlockAt(target);\n        } else {\n          connectFailedOnce \u003d true;\n          DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n            + \", add to deadNodes and continue. \" + ex, ex);\n          // Put chosen node into dead list, continue\n          addToDeadNodes(chosenNode);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "3ab2e79ad7786623798c5c8816fcdb4173b09da1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2209 datanode connection failure logging\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1180353 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/10/11 3:41 AM",
      "commitName": "3ab2e79ad7786623798c5c8816fcdb4173b09da1",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "24/08/11 5:14 PM",
      "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 44.44,
      "commitsBetweenForRepo": 299,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,68 +1,72 @@\n   private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n     if (target \u003e\u003d getFileLength()) {\n       throw new IOException(\"Attempted to read past end of file\");\n     }\n \n     // Will be getting a new BlockReader.\n     if (blockReader !\u003d null) {\n       closeBlockReader(blockReader);\n       blockReader \u003d null;\n     }\n \n     //\n     // Connect to best DataNode for desired Block, with potential offset\n     //\n     DatanodeInfo chosenNode \u003d null;\n     int refetchToken \u003d 1; // only need to get a new access token once\n     \n+    boolean connectFailedOnce \u003d false;\n+\n     while (true) {\n       //\n       // Compute desired block\n       //\n       LocatedBlock targetBlock \u003d getBlockAt(target, true);\n       assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n       long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n \n       DNAddrPair retval \u003d chooseDataNode(targetBlock);\n       chosenNode \u003d retval.info;\n       InetSocketAddress targetAddr \u003d retval.addr;\n \n       try {\n         ExtendedBlock blk \u003d targetBlock.getBlock();\n         Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n         \n         blockReader \u003d getBlockReader(\n             targetAddr, src, blk,\n             accessToken,\n             offsetIntoBlock, blk.getNumBytes() - offsetIntoBlock,\n             buffersize, verifyChecksum, dfsClient.clientName);\n+        if(connectFailedOnce) {\n+          DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n+                             \" for block \" + blk.getBlockId());\n+        }\n         return chosenNode;\n       } catch (IOException ex) {\n         if (ex instanceof InvalidBlockTokenException \u0026\u0026 refetchToken \u003e 0) {\n           DFSClient.LOG.info(\"Will fetch a new access token and retry, \" \n               + \"access token was invalid when connecting to \" + targetAddr\n               + \" : \" + ex);\n           /*\n            * Get a new access token and retry. Retry is needed in 2 cases. 1)\n            * When both NN and DN re-started while DFSClient holding a cached\n            * access token. 2) In the case that NN fails to update its\n            * access key at pre-set interval (by a wide margin) and\n            * subsequently restarts. In this case, DN re-registers itself with\n            * NN and receives a new access key, but DN will delete the old\n            * access key from its memory since it\u0027s considered expired based on\n            * the estimated expiration date.\n            */\n           refetchToken--;\n           fetchBlockAt(target);\n         } else {\n-          DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr\n-              + \", add to deadNodes and continue \" + ex);\n-          if (DFSClient.LOG.isDebugEnabled()) {\n-            DFSClient.LOG.debug(\"Connection failure \", ex);\n-          }\n+          connectFailedOnce \u003d true;\n+          DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n+            + \", add to deadNodes and continue. \" + ex, ex);\n           // Put chosen node into dead list, continue\n           addToDeadNodes(chosenNode);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n    if (target \u003e\u003d getFileLength()) {\n      throw new IOException(\"Attempted to read past end of file\");\n    }\n\n    // Will be getting a new BlockReader.\n    if (blockReader !\u003d null) {\n      closeBlockReader(blockReader);\n      blockReader \u003d null;\n    }\n\n    //\n    // Connect to best DataNode for desired Block, with potential offset\n    //\n    DatanodeInfo chosenNode \u003d null;\n    int refetchToken \u003d 1; // only need to get a new access token once\n    \n    boolean connectFailedOnce \u003d false;\n\n    while (true) {\n      //\n      // Compute desired block\n      //\n      LocatedBlock targetBlock \u003d getBlockAt(target, true);\n      assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n      long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n\n      DNAddrPair retval \u003d chooseDataNode(targetBlock);\n      chosenNode \u003d retval.info;\n      InetSocketAddress targetAddr \u003d retval.addr;\n\n      try {\n        ExtendedBlock blk \u003d targetBlock.getBlock();\n        Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n        \n        blockReader \u003d getBlockReader(\n            targetAddr, src, blk,\n            accessToken,\n            offsetIntoBlock, blk.getNumBytes() - offsetIntoBlock,\n            buffersize, verifyChecksum, dfsClient.clientName);\n        if(connectFailedOnce) {\n          DFSClient.LOG.info(\"Successfully connected to \" + targetAddr +\n                             \" for block \" + blk.getBlockId());\n        }\n        return chosenNode;\n      } catch (IOException ex) {\n        if (ex instanceof InvalidBlockTokenException \u0026\u0026 refetchToken \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new access token and retry, \" \n              + \"access token was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          /*\n           * Get a new access token and retry. Retry is needed in 2 cases. 1)\n           * When both NN and DN re-started while DFSClient holding a cached\n           * access token. 2) In the case that NN fails to update its\n           * access key at pre-set interval (by a wide margin) and\n           * subsequently restarts. In this case, DN re-registers itself with\n           * NN and receives a new access key, but DN will delete the old\n           * access key from its memory since it\u0027s considered expired based on\n           * the estimated expiration date.\n           */\n          refetchToken--;\n          fetchBlockAt(target);\n        } else {\n          connectFailedOnce \u003d true;\n          DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr + \" for block\"\n            + \", add to deadNodes and continue. \" + ex, ex);\n          // Put chosen node into dead list, continue\n          addToDeadNodes(chosenNode);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n    if (target \u003e\u003d getFileLength()) {\n      throw new IOException(\"Attempted to read past end of file\");\n    }\n\n    // Will be getting a new BlockReader.\n    if (blockReader !\u003d null) {\n      closeBlockReader(blockReader);\n      blockReader \u003d null;\n    }\n\n    //\n    // Connect to best DataNode for desired Block, with potential offset\n    //\n    DatanodeInfo chosenNode \u003d null;\n    int refetchToken \u003d 1; // only need to get a new access token once\n    \n    while (true) {\n      //\n      // Compute desired block\n      //\n      LocatedBlock targetBlock \u003d getBlockAt(target, true);\n      assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n      long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n\n      DNAddrPair retval \u003d chooseDataNode(targetBlock);\n      chosenNode \u003d retval.info;\n      InetSocketAddress targetAddr \u003d retval.addr;\n\n      try {\n        ExtendedBlock blk \u003d targetBlock.getBlock();\n        Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n        \n        blockReader \u003d getBlockReader(\n            targetAddr, src, blk,\n            accessToken,\n            offsetIntoBlock, blk.getNumBytes() - offsetIntoBlock,\n            buffersize, verifyChecksum, dfsClient.clientName);\n        return chosenNode;\n      } catch (IOException ex) {\n        if (ex instanceof InvalidBlockTokenException \u0026\u0026 refetchToken \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new access token and retry, \" \n              + \"access token was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          /*\n           * Get a new access token and retry. Retry is needed in 2 cases. 1)\n           * When both NN and DN re-started while DFSClient holding a cached\n           * access token. 2) In the case that NN fails to update its\n           * access key at pre-set interval (by a wide margin) and\n           * subsequently restarts. In this case, DN re-registers itself with\n           * NN and receives a new access key, but DN will delete the old\n           * access key from its memory since it\u0027s considered expired based on\n           * the estimated expiration date.\n           */\n          refetchToken--;\n          fetchBlockAt(target);\n        } else {\n          DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr\n              + \", add to deadNodes and continue \" + ex);\n          if (DFSClient.LOG.isDebugEnabled()) {\n            DFSClient.LOG.debug(\"Connection failure \", ex);\n          }\n          // Put chosen node into dead list, continue\n          addToDeadNodes(chosenNode);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n    if (target \u003e\u003d getFileLength()) {\n      throw new IOException(\"Attempted to read past end of file\");\n    }\n\n    // Will be getting a new BlockReader.\n    if (blockReader !\u003d null) {\n      closeBlockReader(blockReader);\n      blockReader \u003d null;\n    }\n\n    //\n    // Connect to best DataNode for desired Block, with potential offset\n    //\n    DatanodeInfo chosenNode \u003d null;\n    int refetchToken \u003d 1; // only need to get a new access token once\n    \n    while (true) {\n      //\n      // Compute desired block\n      //\n      LocatedBlock targetBlock \u003d getBlockAt(target, true);\n      assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n      long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n\n      DNAddrPair retval \u003d chooseDataNode(targetBlock);\n      chosenNode \u003d retval.info;\n      InetSocketAddress targetAddr \u003d retval.addr;\n\n      try {\n        ExtendedBlock blk \u003d targetBlock.getBlock();\n        Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n        \n        blockReader \u003d getBlockReader(\n            targetAddr, src, blk,\n            accessToken,\n            offsetIntoBlock, blk.getNumBytes() - offsetIntoBlock,\n            buffersize, verifyChecksum, dfsClient.clientName);\n        return chosenNode;\n      } catch (IOException ex) {\n        if (ex instanceof InvalidBlockTokenException \u0026\u0026 refetchToken \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new access token and retry, \" \n              + \"access token was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          /*\n           * Get a new access token and retry. Retry is needed in 2 cases. 1)\n           * When both NN and DN re-started while DFSClient holding a cached\n           * access token. 2) In the case that NN fails to update its\n           * access key at pre-set interval (by a wide margin) and\n           * subsequently restarts. In this case, DN re-registers itself with\n           * NN and receives a new access key, but DN will delete the old\n           * access key from its memory since it\u0027s considered expired based on\n           * the estimated expiration date.\n           */\n          refetchToken--;\n          fetchBlockAt(target);\n        } else {\n          DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr\n              + \", add to deadNodes and continue \" + ex);\n          if (DFSClient.LOG.isDebugEnabled()) {\n            DFSClient.LOG.debug(\"Connection failure \", ex);\n          }\n          // Put chosen node into dead list, continue\n          addToDeadNodes(chosenNode);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/DFSInputStream.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,68 @@\n+  private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n+    if (target \u003e\u003d getFileLength()) {\n+      throw new IOException(\"Attempted to read past end of file\");\n+    }\n+\n+    // Will be getting a new BlockReader.\n+    if (blockReader !\u003d null) {\n+      closeBlockReader(blockReader);\n+      blockReader \u003d null;\n+    }\n+\n+    //\n+    // Connect to best DataNode for desired Block, with potential offset\n+    //\n+    DatanodeInfo chosenNode \u003d null;\n+    int refetchToken \u003d 1; // only need to get a new access token once\n+    \n+    while (true) {\n+      //\n+      // Compute desired block\n+      //\n+      LocatedBlock targetBlock \u003d getBlockAt(target, true);\n+      assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n+      long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n+\n+      DNAddrPair retval \u003d chooseDataNode(targetBlock);\n+      chosenNode \u003d retval.info;\n+      InetSocketAddress targetAddr \u003d retval.addr;\n+\n+      try {\n+        ExtendedBlock blk \u003d targetBlock.getBlock();\n+        Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n+        \n+        blockReader \u003d getBlockReader(\n+            targetAddr, src, blk,\n+            accessToken,\n+            offsetIntoBlock, blk.getNumBytes() - offsetIntoBlock,\n+            buffersize, verifyChecksum, dfsClient.clientName);\n+        return chosenNode;\n+      } catch (IOException ex) {\n+        if (ex instanceof InvalidBlockTokenException \u0026\u0026 refetchToken \u003e 0) {\n+          DFSClient.LOG.info(\"Will fetch a new access token and retry, \" \n+              + \"access token was invalid when connecting to \" + targetAddr\n+              + \" : \" + ex);\n+          /*\n+           * Get a new access token and retry. Retry is needed in 2 cases. 1)\n+           * When both NN and DN re-started while DFSClient holding a cached\n+           * access token. 2) In the case that NN fails to update its\n+           * access key at pre-set interval (by a wide margin) and\n+           * subsequently restarts. In this case, DN re-registers itself with\n+           * NN and receives a new access key, but DN will delete the old\n+           * access key from its memory since it\u0027s considered expired based on\n+           * the estimated expiration date.\n+           */\n+          refetchToken--;\n+          fetchBlockAt(target);\n+        } else {\n+          DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr\n+              + \", add to deadNodes and continue \" + ex);\n+          if (DFSClient.LOG.isDebugEnabled()) {\n+            DFSClient.LOG.debug(\"Connection failure \", ex);\n+          }\n+          // Put chosen node into dead list, continue\n+          addToDeadNodes(chosenNode);\n+        }\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n    if (target \u003e\u003d getFileLength()) {\n      throw new IOException(\"Attempted to read past end of file\");\n    }\n\n    // Will be getting a new BlockReader.\n    if (blockReader !\u003d null) {\n      closeBlockReader(blockReader);\n      blockReader \u003d null;\n    }\n\n    //\n    // Connect to best DataNode for desired Block, with potential offset\n    //\n    DatanodeInfo chosenNode \u003d null;\n    int refetchToken \u003d 1; // only need to get a new access token once\n    \n    while (true) {\n      //\n      // Compute desired block\n      //\n      LocatedBlock targetBlock \u003d getBlockAt(target, true);\n      assert (target\u003d\u003dpos) : \"Wrong postion \" + pos + \" expect \" + target;\n      long offsetIntoBlock \u003d target - targetBlock.getStartOffset();\n\n      DNAddrPair retval \u003d chooseDataNode(targetBlock);\n      chosenNode \u003d retval.info;\n      InetSocketAddress targetAddr \u003d retval.addr;\n\n      try {\n        ExtendedBlock blk \u003d targetBlock.getBlock();\n        Token\u003cBlockTokenIdentifier\u003e accessToken \u003d targetBlock.getBlockToken();\n        \n        blockReader \u003d getBlockReader(\n            targetAddr, src, blk,\n            accessToken,\n            offsetIntoBlock, blk.getNumBytes() - offsetIntoBlock,\n            buffersize, verifyChecksum, dfsClient.clientName);\n        return chosenNode;\n      } catch (IOException ex) {\n        if (ex instanceof InvalidBlockTokenException \u0026\u0026 refetchToken \u003e 0) {\n          DFSClient.LOG.info(\"Will fetch a new access token and retry, \" \n              + \"access token was invalid when connecting to \" + targetAddr\n              + \" : \" + ex);\n          /*\n           * Get a new access token and retry. Retry is needed in 2 cases. 1)\n           * When both NN and DN re-started while DFSClient holding a cached\n           * access token. 2) In the case that NN fails to update its\n           * access key at pre-set interval (by a wide margin) and\n           * subsequently restarts. In this case, DN re-registers itself with\n           * NN and receives a new access key, but DN will delete the old\n           * access key from its memory since it\u0027s considered expired based on\n           * the estimated expiration date.\n           */\n          refetchToken--;\n          fetchBlockAt(target);\n        } else {\n          DFSClient.LOG.warn(\"Failed to connect to \" + targetAddr\n              + \", add to deadNodes and continue \" + ex);\n          if (DFSClient.LOG.isDebugEnabled()) {\n            DFSClient.LOG.debug(\"Connection failure \", ex);\n          }\n          // Put chosen node into dead list, continue\n          addToDeadNodes(chosenNode);\n        }\n      }\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/DFSInputStream.java"
    }
  }
}