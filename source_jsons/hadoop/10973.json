{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockSender.java",
  "functionName": "doSendBlock",
  "functionId": "doSendBlock___out-DataOutputStream__baseStream-OutputStream__throttler-DataTransferThrottler",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockSender.java",
  "functionStartLine": 762,
  "functionEndLine": 837,
  "numCommitsSeen": 65,
  "timeTaken": 3975,
  "changeHistory": [
    "df983b524ab68ea0c70cee9033bfff2d28052cbf",
    "dcedb72af468128458e597f08d22f5c34b744ae5",
    "aeecfa24f4fb6af289920cbf8830c394e66bd78e",
    "21d10ccc6e463cf250414264c78acb4a6e7c83e3",
    "4da8490b512a33a255ed27309860859388d7c168",
    "6ae2a0d048e133b43249c248a75a4d77d9abb80d",
    "7f6ed7fe365166e8075359f1d0ad035fa876c70f"
  ],
  "changeHistoryShort": {
    "df983b524ab68ea0c70cee9033bfff2d28052cbf": "Ybodychange",
    "dcedb72af468128458e597f08d22f5c34b744ae5": "Ybodychange",
    "aeecfa24f4fb6af289920cbf8830c394e66bd78e": "Ybodychange",
    "21d10ccc6e463cf250414264c78acb4a6e7c83e3": "Ybodychange",
    "4da8490b512a33a255ed27309860859388d7c168": "Ybodychange",
    "6ae2a0d048e133b43249c248a75a4d77d9abb80d": "Ybodychange",
    "7f6ed7fe365166e8075359f1d0ad035fa876c70f": "Yintroduced"
  },
  "changeHistoryDetails": {
    "df983b524ab68ea0c70cee9033bfff2d28052cbf": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10930. Refactor: Wrap Datanode IO related operations. Contributed by Xiaoyu Yao.\n",
      "commitDate": "06/12/16 11:05 AM",
      "commitName": "df983b524ab68ea0c70cee9033bfff2d28052cbf",
      "commitAuthor": "Xiaoyu Yao",
      "commitDateOld": "05/12/16 12:44 PM",
      "commitNameOld": "dcedb72af468128458e597f08d22f5c34b744ae5",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 0.93,
      "commitsBetweenForRepo": 10,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,75 +1,76 @@\n   private long doSendBlock(DataOutputStream out, OutputStream baseStream,\n         DataTransferThrottler throttler) throws IOException {\n     if (out \u003d\u003d null) {\n       throw new IOException( \"out stream is null\" );\n     }\n     initialOffset \u003d offset;\n     long totalRead \u003d 0;\n     OutputStream streamForSendChunks \u003d out;\n     \n     lastCacheDropOffset \u003d initialOffset;\n \n-    if (isLongRead() \u0026\u0026 blockInFd !\u003d null) {\n+    if (isLongRead() \u0026\u0026 ris.getDataInFd() !\u003d null) {\n       // Advise that this file descriptor will be accessed sequentially.\n-      NativeIO.POSIX.getCacheManipulator().posixFadviseIfPossible(\n-          block.getBlockName(), blockInFd, 0, 0, POSIX_FADV_SEQUENTIAL);\n+      ris.dropCacheBehindReads(block.getBlockName(), 0, 0,\n+          POSIX_FADV_SEQUENTIAL);\n     }\n     \n     // Trigger readahead of beginning of file if configured.\n     manageOsCache();\n \n     final long startTime \u003d ClientTraceLog.isDebugEnabled() ? System.nanoTime() : 0;\n     try {\n       int maxChunksPerPacket;\n       int pktBufSize \u003d PacketHeader.PKT_MAX_HEADER_LEN;\n       boolean transferTo \u003d transferToAllowed \u0026\u0026 !verifyChecksum\n           \u0026\u0026 baseStream instanceof SocketOutputStream\n-          \u0026\u0026 blockIn instanceof FileInputStream;\n+          \u0026\u0026 ris.getDataIn() instanceof FileInputStream;\n       if (transferTo) {\n-        FileChannel fileChannel \u003d ((FileInputStream)blockIn).getChannel();\n+        FileChannel fileChannel \u003d\n+            ((FileInputStream)ris.getDataIn()).getChannel();\n         blockInPosition \u003d fileChannel.position();\n         streamForSendChunks \u003d baseStream;\n         maxChunksPerPacket \u003d numberOfChunks(TRANSFERTO_BUFFER_SIZE);\n         \n         // Smaller packet size to only hold checksum when doing transferTo\n         pktBufSize +\u003d checksumSize * maxChunksPerPacket;\n       } else {\n         maxChunksPerPacket \u003d Math.max(1,\n             numberOfChunks(IO_FILE_BUFFER_SIZE));\n         // Packet size includes both checksum and data\n         pktBufSize +\u003d (chunkSize + checksumSize) * maxChunksPerPacket;\n       }\n \n       ByteBuffer pktBuf \u003d ByteBuffer.allocate(pktBufSize);\n \n       while (endOffset \u003e offset \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n         manageOsCache();\n         long len \u003d sendPacket(pktBuf, maxChunksPerPacket, streamForSendChunks,\n             transferTo, throttler);\n         offset +\u003d len;\n         totalRead +\u003d len + (numberOfChunks(len) * checksumSize);\n         seqno++;\n       }\n       // If this thread was interrupted, then it did not send the full block.\n       if (!Thread.currentThread().isInterrupted()) {\n         try {\n           // send an empty packet to mark the end of the block\n           sendPacket(pktBuf, maxChunksPerPacket, streamForSendChunks, transferTo,\n               throttler);\n           out.flush();\n         } catch (IOException e) { //socket error\n           throw ioeToSocketException(e);\n         }\n \n         sentEntireByteRange \u003d true;\n       }\n     } finally {\n       if ((clientTraceFmt !\u003d null) \u0026\u0026 ClientTraceLog.isDebugEnabled()) {\n         final long endTime \u003d System.nanoTime();\n         ClientTraceLog.debug(String.format(clientTraceFmt, totalRead,\n             initialOffset, endTime - startTime));\n       }\n       close();\n     }\n     return totalRead;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private long doSendBlock(DataOutputStream out, OutputStream baseStream,\n        DataTransferThrottler throttler) throws IOException {\n    if (out \u003d\u003d null) {\n      throw new IOException( \"out stream is null\" );\n    }\n    initialOffset \u003d offset;\n    long totalRead \u003d 0;\n    OutputStream streamForSendChunks \u003d out;\n    \n    lastCacheDropOffset \u003d initialOffset;\n\n    if (isLongRead() \u0026\u0026 ris.getDataInFd() !\u003d null) {\n      // Advise that this file descriptor will be accessed sequentially.\n      ris.dropCacheBehindReads(block.getBlockName(), 0, 0,\n          POSIX_FADV_SEQUENTIAL);\n    }\n    \n    // Trigger readahead of beginning of file if configured.\n    manageOsCache();\n\n    final long startTime \u003d ClientTraceLog.isDebugEnabled() ? System.nanoTime() : 0;\n    try {\n      int maxChunksPerPacket;\n      int pktBufSize \u003d PacketHeader.PKT_MAX_HEADER_LEN;\n      boolean transferTo \u003d transferToAllowed \u0026\u0026 !verifyChecksum\n          \u0026\u0026 baseStream instanceof SocketOutputStream\n          \u0026\u0026 ris.getDataIn() instanceof FileInputStream;\n      if (transferTo) {\n        FileChannel fileChannel \u003d\n            ((FileInputStream)ris.getDataIn()).getChannel();\n        blockInPosition \u003d fileChannel.position();\n        streamForSendChunks \u003d baseStream;\n        maxChunksPerPacket \u003d numberOfChunks(TRANSFERTO_BUFFER_SIZE);\n        \n        // Smaller packet size to only hold checksum when doing transferTo\n        pktBufSize +\u003d checksumSize * maxChunksPerPacket;\n      } else {\n        maxChunksPerPacket \u003d Math.max(1,\n            numberOfChunks(IO_FILE_BUFFER_SIZE));\n        // Packet size includes both checksum and data\n        pktBufSize +\u003d (chunkSize + checksumSize) * maxChunksPerPacket;\n      }\n\n      ByteBuffer pktBuf \u003d ByteBuffer.allocate(pktBufSize);\n\n      while (endOffset \u003e offset \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n        manageOsCache();\n        long len \u003d sendPacket(pktBuf, maxChunksPerPacket, streamForSendChunks,\n            transferTo, throttler);\n        offset +\u003d len;\n        totalRead +\u003d len + (numberOfChunks(len) * checksumSize);\n        seqno++;\n      }\n      // If this thread was interrupted, then it did not send the full block.\n      if (!Thread.currentThread().isInterrupted()) {\n        try {\n          // send an empty packet to mark the end of the block\n          sendPacket(pktBuf, maxChunksPerPacket, streamForSendChunks, transferTo,\n              throttler);\n          out.flush();\n        } catch (IOException e) { //socket error\n          throw ioeToSocketException(e);\n        }\n\n        sentEntireByteRange \u003d true;\n      }\n    } finally {\n      if ((clientTraceFmt !\u003d null) \u0026\u0026 ClientTraceLog.isDebugEnabled()) {\n        final long endTime \u003d System.nanoTime();\n        ClientTraceLog.debug(String.format(clientTraceFmt, totalRead,\n            initialOffset, endTime - startTime));\n      }\n      close();\n    }\n    return totalRead;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockSender.java",
      "extendedDetails": {}
    },
    "dcedb72af468128458e597f08d22f5c34b744ae5": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HADOOP-10930. Refactor: Wrap Datanode IO related operations. Contributed by Xiaoyu Yao.\"\n\nThis reverts commit aeecfa24f4fb6af289920cbf8830c394e66bd78e.\n",
      "commitDate": "05/12/16 12:44 PM",
      "commitName": "dcedb72af468128458e597f08d22f5c34b744ae5",
      "commitAuthor": "Xiaoyu Yao",
      "commitDateOld": "29/11/16 8:52 PM",
      "commitNameOld": "aeecfa24f4fb6af289920cbf8830c394e66bd78e",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 5.66,
      "commitsBetweenForRepo": 32,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,76 +1,75 @@\n   private long doSendBlock(DataOutputStream out, OutputStream baseStream,\n         DataTransferThrottler throttler) throws IOException {\n     if (out \u003d\u003d null) {\n       throw new IOException( \"out stream is null\" );\n     }\n     initialOffset \u003d offset;\n     long totalRead \u003d 0;\n     OutputStream streamForSendChunks \u003d out;\n     \n     lastCacheDropOffset \u003d initialOffset;\n \n-    if (isLongRead() \u0026\u0026 ris.getDataInFd() !\u003d null) {\n+    if (isLongRead() \u0026\u0026 blockInFd !\u003d null) {\n       // Advise that this file descriptor will be accessed sequentially.\n-      ris.dropCacheBehindReads(block.getBlockName(), 0, 0,\n-          POSIX_FADV_SEQUENTIAL);\n+      NativeIO.POSIX.getCacheManipulator().posixFadviseIfPossible(\n+          block.getBlockName(), blockInFd, 0, 0, POSIX_FADV_SEQUENTIAL);\n     }\n     \n     // Trigger readahead of beginning of file if configured.\n     manageOsCache();\n \n     final long startTime \u003d ClientTraceLog.isDebugEnabled() ? System.nanoTime() : 0;\n     try {\n       int maxChunksPerPacket;\n       int pktBufSize \u003d PacketHeader.PKT_MAX_HEADER_LEN;\n       boolean transferTo \u003d transferToAllowed \u0026\u0026 !verifyChecksum\n           \u0026\u0026 baseStream instanceof SocketOutputStream\n-          \u0026\u0026 ris.getDataIn() instanceof FileInputStream;\n+          \u0026\u0026 blockIn instanceof FileInputStream;\n       if (transferTo) {\n-        FileChannel fileChannel \u003d\n-            ((FileInputStream)ris.getDataIn()).getChannel();\n+        FileChannel fileChannel \u003d ((FileInputStream)blockIn).getChannel();\n         blockInPosition \u003d fileChannel.position();\n         streamForSendChunks \u003d baseStream;\n         maxChunksPerPacket \u003d numberOfChunks(TRANSFERTO_BUFFER_SIZE);\n         \n         // Smaller packet size to only hold checksum when doing transferTo\n         pktBufSize +\u003d checksumSize * maxChunksPerPacket;\n       } else {\n         maxChunksPerPacket \u003d Math.max(1,\n             numberOfChunks(IO_FILE_BUFFER_SIZE));\n         // Packet size includes both checksum and data\n         pktBufSize +\u003d (chunkSize + checksumSize) * maxChunksPerPacket;\n       }\n \n       ByteBuffer pktBuf \u003d ByteBuffer.allocate(pktBufSize);\n \n       while (endOffset \u003e offset \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n         manageOsCache();\n         long len \u003d sendPacket(pktBuf, maxChunksPerPacket, streamForSendChunks,\n             transferTo, throttler);\n         offset +\u003d len;\n         totalRead +\u003d len + (numberOfChunks(len) * checksumSize);\n         seqno++;\n       }\n       // If this thread was interrupted, then it did not send the full block.\n       if (!Thread.currentThread().isInterrupted()) {\n         try {\n           // send an empty packet to mark the end of the block\n           sendPacket(pktBuf, maxChunksPerPacket, streamForSendChunks, transferTo,\n               throttler);\n           out.flush();\n         } catch (IOException e) { //socket error\n           throw ioeToSocketException(e);\n         }\n \n         sentEntireByteRange \u003d true;\n       }\n     } finally {\n       if ((clientTraceFmt !\u003d null) \u0026\u0026 ClientTraceLog.isDebugEnabled()) {\n         final long endTime \u003d System.nanoTime();\n         ClientTraceLog.debug(String.format(clientTraceFmt, totalRead,\n             initialOffset, endTime - startTime));\n       }\n       close();\n     }\n     return totalRead;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private long doSendBlock(DataOutputStream out, OutputStream baseStream,\n        DataTransferThrottler throttler) throws IOException {\n    if (out \u003d\u003d null) {\n      throw new IOException( \"out stream is null\" );\n    }\n    initialOffset \u003d offset;\n    long totalRead \u003d 0;\n    OutputStream streamForSendChunks \u003d out;\n    \n    lastCacheDropOffset \u003d initialOffset;\n\n    if (isLongRead() \u0026\u0026 blockInFd !\u003d null) {\n      // Advise that this file descriptor will be accessed sequentially.\n      NativeIO.POSIX.getCacheManipulator().posixFadviseIfPossible(\n          block.getBlockName(), blockInFd, 0, 0, POSIX_FADV_SEQUENTIAL);\n    }\n    \n    // Trigger readahead of beginning of file if configured.\n    manageOsCache();\n\n    final long startTime \u003d ClientTraceLog.isDebugEnabled() ? System.nanoTime() : 0;\n    try {\n      int maxChunksPerPacket;\n      int pktBufSize \u003d PacketHeader.PKT_MAX_HEADER_LEN;\n      boolean transferTo \u003d transferToAllowed \u0026\u0026 !verifyChecksum\n          \u0026\u0026 baseStream instanceof SocketOutputStream\n          \u0026\u0026 blockIn instanceof FileInputStream;\n      if (transferTo) {\n        FileChannel fileChannel \u003d ((FileInputStream)blockIn).getChannel();\n        blockInPosition \u003d fileChannel.position();\n        streamForSendChunks \u003d baseStream;\n        maxChunksPerPacket \u003d numberOfChunks(TRANSFERTO_BUFFER_SIZE);\n        \n        // Smaller packet size to only hold checksum when doing transferTo\n        pktBufSize +\u003d checksumSize * maxChunksPerPacket;\n      } else {\n        maxChunksPerPacket \u003d Math.max(1,\n            numberOfChunks(IO_FILE_BUFFER_SIZE));\n        // Packet size includes both checksum and data\n        pktBufSize +\u003d (chunkSize + checksumSize) * maxChunksPerPacket;\n      }\n\n      ByteBuffer pktBuf \u003d ByteBuffer.allocate(pktBufSize);\n\n      while (endOffset \u003e offset \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n        manageOsCache();\n        long len \u003d sendPacket(pktBuf, maxChunksPerPacket, streamForSendChunks,\n            transferTo, throttler);\n        offset +\u003d len;\n        totalRead +\u003d len + (numberOfChunks(len) * checksumSize);\n        seqno++;\n      }\n      // If this thread was interrupted, then it did not send the full block.\n      if (!Thread.currentThread().isInterrupted()) {\n        try {\n          // send an empty packet to mark the end of the block\n          sendPacket(pktBuf, maxChunksPerPacket, streamForSendChunks, transferTo,\n              throttler);\n          out.flush();\n        } catch (IOException e) { //socket error\n          throw ioeToSocketException(e);\n        }\n\n        sentEntireByteRange \u003d true;\n      }\n    } finally {\n      if ((clientTraceFmt !\u003d null) \u0026\u0026 ClientTraceLog.isDebugEnabled()) {\n        final long endTime \u003d System.nanoTime();\n        ClientTraceLog.debug(String.format(clientTraceFmt, totalRead,\n            initialOffset, endTime - startTime));\n      }\n      close();\n    }\n    return totalRead;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockSender.java",
      "extendedDetails": {}
    },
    "aeecfa24f4fb6af289920cbf8830c394e66bd78e": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-10930. Refactor: Wrap Datanode IO related operations. Contributed by Xiaoyu Yao.\n",
      "commitDate": "29/11/16 8:52 PM",
      "commitName": "aeecfa24f4fb6af289920cbf8830c394e66bd78e",
      "commitAuthor": "Xiaoyu Yao",
      "commitDateOld": "27/10/16 4:14 AM",
      "commitNameOld": "1cf6ec4ad4e1f4ea71f912923b5e8627b61ef482",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 33.74,
      "commitsBetweenForRepo": 277,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,75 +1,76 @@\n   private long doSendBlock(DataOutputStream out, OutputStream baseStream,\n         DataTransferThrottler throttler) throws IOException {\n     if (out \u003d\u003d null) {\n       throw new IOException( \"out stream is null\" );\n     }\n     initialOffset \u003d offset;\n     long totalRead \u003d 0;\n     OutputStream streamForSendChunks \u003d out;\n     \n     lastCacheDropOffset \u003d initialOffset;\n \n-    if (isLongRead() \u0026\u0026 blockInFd !\u003d null) {\n+    if (isLongRead() \u0026\u0026 ris.getDataInFd() !\u003d null) {\n       // Advise that this file descriptor will be accessed sequentially.\n-      NativeIO.POSIX.getCacheManipulator().posixFadviseIfPossible(\n-          block.getBlockName(), blockInFd, 0, 0, POSIX_FADV_SEQUENTIAL);\n+      ris.dropCacheBehindReads(block.getBlockName(), 0, 0,\n+          POSIX_FADV_SEQUENTIAL);\n     }\n     \n     // Trigger readahead of beginning of file if configured.\n     manageOsCache();\n \n     final long startTime \u003d ClientTraceLog.isDebugEnabled() ? System.nanoTime() : 0;\n     try {\n       int maxChunksPerPacket;\n       int pktBufSize \u003d PacketHeader.PKT_MAX_HEADER_LEN;\n       boolean transferTo \u003d transferToAllowed \u0026\u0026 !verifyChecksum\n           \u0026\u0026 baseStream instanceof SocketOutputStream\n-          \u0026\u0026 blockIn instanceof FileInputStream;\n+          \u0026\u0026 ris.getDataIn() instanceof FileInputStream;\n       if (transferTo) {\n-        FileChannel fileChannel \u003d ((FileInputStream)blockIn).getChannel();\n+        FileChannel fileChannel \u003d\n+            ((FileInputStream)ris.getDataIn()).getChannel();\n         blockInPosition \u003d fileChannel.position();\n         streamForSendChunks \u003d baseStream;\n         maxChunksPerPacket \u003d numberOfChunks(TRANSFERTO_BUFFER_SIZE);\n         \n         // Smaller packet size to only hold checksum when doing transferTo\n         pktBufSize +\u003d checksumSize * maxChunksPerPacket;\n       } else {\n         maxChunksPerPacket \u003d Math.max(1,\n             numberOfChunks(IO_FILE_BUFFER_SIZE));\n         // Packet size includes both checksum and data\n         pktBufSize +\u003d (chunkSize + checksumSize) * maxChunksPerPacket;\n       }\n \n       ByteBuffer pktBuf \u003d ByteBuffer.allocate(pktBufSize);\n \n       while (endOffset \u003e offset \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n         manageOsCache();\n         long len \u003d sendPacket(pktBuf, maxChunksPerPacket, streamForSendChunks,\n             transferTo, throttler);\n         offset +\u003d len;\n         totalRead +\u003d len + (numberOfChunks(len) * checksumSize);\n         seqno++;\n       }\n       // If this thread was interrupted, then it did not send the full block.\n       if (!Thread.currentThread().isInterrupted()) {\n         try {\n           // send an empty packet to mark the end of the block\n           sendPacket(pktBuf, maxChunksPerPacket, streamForSendChunks, transferTo,\n               throttler);\n           out.flush();\n         } catch (IOException e) { //socket error\n           throw ioeToSocketException(e);\n         }\n \n         sentEntireByteRange \u003d true;\n       }\n     } finally {\n       if ((clientTraceFmt !\u003d null) \u0026\u0026 ClientTraceLog.isDebugEnabled()) {\n         final long endTime \u003d System.nanoTime();\n         ClientTraceLog.debug(String.format(clientTraceFmt, totalRead,\n             initialOffset, endTime - startTime));\n       }\n       close();\n     }\n     return totalRead;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private long doSendBlock(DataOutputStream out, OutputStream baseStream,\n        DataTransferThrottler throttler) throws IOException {\n    if (out \u003d\u003d null) {\n      throw new IOException( \"out stream is null\" );\n    }\n    initialOffset \u003d offset;\n    long totalRead \u003d 0;\n    OutputStream streamForSendChunks \u003d out;\n    \n    lastCacheDropOffset \u003d initialOffset;\n\n    if (isLongRead() \u0026\u0026 ris.getDataInFd() !\u003d null) {\n      // Advise that this file descriptor will be accessed sequentially.\n      ris.dropCacheBehindReads(block.getBlockName(), 0, 0,\n          POSIX_FADV_SEQUENTIAL);\n    }\n    \n    // Trigger readahead of beginning of file if configured.\n    manageOsCache();\n\n    final long startTime \u003d ClientTraceLog.isDebugEnabled() ? System.nanoTime() : 0;\n    try {\n      int maxChunksPerPacket;\n      int pktBufSize \u003d PacketHeader.PKT_MAX_HEADER_LEN;\n      boolean transferTo \u003d transferToAllowed \u0026\u0026 !verifyChecksum\n          \u0026\u0026 baseStream instanceof SocketOutputStream\n          \u0026\u0026 ris.getDataIn() instanceof FileInputStream;\n      if (transferTo) {\n        FileChannel fileChannel \u003d\n            ((FileInputStream)ris.getDataIn()).getChannel();\n        blockInPosition \u003d fileChannel.position();\n        streamForSendChunks \u003d baseStream;\n        maxChunksPerPacket \u003d numberOfChunks(TRANSFERTO_BUFFER_SIZE);\n        \n        // Smaller packet size to only hold checksum when doing transferTo\n        pktBufSize +\u003d checksumSize * maxChunksPerPacket;\n      } else {\n        maxChunksPerPacket \u003d Math.max(1,\n            numberOfChunks(IO_FILE_BUFFER_SIZE));\n        // Packet size includes both checksum and data\n        pktBufSize +\u003d (chunkSize + checksumSize) * maxChunksPerPacket;\n      }\n\n      ByteBuffer pktBuf \u003d ByteBuffer.allocate(pktBufSize);\n\n      while (endOffset \u003e offset \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n        manageOsCache();\n        long len \u003d sendPacket(pktBuf, maxChunksPerPacket, streamForSendChunks,\n            transferTo, throttler);\n        offset +\u003d len;\n        totalRead +\u003d len + (numberOfChunks(len) * checksumSize);\n        seqno++;\n      }\n      // If this thread was interrupted, then it did not send the full block.\n      if (!Thread.currentThread().isInterrupted()) {\n        try {\n          // send an empty packet to mark the end of the block\n          sendPacket(pktBuf, maxChunksPerPacket, streamForSendChunks, transferTo,\n              throttler);\n          out.flush();\n        } catch (IOException e) { //socket error\n          throw ioeToSocketException(e);\n        }\n\n        sentEntireByteRange \u003d true;\n      }\n    } finally {\n      if ((clientTraceFmt !\u003d null) \u0026\u0026 ClientTraceLog.isDebugEnabled()) {\n        final long endTime \u003d System.nanoTime();\n        ClientTraceLog.debug(String.format(clientTraceFmt, totalRead,\n            initialOffset, endTime - startTime));\n      }\n      close();\n    }\n    return totalRead;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockSender.java",
      "extendedDetails": {}
    },
    "21d10ccc6e463cf250414264c78acb4a6e7c83e3": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-7824. NativeIO.java flags and identifiers must be set correctly for each platform, not hardcoded to their Linux values (Martin Walsh via Colin P. McCabe)\n",
      "commitDate": "31/07/15 3:01 PM",
      "commitName": "21d10ccc6e463cf250414264c78acb4a6e7c83e3",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "05/05/15 3:41 PM",
      "commitNameOld": "4da8490b512a33a255ed27309860859388d7c168",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 86.97,
      "commitsBetweenForRepo": 681,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,76 +1,75 @@\n   private long doSendBlock(DataOutputStream out, OutputStream baseStream,\n         DataTransferThrottler throttler) throws IOException {\n     if (out \u003d\u003d null) {\n       throw new IOException( \"out stream is null\" );\n     }\n     initialOffset \u003d offset;\n     long totalRead \u003d 0;\n     OutputStream streamForSendChunks \u003d out;\n     \n     lastCacheDropOffset \u003d initialOffset;\n \n     if (isLongRead() \u0026\u0026 blockInFd !\u003d null) {\n       // Advise that this file descriptor will be accessed sequentially.\n       NativeIO.POSIX.getCacheManipulator().posixFadviseIfPossible(\n-          block.getBlockName(), blockInFd, 0, 0,\n-          NativeIO.POSIX.POSIX_FADV_SEQUENTIAL);\n+          block.getBlockName(), blockInFd, 0, 0, POSIX_FADV_SEQUENTIAL);\n     }\n     \n     // Trigger readahead of beginning of file if configured.\n     manageOsCache();\n \n     final long startTime \u003d ClientTraceLog.isDebugEnabled() ? System.nanoTime() : 0;\n     try {\n       int maxChunksPerPacket;\n       int pktBufSize \u003d PacketHeader.PKT_MAX_HEADER_LEN;\n       boolean transferTo \u003d transferToAllowed \u0026\u0026 !verifyChecksum\n           \u0026\u0026 baseStream instanceof SocketOutputStream\n           \u0026\u0026 blockIn instanceof FileInputStream;\n       if (transferTo) {\n         FileChannel fileChannel \u003d ((FileInputStream)blockIn).getChannel();\n         blockInPosition \u003d fileChannel.position();\n         streamForSendChunks \u003d baseStream;\n         maxChunksPerPacket \u003d numberOfChunks(TRANSFERTO_BUFFER_SIZE);\n         \n         // Smaller packet size to only hold checksum when doing transferTo\n         pktBufSize +\u003d checksumSize * maxChunksPerPacket;\n       } else {\n         maxChunksPerPacket \u003d Math.max(1,\n             numberOfChunks(IO_FILE_BUFFER_SIZE));\n         // Packet size includes both checksum and data\n         pktBufSize +\u003d (chunkSize + checksumSize) * maxChunksPerPacket;\n       }\n \n       ByteBuffer pktBuf \u003d ByteBuffer.allocate(pktBufSize);\n \n       while (endOffset \u003e offset \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n         manageOsCache();\n         long len \u003d sendPacket(pktBuf, maxChunksPerPacket, streamForSendChunks,\n             transferTo, throttler);\n         offset +\u003d len;\n         totalRead +\u003d len + (numberOfChunks(len) * checksumSize);\n         seqno++;\n       }\n       // If this thread was interrupted, then it did not send the full block.\n       if (!Thread.currentThread().isInterrupted()) {\n         try {\n           // send an empty packet to mark the end of the block\n           sendPacket(pktBuf, maxChunksPerPacket, streamForSendChunks, transferTo,\n               throttler);\n           out.flush();\n         } catch (IOException e) { //socket error\n           throw ioeToSocketException(e);\n         }\n \n         sentEntireByteRange \u003d true;\n       }\n     } finally {\n       if ((clientTraceFmt !\u003d null) \u0026\u0026 ClientTraceLog.isDebugEnabled()) {\n         final long endTime \u003d System.nanoTime();\n         ClientTraceLog.debug(String.format(clientTraceFmt, totalRead,\n             initialOffset, endTime - startTime));\n       }\n       close();\n     }\n     return totalRead;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private long doSendBlock(DataOutputStream out, OutputStream baseStream,\n        DataTransferThrottler throttler) throws IOException {\n    if (out \u003d\u003d null) {\n      throw new IOException( \"out stream is null\" );\n    }\n    initialOffset \u003d offset;\n    long totalRead \u003d 0;\n    OutputStream streamForSendChunks \u003d out;\n    \n    lastCacheDropOffset \u003d initialOffset;\n\n    if (isLongRead() \u0026\u0026 blockInFd !\u003d null) {\n      // Advise that this file descriptor will be accessed sequentially.\n      NativeIO.POSIX.getCacheManipulator().posixFadviseIfPossible(\n          block.getBlockName(), blockInFd, 0, 0, POSIX_FADV_SEQUENTIAL);\n    }\n    \n    // Trigger readahead of beginning of file if configured.\n    manageOsCache();\n\n    final long startTime \u003d ClientTraceLog.isDebugEnabled() ? System.nanoTime() : 0;\n    try {\n      int maxChunksPerPacket;\n      int pktBufSize \u003d PacketHeader.PKT_MAX_HEADER_LEN;\n      boolean transferTo \u003d transferToAllowed \u0026\u0026 !verifyChecksum\n          \u0026\u0026 baseStream instanceof SocketOutputStream\n          \u0026\u0026 blockIn instanceof FileInputStream;\n      if (transferTo) {\n        FileChannel fileChannel \u003d ((FileInputStream)blockIn).getChannel();\n        blockInPosition \u003d fileChannel.position();\n        streamForSendChunks \u003d baseStream;\n        maxChunksPerPacket \u003d numberOfChunks(TRANSFERTO_BUFFER_SIZE);\n        \n        // Smaller packet size to only hold checksum when doing transferTo\n        pktBufSize +\u003d checksumSize * maxChunksPerPacket;\n      } else {\n        maxChunksPerPacket \u003d Math.max(1,\n            numberOfChunks(IO_FILE_BUFFER_SIZE));\n        // Packet size includes both checksum and data\n        pktBufSize +\u003d (chunkSize + checksumSize) * maxChunksPerPacket;\n      }\n\n      ByteBuffer pktBuf \u003d ByteBuffer.allocate(pktBufSize);\n\n      while (endOffset \u003e offset \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n        manageOsCache();\n        long len \u003d sendPacket(pktBuf, maxChunksPerPacket, streamForSendChunks,\n            transferTo, throttler);\n        offset +\u003d len;\n        totalRead +\u003d len + (numberOfChunks(len) * checksumSize);\n        seqno++;\n      }\n      // If this thread was interrupted, then it did not send the full block.\n      if (!Thread.currentThread().isInterrupted()) {\n        try {\n          // send an empty packet to mark the end of the block\n          sendPacket(pktBuf, maxChunksPerPacket, streamForSendChunks, transferTo,\n              throttler);\n          out.flush();\n        } catch (IOException e) { //socket error\n          throw ioeToSocketException(e);\n        }\n\n        sentEntireByteRange \u003d true;\n      }\n    } finally {\n      if ((clientTraceFmt !\u003d null) \u0026\u0026 ClientTraceLog.isDebugEnabled()) {\n        final long endTime \u003d System.nanoTime();\n        ClientTraceLog.debug(String.format(clientTraceFmt, totalRead,\n            initialOffset, endTime - startTime));\n      }\n      close();\n    }\n    return totalRead;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockSender.java",
      "extendedDetails": {}
    },
    "4da8490b512a33a255ed27309860859388d7c168": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8314. Move HdfsServerConstants#IO_FILE_BUFFER_SIZE and SMALL_BUFFER_SIZE to the users. Contributed by Li Lu.\n",
      "commitDate": "05/05/15 3:41 PM",
      "commitName": "4da8490b512a33a255ed27309860859388d7c168",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "02/05/15 10:03 AM",
      "commitNameOld": "6ae2a0d048e133b43249c248a75a4d77d9abb80d",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 3.23,
      "commitsBetweenForRepo": 31,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,76 +1,76 @@\n   private long doSendBlock(DataOutputStream out, OutputStream baseStream,\n         DataTransferThrottler throttler) throws IOException {\n     if (out \u003d\u003d null) {\n       throw new IOException( \"out stream is null\" );\n     }\n     initialOffset \u003d offset;\n     long totalRead \u003d 0;\n     OutputStream streamForSendChunks \u003d out;\n     \n     lastCacheDropOffset \u003d initialOffset;\n \n     if (isLongRead() \u0026\u0026 blockInFd !\u003d null) {\n       // Advise that this file descriptor will be accessed sequentially.\n       NativeIO.POSIX.getCacheManipulator().posixFadviseIfPossible(\n           block.getBlockName(), blockInFd, 0, 0,\n           NativeIO.POSIX.POSIX_FADV_SEQUENTIAL);\n     }\n     \n     // Trigger readahead of beginning of file if configured.\n     manageOsCache();\n \n     final long startTime \u003d ClientTraceLog.isDebugEnabled() ? System.nanoTime() : 0;\n     try {\n       int maxChunksPerPacket;\n       int pktBufSize \u003d PacketHeader.PKT_MAX_HEADER_LEN;\n       boolean transferTo \u003d transferToAllowed \u0026\u0026 !verifyChecksum\n           \u0026\u0026 baseStream instanceof SocketOutputStream\n           \u0026\u0026 blockIn instanceof FileInputStream;\n       if (transferTo) {\n         FileChannel fileChannel \u003d ((FileInputStream)blockIn).getChannel();\n         blockInPosition \u003d fileChannel.position();\n         streamForSendChunks \u003d baseStream;\n         maxChunksPerPacket \u003d numberOfChunks(TRANSFERTO_BUFFER_SIZE);\n         \n         // Smaller packet size to only hold checksum when doing transferTo\n         pktBufSize +\u003d checksumSize * maxChunksPerPacket;\n       } else {\n         maxChunksPerPacket \u003d Math.max(1,\n-            numberOfChunks(HdfsServerConstants.IO_FILE_BUFFER_SIZE));\n+            numberOfChunks(IO_FILE_BUFFER_SIZE));\n         // Packet size includes both checksum and data\n         pktBufSize +\u003d (chunkSize + checksumSize) * maxChunksPerPacket;\n       }\n \n       ByteBuffer pktBuf \u003d ByteBuffer.allocate(pktBufSize);\n \n       while (endOffset \u003e offset \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n         manageOsCache();\n         long len \u003d sendPacket(pktBuf, maxChunksPerPacket, streamForSendChunks,\n             transferTo, throttler);\n         offset +\u003d len;\n         totalRead +\u003d len + (numberOfChunks(len) * checksumSize);\n         seqno++;\n       }\n       // If this thread was interrupted, then it did not send the full block.\n       if (!Thread.currentThread().isInterrupted()) {\n         try {\n           // send an empty packet to mark the end of the block\n           sendPacket(pktBuf, maxChunksPerPacket, streamForSendChunks, transferTo,\n               throttler);\n           out.flush();\n         } catch (IOException e) { //socket error\n           throw ioeToSocketException(e);\n         }\n \n         sentEntireByteRange \u003d true;\n       }\n     } finally {\n       if ((clientTraceFmt !\u003d null) \u0026\u0026 ClientTraceLog.isDebugEnabled()) {\n         final long endTime \u003d System.nanoTime();\n         ClientTraceLog.debug(String.format(clientTraceFmt, totalRead,\n             initialOffset, endTime - startTime));\n       }\n       close();\n     }\n     return totalRead;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private long doSendBlock(DataOutputStream out, OutputStream baseStream,\n        DataTransferThrottler throttler) throws IOException {\n    if (out \u003d\u003d null) {\n      throw new IOException( \"out stream is null\" );\n    }\n    initialOffset \u003d offset;\n    long totalRead \u003d 0;\n    OutputStream streamForSendChunks \u003d out;\n    \n    lastCacheDropOffset \u003d initialOffset;\n\n    if (isLongRead() \u0026\u0026 blockInFd !\u003d null) {\n      // Advise that this file descriptor will be accessed sequentially.\n      NativeIO.POSIX.getCacheManipulator().posixFadviseIfPossible(\n          block.getBlockName(), blockInFd, 0, 0,\n          NativeIO.POSIX.POSIX_FADV_SEQUENTIAL);\n    }\n    \n    // Trigger readahead of beginning of file if configured.\n    manageOsCache();\n\n    final long startTime \u003d ClientTraceLog.isDebugEnabled() ? System.nanoTime() : 0;\n    try {\n      int maxChunksPerPacket;\n      int pktBufSize \u003d PacketHeader.PKT_MAX_HEADER_LEN;\n      boolean transferTo \u003d transferToAllowed \u0026\u0026 !verifyChecksum\n          \u0026\u0026 baseStream instanceof SocketOutputStream\n          \u0026\u0026 blockIn instanceof FileInputStream;\n      if (transferTo) {\n        FileChannel fileChannel \u003d ((FileInputStream)blockIn).getChannel();\n        blockInPosition \u003d fileChannel.position();\n        streamForSendChunks \u003d baseStream;\n        maxChunksPerPacket \u003d numberOfChunks(TRANSFERTO_BUFFER_SIZE);\n        \n        // Smaller packet size to only hold checksum when doing transferTo\n        pktBufSize +\u003d checksumSize * maxChunksPerPacket;\n      } else {\n        maxChunksPerPacket \u003d Math.max(1,\n            numberOfChunks(IO_FILE_BUFFER_SIZE));\n        // Packet size includes both checksum and data\n        pktBufSize +\u003d (chunkSize + checksumSize) * maxChunksPerPacket;\n      }\n\n      ByteBuffer pktBuf \u003d ByteBuffer.allocate(pktBufSize);\n\n      while (endOffset \u003e offset \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n        manageOsCache();\n        long len \u003d sendPacket(pktBuf, maxChunksPerPacket, streamForSendChunks,\n            transferTo, throttler);\n        offset +\u003d len;\n        totalRead +\u003d len + (numberOfChunks(len) * checksumSize);\n        seqno++;\n      }\n      // If this thread was interrupted, then it did not send the full block.\n      if (!Thread.currentThread().isInterrupted()) {\n        try {\n          // send an empty packet to mark the end of the block\n          sendPacket(pktBuf, maxChunksPerPacket, streamForSendChunks, transferTo,\n              throttler);\n          out.flush();\n        } catch (IOException e) { //socket error\n          throw ioeToSocketException(e);\n        }\n\n        sentEntireByteRange \u003d true;\n      }\n    } finally {\n      if ((clientTraceFmt !\u003d null) \u0026\u0026 ClientTraceLog.isDebugEnabled()) {\n        final long endTime \u003d System.nanoTime();\n        ClientTraceLog.debug(String.format(clientTraceFmt, totalRead,\n            initialOffset, endTime - startTime));\n      }\n      close();\n    }\n    return totalRead;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockSender.java",
      "extendedDetails": {}
    },
    "6ae2a0d048e133b43249c248a75a4d77d9abb80d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8249. Separate HdfsConstants into the client and the server side class. Contributed by Haohui Mai.\n",
      "commitDate": "02/05/15 10:03 AM",
      "commitName": "6ae2a0d048e133b43249c248a75a4d77d9abb80d",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "23/03/15 9:49 PM",
      "commitNameOld": "d7e3c3364eb904f55a878bc14c331952f9dadab2",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 39.51,
      "commitsBetweenForRepo": 349,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,76 +1,76 @@\n   private long doSendBlock(DataOutputStream out, OutputStream baseStream,\n         DataTransferThrottler throttler) throws IOException {\n     if (out \u003d\u003d null) {\n       throw new IOException( \"out stream is null\" );\n     }\n     initialOffset \u003d offset;\n     long totalRead \u003d 0;\n     OutputStream streamForSendChunks \u003d out;\n     \n     lastCacheDropOffset \u003d initialOffset;\n \n     if (isLongRead() \u0026\u0026 blockInFd !\u003d null) {\n       // Advise that this file descriptor will be accessed sequentially.\n       NativeIO.POSIX.getCacheManipulator().posixFadviseIfPossible(\n           block.getBlockName(), blockInFd, 0, 0,\n           NativeIO.POSIX.POSIX_FADV_SEQUENTIAL);\n     }\n     \n     // Trigger readahead of beginning of file if configured.\n     manageOsCache();\n \n     final long startTime \u003d ClientTraceLog.isDebugEnabled() ? System.nanoTime() : 0;\n     try {\n       int maxChunksPerPacket;\n       int pktBufSize \u003d PacketHeader.PKT_MAX_HEADER_LEN;\n       boolean transferTo \u003d transferToAllowed \u0026\u0026 !verifyChecksum\n           \u0026\u0026 baseStream instanceof SocketOutputStream\n           \u0026\u0026 blockIn instanceof FileInputStream;\n       if (transferTo) {\n         FileChannel fileChannel \u003d ((FileInputStream)blockIn).getChannel();\n         blockInPosition \u003d fileChannel.position();\n         streamForSendChunks \u003d baseStream;\n         maxChunksPerPacket \u003d numberOfChunks(TRANSFERTO_BUFFER_SIZE);\n         \n         // Smaller packet size to only hold checksum when doing transferTo\n         pktBufSize +\u003d checksumSize * maxChunksPerPacket;\n       } else {\n         maxChunksPerPacket \u003d Math.max(1,\n-            numberOfChunks(HdfsConstants.IO_FILE_BUFFER_SIZE));\n+            numberOfChunks(HdfsServerConstants.IO_FILE_BUFFER_SIZE));\n         // Packet size includes both checksum and data\n         pktBufSize +\u003d (chunkSize + checksumSize) * maxChunksPerPacket;\n       }\n \n       ByteBuffer pktBuf \u003d ByteBuffer.allocate(pktBufSize);\n \n       while (endOffset \u003e offset \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n         manageOsCache();\n         long len \u003d sendPacket(pktBuf, maxChunksPerPacket, streamForSendChunks,\n             transferTo, throttler);\n         offset +\u003d len;\n         totalRead +\u003d len + (numberOfChunks(len) * checksumSize);\n         seqno++;\n       }\n       // If this thread was interrupted, then it did not send the full block.\n       if (!Thread.currentThread().isInterrupted()) {\n         try {\n           // send an empty packet to mark the end of the block\n           sendPacket(pktBuf, maxChunksPerPacket, streamForSendChunks, transferTo,\n               throttler);\n           out.flush();\n         } catch (IOException e) { //socket error\n           throw ioeToSocketException(e);\n         }\n \n         sentEntireByteRange \u003d true;\n       }\n     } finally {\n       if ((clientTraceFmt !\u003d null) \u0026\u0026 ClientTraceLog.isDebugEnabled()) {\n         final long endTime \u003d System.nanoTime();\n         ClientTraceLog.debug(String.format(clientTraceFmt, totalRead,\n             initialOffset, endTime - startTime));\n       }\n       close();\n     }\n     return totalRead;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private long doSendBlock(DataOutputStream out, OutputStream baseStream,\n        DataTransferThrottler throttler) throws IOException {\n    if (out \u003d\u003d null) {\n      throw new IOException( \"out stream is null\" );\n    }\n    initialOffset \u003d offset;\n    long totalRead \u003d 0;\n    OutputStream streamForSendChunks \u003d out;\n    \n    lastCacheDropOffset \u003d initialOffset;\n\n    if (isLongRead() \u0026\u0026 blockInFd !\u003d null) {\n      // Advise that this file descriptor will be accessed sequentially.\n      NativeIO.POSIX.getCacheManipulator().posixFadviseIfPossible(\n          block.getBlockName(), blockInFd, 0, 0,\n          NativeIO.POSIX.POSIX_FADV_SEQUENTIAL);\n    }\n    \n    // Trigger readahead of beginning of file if configured.\n    manageOsCache();\n\n    final long startTime \u003d ClientTraceLog.isDebugEnabled() ? System.nanoTime() : 0;\n    try {\n      int maxChunksPerPacket;\n      int pktBufSize \u003d PacketHeader.PKT_MAX_HEADER_LEN;\n      boolean transferTo \u003d transferToAllowed \u0026\u0026 !verifyChecksum\n          \u0026\u0026 baseStream instanceof SocketOutputStream\n          \u0026\u0026 blockIn instanceof FileInputStream;\n      if (transferTo) {\n        FileChannel fileChannel \u003d ((FileInputStream)blockIn).getChannel();\n        blockInPosition \u003d fileChannel.position();\n        streamForSendChunks \u003d baseStream;\n        maxChunksPerPacket \u003d numberOfChunks(TRANSFERTO_BUFFER_SIZE);\n        \n        // Smaller packet size to only hold checksum when doing transferTo\n        pktBufSize +\u003d checksumSize * maxChunksPerPacket;\n      } else {\n        maxChunksPerPacket \u003d Math.max(1,\n            numberOfChunks(HdfsServerConstants.IO_FILE_BUFFER_SIZE));\n        // Packet size includes both checksum and data\n        pktBufSize +\u003d (chunkSize + checksumSize) * maxChunksPerPacket;\n      }\n\n      ByteBuffer pktBuf \u003d ByteBuffer.allocate(pktBufSize);\n\n      while (endOffset \u003e offset \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n        manageOsCache();\n        long len \u003d sendPacket(pktBuf, maxChunksPerPacket, streamForSendChunks,\n            transferTo, throttler);\n        offset +\u003d len;\n        totalRead +\u003d len + (numberOfChunks(len) * checksumSize);\n        seqno++;\n      }\n      // If this thread was interrupted, then it did not send the full block.\n      if (!Thread.currentThread().isInterrupted()) {\n        try {\n          // send an empty packet to mark the end of the block\n          sendPacket(pktBuf, maxChunksPerPacket, streamForSendChunks, transferTo,\n              throttler);\n          out.flush();\n        } catch (IOException e) { //socket error\n          throw ioeToSocketException(e);\n        }\n\n        sentEntireByteRange \u003d true;\n      }\n    } finally {\n      if ((clientTraceFmt !\u003d null) \u0026\u0026 ClientTraceLog.isDebugEnabled()) {\n        final long endTime \u003d System.nanoTime();\n        ClientTraceLog.debug(String.format(clientTraceFmt, totalRead,\n            initialOffset, endTime - startTime));\n      }\n      close();\n    }\n    return totalRead;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockSender.java",
      "extendedDetails": {}
    },
    "7f6ed7fe365166e8075359f1d0ad035fa876c70f": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-7055. Add tracing to DFSInputStream (cmccabe)\n",
      "commitDate": "03/10/14 1:35 PM",
      "commitName": "7f6ed7fe365166e8075359f1d0ad035fa876c70f",
      "commitAuthor": "Colin Patrick Mccabe",
      "diff": "@@ -0,0 +1,76 @@\n+  private long doSendBlock(DataOutputStream out, OutputStream baseStream,\n+        DataTransferThrottler throttler) throws IOException {\n+    if (out \u003d\u003d null) {\n+      throw new IOException( \"out stream is null\" );\n+    }\n+    initialOffset \u003d offset;\n+    long totalRead \u003d 0;\n+    OutputStream streamForSendChunks \u003d out;\n+    \n+    lastCacheDropOffset \u003d initialOffset;\n+\n+    if (isLongRead() \u0026\u0026 blockInFd !\u003d null) {\n+      // Advise that this file descriptor will be accessed sequentially.\n+      NativeIO.POSIX.getCacheManipulator().posixFadviseIfPossible(\n+          block.getBlockName(), blockInFd, 0, 0,\n+          NativeIO.POSIX.POSIX_FADV_SEQUENTIAL);\n+    }\n+    \n+    // Trigger readahead of beginning of file if configured.\n+    manageOsCache();\n+\n+    final long startTime \u003d ClientTraceLog.isDebugEnabled() ? System.nanoTime() : 0;\n+    try {\n+      int maxChunksPerPacket;\n+      int pktBufSize \u003d PacketHeader.PKT_MAX_HEADER_LEN;\n+      boolean transferTo \u003d transferToAllowed \u0026\u0026 !verifyChecksum\n+          \u0026\u0026 baseStream instanceof SocketOutputStream\n+          \u0026\u0026 blockIn instanceof FileInputStream;\n+      if (transferTo) {\n+        FileChannel fileChannel \u003d ((FileInputStream)blockIn).getChannel();\n+        blockInPosition \u003d fileChannel.position();\n+        streamForSendChunks \u003d baseStream;\n+        maxChunksPerPacket \u003d numberOfChunks(TRANSFERTO_BUFFER_SIZE);\n+        \n+        // Smaller packet size to only hold checksum when doing transferTo\n+        pktBufSize +\u003d checksumSize * maxChunksPerPacket;\n+      } else {\n+        maxChunksPerPacket \u003d Math.max(1,\n+            numberOfChunks(HdfsConstants.IO_FILE_BUFFER_SIZE));\n+        // Packet size includes both checksum and data\n+        pktBufSize +\u003d (chunkSize + checksumSize) * maxChunksPerPacket;\n+      }\n+\n+      ByteBuffer pktBuf \u003d ByteBuffer.allocate(pktBufSize);\n+\n+      while (endOffset \u003e offset \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n+        manageOsCache();\n+        long len \u003d sendPacket(pktBuf, maxChunksPerPacket, streamForSendChunks,\n+            transferTo, throttler);\n+        offset +\u003d len;\n+        totalRead +\u003d len + (numberOfChunks(len) * checksumSize);\n+        seqno++;\n+      }\n+      // If this thread was interrupted, then it did not send the full block.\n+      if (!Thread.currentThread().isInterrupted()) {\n+        try {\n+          // send an empty packet to mark the end of the block\n+          sendPacket(pktBuf, maxChunksPerPacket, streamForSendChunks, transferTo,\n+              throttler);\n+          out.flush();\n+        } catch (IOException e) { //socket error\n+          throw ioeToSocketException(e);\n+        }\n+\n+        sentEntireByteRange \u003d true;\n+      }\n+    } finally {\n+      if ((clientTraceFmt !\u003d null) \u0026\u0026 ClientTraceLog.isDebugEnabled()) {\n+        final long endTime \u003d System.nanoTime();\n+        ClientTraceLog.debug(String.format(clientTraceFmt, totalRead,\n+            initialOffset, endTime - startTime));\n+      }\n+      close();\n+    }\n+    return totalRead;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private long doSendBlock(DataOutputStream out, OutputStream baseStream,\n        DataTransferThrottler throttler) throws IOException {\n    if (out \u003d\u003d null) {\n      throw new IOException( \"out stream is null\" );\n    }\n    initialOffset \u003d offset;\n    long totalRead \u003d 0;\n    OutputStream streamForSendChunks \u003d out;\n    \n    lastCacheDropOffset \u003d initialOffset;\n\n    if (isLongRead() \u0026\u0026 blockInFd !\u003d null) {\n      // Advise that this file descriptor will be accessed sequentially.\n      NativeIO.POSIX.getCacheManipulator().posixFadviseIfPossible(\n          block.getBlockName(), blockInFd, 0, 0,\n          NativeIO.POSIX.POSIX_FADV_SEQUENTIAL);\n    }\n    \n    // Trigger readahead of beginning of file if configured.\n    manageOsCache();\n\n    final long startTime \u003d ClientTraceLog.isDebugEnabled() ? System.nanoTime() : 0;\n    try {\n      int maxChunksPerPacket;\n      int pktBufSize \u003d PacketHeader.PKT_MAX_HEADER_LEN;\n      boolean transferTo \u003d transferToAllowed \u0026\u0026 !verifyChecksum\n          \u0026\u0026 baseStream instanceof SocketOutputStream\n          \u0026\u0026 blockIn instanceof FileInputStream;\n      if (transferTo) {\n        FileChannel fileChannel \u003d ((FileInputStream)blockIn).getChannel();\n        blockInPosition \u003d fileChannel.position();\n        streamForSendChunks \u003d baseStream;\n        maxChunksPerPacket \u003d numberOfChunks(TRANSFERTO_BUFFER_SIZE);\n        \n        // Smaller packet size to only hold checksum when doing transferTo\n        pktBufSize +\u003d checksumSize * maxChunksPerPacket;\n      } else {\n        maxChunksPerPacket \u003d Math.max(1,\n            numberOfChunks(HdfsConstants.IO_FILE_BUFFER_SIZE));\n        // Packet size includes both checksum and data\n        pktBufSize +\u003d (chunkSize + checksumSize) * maxChunksPerPacket;\n      }\n\n      ByteBuffer pktBuf \u003d ByteBuffer.allocate(pktBufSize);\n\n      while (endOffset \u003e offset \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n        manageOsCache();\n        long len \u003d sendPacket(pktBuf, maxChunksPerPacket, streamForSendChunks,\n            transferTo, throttler);\n        offset +\u003d len;\n        totalRead +\u003d len + (numberOfChunks(len) * checksumSize);\n        seqno++;\n      }\n      // If this thread was interrupted, then it did not send the full block.\n      if (!Thread.currentThread().isInterrupted()) {\n        try {\n          // send an empty packet to mark the end of the block\n          sendPacket(pktBuf, maxChunksPerPacket, streamForSendChunks, transferTo,\n              throttler);\n          out.flush();\n        } catch (IOException e) { //socket error\n          throw ioeToSocketException(e);\n        }\n\n        sentEntireByteRange \u003d true;\n      }\n    } finally {\n      if ((clientTraceFmt !\u003d null) \u0026\u0026 ClientTraceLog.isDebugEnabled()) {\n        final long endTime \u003d System.nanoTime();\n        ClientTraceLog.debug(String.format(clientTraceFmt, totalRead,\n            initialOffset, endTime - startTime));\n      }\n      close();\n    }\n    return totalRead;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockSender.java"
    }
  }
}