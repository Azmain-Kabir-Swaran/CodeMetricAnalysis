{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSNamesystem.java",
  "functionName": "getAdditionalBlock",
  "functionId": "getAdditionalBlock___src-String__fileId-long__clientName-String__previous-ExtendedBlock__excludedNodes-DatanodeInfo[]__favoredNodes-String[]__flags-EnumSet__AddBlockFlag__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
  "functionStartLine": 2940,
  "functionEndLine": 2983,
  "numCommitsSeen": 2676,
  "timeTaken": 59584,
  "changeHistory": [
    "4b95c242eca540455a4d5d0899aaf73b6064b5ea",
    "84a1321f6aa0af6895564a7c47f8f264656f0294",
    "ff0b99eafeda035ebe0dc82cfe689808047a8893",
    "0a152103f19a3e8e1b7f33aeb9dd115ba231d7b7",
    "3fa33b5c2c289ceaced30c6c5451f3569110459d",
    "3841d09765bab332c9ae4803c5981799585b1f41",
    "e5afac5896a1a88e152746598527d91f73cbb724",
    "0959b67f1a189b4a99752904115efbd471f1d6d7",
    "75c545486080042952c775f7964212c15ce65f73",
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177",
    "c78e3a7cdd10c40454e9acb06986ba6d8573cb19",
    "c95b878abf313507666ea018f9e6033c4c166e10",
    "18312804e9c86c0ea6a259e288994fea6fa366ef",
    "ed841dd9a96e54cb84d9cae5507e47ff1c8cdf6e",
    "407bb3d3e452c8277c498dd14e0cc5b7762a7091",
    "38af6101d8ee199089c3d92ee3798ee674fb8acd",
    "d9c5f20333ef510c0ace066c0a811f9e953e9e17",
    "1e89eba47d0f291b33fc26f9406231fc70b63a87",
    "a4e0ff5e052abad498595ee198b49c5310c9ec0d",
    "e98529858edeed11c4f900b0db30d7e4eb2ab1ec",
    "f131dba8a3d603a5d15c4f035ed3da75b4daf0dc",
    "c00703dd082474fea98a63b871c2183ca01147ed",
    "578dae9ef39eef046b0a0ff9cd830c753a98afad",
    "9df84c35d5a228e3ae42e90487f2d1f1264e5eea",
    "ce68f410b05a58ad05965f32ad7f5b246b363a75",
    "8162fdcdbc23d749fdb188ae8419e173c59cb1ed",
    "5829029154b8e8e02bc6aeb45435046ca080bbe9",
    "34f08944b7c8d58f531a3f3bf3d4ee4cd3fa643a",
    "8c7a7e619699386f9e6991842558d78aa0c8053d",
    "ce7e5565f41eb23975eee1150e00a4cb4842a727",
    "5d2ffde68e2c14ee33fa2ba4a34cb42fbd14b5ec",
    "980e6c54bab4ffc87e168cd5c217fef44c72a878",
    "3bf09c51501a23b7fa28fd0a0c4c0965858d026c",
    "4525c4a25ba90163c9543116e2bd54239e0dd097",
    "61a262757ca70f30956b467ea8e40e73bf7dc634",
    "7ee5ce3176a74d217551b5981f809a56c719424b",
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de",
    "ad06a087131d69d173d8e03dce5c97650a530f2e",
    "bcdb125643d4ec834f6bd5d4fafb079391f31fc6",
    "36d1c49486587c2dbb193e8538b1d4510c462fa6",
    "71071b904d0c9aec7b3713d41740f24182e81c36",
    "b7cd8c0f865e88e40eee75fd2690b1fdc4155071",
    "f00198b16c529bafeb8460427f12de69401941c3",
    "9992cae54120d2742922745c1f513c6bfbde67a9",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "2892f6d817d74e90ff50073cd3721ed4ec75ba92",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "5d5b1c6c10c66c6a17b483a3e1a98d59d3d0bdee",
    "371f4a59059322000a40eb4bdf5386b96b626ece",
    "d68e38b78d9687987c4de2046ce9aa0016685e98",
    "c3f6575ca44e8ad803d0b46991472465b595cdeb",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "4b95c242eca540455a4d5d0899aaf73b6064b5ea": "Ybodychange",
    "84a1321f6aa0af6895564a7c47f8f264656f0294": "Ybodychange",
    "ff0b99eafeda035ebe0dc82cfe689808047a8893": "Ybodychange",
    "0a152103f19a3e8e1b7f33aeb9dd115ba231d7b7": "Ymultichange(Yparameterchange,Ybodychange)",
    "3fa33b5c2c289ceaced30c6c5451f3569110459d": "Ybodychange",
    "3841d09765bab332c9ae4803c5981799585b1f41": "Ybodychange",
    "e5afac5896a1a88e152746598527d91f73cbb724": "Ymultichange(Yparameterchange,Ybodychange)",
    "0959b67f1a189b4a99752904115efbd471f1d6d7": "Ybodychange",
    "75c545486080042952c775f7964212c15ce65f73": "Ybodychange",
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177": "Ybodychange",
    "c78e3a7cdd10c40454e9acb06986ba6d8573cb19": "Ymultichange(Yexceptionschange,Ybodychange)",
    "c95b878abf313507666ea018f9e6033c4c166e10": "Ybodychange",
    "18312804e9c86c0ea6a259e288994fea6fa366ef": "Ybodychange",
    "ed841dd9a96e54cb84d9cae5507e47ff1c8cdf6e": "Ybodychange",
    "407bb3d3e452c8277c498dd14e0cc5b7762a7091": "Ybodychange",
    "38af6101d8ee199089c3d92ee3798ee674fb8acd": "Ybodychange",
    "d9c5f20333ef510c0ace066c0a811f9e953e9e17": "Ybodychange",
    "1e89eba47d0f291b33fc26f9406231fc70b63a87": "Ybodychange",
    "a4e0ff5e052abad498595ee198b49c5310c9ec0d": "Ybodychange",
    "e98529858edeed11c4f900b0db30d7e4eb2ab1ec": "Ybodychange",
    "f131dba8a3d603a5d15c4f035ed3da75b4daf0dc": "Ybodychange",
    "c00703dd082474fea98a63b871c2183ca01147ed": "Ybodychange",
    "578dae9ef39eef046b0a0ff9cd830c753a98afad": "Ybodychange",
    "9df84c35d5a228e3ae42e90487f2d1f1264e5eea": "Ybodychange",
    "ce68f410b05a58ad05965f32ad7f5b246b363a75": "Ybodychange",
    "8162fdcdbc23d749fdb188ae8419e173c59cb1ed": "Ybodychange",
    "5829029154b8e8e02bc6aeb45435046ca080bbe9": "Ybodychange",
    "34f08944b7c8d58f531a3f3bf3d4ee4cd3fa643a": "Yparameterchange",
    "8c7a7e619699386f9e6991842558d78aa0c8053d": "Ybodychange",
    "ce7e5565f41eb23975eee1150e00a4cb4842a727": "Ybodychange",
    "5d2ffde68e2c14ee33fa2ba4a34cb42fbd14b5ec": "Ymultichange(Yparameterchange,Ybodychange)",
    "980e6c54bab4ffc87e168cd5c217fef44c72a878": "Ybodychange",
    "3bf09c51501a23b7fa28fd0a0c4c0965858d026c": "Ybodychange",
    "4525c4a25ba90163c9543116e2bd54239e0dd097": "Ymultichange(Yparameterchange,Ybodychange)",
    "61a262757ca70f30956b467ea8e40e73bf7dc634": "Ybodychange",
    "7ee5ce3176a74d217551b5981f809a56c719424b": "Ybodychange",
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de": "Ybodychange",
    "ad06a087131d69d173d8e03dce5c97650a530f2e": "Ybodychange",
    "bcdb125643d4ec834f6bd5d4fafb079391f31fc6": "Ybodychange",
    "36d1c49486587c2dbb193e8538b1d4510c462fa6": "Ybodychange",
    "71071b904d0c9aec7b3713d41740f24182e81c36": "Ybodychange",
    "b7cd8c0f865e88e40eee75fd2690b1fdc4155071": "Ybodychange",
    "f00198b16c529bafeb8460427f12de69401941c3": "Ybodychange",
    "9992cae54120d2742922745c1f513c6bfbde67a9": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "2892f6d817d74e90ff50073cd3721ed4ec75ba92": "Ybodychange",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "5d5b1c6c10c66c6a17b483a3e1a98d59d3d0bdee": "Ymodifierchange",
    "371f4a59059322000a40eb4bdf5386b96b626ece": "Ybodychange",
    "d68e38b78d9687987c4de2046ce9aa0016685e98": "Ybodychange",
    "c3f6575ca44e8ad803d0b46991472465b595cdeb": "Ybodychange",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "4b95c242eca540455a4d5d0899aaf73b6064b5ea": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14743. Enhance INodeAttributeProvider/ AccessControlEnforcer Interface in HDFS to support Authorization of mkdir, rm, rmdir, copy, move etc... (#1829)\n\nReviewed-by: Xiaoyu Yao \u003cxyao@apache.org\u003e",
      "commitDate": "13/03/20 11:29 AM",
      "commitName": "4b95c242eca540455a4d5d0899aaf73b6064b5ea",
      "commitAuthor": "Wei-Chiu Chuang",
      "commitDateOld": "27/02/20 8:49 AM",
      "commitNameOld": "cd2c6b1aac470991b9b90339ce2721ba179e7c48",
      "commitAuthorOld": "Ayush Saxena",
      "daysBetweenCommits": 15.07,
      "commitsBetweenForRepo": 51,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,43 +1,44 @@\n   LocatedBlock getAdditionalBlock(\n       String src, long fileId, String clientName, ExtendedBlock previous,\n       DatanodeInfo[] excludedNodes, String[] favoredNodes,\n       EnumSet\u003cAddBlockFlag\u003e flags) throws IOException {\n     final String operationName \u003d \"getAdditionalBlock\";\n     NameNode.stateChangeLog.debug(\"BLOCK* getAdditionalBlock: {}  inodeId {}\" +\n         \" for {}\", src, fileId, clientName);\n \n     LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n     FSDirWriteFileOp.ValidateAddBlockResult r;\n     checkOperation(OperationCategory.READ);\n     final FSPermissionChecker pc \u003d getPermissionChecker();\n+    FSPermissionChecker.setOperationType(operationName);\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       r \u003d FSDirWriteFileOp.validateAddBlock(this, pc, src, fileId, clientName,\n                                             previous, onRetryBlock);\n     } finally {\n       readUnlock(operationName);\n     }\n \n     if (r \u003d\u003d null) {\n       assert onRetryBlock[0] !\u003d null : \"Retry block is null\";\n       // This is a retry. Just return the last block.\n       return onRetryBlock[0];\n     }\n \n     DatanodeStorageInfo[] targets \u003d FSDirWriteFileOp.chooseTargetForNewBlock(\n         blockManager, src, excludedNodes, favoredNodes, flags, r);\n \n     checkOperation(OperationCategory.WRITE);\n     writeLock();\n     LocatedBlock lb;\n     try {\n       checkOperation(OperationCategory.WRITE);\n       lb \u003d FSDirWriteFileOp.storeAllocatedBlock(\n           this, src, fileId, clientName, previous, targets);\n     } finally {\n       writeUnlock(operationName);\n     }\n     getEditLog().logSync();\n     return lb;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(\n      String src, long fileId, String clientName, ExtendedBlock previous,\n      DatanodeInfo[] excludedNodes, String[] favoredNodes,\n      EnumSet\u003cAddBlockFlag\u003e flags) throws IOException {\n    final String operationName \u003d \"getAdditionalBlock\";\n    NameNode.stateChangeLog.debug(\"BLOCK* getAdditionalBlock: {}  inodeId {}\" +\n        \" for {}\", src, fileId, clientName);\n\n    LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n    FSDirWriteFileOp.ValidateAddBlockResult r;\n    checkOperation(OperationCategory.READ);\n    final FSPermissionChecker pc \u003d getPermissionChecker();\n    FSPermissionChecker.setOperationType(operationName);\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      r \u003d FSDirWriteFileOp.validateAddBlock(this, pc, src, fileId, clientName,\n                                            previous, onRetryBlock);\n    } finally {\n      readUnlock(operationName);\n    }\n\n    if (r \u003d\u003d null) {\n      assert onRetryBlock[0] !\u003d null : \"Retry block is null\";\n      // This is a retry. Just return the last block.\n      return onRetryBlock[0];\n    }\n\n    DatanodeStorageInfo[] targets \u003d FSDirWriteFileOp.chooseTargetForNewBlock(\n        blockManager, src, excludedNodes, favoredNodes, flags, r);\n\n    checkOperation(OperationCategory.WRITE);\n    writeLock();\n    LocatedBlock lb;\n    try {\n      checkOperation(OperationCategory.WRITE);\n      lb \u003d FSDirWriteFileOp.storeAllocatedBlock(\n          this, src, fileId, clientName, previous, targets);\n    } finally {\n      writeUnlock(operationName);\n    }\n    getEditLog().logSync();\n    return lb;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "84a1321f6aa0af6895564a7c47f8f264656f0294": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13136. Avoid taking FSN lock while doing group member lookup for FSD permission check. Contributed by Xiaoyu Yao.\n",
      "commitDate": "22/02/18 11:32 AM",
      "commitName": "84a1321f6aa0af6895564a7c47f8f264656f0294",
      "commitAuthor": "Xiaoyu Yao",
      "commitDateOld": "15/02/18 1:32 PM",
      "commitNameOld": "47473952e56b0380147d42f4110ad03c2276c961",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 6.92,
      "commitsBetweenForRepo": 36,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,43 +1,43 @@\n   LocatedBlock getAdditionalBlock(\n       String src, long fileId, String clientName, ExtendedBlock previous,\n       DatanodeInfo[] excludedNodes, String[] favoredNodes,\n       EnumSet\u003cAddBlockFlag\u003e flags) throws IOException {\n     final String operationName \u003d \"getAdditionalBlock\";\n     NameNode.stateChangeLog.debug(\"BLOCK* getAdditionalBlock: {}  inodeId {}\" +\n         \" for {}\", src, fileId, clientName);\n \n     LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n     FSDirWriteFileOp.ValidateAddBlockResult r;\n-    FSPermissionChecker pc \u003d getPermissionChecker();\n     checkOperation(OperationCategory.READ);\n+    final FSPermissionChecker pc \u003d getPermissionChecker();\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       r \u003d FSDirWriteFileOp.validateAddBlock(this, pc, src, fileId, clientName,\n                                             previous, onRetryBlock);\n     } finally {\n       readUnlock(operationName);\n     }\n \n     if (r \u003d\u003d null) {\n       assert onRetryBlock[0] !\u003d null : \"Retry block is null\";\n       // This is a retry. Just return the last block.\n       return onRetryBlock[0];\n     }\n \n     DatanodeStorageInfo[] targets \u003d FSDirWriteFileOp.chooseTargetForNewBlock(\n         blockManager, src, excludedNodes, favoredNodes, flags, r);\n \n     checkOperation(OperationCategory.WRITE);\n     writeLock();\n     LocatedBlock lb;\n     try {\n       checkOperation(OperationCategory.WRITE);\n       lb \u003d FSDirWriteFileOp.storeAllocatedBlock(\n           this, src, fileId, clientName, previous, targets);\n     } finally {\n       writeUnlock(operationName);\n     }\n     getEditLog().logSync();\n     return lb;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(\n      String src, long fileId, String clientName, ExtendedBlock previous,\n      DatanodeInfo[] excludedNodes, String[] favoredNodes,\n      EnumSet\u003cAddBlockFlag\u003e flags) throws IOException {\n    final String operationName \u003d \"getAdditionalBlock\";\n    NameNode.stateChangeLog.debug(\"BLOCK* getAdditionalBlock: {}  inodeId {}\" +\n        \" for {}\", src, fileId, clientName);\n\n    LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n    FSDirWriteFileOp.ValidateAddBlockResult r;\n    checkOperation(OperationCategory.READ);\n    final FSPermissionChecker pc \u003d getPermissionChecker();\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      r \u003d FSDirWriteFileOp.validateAddBlock(this, pc, src, fileId, clientName,\n                                            previous, onRetryBlock);\n    } finally {\n      readUnlock(operationName);\n    }\n\n    if (r \u003d\u003d null) {\n      assert onRetryBlock[0] !\u003d null : \"Retry block is null\";\n      // This is a retry. Just return the last block.\n      return onRetryBlock[0];\n    }\n\n    DatanodeStorageInfo[] targets \u003d FSDirWriteFileOp.chooseTargetForNewBlock(\n        blockManager, src, excludedNodes, favoredNodes, flags, r);\n\n    checkOperation(OperationCategory.WRITE);\n    writeLock();\n    LocatedBlock lb;\n    try {\n      checkOperation(OperationCategory.WRITE);\n      lb \u003d FSDirWriteFileOp.storeAllocatedBlock(\n          this, src, fileId, clientName, previous, targets);\n    } finally {\n      writeUnlock(operationName);\n    }\n    getEditLog().logSync();\n    return lb;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "ff0b99eafeda035ebe0dc82cfe689808047a8893": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10872. Add MutableRate metrics for FSNamesystemLock operations. Contributed by Erik Krogen.\n",
      "commitDate": "14/11/16 11:05 AM",
      "commitName": "ff0b99eafeda035ebe0dc82cfe689808047a8893",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "08/11/16 6:17 PM",
      "commitNameOld": "ed0bebabaaf27cd730f7f8eb002d92c9c7db327d",
      "commitAuthorOld": "Brahma Reddy Battula",
      "daysBetweenCommits": 5.7,
      "commitsBetweenForRepo": 36,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,42 +1,43 @@\n   LocatedBlock getAdditionalBlock(\n       String src, long fileId, String clientName, ExtendedBlock previous,\n       DatanodeInfo[] excludedNodes, String[] favoredNodes,\n       EnumSet\u003cAddBlockFlag\u003e flags) throws IOException {\n+    final String operationName \u003d \"getAdditionalBlock\";\n     NameNode.stateChangeLog.debug(\"BLOCK* getAdditionalBlock: {}  inodeId {}\" +\n         \" for {}\", src, fileId, clientName);\n \n     LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n     FSDirWriteFileOp.ValidateAddBlockResult r;\n     FSPermissionChecker pc \u003d getPermissionChecker();\n     checkOperation(OperationCategory.READ);\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       r \u003d FSDirWriteFileOp.validateAddBlock(this, pc, src, fileId, clientName,\n                                             previous, onRetryBlock);\n     } finally {\n-      readUnlock();\n+      readUnlock(operationName);\n     }\n \n     if (r \u003d\u003d null) {\n       assert onRetryBlock[0] !\u003d null : \"Retry block is null\";\n       // This is a retry. Just return the last block.\n       return onRetryBlock[0];\n     }\n \n     DatanodeStorageInfo[] targets \u003d FSDirWriteFileOp.chooseTargetForNewBlock(\n         blockManager, src, excludedNodes, favoredNodes, flags, r);\n \n     checkOperation(OperationCategory.WRITE);\n     writeLock();\n     LocatedBlock lb;\n     try {\n       checkOperation(OperationCategory.WRITE);\n       lb \u003d FSDirWriteFileOp.storeAllocatedBlock(\n           this, src, fileId, clientName, previous, targets);\n     } finally {\n-      writeUnlock();\n+      writeUnlock(operationName);\n     }\n     getEditLog().logSync();\n     return lb;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(\n      String src, long fileId, String clientName, ExtendedBlock previous,\n      DatanodeInfo[] excludedNodes, String[] favoredNodes,\n      EnumSet\u003cAddBlockFlag\u003e flags) throws IOException {\n    final String operationName \u003d \"getAdditionalBlock\";\n    NameNode.stateChangeLog.debug(\"BLOCK* getAdditionalBlock: {}  inodeId {}\" +\n        \" for {}\", src, fileId, clientName);\n\n    LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n    FSDirWriteFileOp.ValidateAddBlockResult r;\n    FSPermissionChecker pc \u003d getPermissionChecker();\n    checkOperation(OperationCategory.READ);\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      r \u003d FSDirWriteFileOp.validateAddBlock(this, pc, src, fileId, clientName,\n                                            previous, onRetryBlock);\n    } finally {\n      readUnlock(operationName);\n    }\n\n    if (r \u003d\u003d null) {\n      assert onRetryBlock[0] !\u003d null : \"Retry block is null\";\n      // This is a retry. Just return the last block.\n      return onRetryBlock[0];\n    }\n\n    DatanodeStorageInfo[] targets \u003d FSDirWriteFileOp.chooseTargetForNewBlock(\n        blockManager, src, excludedNodes, favoredNodes, flags, r);\n\n    checkOperation(OperationCategory.WRITE);\n    writeLock();\n    LocatedBlock lb;\n    try {\n      checkOperation(OperationCategory.WRITE);\n      lb \u003d FSDirWriteFileOp.storeAllocatedBlock(\n          this, src, fileId, clientName, previous, targets);\n    } finally {\n      writeUnlock(operationName);\n    }\n    getEditLog().logSync();\n    return lb;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "0a152103f19a3e8e1b7f33aeb9dd115ba231d7b7": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-3702. Add an option for NOT writing the blocks locally if there is a datanode on the same box as the client. (Contributed by Lei (Eddy) Xu)\n",
      "commitDate": "27/04/16 2:22 PM",
      "commitName": "0a152103f19a3e8e1b7f33aeb9dd115ba231d7b7",
      "commitAuthor": "Lei Xu",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-3702. Add an option for NOT writing the blocks locally if there is a datanode on the same box as the client. (Contributed by Lei (Eddy) Xu)\n",
          "commitDate": "27/04/16 2:22 PM",
          "commitName": "0a152103f19a3e8e1b7f33aeb9dd115ba231d7b7",
          "commitAuthor": "Lei Xu",
          "commitDateOld": "25/04/16 10:01 PM",
          "commitNameOld": "5865fe2bf01284993572ea60b3ec3bf8b4492818",
          "commitAuthorOld": "Zhe Zhang",
          "daysBetweenCommits": 1.68,
          "commitsBetweenForRepo": 18,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,41 +1,42 @@\n   LocatedBlock getAdditionalBlock(\n       String src, long fileId, String clientName, ExtendedBlock previous,\n-      DatanodeInfo[] excludedNodes, String[] favoredNodes) throws IOException {\n+      DatanodeInfo[] excludedNodes, String[] favoredNodes,\n+      EnumSet\u003cAddBlockFlag\u003e flags) throws IOException {\n     NameNode.stateChangeLog.debug(\"BLOCK* getAdditionalBlock: {}  inodeId {}\" +\n         \" for {}\", src, fileId, clientName);\n \n     LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n     FSDirWriteFileOp.ValidateAddBlockResult r;\n     FSPermissionChecker pc \u003d getPermissionChecker();\n     checkOperation(OperationCategory.READ);\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       r \u003d FSDirWriteFileOp.validateAddBlock(this, pc, src, fileId, clientName,\n                                             previous, onRetryBlock);\n     } finally {\n       readUnlock();\n     }\n \n     if (r \u003d\u003d null) {\n       assert onRetryBlock[0] !\u003d null : \"Retry block is null\";\n       // This is a retry. Just return the last block.\n       return onRetryBlock[0];\n     }\n \n     DatanodeStorageInfo[] targets \u003d FSDirWriteFileOp.chooseTargetForNewBlock(\n-        blockManager, src, excludedNodes, favoredNodes, r);\n+        blockManager, src, excludedNodes, favoredNodes, flags, r);\n \n     checkOperation(OperationCategory.WRITE);\n     writeLock();\n     LocatedBlock lb;\n     try {\n       checkOperation(OperationCategory.WRITE);\n       lb \u003d FSDirWriteFileOp.storeAllocatedBlock(\n           this, src, fileId, clientName, previous, targets);\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n     return lb;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  LocatedBlock getAdditionalBlock(\n      String src, long fileId, String clientName, ExtendedBlock previous,\n      DatanodeInfo[] excludedNodes, String[] favoredNodes,\n      EnumSet\u003cAddBlockFlag\u003e flags) throws IOException {\n    NameNode.stateChangeLog.debug(\"BLOCK* getAdditionalBlock: {}  inodeId {}\" +\n        \" for {}\", src, fileId, clientName);\n\n    LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n    FSDirWriteFileOp.ValidateAddBlockResult r;\n    FSPermissionChecker pc \u003d getPermissionChecker();\n    checkOperation(OperationCategory.READ);\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      r \u003d FSDirWriteFileOp.validateAddBlock(this, pc, src, fileId, clientName,\n                                            previous, onRetryBlock);\n    } finally {\n      readUnlock();\n    }\n\n    if (r \u003d\u003d null) {\n      assert onRetryBlock[0] !\u003d null : \"Retry block is null\";\n      // This is a retry. Just return the last block.\n      return onRetryBlock[0];\n    }\n\n    DatanodeStorageInfo[] targets \u003d FSDirWriteFileOp.chooseTargetForNewBlock(\n        blockManager, src, excludedNodes, favoredNodes, flags, r);\n\n    checkOperation(OperationCategory.WRITE);\n    writeLock();\n    LocatedBlock lb;\n    try {\n      checkOperation(OperationCategory.WRITE);\n      lb \u003d FSDirWriteFileOp.storeAllocatedBlock(\n          this, src, fileId, clientName, previous, targets);\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n    return lb;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {
            "oldValue": "[src-String, fileId-long, clientName-String, previous-ExtendedBlock, excludedNodes-DatanodeInfo[], favoredNodes-String[]]",
            "newValue": "[src-String, fileId-long, clientName-String, previous-ExtendedBlock, excludedNodes-DatanodeInfo[], favoredNodes-String[], flags-EnumSet\u003cAddBlockFlag\u003e]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-3702. Add an option for NOT writing the blocks locally if there is a datanode on the same box as the client. (Contributed by Lei (Eddy) Xu)\n",
          "commitDate": "27/04/16 2:22 PM",
          "commitName": "0a152103f19a3e8e1b7f33aeb9dd115ba231d7b7",
          "commitAuthor": "Lei Xu",
          "commitDateOld": "25/04/16 10:01 PM",
          "commitNameOld": "5865fe2bf01284993572ea60b3ec3bf8b4492818",
          "commitAuthorOld": "Zhe Zhang",
          "daysBetweenCommits": 1.68,
          "commitsBetweenForRepo": 18,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,41 +1,42 @@\n   LocatedBlock getAdditionalBlock(\n       String src, long fileId, String clientName, ExtendedBlock previous,\n-      DatanodeInfo[] excludedNodes, String[] favoredNodes) throws IOException {\n+      DatanodeInfo[] excludedNodes, String[] favoredNodes,\n+      EnumSet\u003cAddBlockFlag\u003e flags) throws IOException {\n     NameNode.stateChangeLog.debug(\"BLOCK* getAdditionalBlock: {}  inodeId {}\" +\n         \" for {}\", src, fileId, clientName);\n \n     LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n     FSDirWriteFileOp.ValidateAddBlockResult r;\n     FSPermissionChecker pc \u003d getPermissionChecker();\n     checkOperation(OperationCategory.READ);\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       r \u003d FSDirWriteFileOp.validateAddBlock(this, pc, src, fileId, clientName,\n                                             previous, onRetryBlock);\n     } finally {\n       readUnlock();\n     }\n \n     if (r \u003d\u003d null) {\n       assert onRetryBlock[0] !\u003d null : \"Retry block is null\";\n       // This is a retry. Just return the last block.\n       return onRetryBlock[0];\n     }\n \n     DatanodeStorageInfo[] targets \u003d FSDirWriteFileOp.chooseTargetForNewBlock(\n-        blockManager, src, excludedNodes, favoredNodes, r);\n+        blockManager, src, excludedNodes, favoredNodes, flags, r);\n \n     checkOperation(OperationCategory.WRITE);\n     writeLock();\n     LocatedBlock lb;\n     try {\n       checkOperation(OperationCategory.WRITE);\n       lb \u003d FSDirWriteFileOp.storeAllocatedBlock(\n           this, src, fileId, clientName, previous, targets);\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n     return lb;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  LocatedBlock getAdditionalBlock(\n      String src, long fileId, String clientName, ExtendedBlock previous,\n      DatanodeInfo[] excludedNodes, String[] favoredNodes,\n      EnumSet\u003cAddBlockFlag\u003e flags) throws IOException {\n    NameNode.stateChangeLog.debug(\"BLOCK* getAdditionalBlock: {}  inodeId {}\" +\n        \" for {}\", src, fileId, clientName);\n\n    LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n    FSDirWriteFileOp.ValidateAddBlockResult r;\n    FSPermissionChecker pc \u003d getPermissionChecker();\n    checkOperation(OperationCategory.READ);\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      r \u003d FSDirWriteFileOp.validateAddBlock(this, pc, src, fileId, clientName,\n                                            previous, onRetryBlock);\n    } finally {\n      readUnlock();\n    }\n\n    if (r \u003d\u003d null) {\n      assert onRetryBlock[0] !\u003d null : \"Retry block is null\";\n      // This is a retry. Just return the last block.\n      return onRetryBlock[0];\n    }\n\n    DatanodeStorageInfo[] targets \u003d FSDirWriteFileOp.chooseTargetForNewBlock(\n        blockManager, src, excludedNodes, favoredNodes, flags, r);\n\n    checkOperation(OperationCategory.WRITE);\n    writeLock();\n    LocatedBlock lb;\n    try {\n      checkOperation(OperationCategory.WRITE);\n      lb \u003d FSDirWriteFileOp.storeAllocatedBlock(\n          this, src, fileId, clientName, previous, targets);\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n    return lb;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "3fa33b5c2c289ceaced30c6c5451f3569110459d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9430 Remove waitForLoadingFSImage since checkNNStartup has ensured image loaded and namenode started. (Brahma Reddy Battula via mingma)\n",
      "commitDate": "04/12/15 9:47 AM",
      "commitName": "3fa33b5c2c289ceaced30c6c5451f3569110459d",
      "commitAuthor": "Ming Ma",
      "commitDateOld": "01/12/15 4:09 PM",
      "commitNameOld": "a49cc74b4c72195dee1dfb6f9548e5e411dff553",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 2.74,
      "commitsBetweenForRepo": 13,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,42 +1,41 @@\n   LocatedBlock getAdditionalBlock(\n       String src, long fileId, String clientName, ExtendedBlock previous,\n       DatanodeInfo[] excludedNodes, String[] favoredNodes) throws IOException {\n     NameNode.stateChangeLog.debug(\"BLOCK* getAdditionalBlock: {}  inodeId {}\" +\n         \" for {}\", src, fileId, clientName);\n \n-    waitForLoadingFSImage();\n     LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n     FSDirWriteFileOp.ValidateAddBlockResult r;\n     FSPermissionChecker pc \u003d getPermissionChecker();\n     checkOperation(OperationCategory.READ);\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       r \u003d FSDirWriteFileOp.validateAddBlock(this, pc, src, fileId, clientName,\n                                             previous, onRetryBlock);\n     } finally {\n       readUnlock();\n     }\n \n     if (r \u003d\u003d null) {\n       assert onRetryBlock[0] !\u003d null : \"Retry block is null\";\n       // This is a retry. Just return the last block.\n       return onRetryBlock[0];\n     }\n \n     DatanodeStorageInfo[] targets \u003d FSDirWriteFileOp.chooseTargetForNewBlock(\n         blockManager, src, excludedNodes, favoredNodes, r);\n \n     checkOperation(OperationCategory.WRITE);\n     writeLock();\n     LocatedBlock lb;\n     try {\n       checkOperation(OperationCategory.WRITE);\n       lb \u003d FSDirWriteFileOp.storeAllocatedBlock(\n           this, src, fileId, clientName, previous, targets);\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n     return lb;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(\n      String src, long fileId, String clientName, ExtendedBlock previous,\n      DatanodeInfo[] excludedNodes, String[] favoredNodes) throws IOException {\n    NameNode.stateChangeLog.debug(\"BLOCK* getAdditionalBlock: {}  inodeId {}\" +\n        \" for {}\", src, fileId, clientName);\n\n    LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n    FSDirWriteFileOp.ValidateAddBlockResult r;\n    FSPermissionChecker pc \u003d getPermissionChecker();\n    checkOperation(OperationCategory.READ);\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      r \u003d FSDirWriteFileOp.validateAddBlock(this, pc, src, fileId, clientName,\n                                            previous, onRetryBlock);\n    } finally {\n      readUnlock();\n    }\n\n    if (r \u003d\u003d null) {\n      assert onRetryBlock[0] !\u003d null : \"Retry block is null\";\n      // This is a retry. Just return the last block.\n      return onRetryBlock[0];\n    }\n\n    DatanodeStorageInfo[] targets \u003d FSDirWriteFileOp.chooseTargetForNewBlock(\n        blockManager, src, excludedNodes, favoredNodes, r);\n\n    checkOperation(OperationCategory.WRITE);\n    writeLock();\n    LocatedBlock lb;\n    try {\n      checkOperation(OperationCategory.WRITE);\n      lb \u003d FSDirWriteFileOp.storeAllocatedBlock(\n          this, src, fileId, clientName, previous, targets);\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n    return lb;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "3841d09765bab332c9ae4803c5981799585b1f41": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8522. Change heavily recorded NN logs from INFO to DEBUG level. (Contributed by Xiaoyu Yao)\n",
      "commitDate": "05/06/15 3:09 PM",
      "commitName": "3841d09765bab332c9ae4803c5981799585b1f41",
      "commitAuthor": "Xiaoyu Yao",
      "commitDateOld": "29/05/15 11:05 AM",
      "commitNameOld": "7817674a3a4d097b647dd77f1345787dd376d5ea",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 7.17,
      "commitsBetweenForRepo": 58,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,44 +1,42 @@\n   LocatedBlock getAdditionalBlock(\n       String src, long fileId, String clientName, ExtendedBlock previous,\n       DatanodeInfo[] excludedNodes, String[] favoredNodes) throws IOException {\n-    if(NameNode.stateChangeLog.isDebugEnabled()) {\n-      NameNode.stateChangeLog.debug(\"BLOCK* getAdditionalBlock: \"\n-          + src + \" inodeId \" +  fileId  + \" for \" + clientName);\n-    }\n+    NameNode.stateChangeLog.debug(\"BLOCK* getAdditionalBlock: {}  inodeId {}\" +\n+        \" for {}\", src, fileId, clientName);\n \n     waitForLoadingFSImage();\n     LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n     FSDirWriteFileOp.ValidateAddBlockResult r;\n     FSPermissionChecker pc \u003d getPermissionChecker();\n     checkOperation(OperationCategory.READ);\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       r \u003d FSDirWriteFileOp.validateAddBlock(this, pc, src, fileId, clientName,\n                                             previous, onRetryBlock);\n     } finally {\n       readUnlock();\n     }\n \n     if (r \u003d\u003d null) {\n       assert onRetryBlock[0] !\u003d null : \"Retry block is null\";\n       // This is a retry. Just return the last block.\n       return onRetryBlock[0];\n     }\n \n     DatanodeStorageInfo[] targets \u003d FSDirWriteFileOp.chooseTargetForNewBlock(\n         blockManager, src, excludedNodes, favoredNodes, r);\n \n     checkOperation(OperationCategory.WRITE);\n     writeLock();\n     LocatedBlock lb;\n     try {\n       checkOperation(OperationCategory.WRITE);\n       lb \u003d FSDirWriteFileOp.storeAllocatedBlock(\n           this, src, fileId, clientName, previous, targets);\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n     return lb;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(\n      String src, long fileId, String clientName, ExtendedBlock previous,\n      DatanodeInfo[] excludedNodes, String[] favoredNodes) throws IOException {\n    NameNode.stateChangeLog.debug(\"BLOCK* getAdditionalBlock: {}  inodeId {}\" +\n        \" for {}\", src, fileId, clientName);\n\n    waitForLoadingFSImage();\n    LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n    FSDirWriteFileOp.ValidateAddBlockResult r;\n    FSPermissionChecker pc \u003d getPermissionChecker();\n    checkOperation(OperationCategory.READ);\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      r \u003d FSDirWriteFileOp.validateAddBlock(this, pc, src, fileId, clientName,\n                                            previous, onRetryBlock);\n    } finally {\n      readUnlock();\n    }\n\n    if (r \u003d\u003d null) {\n      assert onRetryBlock[0] !\u003d null : \"Retry block is null\";\n      // This is a retry. Just return the last block.\n      return onRetryBlock[0];\n    }\n\n    DatanodeStorageInfo[] targets \u003d FSDirWriteFileOp.chooseTargetForNewBlock(\n        blockManager, src, excludedNodes, favoredNodes, r);\n\n    checkOperation(OperationCategory.WRITE);\n    writeLock();\n    LocatedBlock lb;\n    try {\n      checkOperation(OperationCategory.WRITE);\n      lb \u003d FSDirWriteFileOp.storeAllocatedBlock(\n          this, src, fileId, clientName, previous, targets);\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n    return lb;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "e5afac5896a1a88e152746598527d91f73cbb724": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-8394. Move getAdditionalBlock() and related functionalities into a separate class. Contributed by Haohui Mai.\n",
      "commitDate": "15/05/15 7:09 PM",
      "commitName": "e5afac5896a1a88e152746598527d91f73cbb724",
      "commitAuthor": "Haohui Mai",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-8394. Move getAdditionalBlock() and related functionalities into a separate class. Contributed by Haohui Mai.\n",
          "commitDate": "15/05/15 7:09 PM",
          "commitName": "e5afac5896a1a88e152746598527d91f73cbb724",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "14/05/15 10:37 PM",
          "commitNameOld": "3bef7c80a97709b367781180b2e11fc50653d3c8",
          "commitAuthorOld": "Vinayakumar B",
          "daysBetweenCommits": 0.86,
          "commitsBetweenForRepo": 5,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,15 +1,44 @@\n-  LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n-      ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n-      List\u003cString\u003e favoredNodes) throws IOException {\n+  LocatedBlock getAdditionalBlock(\n+      String src, long fileId, String clientName, ExtendedBlock previous,\n+      DatanodeInfo[] excludedNodes, String[] favoredNodes) throws IOException {\n+    if(NameNode.stateChangeLog.isDebugEnabled()) {\n+      NameNode.stateChangeLog.debug(\"BLOCK* getAdditionalBlock: \"\n+          + src + \" inodeId \" +  fileId  + \" for \" + clientName);\n+    }\n+\n+    waitForLoadingFSImage();\n     LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n-    DatanodeStorageInfo targets[] \u003d getNewBlockTargets(src, fileId,\n-        clientName, previous, excludedNodes, favoredNodes, onRetryBlock);\n-    if (targets \u003d\u003d null) {\n+    FSDirWriteFileOp.ValidateAddBlockResult r;\n+    FSPermissionChecker pc \u003d getPermissionChecker();\n+    checkOperation(OperationCategory.READ);\n+    readLock();\n+    try {\n+      checkOperation(OperationCategory.READ);\n+      r \u003d FSDirWriteFileOp.validateAddBlock(this, pc, src, fileId, clientName,\n+                                            previous, onRetryBlock);\n+    } finally {\n+      readUnlock();\n+    }\n+\n+    if (r \u003d\u003d null) {\n       assert onRetryBlock[0] !\u003d null : \"Retry block is null\";\n       // This is a retry. Just return the last block.\n       return onRetryBlock[0];\n     }\n-    LocatedBlock newBlock \u003d storeAllocatedBlock(\n-        src, fileId, clientName, previous, targets);\n-    return newBlock;\n+\n+    DatanodeStorageInfo[] targets \u003d FSDirWriteFileOp.chooseTargetForNewBlock(\n+        blockManager, src, excludedNodes, favoredNodes, r);\n+\n+    checkOperation(OperationCategory.WRITE);\n+    writeLock();\n+    LocatedBlock lb;\n+    try {\n+      checkOperation(OperationCategory.WRITE);\n+      lb \u003d FSDirWriteFileOp.storeAllocatedBlock(\n+          this, src, fileId, clientName, previous, targets);\n+    } finally {\n+      writeUnlock();\n+    }\n+    getEditLog().logSync();\n+    return lb;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  LocatedBlock getAdditionalBlock(\n      String src, long fileId, String clientName, ExtendedBlock previous,\n      DatanodeInfo[] excludedNodes, String[] favoredNodes) throws IOException {\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\"BLOCK* getAdditionalBlock: \"\n          + src + \" inodeId \" +  fileId  + \" for \" + clientName);\n    }\n\n    waitForLoadingFSImage();\n    LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n    FSDirWriteFileOp.ValidateAddBlockResult r;\n    FSPermissionChecker pc \u003d getPermissionChecker();\n    checkOperation(OperationCategory.READ);\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      r \u003d FSDirWriteFileOp.validateAddBlock(this, pc, src, fileId, clientName,\n                                            previous, onRetryBlock);\n    } finally {\n      readUnlock();\n    }\n\n    if (r \u003d\u003d null) {\n      assert onRetryBlock[0] !\u003d null : \"Retry block is null\";\n      // This is a retry. Just return the last block.\n      return onRetryBlock[0];\n    }\n\n    DatanodeStorageInfo[] targets \u003d FSDirWriteFileOp.chooseTargetForNewBlock(\n        blockManager, src, excludedNodes, favoredNodes, r);\n\n    checkOperation(OperationCategory.WRITE);\n    writeLock();\n    LocatedBlock lb;\n    try {\n      checkOperation(OperationCategory.WRITE);\n      lb \u003d FSDirWriteFileOp.storeAllocatedBlock(\n          this, src, fileId, clientName, previous, targets);\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n    return lb;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {
            "oldValue": "[src-String, fileId-long, clientName-String, previous-ExtendedBlock, excludedNodes-Set\u003cNode\u003e, favoredNodes-List\u003cString\u003e]",
            "newValue": "[src-String, fileId-long, clientName-String, previous-ExtendedBlock, excludedNodes-DatanodeInfo[], favoredNodes-String[]]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-8394. Move getAdditionalBlock() and related functionalities into a separate class. Contributed by Haohui Mai.\n",
          "commitDate": "15/05/15 7:09 PM",
          "commitName": "e5afac5896a1a88e152746598527d91f73cbb724",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "14/05/15 10:37 PM",
          "commitNameOld": "3bef7c80a97709b367781180b2e11fc50653d3c8",
          "commitAuthorOld": "Vinayakumar B",
          "daysBetweenCommits": 0.86,
          "commitsBetweenForRepo": 5,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,15 +1,44 @@\n-  LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n-      ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n-      List\u003cString\u003e favoredNodes) throws IOException {\n+  LocatedBlock getAdditionalBlock(\n+      String src, long fileId, String clientName, ExtendedBlock previous,\n+      DatanodeInfo[] excludedNodes, String[] favoredNodes) throws IOException {\n+    if(NameNode.stateChangeLog.isDebugEnabled()) {\n+      NameNode.stateChangeLog.debug(\"BLOCK* getAdditionalBlock: \"\n+          + src + \" inodeId \" +  fileId  + \" for \" + clientName);\n+    }\n+\n+    waitForLoadingFSImage();\n     LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n-    DatanodeStorageInfo targets[] \u003d getNewBlockTargets(src, fileId,\n-        clientName, previous, excludedNodes, favoredNodes, onRetryBlock);\n-    if (targets \u003d\u003d null) {\n+    FSDirWriteFileOp.ValidateAddBlockResult r;\n+    FSPermissionChecker pc \u003d getPermissionChecker();\n+    checkOperation(OperationCategory.READ);\n+    readLock();\n+    try {\n+      checkOperation(OperationCategory.READ);\n+      r \u003d FSDirWriteFileOp.validateAddBlock(this, pc, src, fileId, clientName,\n+                                            previous, onRetryBlock);\n+    } finally {\n+      readUnlock();\n+    }\n+\n+    if (r \u003d\u003d null) {\n       assert onRetryBlock[0] !\u003d null : \"Retry block is null\";\n       // This is a retry. Just return the last block.\n       return onRetryBlock[0];\n     }\n-    LocatedBlock newBlock \u003d storeAllocatedBlock(\n-        src, fileId, clientName, previous, targets);\n-    return newBlock;\n+\n+    DatanodeStorageInfo[] targets \u003d FSDirWriteFileOp.chooseTargetForNewBlock(\n+        blockManager, src, excludedNodes, favoredNodes, r);\n+\n+    checkOperation(OperationCategory.WRITE);\n+    writeLock();\n+    LocatedBlock lb;\n+    try {\n+      checkOperation(OperationCategory.WRITE);\n+      lb \u003d FSDirWriteFileOp.storeAllocatedBlock(\n+          this, src, fileId, clientName, previous, targets);\n+    } finally {\n+      writeUnlock();\n+    }\n+    getEditLog().logSync();\n+    return lb;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  LocatedBlock getAdditionalBlock(\n      String src, long fileId, String clientName, ExtendedBlock previous,\n      DatanodeInfo[] excludedNodes, String[] favoredNodes) throws IOException {\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\"BLOCK* getAdditionalBlock: \"\n          + src + \" inodeId \" +  fileId  + \" for \" + clientName);\n    }\n\n    waitForLoadingFSImage();\n    LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n    FSDirWriteFileOp.ValidateAddBlockResult r;\n    FSPermissionChecker pc \u003d getPermissionChecker();\n    checkOperation(OperationCategory.READ);\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      r \u003d FSDirWriteFileOp.validateAddBlock(this, pc, src, fileId, clientName,\n                                            previous, onRetryBlock);\n    } finally {\n      readUnlock();\n    }\n\n    if (r \u003d\u003d null) {\n      assert onRetryBlock[0] !\u003d null : \"Retry block is null\";\n      // This is a retry. Just return the last block.\n      return onRetryBlock[0];\n    }\n\n    DatanodeStorageInfo[] targets \u003d FSDirWriteFileOp.chooseTargetForNewBlock(\n        blockManager, src, excludedNodes, favoredNodes, r);\n\n    checkOperation(OperationCategory.WRITE);\n    writeLock();\n    LocatedBlock lb;\n    try {\n      checkOperation(OperationCategory.WRITE);\n      lb \u003d FSDirWriteFileOp.storeAllocatedBlock(\n          this, src, fileId, clientName, previous, targets);\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n    return lb;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "0959b67f1a189b4a99752904115efbd471f1d6d7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8081. Split getAdditionalBlock() into two methods. Contributed by Konstantin Shvachko",
      "commitDate": "09/04/15 10:00 PM",
      "commitName": "0959b67f1a189b4a99752904115efbd471f1d6d7",
      "commitAuthor": "Konstantin V Shvachko",
      "commitDateOld": "06/04/15 10:20 PM",
      "commitNameOld": "75c545486080042952c775f7964212c15ce65f73",
      "commitAuthorOld": "Konstantin V Shvachko",
      "daysBetweenCommits": 2.99,
      "commitsBetweenForRepo": 43,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,112 +1,15 @@\n   LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n       ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n       List\u003cString\u003e favoredNodes) throws IOException {\n-    final long blockSize;\n-    final int replication;\n-    final byte storagePolicyID;\n-    Node clientNode \u003d null;\n-    String clientMachine \u003d null;\n-\n-    if(NameNode.stateChangeLog.isDebugEnabled()) {\n-      NameNode.stateChangeLog.debug(\"BLOCK* getAdditionalBlock: \"\n-          + src + \" inodeId \" +  fileId  + \" for \" + clientName);\n+    LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n+    DatanodeStorageInfo targets[] \u003d getNewBlockTargets(src, fileId,\n+        clientName, previous, excludedNodes, favoredNodes, onRetryBlock);\n+    if (targets \u003d\u003d null) {\n+      assert onRetryBlock[0] !\u003d null : \"Retry block is null\";\n+      // This is a retry. Just return the last block.\n+      return onRetryBlock[0];\n     }\n-\n-    // Part I. Analyze the state of the file with respect to the input data.\n-    checkOperation(OperationCategory.READ);\n-    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n-    FSPermissionChecker pc \u003d getPermissionChecker();\n-    readLock();\n-    try {\n-      checkOperation(OperationCategory.READ);\n-      src \u003d dir.resolvePath(pc, src, pathComponents);\n-      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n-      FileState fileState \u003d analyzeFileState(\n-          src, fileId, clientName, previous, onRetryBlock);\n-      final INodeFile pendingFile \u003d fileState.inode;\n-      // Check if the penultimate block is minimally replicated\n-      if (!checkFileProgress(src, pendingFile, false)) {\n-        throw new NotReplicatedYetException(\"Not replicated yet: \" + src);\n-      }\n-      src \u003d fileState.path;\n-\n-      if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n-        // This is a retry. Just return the last block if having locations.\n-        return onRetryBlock[0];\n-      }\n-      if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n-        throw new IOException(\"File has reached the limit on maximum number of\"\n-            + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n-            + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n-            + maxBlocksPerFile);\n-      }\n-      blockSize \u003d pendingFile.getPreferredBlockSize();\n-      clientMachine \u003d pendingFile.getFileUnderConstructionFeature()\n-          .getClientMachine();\n-      clientNode \u003d blockManager.getDatanodeManager().getDatanodeByHost(\n-          clientMachine);\n-      replication \u003d pendingFile.getFileReplication();\n-      storagePolicyID \u003d pendingFile.getStoragePolicyID();\n-    } finally {\n-      readUnlock();\n-    }\n-\n-    if (clientNode \u003d\u003d null) {\n-      clientNode \u003d getClientNode(clientMachine);\n-    }\n-\n-    // choose targets for the new block to be allocated.\n-    final DatanodeStorageInfo targets[] \u003d getBlockManager().chooseTarget4NewBlock( \n-        src, replication, clientNode, excludedNodes, blockSize, favoredNodes,\n-        storagePolicyID);\n-\n-    // Part II.\n-    // Allocate a new block, add it to the INode and the BlocksMap. \n-    Block newBlock \u003d null;\n-    long offset;\n-    checkOperation(OperationCategory.WRITE);\n-    waitForLoadingFSImage();\n-    writeLock();\n-    try {\n-      checkOperation(OperationCategory.WRITE);\n-      // Run the full analysis again, since things could have changed\n-      // while chooseTarget() was executing.\n-      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n-      FileState fileState \u003d \n-          analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n-      final INodeFile pendingFile \u003d fileState.inode;\n-      src \u003d fileState.path;\n-\n-      if (onRetryBlock[0] !\u003d null) {\n-        if (onRetryBlock[0].getLocations().length \u003e 0) {\n-          // This is a retry. Just return the last block if having locations.\n-          return onRetryBlock[0];\n-        } else {\n-          // add new chosen targets to already allocated block and return\n-          BlockInfoContiguous lastBlockInFile \u003d pendingFile.getLastBlock();\n-          ((BlockInfoContiguousUnderConstruction) lastBlockInFile)\n-              .setExpectedLocations(targets);\n-          offset \u003d pendingFile.computeFileSize();\n-          return makeLocatedBlock(lastBlockInFile, targets, offset);\n-        }\n-      }\n-\n-      // commit the last block and complete it if it has minimum replicas\n-      commitOrCompleteLastBlock(pendingFile, fileState.iip,\n-                                ExtendedBlock.getLocalBlock(previous));\n-\n-      // allocate new block, record block locations in INode.\n-      newBlock \u003d createNewBlock();\n-      INodesInPath inodesInPath \u003d INodesInPath.fromINode(pendingFile);\n-      saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n-\n-      persistNewBlock(src, pendingFile);\n-      offset \u003d pendingFile.computeFileSize();\n-    } finally {\n-      writeUnlock();\n-    }\n-    getEditLog().logSync();\n-\n-    // Return located block\n-    return makeLocatedBlock(newBlock, targets, offset);\n+    LocatedBlock newBlock \u003d storeAllocatedBlock(\n+        src, fileId, clientName, previous, targets);\n+    return newBlock;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n      ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n      List\u003cString\u003e favoredNodes) throws IOException {\n    LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n    DatanodeStorageInfo targets[] \u003d getNewBlockTargets(src, fileId,\n        clientName, previous, excludedNodes, favoredNodes, onRetryBlock);\n    if (targets \u003d\u003d null) {\n      assert onRetryBlock[0] !\u003d null : \"Retry block is null\";\n      // This is a retry. Just return the last block.\n      return onRetryBlock[0];\n    }\n    LocatedBlock newBlock \u003d storeAllocatedBlock(\n        src, fileId, clientName, previous, targets);\n    return newBlock;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "75c545486080042952c775f7964212c15ce65f73": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8071. Redundant checkFileProgress() in PART II of getAdditionalBlock(). Contributed by Konstantin Shvachko.",
      "commitDate": "06/04/15 10:20 PM",
      "commitName": "75c545486080042952c775f7964212c15ce65f73",
      "commitAuthor": "Konstantin V Shvachko",
      "commitDateOld": "02/04/15 11:36 AM",
      "commitNameOld": "96649c38f9ab00a9845d2c6e35e6264894da5309",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 4.45,
      "commitsBetweenForRepo": 23,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,108 +1,112 @@\n   LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n       ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n       List\u003cString\u003e favoredNodes) throws IOException {\n     final long blockSize;\n     final int replication;\n     final byte storagePolicyID;\n     Node clientNode \u003d null;\n     String clientMachine \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\"BLOCK* getAdditionalBlock: \"\n           + src + \" inodeId \" +  fileId  + \" for \" + clientName);\n     }\n \n     // Part I. Analyze the state of the file with respect to the input data.\n     checkOperation(OperationCategory.READ);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     FSPermissionChecker pc \u003d getPermissionChecker();\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       src \u003d dir.resolvePath(pc, src, pathComponents);\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       FileState fileState \u003d analyzeFileState(\n           src, fileId, clientName, previous, onRetryBlock);\n       final INodeFile pendingFile \u003d fileState.inode;\n+      // Check if the penultimate block is minimally replicated\n+      if (!checkFileProgress(src, pendingFile, false)) {\n+        throw new NotReplicatedYetException(\"Not replicated yet: \" + src);\n+      }\n       src \u003d fileState.path;\n \n       if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n         // This is a retry. Just return the last block if having locations.\n         return onRetryBlock[0];\n       }\n       if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n         throw new IOException(\"File has reached the limit on maximum number of\"\n             + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n             + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n             + maxBlocksPerFile);\n       }\n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientMachine \u003d pendingFile.getFileUnderConstructionFeature()\n           .getClientMachine();\n       clientNode \u003d blockManager.getDatanodeManager().getDatanodeByHost(\n           clientMachine);\n       replication \u003d pendingFile.getFileReplication();\n       storagePolicyID \u003d pendingFile.getStoragePolicyID();\n     } finally {\n       readUnlock();\n     }\n \n     if (clientNode \u003d\u003d null) {\n       clientNode \u003d getClientNode(clientMachine);\n     }\n \n     // choose targets for the new block to be allocated.\n     final DatanodeStorageInfo targets[] \u003d getBlockManager().chooseTarget4NewBlock( \n         src, replication, clientNode, excludedNodes, blockSize, favoredNodes,\n         storagePolicyID);\n \n     // Part II.\n     // Allocate a new block, add it to the INode and the BlocksMap. \n     Block newBlock \u003d null;\n     long offset;\n     checkOperation(OperationCategory.WRITE);\n     waitForLoadingFSImage();\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       // Run the full analysis again, since things could have changed\n       // while chooseTarget() was executing.\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       FileState fileState \u003d \n           analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n       final INodeFile pendingFile \u003d fileState.inode;\n       src \u003d fileState.path;\n \n       if (onRetryBlock[0] !\u003d null) {\n         if (onRetryBlock[0].getLocations().length \u003e 0) {\n           // This is a retry. Just return the last block if having locations.\n           return onRetryBlock[0];\n         } else {\n           // add new chosen targets to already allocated block and return\n           BlockInfoContiguous lastBlockInFile \u003d pendingFile.getLastBlock();\n           ((BlockInfoContiguousUnderConstruction) lastBlockInFile)\n               .setExpectedLocations(targets);\n           offset \u003d pendingFile.computeFileSize();\n           return makeLocatedBlock(lastBlockInFile, targets, offset);\n         }\n       }\n \n       // commit the last block and complete it if it has minimum replicas\n       commitOrCompleteLastBlock(pendingFile, fileState.iip,\n                                 ExtendedBlock.getLocalBlock(previous));\n \n       // allocate new block, record block locations in INode.\n       newBlock \u003d createNewBlock();\n       INodesInPath inodesInPath \u003d INodesInPath.fromINode(pendingFile);\n       saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n \n       persistNewBlock(src, pendingFile);\n       offset \u003d pendingFile.computeFileSize();\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n \n     // Return located block\n     return makeLocatedBlock(newBlock, targets, offset);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n      ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n      List\u003cString\u003e favoredNodes) throws IOException {\n    final long blockSize;\n    final int replication;\n    final byte storagePolicyID;\n    Node clientNode \u003d null;\n    String clientMachine \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\"BLOCK* getAdditionalBlock: \"\n          + src + \" inodeId \" +  fileId  + \" for \" + clientName);\n    }\n\n    // Part I. Analyze the state of the file with respect to the input data.\n    checkOperation(OperationCategory.READ);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    FSPermissionChecker pc \u003d getPermissionChecker();\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      src \u003d dir.resolvePath(pc, src, pathComponents);\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      FileState fileState \u003d analyzeFileState(\n          src, fileId, clientName, previous, onRetryBlock);\n      final INodeFile pendingFile \u003d fileState.inode;\n      // Check if the penultimate block is minimally replicated\n      if (!checkFileProgress(src, pendingFile, false)) {\n        throw new NotReplicatedYetException(\"Not replicated yet: \" + src);\n      }\n      src \u003d fileState.path;\n\n      if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n        // This is a retry. Just return the last block if having locations.\n        return onRetryBlock[0];\n      }\n      if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n        throw new IOException(\"File has reached the limit on maximum number of\"\n            + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n            + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n            + maxBlocksPerFile);\n      }\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientMachine \u003d pendingFile.getFileUnderConstructionFeature()\n          .getClientMachine();\n      clientNode \u003d blockManager.getDatanodeManager().getDatanodeByHost(\n          clientMachine);\n      replication \u003d pendingFile.getFileReplication();\n      storagePolicyID \u003d pendingFile.getStoragePolicyID();\n    } finally {\n      readUnlock();\n    }\n\n    if (clientNode \u003d\u003d null) {\n      clientNode \u003d getClientNode(clientMachine);\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeStorageInfo targets[] \u003d getBlockManager().chooseTarget4NewBlock( \n        src, replication, clientNode, excludedNodes, blockSize, favoredNodes,\n        storagePolicyID);\n\n    // Part II.\n    // Allocate a new block, add it to the INode and the BlocksMap. \n    Block newBlock \u003d null;\n    long offset;\n    checkOperation(OperationCategory.WRITE);\n    waitForLoadingFSImage();\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      // Run the full analysis again, since things could have changed\n      // while chooseTarget() was executing.\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      FileState fileState \u003d \n          analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n      final INodeFile pendingFile \u003d fileState.inode;\n      src \u003d fileState.path;\n\n      if (onRetryBlock[0] !\u003d null) {\n        if (onRetryBlock[0].getLocations().length \u003e 0) {\n          // This is a retry. Just return the last block if having locations.\n          return onRetryBlock[0];\n        } else {\n          // add new chosen targets to already allocated block and return\n          BlockInfoContiguous lastBlockInFile \u003d pendingFile.getLastBlock();\n          ((BlockInfoContiguousUnderConstruction) lastBlockInFile)\n              .setExpectedLocations(targets);\n          offset \u003d pendingFile.computeFileSize();\n          return makeLocatedBlock(lastBlockInFile, targets, offset);\n        }\n      }\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile, fileState.iip,\n                                ExtendedBlock.getLocalBlock(previous));\n\n      // allocate new block, record block locations in INode.\n      newBlock \u003d createNewBlock();\n      INodesInPath inodesInPath \u003d INodesInPath.fromINode(pendingFile);\n      saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n\n      persistNewBlock(src, pendingFile);\n      offset \u003d pendingFile.computeFileSize();\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n\n    // Return located block\n    return makeLocatedBlock(newBlock, targets, offset);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7743. Code cleanup of BlockInfo and rename BlockInfo to BlockInfoContiguous. Contributed by Jing Zhao.\n",
      "commitDate": "08/02/15 11:51 AM",
      "commitName": "1382ae525c67bf95d8f3a436b547dbc72cfbb177",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "07/02/15 3:21 PM",
      "commitNameOld": "8f7d4bb09f760780dd193c97796ebf4d22cfd2d7",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 0.85,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,108 +1,108 @@\n   LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n       ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n       List\u003cString\u003e favoredNodes) throws IOException {\n     final long blockSize;\n     final int replication;\n     final byte storagePolicyID;\n     Node clientNode \u003d null;\n     String clientMachine \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\"BLOCK* getAdditionalBlock: \"\n           + src + \" inodeId \" +  fileId  + \" for \" + clientName);\n     }\n \n     // Part I. Analyze the state of the file with respect to the input data.\n     checkOperation(OperationCategory.READ);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     FSPermissionChecker pc \u003d getPermissionChecker();\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       src \u003d dir.resolvePath(pc, src, pathComponents);\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       FileState fileState \u003d analyzeFileState(\n           src, fileId, clientName, previous, onRetryBlock);\n       final INodeFile pendingFile \u003d fileState.inode;\n       src \u003d fileState.path;\n \n       if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n         // This is a retry. Just return the last block if having locations.\n         return onRetryBlock[0];\n       }\n       if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n         throw new IOException(\"File has reached the limit on maximum number of\"\n             + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n             + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n             + maxBlocksPerFile);\n       }\n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientMachine \u003d pendingFile.getFileUnderConstructionFeature()\n           .getClientMachine();\n       clientNode \u003d blockManager.getDatanodeManager().getDatanodeByHost(\n           clientMachine);\n       replication \u003d pendingFile.getFileReplication();\n       storagePolicyID \u003d pendingFile.getStoragePolicyID();\n     } finally {\n       readUnlock();\n     }\n \n     if (clientNode \u003d\u003d null) {\n       clientNode \u003d getClientNode(clientMachine);\n     }\n \n     // choose targets for the new block to be allocated.\n     final DatanodeStorageInfo targets[] \u003d getBlockManager().chooseTarget4NewBlock( \n         src, replication, clientNode, excludedNodes, blockSize, favoredNodes,\n         storagePolicyID);\n \n     // Part II.\n     // Allocate a new block, add it to the INode and the BlocksMap. \n     Block newBlock \u003d null;\n     long offset;\n     checkOperation(OperationCategory.WRITE);\n     waitForLoadingFSImage();\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       // Run the full analysis again, since things could have changed\n       // while chooseTarget() was executing.\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       FileState fileState \u003d \n           analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n       final INodeFile pendingFile \u003d fileState.inode;\n       src \u003d fileState.path;\n \n       if (onRetryBlock[0] !\u003d null) {\n         if (onRetryBlock[0].getLocations().length \u003e 0) {\n           // This is a retry. Just return the last block if having locations.\n           return onRetryBlock[0];\n         } else {\n           // add new chosen targets to already allocated block and return\n-          BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n-          ((BlockInfoUnderConstruction) lastBlockInFile)\n+          BlockInfoContiguous lastBlockInFile \u003d pendingFile.getLastBlock();\n+          ((BlockInfoContiguousUnderConstruction) lastBlockInFile)\n               .setExpectedLocations(targets);\n           offset \u003d pendingFile.computeFileSize();\n           return makeLocatedBlock(lastBlockInFile, targets, offset);\n         }\n       }\n \n       // commit the last block and complete it if it has minimum replicas\n       commitOrCompleteLastBlock(pendingFile, fileState.iip,\n                                 ExtendedBlock.getLocalBlock(previous));\n \n       // allocate new block, record block locations in INode.\n       newBlock \u003d createNewBlock();\n       INodesInPath inodesInPath \u003d INodesInPath.fromINode(pendingFile);\n       saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n \n       persistNewBlock(src, pendingFile);\n       offset \u003d pendingFile.computeFileSize();\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n \n     // Return located block\n     return makeLocatedBlock(newBlock, targets, offset);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n      ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n      List\u003cString\u003e favoredNodes) throws IOException {\n    final long blockSize;\n    final int replication;\n    final byte storagePolicyID;\n    Node clientNode \u003d null;\n    String clientMachine \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\"BLOCK* getAdditionalBlock: \"\n          + src + \" inodeId \" +  fileId  + \" for \" + clientName);\n    }\n\n    // Part I. Analyze the state of the file with respect to the input data.\n    checkOperation(OperationCategory.READ);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    FSPermissionChecker pc \u003d getPermissionChecker();\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      src \u003d dir.resolvePath(pc, src, pathComponents);\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      FileState fileState \u003d analyzeFileState(\n          src, fileId, clientName, previous, onRetryBlock);\n      final INodeFile pendingFile \u003d fileState.inode;\n      src \u003d fileState.path;\n\n      if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n        // This is a retry. Just return the last block if having locations.\n        return onRetryBlock[0];\n      }\n      if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n        throw new IOException(\"File has reached the limit on maximum number of\"\n            + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n            + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n            + maxBlocksPerFile);\n      }\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientMachine \u003d pendingFile.getFileUnderConstructionFeature()\n          .getClientMachine();\n      clientNode \u003d blockManager.getDatanodeManager().getDatanodeByHost(\n          clientMachine);\n      replication \u003d pendingFile.getFileReplication();\n      storagePolicyID \u003d pendingFile.getStoragePolicyID();\n    } finally {\n      readUnlock();\n    }\n\n    if (clientNode \u003d\u003d null) {\n      clientNode \u003d getClientNode(clientMachine);\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeStorageInfo targets[] \u003d getBlockManager().chooseTarget4NewBlock( \n        src, replication, clientNode, excludedNodes, blockSize, favoredNodes,\n        storagePolicyID);\n\n    // Part II.\n    // Allocate a new block, add it to the INode and the BlocksMap. \n    Block newBlock \u003d null;\n    long offset;\n    checkOperation(OperationCategory.WRITE);\n    waitForLoadingFSImage();\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      // Run the full analysis again, since things could have changed\n      // while chooseTarget() was executing.\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      FileState fileState \u003d \n          analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n      final INodeFile pendingFile \u003d fileState.inode;\n      src \u003d fileState.path;\n\n      if (onRetryBlock[0] !\u003d null) {\n        if (onRetryBlock[0].getLocations().length \u003e 0) {\n          // This is a retry. Just return the last block if having locations.\n          return onRetryBlock[0];\n        } else {\n          // add new chosen targets to already allocated block and return\n          BlockInfoContiguous lastBlockInFile \u003d pendingFile.getLastBlock();\n          ((BlockInfoContiguousUnderConstruction) lastBlockInFile)\n              .setExpectedLocations(targets);\n          offset \u003d pendingFile.computeFileSize();\n          return makeLocatedBlock(lastBlockInFile, targets, offset);\n        }\n      }\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile, fileState.iip,\n                                ExtendedBlock.getLocalBlock(previous));\n\n      // allocate new block, record block locations in INode.\n      newBlock \u003d createNewBlock();\n      INodesInPath inodesInPath \u003d INodesInPath.fromINode(pendingFile);\n      saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n\n      persistNewBlock(src, pendingFile);\n      offset \u003d pendingFile.computeFileSize();\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n\n    // Return located block\n    return makeLocatedBlock(newBlock, targets, offset);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "c78e3a7cdd10c40454e9acb06986ba6d8573cb19": {
      "type": "Ymultichange(Yexceptionschange,Ybodychange)",
      "commitMessage": "HDFS-7059. Avoid resolving path multiple times. Contributed by Jing Zhao.\n",
      "commitDate": "12/12/14 3:13 PM",
      "commitName": "c78e3a7cdd10c40454e9acb06986ba6d8573cb19",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yexceptionschange",
          "commitMessage": "HDFS-7059. Avoid resolving path multiple times. Contributed by Jing Zhao.\n",
          "commitDate": "12/12/14 3:13 PM",
          "commitName": "c78e3a7cdd10c40454e9acb06986ba6d8573cb19",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "12/12/14 11:51 AM",
          "commitNameOld": "46612c7a5135d20b20403780b47dd00654aab057",
          "commitAuthorOld": "Haohui Mai",
          "daysBetweenCommits": 0.14,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,111 +1,108 @@\n   LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n       ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n-      List\u003cString\u003e favoredNodes)\n-      throws LeaseExpiredException, NotReplicatedYetException,\n-      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n-      IOException {\n+      List\u003cString\u003e favoredNodes) throws IOException {\n     final long blockSize;\n     final int replication;\n     final byte storagePolicyID;\n     Node clientNode \u003d null;\n     String clientMachine \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\"BLOCK* getAdditionalBlock: \"\n           + src + \" inodeId \" +  fileId  + \" for \" + clientName);\n     }\n \n     // Part I. Analyze the state of the file with respect to the input data.\n     checkOperation(OperationCategory.READ);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     FSPermissionChecker pc \u003d getPermissionChecker();\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       src \u003d dir.resolvePath(pc, src, pathComponents);\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       FileState fileState \u003d analyzeFileState(\n           src, fileId, clientName, previous, onRetryBlock);\n       final INodeFile pendingFile \u003d fileState.inode;\n       src \u003d fileState.path;\n \n       if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n         // This is a retry. Just return the last block if having locations.\n         return onRetryBlock[0];\n       }\n       if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n         throw new IOException(\"File has reached the limit on maximum number of\"\n             + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n             + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n             + maxBlocksPerFile);\n       }\n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientMachine \u003d pendingFile.getFileUnderConstructionFeature()\n           .getClientMachine();\n       clientNode \u003d blockManager.getDatanodeManager().getDatanodeByHost(\n           clientMachine);\n       replication \u003d pendingFile.getFileReplication();\n       storagePolicyID \u003d pendingFile.getStoragePolicyID();\n     } finally {\n       readUnlock();\n     }\n \n     if (clientNode \u003d\u003d null) {\n       clientNode \u003d getClientNode(clientMachine);\n     }\n \n     // choose targets for the new block to be allocated.\n     final DatanodeStorageInfo targets[] \u003d getBlockManager().chooseTarget4NewBlock( \n         src, replication, clientNode, excludedNodes, blockSize, favoredNodes,\n         storagePolicyID);\n \n     // Part II.\n     // Allocate a new block, add it to the INode and the BlocksMap. \n     Block newBlock \u003d null;\n     long offset;\n     checkOperation(OperationCategory.WRITE);\n     waitForLoadingFSImage();\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       // Run the full analysis again, since things could have changed\n       // while chooseTarget() was executing.\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       FileState fileState \u003d \n           analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n       final INodeFile pendingFile \u003d fileState.inode;\n       src \u003d fileState.path;\n \n       if (onRetryBlock[0] !\u003d null) {\n         if (onRetryBlock[0].getLocations().length \u003e 0) {\n           // This is a retry. Just return the last block if having locations.\n           return onRetryBlock[0];\n         } else {\n           // add new chosen targets to already allocated block and return\n           BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n           ((BlockInfoUnderConstruction) lastBlockInFile)\n               .setExpectedLocations(targets);\n           offset \u003d pendingFile.computeFileSize();\n           return makeLocatedBlock(lastBlockInFile, targets, offset);\n         }\n       }\n \n       // commit the last block and complete it if it has minimum replicas\n-      commitOrCompleteLastBlock(pendingFile,\n+      commitOrCompleteLastBlock(pendingFile, fileState.iip,\n                                 ExtendedBlock.getLocalBlock(previous));\n \n       // allocate new block, record block locations in INode.\n       newBlock \u003d createNewBlock();\n       INodesInPath inodesInPath \u003d INodesInPath.fromINode(pendingFile);\n       saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n \n       persistNewBlock(src, pendingFile);\n       offset \u003d pendingFile.computeFileSize();\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n \n     // Return located block\n     return makeLocatedBlock(newBlock, targets, offset);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n      ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n      List\u003cString\u003e favoredNodes) throws IOException {\n    final long blockSize;\n    final int replication;\n    final byte storagePolicyID;\n    Node clientNode \u003d null;\n    String clientMachine \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\"BLOCK* getAdditionalBlock: \"\n          + src + \" inodeId \" +  fileId  + \" for \" + clientName);\n    }\n\n    // Part I. Analyze the state of the file with respect to the input data.\n    checkOperation(OperationCategory.READ);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    FSPermissionChecker pc \u003d getPermissionChecker();\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      src \u003d dir.resolvePath(pc, src, pathComponents);\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      FileState fileState \u003d analyzeFileState(\n          src, fileId, clientName, previous, onRetryBlock);\n      final INodeFile pendingFile \u003d fileState.inode;\n      src \u003d fileState.path;\n\n      if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n        // This is a retry. Just return the last block if having locations.\n        return onRetryBlock[0];\n      }\n      if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n        throw new IOException(\"File has reached the limit on maximum number of\"\n            + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n            + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n            + maxBlocksPerFile);\n      }\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientMachine \u003d pendingFile.getFileUnderConstructionFeature()\n          .getClientMachine();\n      clientNode \u003d blockManager.getDatanodeManager().getDatanodeByHost(\n          clientMachine);\n      replication \u003d pendingFile.getFileReplication();\n      storagePolicyID \u003d pendingFile.getStoragePolicyID();\n    } finally {\n      readUnlock();\n    }\n\n    if (clientNode \u003d\u003d null) {\n      clientNode \u003d getClientNode(clientMachine);\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeStorageInfo targets[] \u003d getBlockManager().chooseTarget4NewBlock( \n        src, replication, clientNode, excludedNodes, blockSize, favoredNodes,\n        storagePolicyID);\n\n    // Part II.\n    // Allocate a new block, add it to the INode and the BlocksMap. \n    Block newBlock \u003d null;\n    long offset;\n    checkOperation(OperationCategory.WRITE);\n    waitForLoadingFSImage();\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      // Run the full analysis again, since things could have changed\n      // while chooseTarget() was executing.\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      FileState fileState \u003d \n          analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n      final INodeFile pendingFile \u003d fileState.inode;\n      src \u003d fileState.path;\n\n      if (onRetryBlock[0] !\u003d null) {\n        if (onRetryBlock[0].getLocations().length \u003e 0) {\n          // This is a retry. Just return the last block if having locations.\n          return onRetryBlock[0];\n        } else {\n          // add new chosen targets to already allocated block and return\n          BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n          ((BlockInfoUnderConstruction) lastBlockInFile)\n              .setExpectedLocations(targets);\n          offset \u003d pendingFile.computeFileSize();\n          return makeLocatedBlock(lastBlockInFile, targets, offset);\n        }\n      }\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile, fileState.iip,\n                                ExtendedBlock.getLocalBlock(previous));\n\n      // allocate new block, record block locations in INode.\n      newBlock \u003d createNewBlock();\n      INodesInPath inodesInPath \u003d INodesInPath.fromINode(pendingFile);\n      saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n\n      persistNewBlock(src, pendingFile);\n      offset \u003d pendingFile.computeFileSize();\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n\n    // Return located block\n    return makeLocatedBlock(newBlock, targets, offset);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {
            "oldValue": "[LeaseExpiredException, NotReplicatedYetException, QuotaExceededException, SafeModeException, UnresolvedLinkException, IOException]",
            "newValue": "[IOException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7059. Avoid resolving path multiple times. Contributed by Jing Zhao.\n",
          "commitDate": "12/12/14 3:13 PM",
          "commitName": "c78e3a7cdd10c40454e9acb06986ba6d8573cb19",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "12/12/14 11:51 AM",
          "commitNameOld": "46612c7a5135d20b20403780b47dd00654aab057",
          "commitAuthorOld": "Haohui Mai",
          "daysBetweenCommits": 0.14,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,111 +1,108 @@\n   LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n       ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n-      List\u003cString\u003e favoredNodes)\n-      throws LeaseExpiredException, NotReplicatedYetException,\n-      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n-      IOException {\n+      List\u003cString\u003e favoredNodes) throws IOException {\n     final long blockSize;\n     final int replication;\n     final byte storagePolicyID;\n     Node clientNode \u003d null;\n     String clientMachine \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\"BLOCK* getAdditionalBlock: \"\n           + src + \" inodeId \" +  fileId  + \" for \" + clientName);\n     }\n \n     // Part I. Analyze the state of the file with respect to the input data.\n     checkOperation(OperationCategory.READ);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     FSPermissionChecker pc \u003d getPermissionChecker();\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       src \u003d dir.resolvePath(pc, src, pathComponents);\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       FileState fileState \u003d analyzeFileState(\n           src, fileId, clientName, previous, onRetryBlock);\n       final INodeFile pendingFile \u003d fileState.inode;\n       src \u003d fileState.path;\n \n       if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n         // This is a retry. Just return the last block if having locations.\n         return onRetryBlock[0];\n       }\n       if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n         throw new IOException(\"File has reached the limit on maximum number of\"\n             + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n             + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n             + maxBlocksPerFile);\n       }\n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientMachine \u003d pendingFile.getFileUnderConstructionFeature()\n           .getClientMachine();\n       clientNode \u003d blockManager.getDatanodeManager().getDatanodeByHost(\n           clientMachine);\n       replication \u003d pendingFile.getFileReplication();\n       storagePolicyID \u003d pendingFile.getStoragePolicyID();\n     } finally {\n       readUnlock();\n     }\n \n     if (clientNode \u003d\u003d null) {\n       clientNode \u003d getClientNode(clientMachine);\n     }\n \n     // choose targets for the new block to be allocated.\n     final DatanodeStorageInfo targets[] \u003d getBlockManager().chooseTarget4NewBlock( \n         src, replication, clientNode, excludedNodes, blockSize, favoredNodes,\n         storagePolicyID);\n \n     // Part II.\n     // Allocate a new block, add it to the INode and the BlocksMap. \n     Block newBlock \u003d null;\n     long offset;\n     checkOperation(OperationCategory.WRITE);\n     waitForLoadingFSImage();\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       // Run the full analysis again, since things could have changed\n       // while chooseTarget() was executing.\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       FileState fileState \u003d \n           analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n       final INodeFile pendingFile \u003d fileState.inode;\n       src \u003d fileState.path;\n \n       if (onRetryBlock[0] !\u003d null) {\n         if (onRetryBlock[0].getLocations().length \u003e 0) {\n           // This is a retry. Just return the last block if having locations.\n           return onRetryBlock[0];\n         } else {\n           // add new chosen targets to already allocated block and return\n           BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n           ((BlockInfoUnderConstruction) lastBlockInFile)\n               .setExpectedLocations(targets);\n           offset \u003d pendingFile.computeFileSize();\n           return makeLocatedBlock(lastBlockInFile, targets, offset);\n         }\n       }\n \n       // commit the last block and complete it if it has minimum replicas\n-      commitOrCompleteLastBlock(pendingFile,\n+      commitOrCompleteLastBlock(pendingFile, fileState.iip,\n                                 ExtendedBlock.getLocalBlock(previous));\n \n       // allocate new block, record block locations in INode.\n       newBlock \u003d createNewBlock();\n       INodesInPath inodesInPath \u003d INodesInPath.fromINode(pendingFile);\n       saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n \n       persistNewBlock(src, pendingFile);\n       offset \u003d pendingFile.computeFileSize();\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n \n     // Return located block\n     return makeLocatedBlock(newBlock, targets, offset);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n      ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n      List\u003cString\u003e favoredNodes) throws IOException {\n    final long blockSize;\n    final int replication;\n    final byte storagePolicyID;\n    Node clientNode \u003d null;\n    String clientMachine \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\"BLOCK* getAdditionalBlock: \"\n          + src + \" inodeId \" +  fileId  + \" for \" + clientName);\n    }\n\n    // Part I. Analyze the state of the file with respect to the input data.\n    checkOperation(OperationCategory.READ);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    FSPermissionChecker pc \u003d getPermissionChecker();\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      src \u003d dir.resolvePath(pc, src, pathComponents);\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      FileState fileState \u003d analyzeFileState(\n          src, fileId, clientName, previous, onRetryBlock);\n      final INodeFile pendingFile \u003d fileState.inode;\n      src \u003d fileState.path;\n\n      if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n        // This is a retry. Just return the last block if having locations.\n        return onRetryBlock[0];\n      }\n      if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n        throw new IOException(\"File has reached the limit on maximum number of\"\n            + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n            + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n            + maxBlocksPerFile);\n      }\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientMachine \u003d pendingFile.getFileUnderConstructionFeature()\n          .getClientMachine();\n      clientNode \u003d blockManager.getDatanodeManager().getDatanodeByHost(\n          clientMachine);\n      replication \u003d pendingFile.getFileReplication();\n      storagePolicyID \u003d pendingFile.getStoragePolicyID();\n    } finally {\n      readUnlock();\n    }\n\n    if (clientNode \u003d\u003d null) {\n      clientNode \u003d getClientNode(clientMachine);\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeStorageInfo targets[] \u003d getBlockManager().chooseTarget4NewBlock( \n        src, replication, clientNode, excludedNodes, blockSize, favoredNodes,\n        storagePolicyID);\n\n    // Part II.\n    // Allocate a new block, add it to the INode and the BlocksMap. \n    Block newBlock \u003d null;\n    long offset;\n    checkOperation(OperationCategory.WRITE);\n    waitForLoadingFSImage();\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      // Run the full analysis again, since things could have changed\n      // while chooseTarget() was executing.\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      FileState fileState \u003d \n          analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n      final INodeFile pendingFile \u003d fileState.inode;\n      src \u003d fileState.path;\n\n      if (onRetryBlock[0] !\u003d null) {\n        if (onRetryBlock[0].getLocations().length \u003e 0) {\n          // This is a retry. Just return the last block if having locations.\n          return onRetryBlock[0];\n        } else {\n          // add new chosen targets to already allocated block and return\n          BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n          ((BlockInfoUnderConstruction) lastBlockInFile)\n              .setExpectedLocations(targets);\n          offset \u003d pendingFile.computeFileSize();\n          return makeLocatedBlock(lastBlockInFile, targets, offset);\n        }\n      }\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile, fileState.iip,\n                                ExtendedBlock.getLocalBlock(previous));\n\n      // allocate new block, record block locations in INode.\n      newBlock \u003d createNewBlock();\n      INodesInPath inodesInPath \u003d INodesInPath.fromINode(pendingFile);\n      saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n\n      persistNewBlock(src, pendingFile);\n      offset \u003d pendingFile.computeFileSize();\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n\n    // Return located block\n    return makeLocatedBlock(newBlock, targets, offset);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "c95b878abf313507666ea018f9e6033c4c166e10": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7415. Move FSNameSystem.resolvePath() to FSDirectory. Contributed by Haohui Mai.\n",
      "commitDate": "20/11/14 7:23 PM",
      "commitName": "c95b878abf313507666ea018f9e6033c4c166e10",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "17/11/14 5:33 PM",
      "commitNameOld": "dcb8e24427b02e2f3ff9a12d2eb1eb878e3443bb",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 3.08,
      "commitsBetweenForRepo": 22,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,110 +1,111 @@\n   LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n       ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n       List\u003cString\u003e favoredNodes)\n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n     final long blockSize;\n     final int replication;\n     final byte storagePolicyID;\n     Node clientNode \u003d null;\n     String clientMachine \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\"BLOCK* getAdditionalBlock: \"\n           + src + \" inodeId \" +  fileId  + \" for \" + clientName);\n     }\n \n     // Part I. Analyze the state of the file with respect to the input data.\n     checkOperation(OperationCategory.READ);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n+    FSPermissionChecker pc \u003d getPermissionChecker();\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n-      src \u003d resolvePath(src, pathComponents);\n+      src \u003d dir.resolvePath(pc, src, pathComponents);\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       FileState fileState \u003d analyzeFileState(\n           src, fileId, clientName, previous, onRetryBlock);\n       final INodeFile pendingFile \u003d fileState.inode;\n       src \u003d fileState.path;\n \n       if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n         // This is a retry. Just return the last block if having locations.\n         return onRetryBlock[0];\n       }\n       if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n         throw new IOException(\"File has reached the limit on maximum number of\"\n             + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n             + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n             + maxBlocksPerFile);\n       }\n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientMachine \u003d pendingFile.getFileUnderConstructionFeature()\n           .getClientMachine();\n       clientNode \u003d blockManager.getDatanodeManager().getDatanodeByHost(\n           clientMachine);\n       replication \u003d pendingFile.getFileReplication();\n       storagePolicyID \u003d pendingFile.getStoragePolicyID();\n     } finally {\n       readUnlock();\n     }\n \n     if (clientNode \u003d\u003d null) {\n       clientNode \u003d getClientNode(clientMachine);\n     }\n \n     // choose targets for the new block to be allocated.\n     final DatanodeStorageInfo targets[] \u003d getBlockManager().chooseTarget4NewBlock( \n         src, replication, clientNode, excludedNodes, blockSize, favoredNodes,\n         storagePolicyID);\n \n     // Part II.\n     // Allocate a new block, add it to the INode and the BlocksMap. \n     Block newBlock \u003d null;\n     long offset;\n     checkOperation(OperationCategory.WRITE);\n     waitForLoadingFSImage();\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       // Run the full analysis again, since things could have changed\n       // while chooseTarget() was executing.\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       FileState fileState \u003d \n           analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n       final INodeFile pendingFile \u003d fileState.inode;\n       src \u003d fileState.path;\n \n       if (onRetryBlock[0] !\u003d null) {\n         if (onRetryBlock[0].getLocations().length \u003e 0) {\n           // This is a retry. Just return the last block if having locations.\n           return onRetryBlock[0];\n         } else {\n           // add new chosen targets to already allocated block and return\n           BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n           ((BlockInfoUnderConstruction) lastBlockInFile)\n               .setExpectedLocations(targets);\n           offset \u003d pendingFile.computeFileSize();\n           return makeLocatedBlock(lastBlockInFile, targets, offset);\n         }\n       }\n \n       // commit the last block and complete it if it has minimum replicas\n       commitOrCompleteLastBlock(pendingFile,\n                                 ExtendedBlock.getLocalBlock(previous));\n \n       // allocate new block, record block locations in INode.\n       newBlock \u003d createNewBlock();\n       INodesInPath inodesInPath \u003d INodesInPath.fromINode(pendingFile);\n       saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n \n       persistNewBlock(src, pendingFile);\n       offset \u003d pendingFile.computeFileSize();\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n \n     // Return located block\n     return makeLocatedBlock(newBlock, targets, offset);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n      ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n      List\u003cString\u003e favoredNodes)\n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    final long blockSize;\n    final int replication;\n    final byte storagePolicyID;\n    Node clientNode \u003d null;\n    String clientMachine \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\"BLOCK* getAdditionalBlock: \"\n          + src + \" inodeId \" +  fileId  + \" for \" + clientName);\n    }\n\n    // Part I. Analyze the state of the file with respect to the input data.\n    checkOperation(OperationCategory.READ);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    FSPermissionChecker pc \u003d getPermissionChecker();\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      src \u003d dir.resolvePath(pc, src, pathComponents);\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      FileState fileState \u003d analyzeFileState(\n          src, fileId, clientName, previous, onRetryBlock);\n      final INodeFile pendingFile \u003d fileState.inode;\n      src \u003d fileState.path;\n\n      if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n        // This is a retry. Just return the last block if having locations.\n        return onRetryBlock[0];\n      }\n      if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n        throw new IOException(\"File has reached the limit on maximum number of\"\n            + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n            + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n            + maxBlocksPerFile);\n      }\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientMachine \u003d pendingFile.getFileUnderConstructionFeature()\n          .getClientMachine();\n      clientNode \u003d blockManager.getDatanodeManager().getDatanodeByHost(\n          clientMachine);\n      replication \u003d pendingFile.getFileReplication();\n      storagePolicyID \u003d pendingFile.getStoragePolicyID();\n    } finally {\n      readUnlock();\n    }\n\n    if (clientNode \u003d\u003d null) {\n      clientNode \u003d getClientNode(clientMachine);\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeStorageInfo targets[] \u003d getBlockManager().chooseTarget4NewBlock( \n        src, replication, clientNode, excludedNodes, blockSize, favoredNodes,\n        storagePolicyID);\n\n    // Part II.\n    // Allocate a new block, add it to the INode and the BlocksMap. \n    Block newBlock \u003d null;\n    long offset;\n    checkOperation(OperationCategory.WRITE);\n    waitForLoadingFSImage();\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      // Run the full analysis again, since things could have changed\n      // while chooseTarget() was executing.\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      FileState fileState \u003d \n          analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n      final INodeFile pendingFile \u003d fileState.inode;\n      src \u003d fileState.path;\n\n      if (onRetryBlock[0] !\u003d null) {\n        if (onRetryBlock[0].getLocations().length \u003e 0) {\n          // This is a retry. Just return the last block if having locations.\n          return onRetryBlock[0];\n        } else {\n          // add new chosen targets to already allocated block and return\n          BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n          ((BlockInfoUnderConstruction) lastBlockInFile)\n              .setExpectedLocations(targets);\n          offset \u003d pendingFile.computeFileSize();\n          return makeLocatedBlock(lastBlockInFile, targets, offset);\n        }\n      }\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile,\n                                ExtendedBlock.getLocalBlock(previous));\n\n      // allocate new block, record block locations in INode.\n      newBlock \u003d createNewBlock();\n      INodesInPath inodesInPath \u003d INodesInPath.fromINode(pendingFile);\n      saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n\n      persistNewBlock(src, pendingFile);\n      offset \u003d pendingFile.computeFileSize();\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n\n    // Return located block\n    return makeLocatedBlock(newBlock, targets, offset);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "18312804e9c86c0ea6a259e288994fea6fa366ef": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7357. FSNamesystem.checkFileProgress should log file path. Contributed by Tsz Wo Nicholas Sze.\n",
      "commitDate": "05/11/14 10:14 AM",
      "commitName": "18312804e9c86c0ea6a259e288994fea6fa366ef",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "05/11/14 9:32 AM",
      "commitNameOld": "6e8722e49c29a19dd13e161001d2464bb1f22189",
      "commitAuthorOld": "Konstantin V Shvachko",
      "daysBetweenCommits": 0.03,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,110 +1,110 @@\n   LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n       ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n       List\u003cString\u003e favoredNodes)\n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n     final long blockSize;\n     final int replication;\n     final byte storagePolicyID;\n     Node clientNode \u003d null;\n     String clientMachine \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n-      NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.getAdditionalBlock: \"\n+      NameNode.stateChangeLog.debug(\"BLOCK* getAdditionalBlock: \"\n           + src + \" inodeId \" +  fileId  + \" for \" + clientName);\n     }\n \n     // Part I. Analyze the state of the file with respect to the input data.\n     checkOperation(OperationCategory.READ);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       src \u003d resolvePath(src, pathComponents);\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       FileState fileState \u003d analyzeFileState(\n           src, fileId, clientName, previous, onRetryBlock);\n       final INodeFile pendingFile \u003d fileState.inode;\n       src \u003d fileState.path;\n \n       if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n         // This is a retry. Just return the last block if having locations.\n         return onRetryBlock[0];\n       }\n       if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n         throw new IOException(\"File has reached the limit on maximum number of\"\n             + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n             + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n             + maxBlocksPerFile);\n       }\n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientMachine \u003d pendingFile.getFileUnderConstructionFeature()\n           .getClientMachine();\n       clientNode \u003d blockManager.getDatanodeManager().getDatanodeByHost(\n           clientMachine);\n       replication \u003d pendingFile.getFileReplication();\n       storagePolicyID \u003d pendingFile.getStoragePolicyID();\n     } finally {\n       readUnlock();\n     }\n \n     if (clientNode \u003d\u003d null) {\n       clientNode \u003d getClientNode(clientMachine);\n     }\n \n     // choose targets for the new block to be allocated.\n     final DatanodeStorageInfo targets[] \u003d getBlockManager().chooseTarget4NewBlock( \n         src, replication, clientNode, excludedNodes, blockSize, favoredNodes,\n         storagePolicyID);\n \n     // Part II.\n     // Allocate a new block, add it to the INode and the BlocksMap. \n     Block newBlock \u003d null;\n     long offset;\n     checkOperation(OperationCategory.WRITE);\n     waitForLoadingFSImage();\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       // Run the full analysis again, since things could have changed\n       // while chooseTarget() was executing.\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       FileState fileState \u003d \n           analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n       final INodeFile pendingFile \u003d fileState.inode;\n       src \u003d fileState.path;\n \n       if (onRetryBlock[0] !\u003d null) {\n         if (onRetryBlock[0].getLocations().length \u003e 0) {\n           // This is a retry. Just return the last block if having locations.\n           return onRetryBlock[0];\n         } else {\n           // add new chosen targets to already allocated block and return\n           BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n           ((BlockInfoUnderConstruction) lastBlockInFile)\n               .setExpectedLocations(targets);\n           offset \u003d pendingFile.computeFileSize();\n           return makeLocatedBlock(lastBlockInFile, targets, offset);\n         }\n       }\n \n       // commit the last block and complete it if it has minimum replicas\n       commitOrCompleteLastBlock(pendingFile,\n                                 ExtendedBlock.getLocalBlock(previous));\n \n       // allocate new block, record block locations in INode.\n       newBlock \u003d createNewBlock();\n       INodesInPath inodesInPath \u003d INodesInPath.fromINode(pendingFile);\n       saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n \n       persistNewBlock(src, pendingFile);\n       offset \u003d pendingFile.computeFileSize();\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n \n     // Return located block\n     return makeLocatedBlock(newBlock, targets, offset);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n      ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n      List\u003cString\u003e favoredNodes)\n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    final long blockSize;\n    final int replication;\n    final byte storagePolicyID;\n    Node clientNode \u003d null;\n    String clientMachine \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\"BLOCK* getAdditionalBlock: \"\n          + src + \" inodeId \" +  fileId  + \" for \" + clientName);\n    }\n\n    // Part I. Analyze the state of the file with respect to the input data.\n    checkOperation(OperationCategory.READ);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      src \u003d resolvePath(src, pathComponents);\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      FileState fileState \u003d analyzeFileState(\n          src, fileId, clientName, previous, onRetryBlock);\n      final INodeFile pendingFile \u003d fileState.inode;\n      src \u003d fileState.path;\n\n      if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n        // This is a retry. Just return the last block if having locations.\n        return onRetryBlock[0];\n      }\n      if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n        throw new IOException(\"File has reached the limit on maximum number of\"\n            + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n            + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n            + maxBlocksPerFile);\n      }\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientMachine \u003d pendingFile.getFileUnderConstructionFeature()\n          .getClientMachine();\n      clientNode \u003d blockManager.getDatanodeManager().getDatanodeByHost(\n          clientMachine);\n      replication \u003d pendingFile.getFileReplication();\n      storagePolicyID \u003d pendingFile.getStoragePolicyID();\n    } finally {\n      readUnlock();\n    }\n\n    if (clientNode \u003d\u003d null) {\n      clientNode \u003d getClientNode(clientMachine);\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeStorageInfo targets[] \u003d getBlockManager().chooseTarget4NewBlock( \n        src, replication, clientNode, excludedNodes, blockSize, favoredNodes,\n        storagePolicyID);\n\n    // Part II.\n    // Allocate a new block, add it to the INode and the BlocksMap. \n    Block newBlock \u003d null;\n    long offset;\n    checkOperation(OperationCategory.WRITE);\n    waitForLoadingFSImage();\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      // Run the full analysis again, since things could have changed\n      // while chooseTarget() was executing.\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      FileState fileState \u003d \n          analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n      final INodeFile pendingFile \u003d fileState.inode;\n      src \u003d fileState.path;\n\n      if (onRetryBlock[0] !\u003d null) {\n        if (onRetryBlock[0].getLocations().length \u003e 0) {\n          // This is a retry. Just return the last block if having locations.\n          return onRetryBlock[0];\n        } else {\n          // add new chosen targets to already allocated block and return\n          BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n          ((BlockInfoUnderConstruction) lastBlockInFile)\n              .setExpectedLocations(targets);\n          offset \u003d pendingFile.computeFileSize();\n          return makeLocatedBlock(lastBlockInFile, targets, offset);\n        }\n      }\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile,\n                                ExtendedBlock.getLocalBlock(previous));\n\n      // allocate new block, record block locations in INode.\n      newBlock \u003d createNewBlock();\n      INodesInPath inodesInPath \u003d INodesInPath.fromINode(pendingFile);\n      saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n\n      persistNewBlock(src, pendingFile);\n      offset \u003d pendingFile.computeFileSize();\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n\n    // Return located block\n    return makeLocatedBlock(newBlock, targets, offset);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "ed841dd9a96e54cb84d9cae5507e47ff1c8cdf6e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6995. Block should be placed in the client\u0027s \u0027rack-local\u0027 node if \u0027client-local\u0027 node is not available (vinayakumarb)\n",
      "commitDate": "06/10/14 2:01 AM",
      "commitName": "ed841dd9a96e54cb84d9cae5507e47ff1c8cdf6e",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "30/09/14 6:25 PM",
      "commitNameOld": "a45ad330facc56f06ed42eb71304c49ef56dc549",
      "commitAuthorOld": "arp",
      "daysBetweenCommits": 5.32,
      "commitsBetweenForRepo": 47,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,103 +1,110 @@\n   LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n       ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n       List\u003cString\u003e favoredNodes)\n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n     final long blockSize;\n     final int replication;\n     final byte storagePolicyID;\n-    DatanodeDescriptor clientNode \u003d null;\n+    Node clientNode \u003d null;\n+    String clientMachine \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.getAdditionalBlock: \"\n           + src + \" inodeId \" +  fileId  + \" for \" + clientName);\n     }\n \n     // Part I. Analyze the state of the file with respect to the input data.\n     checkOperation(OperationCategory.READ);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       src \u003d resolvePath(src, pathComponents);\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       FileState fileState \u003d analyzeFileState(\n           src, fileId, clientName, previous, onRetryBlock);\n       final INodeFile pendingFile \u003d fileState.inode;\n       src \u003d fileState.path;\n \n       if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n         // This is a retry. Just return the last block if having locations.\n         return onRetryBlock[0];\n       }\n       if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n         throw new IOException(\"File has reached the limit on maximum number of\"\n             + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n             + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n             + maxBlocksPerFile);\n       }\n       blockSize \u003d pendingFile.getPreferredBlockSize();\n+      clientMachine \u003d pendingFile.getFileUnderConstructionFeature()\n+          .getClientMachine();\n       clientNode \u003d blockManager.getDatanodeManager().getDatanodeByHost(\n-              pendingFile.getFileUnderConstructionFeature().getClientMachine());\n+          clientMachine);\n       replication \u003d pendingFile.getFileReplication();\n       storagePolicyID \u003d pendingFile.getStoragePolicyID();\n     } finally {\n       readUnlock();\n     }\n \n+    if (clientNode \u003d\u003d null) {\n+      clientNode \u003d getClientNode(clientMachine);\n+    }\n+\n     // choose targets for the new block to be allocated.\n     final DatanodeStorageInfo targets[] \u003d getBlockManager().chooseTarget4NewBlock( \n         src, replication, clientNode, excludedNodes, blockSize, favoredNodes,\n         storagePolicyID);\n \n     // Part II.\n     // Allocate a new block, add it to the INode and the BlocksMap. \n     Block newBlock \u003d null;\n     long offset;\n     checkOperation(OperationCategory.WRITE);\n     waitForLoadingFSImage();\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       // Run the full analysis again, since things could have changed\n       // while chooseTarget() was executing.\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       FileState fileState \u003d \n           analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n       final INodeFile pendingFile \u003d fileState.inode;\n       src \u003d fileState.path;\n \n       if (onRetryBlock[0] !\u003d null) {\n         if (onRetryBlock[0].getLocations().length \u003e 0) {\n           // This is a retry. Just return the last block if having locations.\n           return onRetryBlock[0];\n         } else {\n           // add new chosen targets to already allocated block and return\n           BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n           ((BlockInfoUnderConstruction) lastBlockInFile)\n               .setExpectedLocations(targets);\n           offset \u003d pendingFile.computeFileSize();\n           return makeLocatedBlock(lastBlockInFile, targets, offset);\n         }\n       }\n \n       // commit the last block and complete it if it has minimum replicas\n       commitOrCompleteLastBlock(pendingFile,\n                                 ExtendedBlock.getLocalBlock(previous));\n \n       // allocate new block, record block locations in INode.\n       newBlock \u003d createNewBlock();\n       INodesInPath inodesInPath \u003d INodesInPath.fromINode(pendingFile);\n       saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n \n       persistNewBlock(src, pendingFile);\n       offset \u003d pendingFile.computeFileSize();\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n \n     // Return located block\n     return makeLocatedBlock(newBlock, targets, offset);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n      ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n      List\u003cString\u003e favoredNodes)\n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    final long blockSize;\n    final int replication;\n    final byte storagePolicyID;\n    Node clientNode \u003d null;\n    String clientMachine \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.getAdditionalBlock: \"\n          + src + \" inodeId \" +  fileId  + \" for \" + clientName);\n    }\n\n    // Part I. Analyze the state of the file with respect to the input data.\n    checkOperation(OperationCategory.READ);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      src \u003d resolvePath(src, pathComponents);\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      FileState fileState \u003d analyzeFileState(\n          src, fileId, clientName, previous, onRetryBlock);\n      final INodeFile pendingFile \u003d fileState.inode;\n      src \u003d fileState.path;\n\n      if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n        // This is a retry. Just return the last block if having locations.\n        return onRetryBlock[0];\n      }\n      if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n        throw new IOException(\"File has reached the limit on maximum number of\"\n            + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n            + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n            + maxBlocksPerFile);\n      }\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientMachine \u003d pendingFile.getFileUnderConstructionFeature()\n          .getClientMachine();\n      clientNode \u003d blockManager.getDatanodeManager().getDatanodeByHost(\n          clientMachine);\n      replication \u003d pendingFile.getFileReplication();\n      storagePolicyID \u003d pendingFile.getStoragePolicyID();\n    } finally {\n      readUnlock();\n    }\n\n    if (clientNode \u003d\u003d null) {\n      clientNode \u003d getClientNode(clientMachine);\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeStorageInfo targets[] \u003d getBlockManager().chooseTarget4NewBlock( \n        src, replication, clientNode, excludedNodes, blockSize, favoredNodes,\n        storagePolicyID);\n\n    // Part II.\n    // Allocate a new block, add it to the INode and the BlocksMap. \n    Block newBlock \u003d null;\n    long offset;\n    checkOperation(OperationCategory.WRITE);\n    waitForLoadingFSImage();\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      // Run the full analysis again, since things could have changed\n      // while chooseTarget() was executing.\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      FileState fileState \u003d \n          analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n      final INodeFile pendingFile \u003d fileState.inode;\n      src \u003d fileState.path;\n\n      if (onRetryBlock[0] !\u003d null) {\n        if (onRetryBlock[0].getLocations().length \u003e 0) {\n          // This is a retry. Just return the last block if having locations.\n          return onRetryBlock[0];\n        } else {\n          // add new chosen targets to already allocated block and return\n          BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n          ((BlockInfoUnderConstruction) lastBlockInFile)\n              .setExpectedLocations(targets);\n          offset \u003d pendingFile.computeFileSize();\n          return makeLocatedBlock(lastBlockInFile, targets, offset);\n        }\n      }\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile,\n                                ExtendedBlock.getLocalBlock(previous));\n\n      // allocate new block, record block locations in INode.\n      newBlock \u003d createNewBlock();\n      INodesInPath inodesInPath \u003d INodesInPath.fromINode(pendingFile);\n      saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n\n      persistNewBlock(src, pendingFile);\n      offset \u003d pendingFile.computeFileSize();\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n\n    // Return located block\n    return makeLocatedBlock(newBlock, targets, offset);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "407bb3d3e452c8277c498dd14e0cc5b7762a7091": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6509. Create a special /.reserved/raw directory for raw access to encrypted data. Contributed by Charles Lamb.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/fs-encryption@1614490 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/07/14 2:11 PM",
      "commitName": "407bb3d3e452c8277c498dd14e0cc5b7762a7091",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "27/07/14 6:32 AM",
      "commitNameOld": "1d3e9ec935de0e5bcb6fda0b88fa69d9e9ce6595",
      "commitAuthorOld": "",
      "daysBetweenCommits": 2.32,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,100 +1,100 @@\n   LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n       ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n       List\u003cString\u003e favoredNodes)\n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n     long blockSize;\n     int replication;\n     DatanodeDescriptor clientNode \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.getAdditionalBlock: \"\n           + src + \" inodeId \" +  fileId  + \" for \" + clientName);\n     }\n \n     // Part I. Analyze the state of the file with respect to the input data.\n     checkOperation(OperationCategory.READ);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n-      src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n+      src \u003d resolvePath(src, pathComponents);\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       FileState fileState \u003d analyzeFileState(\n           src, fileId, clientName, previous, onRetryBlock);\n       final INodeFile pendingFile \u003d fileState.inode;\n       src \u003d fileState.path;\n \n       if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n         // This is a retry. Just return the last block if having locations.\n         return onRetryBlock[0];\n       }\n       if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n         throw new IOException(\"File has reached the limit on maximum number of\"\n             + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n             + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n             + maxBlocksPerFile);\n       }\n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientNode \u003d blockManager.getDatanodeManager().getDatanodeByHost(\n               pendingFile.getFileUnderConstructionFeature().getClientMachine());\n       replication \u003d pendingFile.getFileReplication();\n     } finally {\n       readUnlock();\n     }\n \n     // choose targets for the new block to be allocated.\n     final DatanodeStorageInfo targets[] \u003d getBlockManager().chooseTarget( \n         src, replication, clientNode, excludedNodes, blockSize, favoredNodes);\n \n     // Part II.\n     // Allocate a new block, add it to the INode and the BlocksMap. \n     Block newBlock \u003d null;\n     long offset;\n     checkOperation(OperationCategory.WRITE);\n     waitForLoadingFSImage();\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       // Run the full analysis again, since things could have changed\n       // while chooseTarget() was executing.\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       FileState fileState \u003d \n           analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n       final INodeFile pendingFile \u003d fileState.inode;\n       src \u003d fileState.path;\n \n       if (onRetryBlock[0] !\u003d null) {\n         if (onRetryBlock[0].getLocations().length \u003e 0) {\n           // This is a retry. Just return the last block if having locations.\n           return onRetryBlock[0];\n         } else {\n           // add new chosen targets to already allocated block and return\n           BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n           ((BlockInfoUnderConstruction) lastBlockInFile)\n               .setExpectedLocations(targets);\n           offset \u003d pendingFile.computeFileSize();\n           return makeLocatedBlock(lastBlockInFile, targets, offset);\n         }\n       }\n \n       // commit the last block and complete it if it has minimum replicas\n       commitOrCompleteLastBlock(pendingFile,\n                                 ExtendedBlock.getLocalBlock(previous));\n \n       // allocate new block, record block locations in INode.\n       newBlock \u003d createNewBlock();\n       INodesInPath inodesInPath \u003d INodesInPath.fromINode(pendingFile);\n       saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n \n       persistNewBlock(src, pendingFile);\n       offset \u003d pendingFile.computeFileSize();\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n \n     // Return located block\n     return makeLocatedBlock(newBlock, targets, offset);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n      ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n      List\u003cString\u003e favoredNodes)\n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    long blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.getAdditionalBlock: \"\n          + src + \" inodeId \" +  fileId  + \" for \" + clientName);\n    }\n\n    // Part I. Analyze the state of the file with respect to the input data.\n    checkOperation(OperationCategory.READ);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      src \u003d resolvePath(src, pathComponents);\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      FileState fileState \u003d analyzeFileState(\n          src, fileId, clientName, previous, onRetryBlock);\n      final INodeFile pendingFile \u003d fileState.inode;\n      src \u003d fileState.path;\n\n      if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n        // This is a retry. Just return the last block if having locations.\n        return onRetryBlock[0];\n      }\n      if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n        throw new IOException(\"File has reached the limit on maximum number of\"\n            + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n            + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n            + maxBlocksPerFile);\n      }\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d blockManager.getDatanodeManager().getDatanodeByHost(\n              pendingFile.getFileUnderConstructionFeature().getClientMachine());\n      replication \u003d pendingFile.getFileReplication();\n    } finally {\n      readUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeStorageInfo targets[] \u003d getBlockManager().chooseTarget( \n        src, replication, clientNode, excludedNodes, blockSize, favoredNodes);\n\n    // Part II.\n    // Allocate a new block, add it to the INode and the BlocksMap. \n    Block newBlock \u003d null;\n    long offset;\n    checkOperation(OperationCategory.WRITE);\n    waitForLoadingFSImage();\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      // Run the full analysis again, since things could have changed\n      // while chooseTarget() was executing.\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      FileState fileState \u003d \n          analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n      final INodeFile pendingFile \u003d fileState.inode;\n      src \u003d fileState.path;\n\n      if (onRetryBlock[0] !\u003d null) {\n        if (onRetryBlock[0].getLocations().length \u003e 0) {\n          // This is a retry. Just return the last block if having locations.\n          return onRetryBlock[0];\n        } else {\n          // add new chosen targets to already allocated block and return\n          BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n          ((BlockInfoUnderConstruction) lastBlockInFile)\n              .setExpectedLocations(targets);\n          offset \u003d pendingFile.computeFileSize();\n          return makeLocatedBlock(lastBlockInFile, targets, offset);\n        }\n      }\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile,\n                                ExtendedBlock.getLocalBlock(previous));\n\n      // allocate new block, record block locations in INode.\n      newBlock \u003d createNewBlock();\n      INodesInPath inodesInPath \u003d INodesInPath.fromINode(pendingFile);\n      saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n\n      persistNewBlock(src, pendingFile);\n      offset \u003d pendingFile.computeFileSize();\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n\n    // Return located block\n    return makeLocatedBlock(newBlock, targets, offset);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "38af6101d8ee199089c3d92ee3798ee674fb8acd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6671. Change BlockPlacementPolicy to consider block storage policy in replicaiton.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-6584@1611334 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/07/14 4:56 AM",
      "commitName": "38af6101d8ee199089c3d92ee3798ee674fb8acd",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "10/07/14 11:18 AM",
      "commitNameOld": "8f520386fb952b70a4e7a9c460a2ecd9b9b855b4",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 6.73,
      "commitsBetweenForRepo": 22,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,100 +1,103 @@\n   LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n       ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n       List\u003cString\u003e favoredNodes)\n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n-    long blockSize;\n-    int replication;\n+    final long blockSize;\n+    final int replication;\n+    final byte storagePolicyID;\n     DatanodeDescriptor clientNode \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.getAdditionalBlock: \"\n           + src + \" inodeId \" +  fileId  + \" for \" + clientName);\n     }\n \n     // Part I. Analyze the state of the file with respect to the input data.\n     checkOperation(OperationCategory.READ);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       FileState fileState \u003d analyzeFileState(\n           src, fileId, clientName, previous, onRetryBlock);\n       final INodeFile pendingFile \u003d fileState.inode;\n       src \u003d fileState.path;\n \n       if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n         // This is a retry. Just return the last block if having locations.\n         return onRetryBlock[0];\n       }\n       if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n         throw new IOException(\"File has reached the limit on maximum number of\"\n             + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n             + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n             + maxBlocksPerFile);\n       }\n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientNode \u003d blockManager.getDatanodeManager().getDatanodeByHost(\n               pendingFile.getFileUnderConstructionFeature().getClientMachine());\n       replication \u003d pendingFile.getFileReplication();\n+      storagePolicyID \u003d pendingFile.getStoragePolicyID();\n     } finally {\n       readUnlock();\n     }\n \n     // choose targets for the new block to be allocated.\n-    final DatanodeStorageInfo targets[] \u003d getBlockManager().chooseTarget( \n-        src, replication, clientNode, excludedNodes, blockSize, favoredNodes);\n+    final DatanodeStorageInfo targets[] \u003d getBlockManager().chooseTarget4NewBlock( \n+        src, replication, clientNode, excludedNodes, blockSize, favoredNodes,\n+        storagePolicyID);\n \n     // Part II.\n     // Allocate a new block, add it to the INode and the BlocksMap. \n     Block newBlock \u003d null;\n     long offset;\n     checkOperation(OperationCategory.WRITE);\n     waitForLoadingFSImage();\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       // Run the full analysis again, since things could have changed\n       // while chooseTarget() was executing.\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       FileState fileState \u003d \n           analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n       final INodeFile pendingFile \u003d fileState.inode;\n       src \u003d fileState.path;\n \n       if (onRetryBlock[0] !\u003d null) {\n         if (onRetryBlock[0].getLocations().length \u003e 0) {\n           // This is a retry. Just return the last block if having locations.\n           return onRetryBlock[0];\n         } else {\n           // add new chosen targets to already allocated block and return\n           BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n           ((BlockInfoUnderConstruction) lastBlockInFile)\n               .setExpectedLocations(targets);\n           offset \u003d pendingFile.computeFileSize();\n           return makeLocatedBlock(lastBlockInFile, targets, offset);\n         }\n       }\n \n       // commit the last block and complete it if it has minimum replicas\n       commitOrCompleteLastBlock(pendingFile,\n                                 ExtendedBlock.getLocalBlock(previous));\n \n       // allocate new block, record block locations in INode.\n       newBlock \u003d createNewBlock();\n       INodesInPath inodesInPath \u003d INodesInPath.fromINode(pendingFile);\n       saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n \n       persistNewBlock(src, pendingFile);\n       offset \u003d pendingFile.computeFileSize();\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n \n     // Return located block\n     return makeLocatedBlock(newBlock, targets, offset);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n      ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n      List\u003cString\u003e favoredNodes)\n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    final long blockSize;\n    final int replication;\n    final byte storagePolicyID;\n    DatanodeDescriptor clientNode \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.getAdditionalBlock: \"\n          + src + \" inodeId \" +  fileId  + \" for \" + clientName);\n    }\n\n    // Part I. Analyze the state of the file with respect to the input data.\n    checkOperation(OperationCategory.READ);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      FileState fileState \u003d analyzeFileState(\n          src, fileId, clientName, previous, onRetryBlock);\n      final INodeFile pendingFile \u003d fileState.inode;\n      src \u003d fileState.path;\n\n      if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n        // This is a retry. Just return the last block if having locations.\n        return onRetryBlock[0];\n      }\n      if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n        throw new IOException(\"File has reached the limit on maximum number of\"\n            + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n            + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n            + maxBlocksPerFile);\n      }\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d blockManager.getDatanodeManager().getDatanodeByHost(\n              pendingFile.getFileUnderConstructionFeature().getClientMachine());\n      replication \u003d pendingFile.getFileReplication();\n      storagePolicyID \u003d pendingFile.getStoragePolicyID();\n    } finally {\n      readUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeStorageInfo targets[] \u003d getBlockManager().chooseTarget4NewBlock( \n        src, replication, clientNode, excludedNodes, blockSize, favoredNodes,\n        storagePolicyID);\n\n    // Part II.\n    // Allocate a new block, add it to the INode and the BlocksMap. \n    Block newBlock \u003d null;\n    long offset;\n    checkOperation(OperationCategory.WRITE);\n    waitForLoadingFSImage();\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      // Run the full analysis again, since things could have changed\n      // while chooseTarget() was executing.\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      FileState fileState \u003d \n          analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n      final INodeFile pendingFile \u003d fileState.inode;\n      src \u003d fileState.path;\n\n      if (onRetryBlock[0] !\u003d null) {\n        if (onRetryBlock[0].getLocations().length \u003e 0) {\n          // This is a retry. Just return the last block if having locations.\n          return onRetryBlock[0];\n        } else {\n          // add new chosen targets to already allocated block and return\n          BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n          ((BlockInfoUnderConstruction) lastBlockInFile)\n              .setExpectedLocations(targets);\n          offset \u003d pendingFile.computeFileSize();\n          return makeLocatedBlock(lastBlockInFile, targets, offset);\n        }\n      }\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile,\n                                ExtendedBlock.getLocalBlock(previous));\n\n      // allocate new block, record block locations in INode.\n      newBlock \u003d createNewBlock();\n      INodesInPath inodesInPath \u003d INodesInPath.fromINode(pendingFile);\n      saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n\n      persistNewBlock(src, pendingFile);\n      offset \u003d pendingFile.computeFileSize();\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n\n    // Return located block\n    return makeLocatedBlock(newBlock, targets, offset);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "d9c5f20333ef510c0ace066c0a811f9e953e9e17": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6622. Rename and AddBlock may race and produce invalid edits (kihwal via cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1609384 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/07/14 9:03 PM",
      "commitName": "d9c5f20333ef510c0ace066c0a811f9e953e9e17",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "09/07/14 8:49 PM",
      "commitNameOld": "8044a12ac02cc4495935a3afded8c1d4369c1445",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,97 +1,100 @@\n   LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n       ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n       List\u003cString\u003e favoredNodes)\n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n     long blockSize;\n     int replication;\n     DatanodeDescriptor clientNode \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.getAdditionalBlock: \"\n           + src + \" inodeId \" +  fileId  + \" for \" + clientName);\n     }\n \n     // Part I. Analyze the state of the file with respect to the input data.\n     checkOperation(OperationCategory.READ);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n-      final INodeFile pendingFile \u003d analyzeFileState(\n+      FileState fileState \u003d analyzeFileState(\n           src, fileId, clientName, previous, onRetryBlock);\n-      src \u003d pendingFile.getFullPathName();\n+      final INodeFile pendingFile \u003d fileState.inode;\n+      src \u003d fileState.path;\n \n       if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n         // This is a retry. Just return the last block if having locations.\n         return onRetryBlock[0];\n       }\n       if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n         throw new IOException(\"File has reached the limit on maximum number of\"\n             + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n             + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n             + maxBlocksPerFile);\n       }\n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientNode \u003d blockManager.getDatanodeManager().getDatanodeByHost(\n               pendingFile.getFileUnderConstructionFeature().getClientMachine());\n       replication \u003d pendingFile.getFileReplication();\n     } finally {\n       readUnlock();\n     }\n \n     // choose targets for the new block to be allocated.\n     final DatanodeStorageInfo targets[] \u003d getBlockManager().chooseTarget( \n         src, replication, clientNode, excludedNodes, blockSize, favoredNodes);\n \n     // Part II.\n     // Allocate a new block, add it to the INode and the BlocksMap. \n     Block newBlock \u003d null;\n     long offset;\n     checkOperation(OperationCategory.WRITE);\n     waitForLoadingFSImage();\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       // Run the full analysis again, since things could have changed\n       // while chooseTarget() was executing.\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n-      final INodeFile pendingFile \u003d\n+      FileState fileState \u003d \n           analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n+      final INodeFile pendingFile \u003d fileState.inode;\n+      src \u003d fileState.path;\n \n       if (onRetryBlock[0] !\u003d null) {\n         if (onRetryBlock[0].getLocations().length \u003e 0) {\n           // This is a retry. Just return the last block if having locations.\n           return onRetryBlock[0];\n         } else {\n           // add new chosen targets to already allocated block and return\n           BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n           ((BlockInfoUnderConstruction) lastBlockInFile)\n               .setExpectedLocations(targets);\n           offset \u003d pendingFile.computeFileSize();\n           return makeLocatedBlock(lastBlockInFile, targets, offset);\n         }\n       }\n \n       // commit the last block and complete it if it has minimum replicas\n       commitOrCompleteLastBlock(pendingFile,\n                                 ExtendedBlock.getLocalBlock(previous));\n \n       // allocate new block, record block locations in INode.\n       newBlock \u003d createNewBlock();\n       INodesInPath inodesInPath \u003d INodesInPath.fromINode(pendingFile);\n       saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n \n       persistNewBlock(src, pendingFile);\n       offset \u003d pendingFile.computeFileSize();\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n \n     // Return located block\n     return makeLocatedBlock(newBlock, targets, offset);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n      ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n      List\u003cString\u003e favoredNodes)\n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    long blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.getAdditionalBlock: \"\n          + src + \" inodeId \" +  fileId  + \" for \" + clientName);\n    }\n\n    // Part I. Analyze the state of the file with respect to the input data.\n    checkOperation(OperationCategory.READ);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      FileState fileState \u003d analyzeFileState(\n          src, fileId, clientName, previous, onRetryBlock);\n      final INodeFile pendingFile \u003d fileState.inode;\n      src \u003d fileState.path;\n\n      if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n        // This is a retry. Just return the last block if having locations.\n        return onRetryBlock[0];\n      }\n      if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n        throw new IOException(\"File has reached the limit on maximum number of\"\n            + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n            + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n            + maxBlocksPerFile);\n      }\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d blockManager.getDatanodeManager().getDatanodeByHost(\n              pendingFile.getFileUnderConstructionFeature().getClientMachine());\n      replication \u003d pendingFile.getFileReplication();\n    } finally {\n      readUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeStorageInfo targets[] \u003d getBlockManager().chooseTarget( \n        src, replication, clientNode, excludedNodes, blockSize, favoredNodes);\n\n    // Part II.\n    // Allocate a new block, add it to the INode and the BlocksMap. \n    Block newBlock \u003d null;\n    long offset;\n    checkOperation(OperationCategory.WRITE);\n    waitForLoadingFSImage();\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      // Run the full analysis again, since things could have changed\n      // while chooseTarget() was executing.\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      FileState fileState \u003d \n          analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n      final INodeFile pendingFile \u003d fileState.inode;\n      src \u003d fileState.path;\n\n      if (onRetryBlock[0] !\u003d null) {\n        if (onRetryBlock[0].getLocations().length \u003e 0) {\n          // This is a retry. Just return the last block if having locations.\n          return onRetryBlock[0];\n        } else {\n          // add new chosen targets to already allocated block and return\n          BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n          ((BlockInfoUnderConstruction) lastBlockInFile)\n              .setExpectedLocations(targets);\n          offset \u003d pendingFile.computeFileSize();\n          return makeLocatedBlock(lastBlockInFile, targets, offset);\n        }\n      }\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile,\n                                ExtendedBlock.getLocalBlock(previous));\n\n      // allocate new block, record block locations in INode.\n      newBlock \u003d createNewBlock();\n      INodesInPath inodesInPath \u003d INodesInPath.fromINode(pendingFile);\n      saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n\n      persistNewBlock(src, pendingFile);\n      offset \u003d pendingFile.computeFileSize();\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n\n    // Return located block\n    return makeLocatedBlock(newBlock, targets, offset);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "1e89eba47d0f291b33fc26f9406231fc70b63a87": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6583. Remove clientNode in FileUnderConstructionFeature. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1604541 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/06/14 12:39 AM",
      "commitName": "1e89eba47d0f291b33fc26f9406231fc70b63a87",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "20/06/14 11:54 AM",
      "commitNameOld": "9ca79e8d327e95845ef9794396afd43a52bc3d40",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 1.53,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,96 +1,97 @@\n   LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n       ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n       List\u003cString\u003e favoredNodes)\n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n     long blockSize;\n     int replication;\n     DatanodeDescriptor clientNode \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.getAdditionalBlock: \"\n           + src + \" inodeId \" +  fileId  + \" for \" + clientName);\n     }\n \n     // Part I. Analyze the state of the file with respect to the input data.\n     checkOperation(OperationCategory.READ);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       final INodeFile pendingFile \u003d analyzeFileState(\n           src, fileId, clientName, previous, onRetryBlock);\n       src \u003d pendingFile.getFullPathName();\n \n       if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n         // This is a retry. Just return the last block if having locations.\n         return onRetryBlock[0];\n       }\n       if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n         throw new IOException(\"File has reached the limit on maximum number of\"\n             + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n             + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n             + maxBlocksPerFile);\n       }\n       blockSize \u003d pendingFile.getPreferredBlockSize();\n-      clientNode \u003d pendingFile.getFileUnderConstructionFeature().getClientNode();\n+      clientNode \u003d blockManager.getDatanodeManager().getDatanodeByHost(\n+              pendingFile.getFileUnderConstructionFeature().getClientMachine());\n       replication \u003d pendingFile.getFileReplication();\n     } finally {\n       readUnlock();\n     }\n \n     // choose targets for the new block to be allocated.\n     final DatanodeStorageInfo targets[] \u003d getBlockManager().chooseTarget( \n         src, replication, clientNode, excludedNodes, blockSize, favoredNodes);\n \n     // Part II.\n     // Allocate a new block, add it to the INode and the BlocksMap. \n     Block newBlock \u003d null;\n     long offset;\n     checkOperation(OperationCategory.WRITE);\n     waitForLoadingFSImage();\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       // Run the full analysis again, since things could have changed\n       // while chooseTarget() was executing.\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       final INodeFile pendingFile \u003d\n           analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n \n       if (onRetryBlock[0] !\u003d null) {\n         if (onRetryBlock[0].getLocations().length \u003e 0) {\n           // This is a retry. Just return the last block if having locations.\n           return onRetryBlock[0];\n         } else {\n           // add new chosen targets to already allocated block and return\n           BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n           ((BlockInfoUnderConstruction) lastBlockInFile)\n               .setExpectedLocations(targets);\n           offset \u003d pendingFile.computeFileSize();\n           return makeLocatedBlock(lastBlockInFile, targets, offset);\n         }\n       }\n \n       // commit the last block and complete it if it has minimum replicas\n       commitOrCompleteLastBlock(pendingFile,\n                                 ExtendedBlock.getLocalBlock(previous));\n \n       // allocate new block, record block locations in INode.\n       newBlock \u003d createNewBlock();\n       INodesInPath inodesInPath \u003d INodesInPath.fromINode(pendingFile);\n       saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n \n       persistNewBlock(src, pendingFile);\n       offset \u003d pendingFile.computeFileSize();\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n \n     // Return located block\n     return makeLocatedBlock(newBlock, targets, offset);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n      ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n      List\u003cString\u003e favoredNodes)\n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    long blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.getAdditionalBlock: \"\n          + src + \" inodeId \" +  fileId  + \" for \" + clientName);\n    }\n\n    // Part I. Analyze the state of the file with respect to the input data.\n    checkOperation(OperationCategory.READ);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      final INodeFile pendingFile \u003d analyzeFileState(\n          src, fileId, clientName, previous, onRetryBlock);\n      src \u003d pendingFile.getFullPathName();\n\n      if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n        // This is a retry. Just return the last block if having locations.\n        return onRetryBlock[0];\n      }\n      if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n        throw new IOException(\"File has reached the limit on maximum number of\"\n            + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n            + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n            + maxBlocksPerFile);\n      }\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d blockManager.getDatanodeManager().getDatanodeByHost(\n              pendingFile.getFileUnderConstructionFeature().getClientMachine());\n      replication \u003d pendingFile.getFileReplication();\n    } finally {\n      readUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeStorageInfo targets[] \u003d getBlockManager().chooseTarget( \n        src, replication, clientNode, excludedNodes, blockSize, favoredNodes);\n\n    // Part II.\n    // Allocate a new block, add it to the INode and the BlocksMap. \n    Block newBlock \u003d null;\n    long offset;\n    checkOperation(OperationCategory.WRITE);\n    waitForLoadingFSImage();\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      // Run the full analysis again, since things could have changed\n      // while chooseTarget() was executing.\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      final INodeFile pendingFile \u003d\n          analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n\n      if (onRetryBlock[0] !\u003d null) {\n        if (onRetryBlock[0].getLocations().length \u003e 0) {\n          // This is a retry. Just return the last block if having locations.\n          return onRetryBlock[0];\n        } else {\n          // add new chosen targets to already allocated block and return\n          BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n          ((BlockInfoUnderConstruction) lastBlockInFile)\n              .setExpectedLocations(targets);\n          offset \u003d pendingFile.computeFileSize();\n          return makeLocatedBlock(lastBlockInFile, targets, offset);\n        }\n      }\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile,\n                                ExtendedBlock.getLocalBlock(previous));\n\n      // allocate new block, record block locations in INode.\n      newBlock \u003d createNewBlock();\n      INodesInPath inodesInPath \u003d INodesInPath.fromINode(pendingFile);\n      saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n\n      persistNewBlock(src, pendingFile);\n      offset \u003d pendingFile.computeFileSize();\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n\n    // Return located block\n    return makeLocatedBlock(newBlock, targets, offset);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "a4e0ff5e052abad498595ee198b49c5310c9ec0d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6480. Move waitForReady() from FSDirectory to FSNamesystem. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1603705 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/06/14 9:13 PM",
      "commitName": "a4e0ff5e052abad498595ee198b49c5310c9ec0d",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "17/06/14 6:00 PM",
      "commitNameOld": "8e8a769e7f5ce806ffdf584f017512ab58cd84e8",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 1.13,
      "commitsBetweenForRepo": 15,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,95 +1,96 @@\n   LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n       ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n       List\u003cString\u003e favoredNodes)\n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n     long blockSize;\n     int replication;\n     DatanodeDescriptor clientNode \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.getAdditionalBlock: \"\n           + src + \" inodeId \" +  fileId  + \" for \" + clientName);\n     }\n \n     // Part I. Analyze the state of the file with respect to the input data.\n     checkOperation(OperationCategory.READ);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       final INodeFile pendingFile \u003d analyzeFileState(\n           src, fileId, clientName, previous, onRetryBlock);\n       src \u003d pendingFile.getFullPathName();\n \n       if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n         // This is a retry. Just return the last block if having locations.\n         return onRetryBlock[0];\n       }\n       if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n         throw new IOException(\"File has reached the limit on maximum number of\"\n             + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n             + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n             + maxBlocksPerFile);\n       }\n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientNode \u003d pendingFile.getFileUnderConstructionFeature().getClientNode();\n       replication \u003d pendingFile.getFileReplication();\n     } finally {\n       readUnlock();\n     }\n \n     // choose targets for the new block to be allocated.\n     final DatanodeStorageInfo targets[] \u003d getBlockManager().chooseTarget( \n         src, replication, clientNode, excludedNodes, blockSize, favoredNodes);\n \n     // Part II.\n     // Allocate a new block, add it to the INode and the BlocksMap. \n     Block newBlock \u003d null;\n     long offset;\n     checkOperation(OperationCategory.WRITE);\n+    waitForLoadingFSImage();\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       // Run the full analysis again, since things could have changed\n       // while chooseTarget() was executing.\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       final INodeFile pendingFile \u003d\n           analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n \n       if (onRetryBlock[0] !\u003d null) {\n         if (onRetryBlock[0].getLocations().length \u003e 0) {\n           // This is a retry. Just return the last block if having locations.\n           return onRetryBlock[0];\n         } else {\n           // add new chosen targets to already allocated block and return\n           BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n           ((BlockInfoUnderConstruction) lastBlockInFile)\n               .setExpectedLocations(targets);\n           offset \u003d pendingFile.computeFileSize();\n           return makeLocatedBlock(lastBlockInFile, targets, offset);\n         }\n       }\n \n       // commit the last block and complete it if it has minimum replicas\n       commitOrCompleteLastBlock(pendingFile,\n                                 ExtendedBlock.getLocalBlock(previous));\n \n       // allocate new block, record block locations in INode.\n       newBlock \u003d createNewBlock();\n       INodesInPath inodesInPath \u003d INodesInPath.fromINode(pendingFile);\n       saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n \n       persistNewBlock(src, pendingFile);\n       offset \u003d pendingFile.computeFileSize();\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n \n     // Return located block\n     return makeLocatedBlock(newBlock, targets, offset);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n      ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n      List\u003cString\u003e favoredNodes)\n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    long blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.getAdditionalBlock: \"\n          + src + \" inodeId \" +  fileId  + \" for \" + clientName);\n    }\n\n    // Part I. Analyze the state of the file with respect to the input data.\n    checkOperation(OperationCategory.READ);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      final INodeFile pendingFile \u003d analyzeFileState(\n          src, fileId, clientName, previous, onRetryBlock);\n      src \u003d pendingFile.getFullPathName();\n\n      if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n        // This is a retry. Just return the last block if having locations.\n        return onRetryBlock[0];\n      }\n      if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n        throw new IOException(\"File has reached the limit on maximum number of\"\n            + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n            + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n            + maxBlocksPerFile);\n      }\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d pendingFile.getFileUnderConstructionFeature().getClientNode();\n      replication \u003d pendingFile.getFileReplication();\n    } finally {\n      readUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeStorageInfo targets[] \u003d getBlockManager().chooseTarget( \n        src, replication, clientNode, excludedNodes, blockSize, favoredNodes);\n\n    // Part II.\n    // Allocate a new block, add it to the INode and the BlocksMap. \n    Block newBlock \u003d null;\n    long offset;\n    checkOperation(OperationCategory.WRITE);\n    waitForLoadingFSImage();\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      // Run the full analysis again, since things could have changed\n      // while chooseTarget() was executing.\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      final INodeFile pendingFile \u003d\n          analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n\n      if (onRetryBlock[0] !\u003d null) {\n        if (onRetryBlock[0].getLocations().length \u003e 0) {\n          // This is a retry. Just return the last block if having locations.\n          return onRetryBlock[0];\n        } else {\n          // add new chosen targets to already allocated block and return\n          BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n          ((BlockInfoUnderConstruction) lastBlockInFile)\n              .setExpectedLocations(targets);\n          offset \u003d pendingFile.computeFileSize();\n          return makeLocatedBlock(lastBlockInFile, targets, offset);\n        }\n      }\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile,\n                                ExtendedBlock.getLocalBlock(previous));\n\n      // allocate new block, record block locations in INode.\n      newBlock \u003d createNewBlock();\n      INodesInPath inodesInPath \u003d INodesInPath.fromINode(pendingFile);\n      saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n\n      persistNewBlock(src, pendingFile);\n      offset \u003d pendingFile.computeFileSize();\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n\n    // Return located block\n    return makeLocatedBlock(newBlock, targets, offset);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "e98529858edeed11c4f900b0db30d7e4eb2ab1ec": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6315. Decouple recording edit logs from FSDirectory. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1601960 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/06/14 10:22 AM",
      "commitName": "e98529858edeed11c4f900b0db30d7e4eb2ab1ec",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "03/06/14 11:33 AM",
      "commitNameOld": "02fcb6b6bae7c3fe2a10b00b2a563e4098ff225e",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 7.95,
      "commitsBetweenForRepo": 35,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,95 +1,95 @@\n   LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n       ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n       List\u003cString\u003e favoredNodes)\n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n     long blockSize;\n     int replication;\n     DatanodeDescriptor clientNode \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.getAdditionalBlock: \"\n           + src + \" inodeId \" +  fileId  + \" for \" + clientName);\n     }\n \n     // Part I. Analyze the state of the file with respect to the input data.\n     checkOperation(OperationCategory.READ);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       final INodeFile pendingFile \u003d analyzeFileState(\n           src, fileId, clientName, previous, onRetryBlock);\n       src \u003d pendingFile.getFullPathName();\n \n       if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n         // This is a retry. Just return the last block if having locations.\n         return onRetryBlock[0];\n       }\n       if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n         throw new IOException(\"File has reached the limit on maximum number of\"\n             + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n             + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n             + maxBlocksPerFile);\n       }\n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientNode \u003d pendingFile.getFileUnderConstructionFeature().getClientNode();\n       replication \u003d pendingFile.getFileReplication();\n     } finally {\n       readUnlock();\n     }\n \n     // choose targets for the new block to be allocated.\n     final DatanodeStorageInfo targets[] \u003d getBlockManager().chooseTarget( \n         src, replication, clientNode, excludedNodes, blockSize, favoredNodes);\n \n     // Part II.\n     // Allocate a new block, add it to the INode and the BlocksMap. \n     Block newBlock \u003d null;\n     long offset;\n     checkOperation(OperationCategory.WRITE);\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       // Run the full analysis again, since things could have changed\n       // while chooseTarget() was executing.\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       final INodeFile pendingFile \u003d\n           analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n \n       if (onRetryBlock[0] !\u003d null) {\n         if (onRetryBlock[0].getLocations().length \u003e 0) {\n           // This is a retry. Just return the last block if having locations.\n           return onRetryBlock[0];\n         } else {\n           // add new chosen targets to already allocated block and return\n           BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n           ((BlockInfoUnderConstruction) lastBlockInFile)\n               .setExpectedLocations(targets);\n           offset \u003d pendingFile.computeFileSize();\n           return makeLocatedBlock(lastBlockInFile, targets, offset);\n         }\n       }\n \n       // commit the last block and complete it if it has minimum replicas\n       commitOrCompleteLastBlock(pendingFile,\n                                 ExtendedBlock.getLocalBlock(previous));\n \n       // allocate new block, record block locations in INode.\n       newBlock \u003d createNewBlock();\n       INodesInPath inodesInPath \u003d INodesInPath.fromINode(pendingFile);\n       saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n \n-      dir.persistNewBlock(src, pendingFile);\n+      persistNewBlock(src, pendingFile);\n       offset \u003d pendingFile.computeFileSize();\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n \n     // Return located block\n     return makeLocatedBlock(newBlock, targets, offset);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n      ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n      List\u003cString\u003e favoredNodes)\n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    long blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.getAdditionalBlock: \"\n          + src + \" inodeId \" +  fileId  + \" for \" + clientName);\n    }\n\n    // Part I. Analyze the state of the file with respect to the input data.\n    checkOperation(OperationCategory.READ);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      final INodeFile pendingFile \u003d analyzeFileState(\n          src, fileId, clientName, previous, onRetryBlock);\n      src \u003d pendingFile.getFullPathName();\n\n      if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n        // This is a retry. Just return the last block if having locations.\n        return onRetryBlock[0];\n      }\n      if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n        throw new IOException(\"File has reached the limit on maximum number of\"\n            + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n            + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n            + maxBlocksPerFile);\n      }\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d pendingFile.getFileUnderConstructionFeature().getClientNode();\n      replication \u003d pendingFile.getFileReplication();\n    } finally {\n      readUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeStorageInfo targets[] \u003d getBlockManager().chooseTarget( \n        src, replication, clientNode, excludedNodes, blockSize, favoredNodes);\n\n    // Part II.\n    // Allocate a new block, add it to the INode and the BlocksMap. \n    Block newBlock \u003d null;\n    long offset;\n    checkOperation(OperationCategory.WRITE);\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      // Run the full analysis again, since things could have changed\n      // while chooseTarget() was executing.\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      final INodeFile pendingFile \u003d\n          analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n\n      if (onRetryBlock[0] !\u003d null) {\n        if (onRetryBlock[0].getLocations().length \u003e 0) {\n          // This is a retry. Just return the last block if having locations.\n          return onRetryBlock[0];\n        } else {\n          // add new chosen targets to already allocated block and return\n          BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n          ((BlockInfoUnderConstruction) lastBlockInFile)\n              .setExpectedLocations(targets);\n          offset \u003d pendingFile.computeFileSize();\n          return makeLocatedBlock(lastBlockInFile, targets, offset);\n        }\n      }\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile,\n                                ExtendedBlock.getLocalBlock(previous));\n\n      // allocate new block, record block locations in INode.\n      newBlock \u003d createNewBlock();\n      INodesInPath inodesInPath \u003d INodesInPath.fromINode(pendingFile);\n      saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n\n      persistNewBlock(src, pendingFile);\n      offset \u003d pendingFile.computeFileSize();\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n\n    // Return located block\n    return makeLocatedBlock(newBlock, targets, offset);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "f131dba8a3d603a5d15c4f035ed3da75b4daf0dc": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6294. Use INode IDs to avoid conflicts when a file open for write is renamed (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1593634 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/05/14 3:36 PM",
      "commitName": "f131dba8a3d603a5d15c4f035ed3da75b4daf0dc",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "30/04/14 10:44 AM",
      "commitNameOld": "0689363343a281a6f7f6f395227668bddc2663eb",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 9.2,
      "commitsBetweenForRepo": 39,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,96 +1,95 @@\n   LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n       ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n       List\u003cString\u003e favoredNodes)\n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n     long blockSize;\n     int replication;\n     DatanodeDescriptor clientNode \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.getAdditionalBlock: \"\n           + src + \" inodeId \" +  fileId  + \" for \" + clientName);\n     }\n \n     // Part I. Analyze the state of the file with respect to the input data.\n     checkOperation(OperationCategory.READ);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n-      final INode[] inodes \u003d analyzeFileState(\n-          src, fileId, clientName, previous, onRetryBlock).getINodes();\n-      final INodeFile pendingFile \u003d inodes[inodes.length - 1].asFile();\n+      final INodeFile pendingFile \u003d analyzeFileState(\n+          src, fileId, clientName, previous, onRetryBlock);\n+      src \u003d pendingFile.getFullPathName();\n \n       if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n         // This is a retry. Just return the last block if having locations.\n         return onRetryBlock[0];\n       }\n       if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n         throw new IOException(\"File has reached the limit on maximum number of\"\n             + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n             + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n             + maxBlocksPerFile);\n       }\n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientNode \u003d pendingFile.getFileUnderConstructionFeature().getClientNode();\n       replication \u003d pendingFile.getFileReplication();\n     } finally {\n       readUnlock();\n     }\n \n     // choose targets for the new block to be allocated.\n     final DatanodeStorageInfo targets[] \u003d getBlockManager().chooseTarget( \n         src, replication, clientNode, excludedNodes, blockSize, favoredNodes);\n \n     // Part II.\n     // Allocate a new block, add it to the INode and the BlocksMap. \n     Block newBlock \u003d null;\n     long offset;\n     checkOperation(OperationCategory.WRITE);\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       // Run the full analysis again, since things could have changed\n       // while chooseTarget() was executing.\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n-      INodesInPath inodesInPath \u003d\n+      final INodeFile pendingFile \u003d\n           analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n-      INode[] inodes \u003d inodesInPath.getINodes();\n-      final INodeFile pendingFile \u003d inodes[inodes.length - 1].asFile();\n \n       if (onRetryBlock[0] !\u003d null) {\n         if (onRetryBlock[0].getLocations().length \u003e 0) {\n           // This is a retry. Just return the last block if having locations.\n           return onRetryBlock[0];\n         } else {\n           // add new chosen targets to already allocated block and return\n           BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n           ((BlockInfoUnderConstruction) lastBlockInFile)\n               .setExpectedLocations(targets);\n           offset \u003d pendingFile.computeFileSize();\n           return makeLocatedBlock(lastBlockInFile, targets, offset);\n         }\n       }\n \n       // commit the last block and complete it if it has minimum replicas\n       commitOrCompleteLastBlock(pendingFile,\n                                 ExtendedBlock.getLocalBlock(previous));\n \n       // allocate new block, record block locations in INode.\n       newBlock \u003d createNewBlock();\n+      INodesInPath inodesInPath \u003d INodesInPath.fromINode(pendingFile);\n       saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n \n       dir.persistNewBlock(src, pendingFile);\n       offset \u003d pendingFile.computeFileSize();\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n \n     // Return located block\n     return makeLocatedBlock(newBlock, targets, offset);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n      ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n      List\u003cString\u003e favoredNodes)\n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    long blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.getAdditionalBlock: \"\n          + src + \" inodeId \" +  fileId  + \" for \" + clientName);\n    }\n\n    // Part I. Analyze the state of the file with respect to the input data.\n    checkOperation(OperationCategory.READ);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      final INodeFile pendingFile \u003d analyzeFileState(\n          src, fileId, clientName, previous, onRetryBlock);\n      src \u003d pendingFile.getFullPathName();\n\n      if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n        // This is a retry. Just return the last block if having locations.\n        return onRetryBlock[0];\n      }\n      if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n        throw new IOException(\"File has reached the limit on maximum number of\"\n            + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n            + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n            + maxBlocksPerFile);\n      }\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d pendingFile.getFileUnderConstructionFeature().getClientNode();\n      replication \u003d pendingFile.getFileReplication();\n    } finally {\n      readUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeStorageInfo targets[] \u003d getBlockManager().chooseTarget( \n        src, replication, clientNode, excludedNodes, blockSize, favoredNodes);\n\n    // Part II.\n    // Allocate a new block, add it to the INode and the BlocksMap. \n    Block newBlock \u003d null;\n    long offset;\n    checkOperation(OperationCategory.WRITE);\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      // Run the full analysis again, since things could have changed\n      // while chooseTarget() was executing.\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      final INodeFile pendingFile \u003d\n          analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n\n      if (onRetryBlock[0] !\u003d null) {\n        if (onRetryBlock[0].getLocations().length \u003e 0) {\n          // This is a retry. Just return the last block if having locations.\n          return onRetryBlock[0];\n        } else {\n          // add new chosen targets to already allocated block and return\n          BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n          ((BlockInfoUnderConstruction) lastBlockInFile)\n              .setExpectedLocations(targets);\n          offset \u003d pendingFile.computeFileSize();\n          return makeLocatedBlock(lastBlockInFile, targets, offset);\n        }\n      }\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile,\n                                ExtendedBlock.getLocalBlock(previous));\n\n      // allocate new block, record block locations in INode.\n      newBlock \u003d createNewBlock();\n      INodesInPath inodesInPath \u003d INodesInPath.fromINode(pendingFile);\n      saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n\n      dir.persistNewBlock(src, pendingFile);\n      offset \u003d pendingFile.computeFileSize();\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n\n    // Return located block\n    return makeLocatedBlock(newBlock, targets, offset);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "c00703dd082474fea98a63b871c2183ca01147ed": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6150. Add inode id information in the logs to make debugging easier. Contributed by Suresh Srinivas.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1581914 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/03/14 9:32 AM",
      "commitName": "c00703dd082474fea98a63b871c2183ca01147ed",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "25/03/14 10:53 AM",
      "commitNameOld": "867e0f8ea9b285a428db278edce38e241644b749",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.94,
      "commitsBetweenForRepo": 10,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,97 +1,96 @@\n   LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n       ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n       List\u003cString\u003e favoredNodes)\n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n     long blockSize;\n     int replication;\n     DatanodeDescriptor clientNode \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n-      NameNode.stateChangeLog.debug(\n-          \"BLOCK* NameSystem.getAdditionalBlock: file \"\n-          +src+\" for \"+clientName);\n+      NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.getAdditionalBlock: \"\n+          + src + \" inodeId \" +  fileId  + \" for \" + clientName);\n     }\n \n     // Part I. Analyze the state of the file with respect to the input data.\n     checkOperation(OperationCategory.READ);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       final INode[] inodes \u003d analyzeFileState(\n           src, fileId, clientName, previous, onRetryBlock).getINodes();\n       final INodeFile pendingFile \u003d inodes[inodes.length - 1].asFile();\n \n       if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n         // This is a retry. Just return the last block if having locations.\n         return onRetryBlock[0];\n       }\n       if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n         throw new IOException(\"File has reached the limit on maximum number of\"\n             + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n             + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n             + maxBlocksPerFile);\n       }\n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientNode \u003d pendingFile.getFileUnderConstructionFeature().getClientNode();\n       replication \u003d pendingFile.getFileReplication();\n     } finally {\n       readUnlock();\n     }\n \n     // choose targets for the new block to be allocated.\n     final DatanodeStorageInfo targets[] \u003d getBlockManager().chooseTarget( \n         src, replication, clientNode, excludedNodes, blockSize, favoredNodes);\n \n     // Part II.\n     // Allocate a new block, add it to the INode and the BlocksMap. \n     Block newBlock \u003d null;\n     long offset;\n     checkOperation(OperationCategory.WRITE);\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       // Run the full analysis again, since things could have changed\n       // while chooseTarget() was executing.\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       INodesInPath inodesInPath \u003d\n           analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n       INode[] inodes \u003d inodesInPath.getINodes();\n       final INodeFile pendingFile \u003d inodes[inodes.length - 1].asFile();\n \n       if (onRetryBlock[0] !\u003d null) {\n         if (onRetryBlock[0].getLocations().length \u003e 0) {\n           // This is a retry. Just return the last block if having locations.\n           return onRetryBlock[0];\n         } else {\n           // add new chosen targets to already allocated block and return\n           BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n           ((BlockInfoUnderConstruction) lastBlockInFile)\n               .setExpectedLocations(targets);\n           offset \u003d pendingFile.computeFileSize();\n           return makeLocatedBlock(lastBlockInFile, targets, offset);\n         }\n       }\n \n       // commit the last block and complete it if it has minimum replicas\n       commitOrCompleteLastBlock(pendingFile,\n                                 ExtendedBlock.getLocalBlock(previous));\n \n       // allocate new block, record block locations in INode.\n       newBlock \u003d createNewBlock();\n       saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n \n       dir.persistNewBlock(src, pendingFile);\n       offset \u003d pendingFile.computeFileSize();\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n \n     // Return located block\n     return makeLocatedBlock(newBlock, targets, offset);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n      ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n      List\u003cString\u003e favoredNodes)\n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    long blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.getAdditionalBlock: \"\n          + src + \" inodeId \" +  fileId  + \" for \" + clientName);\n    }\n\n    // Part I. Analyze the state of the file with respect to the input data.\n    checkOperation(OperationCategory.READ);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      final INode[] inodes \u003d analyzeFileState(\n          src, fileId, clientName, previous, onRetryBlock).getINodes();\n      final INodeFile pendingFile \u003d inodes[inodes.length - 1].asFile();\n\n      if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n        // This is a retry. Just return the last block if having locations.\n        return onRetryBlock[0];\n      }\n      if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n        throw new IOException(\"File has reached the limit on maximum number of\"\n            + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n            + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n            + maxBlocksPerFile);\n      }\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d pendingFile.getFileUnderConstructionFeature().getClientNode();\n      replication \u003d pendingFile.getFileReplication();\n    } finally {\n      readUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeStorageInfo targets[] \u003d getBlockManager().chooseTarget( \n        src, replication, clientNode, excludedNodes, blockSize, favoredNodes);\n\n    // Part II.\n    // Allocate a new block, add it to the INode and the BlocksMap. \n    Block newBlock \u003d null;\n    long offset;\n    checkOperation(OperationCategory.WRITE);\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      // Run the full analysis again, since things could have changed\n      // while chooseTarget() was executing.\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      INodesInPath inodesInPath \u003d\n          analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n      INode[] inodes \u003d inodesInPath.getINodes();\n      final INodeFile pendingFile \u003d inodes[inodes.length - 1].asFile();\n\n      if (onRetryBlock[0] !\u003d null) {\n        if (onRetryBlock[0].getLocations().length \u003e 0) {\n          // This is a retry. Just return the last block if having locations.\n          return onRetryBlock[0];\n        } else {\n          // add new chosen targets to already allocated block and return\n          BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n          ((BlockInfoUnderConstruction) lastBlockInFile)\n              .setExpectedLocations(targets);\n          offset \u003d pendingFile.computeFileSize();\n          return makeLocatedBlock(lastBlockInFile, targets, offset);\n        }\n      }\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile,\n                                ExtendedBlock.getLocalBlock(previous));\n\n      // allocate new block, record block locations in INode.\n      newBlock \u003d createNewBlock();\n      saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n\n      dir.persistNewBlock(src, pendingFile);\n      offset \u003d pendingFile.computeFileSize();\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n\n    // Return located block\n    return makeLocatedBlock(newBlock, targets, offset);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "578dae9ef39eef046b0a0ff9cd830c753a98afad": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5704. Change OP_UPDATE_BLOCKS with a new OP_ADD_BLOCK. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1558255 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/01/14 5:06 PM",
      "commitName": "578dae9ef39eef046b0a0ff9cd830c753a98afad",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "09/01/14 5:33 AM",
      "commitNameOld": "7186000367df5a994e0270690a95ca49fa7b23a0",
      "commitAuthorOld": "Junping Du",
      "daysBetweenCommits": 5.48,
      "commitsBetweenForRepo": 23,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,97 +1,97 @@\n   LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n       ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n       List\u003cString\u003e favoredNodes)\n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n     long blockSize;\n     int replication;\n     DatanodeDescriptor clientNode \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\n           \"BLOCK* NameSystem.getAdditionalBlock: file \"\n           +src+\" for \"+clientName);\n     }\n \n     // Part I. Analyze the state of the file with respect to the input data.\n     checkOperation(OperationCategory.READ);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       final INode[] inodes \u003d analyzeFileState(\n           src, fileId, clientName, previous, onRetryBlock).getINodes();\n       final INodeFile pendingFile \u003d inodes[inodes.length - 1].asFile();\n \n       if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n         // This is a retry. Just return the last block if having locations.\n         return onRetryBlock[0];\n       }\n       if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n         throw new IOException(\"File has reached the limit on maximum number of\"\n             + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n             + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n             + maxBlocksPerFile);\n       }\n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientNode \u003d pendingFile.getFileUnderConstructionFeature().getClientNode();\n       replication \u003d pendingFile.getFileReplication();\n     } finally {\n       readUnlock();\n     }\n \n     // choose targets for the new block to be allocated.\n     final DatanodeStorageInfo targets[] \u003d getBlockManager().chooseTarget( \n         src, replication, clientNode, excludedNodes, blockSize, favoredNodes);\n \n     // Part II.\n     // Allocate a new block, add it to the INode and the BlocksMap. \n     Block newBlock \u003d null;\n     long offset;\n     checkOperation(OperationCategory.WRITE);\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       // Run the full analysis again, since things could have changed\n       // while chooseTarget() was executing.\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       INodesInPath inodesInPath \u003d\n           analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n       INode[] inodes \u003d inodesInPath.getINodes();\n       final INodeFile pendingFile \u003d inodes[inodes.length - 1].asFile();\n \n       if (onRetryBlock[0] !\u003d null) {\n         if (onRetryBlock[0].getLocations().length \u003e 0) {\n           // This is a retry. Just return the last block if having locations.\n           return onRetryBlock[0];\n         } else {\n           // add new chosen targets to already allocated block and return\n           BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n           ((BlockInfoUnderConstruction) lastBlockInFile)\n               .setExpectedLocations(targets);\n           offset \u003d pendingFile.computeFileSize();\n           return makeLocatedBlock(lastBlockInFile, targets, offset);\n         }\n       }\n \n       // commit the last block and complete it if it has minimum replicas\n       commitOrCompleteLastBlock(pendingFile,\n                                 ExtendedBlock.getLocalBlock(previous));\n \n       // allocate new block, record block locations in INode.\n       newBlock \u003d createNewBlock();\n       saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n \n-      dir.persistBlocks(src, pendingFile, false);\n+      dir.persistNewBlock(src, pendingFile);\n       offset \u003d pendingFile.computeFileSize();\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n \n     // Return located block\n     return makeLocatedBlock(newBlock, targets, offset);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n      ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n      List\u003cString\u003e favoredNodes)\n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    long blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\n          \"BLOCK* NameSystem.getAdditionalBlock: file \"\n          +src+\" for \"+clientName);\n    }\n\n    // Part I. Analyze the state of the file with respect to the input data.\n    checkOperation(OperationCategory.READ);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      final INode[] inodes \u003d analyzeFileState(\n          src, fileId, clientName, previous, onRetryBlock).getINodes();\n      final INodeFile pendingFile \u003d inodes[inodes.length - 1].asFile();\n\n      if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n        // This is a retry. Just return the last block if having locations.\n        return onRetryBlock[0];\n      }\n      if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n        throw new IOException(\"File has reached the limit on maximum number of\"\n            + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n            + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n            + maxBlocksPerFile);\n      }\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d pendingFile.getFileUnderConstructionFeature().getClientNode();\n      replication \u003d pendingFile.getFileReplication();\n    } finally {\n      readUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeStorageInfo targets[] \u003d getBlockManager().chooseTarget( \n        src, replication, clientNode, excludedNodes, blockSize, favoredNodes);\n\n    // Part II.\n    // Allocate a new block, add it to the INode and the BlocksMap. \n    Block newBlock \u003d null;\n    long offset;\n    checkOperation(OperationCategory.WRITE);\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      // Run the full analysis again, since things could have changed\n      // while chooseTarget() was executing.\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      INodesInPath inodesInPath \u003d\n          analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n      INode[] inodes \u003d inodesInPath.getINodes();\n      final INodeFile pendingFile \u003d inodes[inodes.length - 1].asFile();\n\n      if (onRetryBlock[0] !\u003d null) {\n        if (onRetryBlock[0].getLocations().length \u003e 0) {\n          // This is a retry. Just return the last block if having locations.\n          return onRetryBlock[0];\n        } else {\n          // add new chosen targets to already allocated block and return\n          BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n          ((BlockInfoUnderConstruction) lastBlockInFile)\n              .setExpectedLocations(targets);\n          offset \u003d pendingFile.computeFileSize();\n          return makeLocatedBlock(lastBlockInFile, targets, offset);\n        }\n      }\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile,\n                                ExtendedBlock.getLocalBlock(previous));\n\n      // allocate new block, record block locations in INode.\n      newBlock \u003d createNewBlock();\n      saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n\n      dir.persistNewBlock(src, pendingFile);\n      offset \u003d pendingFile.computeFileSize();\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n\n    // Return located block\n    return makeLocatedBlock(newBlock, targets, offset);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "9df84c35d5a228e3ae42e90487f2d1f1264e5eea": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5590. Block ID and generation stamp may be reused when persistBlocks is set to false. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1548368 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "05/12/13 5:55 PM",
      "commitName": "9df84c35d5a228e3ae42e90487f2d1f1264e5eea",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "05/12/13 7:28 AM",
      "commitNameOld": "6828337d855abe8564ece2266ace7cfc51ee16ec",
      "commitAuthorOld": "Daryn Sharp",
      "daysBetweenCommits": 0.44,
      "commitsBetweenForRepo": 14,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,99 +1,97 @@\n   LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n       ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n       List\u003cString\u003e favoredNodes)\n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n     long blockSize;\n     int replication;\n     DatanodeDescriptor clientNode \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\n           \"BLOCK* NameSystem.getAdditionalBlock: file \"\n           +src+\" for \"+clientName);\n     }\n \n     // Part I. Analyze the state of the file with respect to the input data.\n     checkOperation(OperationCategory.READ);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       final INode[] inodes \u003d analyzeFileState(\n           src, fileId, clientName, previous, onRetryBlock).getINodes();\n       final INodeFile pendingFile \u003d inodes[inodes.length - 1].asFile();\n \n       if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n         // This is a retry. Just return the last block if having locations.\n         return onRetryBlock[0];\n       }\n       if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n         throw new IOException(\"File has reached the limit on maximum number of\"\n             + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n             + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n             + maxBlocksPerFile);\n       }\n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientNode \u003d pendingFile.getFileUnderConstructionFeature().getClientNode();\n       replication \u003d pendingFile.getFileReplication();\n     } finally {\n       readUnlock();\n     }\n \n     // choose targets for the new block to be allocated.\n     final DatanodeDescriptor targets[] \u003d getBlockManager().chooseTarget( \n         src, replication, clientNode, excludedNodes, blockSize, favoredNodes);\n \n     // Part II.\n     // Allocate a new block, add it to the INode and the BlocksMap. \n     Block newBlock \u003d null;\n     long offset;\n     checkOperation(OperationCategory.WRITE);\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       // Run the full analysis again, since things could have changed\n       // while chooseTarget() was executing.\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       INodesInPath inodesInPath \u003d\n           analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n       INode[] inodes \u003d inodesInPath.getINodes();\n       final INodeFile pendingFile \u003d inodes[inodes.length - 1].asFile();\n \n       if (onRetryBlock[0] !\u003d null) {\n         if (onRetryBlock[0].getLocations().length \u003e 0) {\n           // This is a retry. Just return the last block if having locations.\n           return onRetryBlock[0];\n         } else {\n           // add new chosen targets to already allocated block and return\n           BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n           ((BlockInfoUnderConstruction) lastBlockInFile)\n               .setExpectedLocations(targets);\n           offset \u003d pendingFile.computeFileSize();\n           return makeLocatedBlock(lastBlockInFile, targets, offset);\n         }\n       }\n \n       // commit the last block and complete it if it has minimum replicas\n       commitOrCompleteLastBlock(pendingFile,\n                                 ExtendedBlock.getLocalBlock(previous));\n \n       // allocate new block, record block locations in INode.\n       newBlock \u003d createNewBlock();\n       saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n \n       dir.persistBlocks(src, pendingFile, false);\n       offset \u003d pendingFile.computeFileSize();\n     } finally {\n       writeUnlock();\n     }\n-    if (persistBlocks) {\n-      getEditLog().logSync();\n-    }\n+    getEditLog().logSync();\n \n     // Return located block\n     return makeLocatedBlock(newBlock, targets, offset);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n      ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n      List\u003cString\u003e favoredNodes)\n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    long blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\n          \"BLOCK* NameSystem.getAdditionalBlock: file \"\n          +src+\" for \"+clientName);\n    }\n\n    // Part I. Analyze the state of the file with respect to the input data.\n    checkOperation(OperationCategory.READ);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      final INode[] inodes \u003d analyzeFileState(\n          src, fileId, clientName, previous, onRetryBlock).getINodes();\n      final INodeFile pendingFile \u003d inodes[inodes.length - 1].asFile();\n\n      if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n        // This is a retry. Just return the last block if having locations.\n        return onRetryBlock[0];\n      }\n      if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n        throw new IOException(\"File has reached the limit on maximum number of\"\n            + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n            + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n            + maxBlocksPerFile);\n      }\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d pendingFile.getFileUnderConstructionFeature().getClientNode();\n      replication \u003d pendingFile.getFileReplication();\n    } finally {\n      readUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeDescriptor targets[] \u003d getBlockManager().chooseTarget( \n        src, replication, clientNode, excludedNodes, blockSize, favoredNodes);\n\n    // Part II.\n    // Allocate a new block, add it to the INode and the BlocksMap. \n    Block newBlock \u003d null;\n    long offset;\n    checkOperation(OperationCategory.WRITE);\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      // Run the full analysis again, since things could have changed\n      // while chooseTarget() was executing.\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      INodesInPath inodesInPath \u003d\n          analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n      INode[] inodes \u003d inodesInPath.getINodes();\n      final INodeFile pendingFile \u003d inodes[inodes.length - 1].asFile();\n\n      if (onRetryBlock[0] !\u003d null) {\n        if (onRetryBlock[0].getLocations().length \u003e 0) {\n          // This is a retry. Just return the last block if having locations.\n          return onRetryBlock[0];\n        } else {\n          // add new chosen targets to already allocated block and return\n          BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n          ((BlockInfoUnderConstruction) lastBlockInFile)\n              .setExpectedLocations(targets);\n          offset \u003d pendingFile.computeFileSize();\n          return makeLocatedBlock(lastBlockInFile, targets, offset);\n        }\n      }\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile,\n                                ExtendedBlock.getLocalBlock(previous));\n\n      // allocate new block, record block locations in INode.\n      newBlock \u003d createNewBlock();\n      saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n\n      dir.persistBlocks(src, pendingFile, false);\n      offset \u003d pendingFile.computeFileSize();\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n\n    // Return located block\n    return makeLocatedBlock(newBlock, targets, offset);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "ce68f410b05a58ad05965f32ad7f5b246b363a75": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5285. Flatten INodeFile hierarchy: Replace INodeFileUnderConstruction and INodeFileUnderConstructionWithSnapshot with FileUnderContructionFeature.  Contributed by jing9\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1544389 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/11/13 5:39 PM",
      "commitName": "ce68f410b05a58ad05965f32ad7f5b246b363a75",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "21/11/13 9:12 AM",
      "commitNameOld": "f91a45a96c21db9e5d40097c7d3f5d005ae10dde",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 0.35,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,101 +1,99 @@\n   LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n       ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n       List\u003cString\u003e favoredNodes)\n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n     long blockSize;\n     int replication;\n     DatanodeDescriptor clientNode \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\n           \"BLOCK* NameSystem.getAdditionalBlock: file \"\n           +src+\" for \"+clientName);\n     }\n \n     // Part I. Analyze the state of the file with respect to the input data.\n     checkOperation(OperationCategory.READ);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       final INode[] inodes \u003d analyzeFileState(\n           src, fileId, clientName, previous, onRetryBlock).getINodes();\n-      final INodeFileUnderConstruction pendingFile \u003d\n-          (INodeFileUnderConstruction) inodes[inodes.length - 1].asFile();\n+      final INodeFile pendingFile \u003d inodes[inodes.length - 1].asFile();\n \n       if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n         // This is a retry. Just return the last block if having locations.\n         return onRetryBlock[0];\n       }\n       if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n         throw new IOException(\"File has reached the limit on maximum number of\"\n             + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n             + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n             + maxBlocksPerFile);\n       }\n       blockSize \u003d pendingFile.getPreferredBlockSize();\n-      clientNode \u003d pendingFile.getClientNode();\n+      clientNode \u003d pendingFile.getFileUnderConstructionFeature().getClientNode();\n       replication \u003d pendingFile.getFileReplication();\n     } finally {\n       readUnlock();\n     }\n \n     // choose targets for the new block to be allocated.\n     final DatanodeDescriptor targets[] \u003d getBlockManager().chooseTarget( \n         src, replication, clientNode, excludedNodes, blockSize, favoredNodes);\n \n     // Part II.\n     // Allocate a new block, add it to the INode and the BlocksMap. \n     Block newBlock \u003d null;\n     long offset;\n     checkOperation(OperationCategory.WRITE);\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       // Run the full analysis again, since things could have changed\n       // while chooseTarget() was executing.\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       INodesInPath inodesInPath \u003d\n           analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n       INode[] inodes \u003d inodesInPath.getINodes();\n-      final INodeFileUnderConstruction pendingFile \u003d\n-          (INodeFileUnderConstruction) inodes[inodes.length - 1].asFile();\n+      final INodeFile pendingFile \u003d inodes[inodes.length - 1].asFile();\n \n       if (onRetryBlock[0] !\u003d null) {\n         if (onRetryBlock[0].getLocations().length \u003e 0) {\n           // This is a retry. Just return the last block if having locations.\n           return onRetryBlock[0];\n         } else {\n           // add new chosen targets to already allocated block and return\n           BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n           ((BlockInfoUnderConstruction) lastBlockInFile)\n               .setExpectedLocations(targets);\n           offset \u003d pendingFile.computeFileSize();\n           return makeLocatedBlock(lastBlockInFile, targets, offset);\n         }\n       }\n \n       // commit the last block and complete it if it has minimum replicas\n       commitOrCompleteLastBlock(pendingFile,\n                                 ExtendedBlock.getLocalBlock(previous));\n \n       // allocate new block, record block locations in INode.\n       newBlock \u003d createNewBlock();\n       saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n \n       dir.persistBlocks(src, pendingFile, false);\n       offset \u003d pendingFile.computeFileSize();\n     } finally {\n       writeUnlock();\n     }\n     if (persistBlocks) {\n       getEditLog().logSync();\n     }\n \n     // Return located block\n     return makeLocatedBlock(newBlock, targets, offset);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n      ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n      List\u003cString\u003e favoredNodes)\n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    long blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\n          \"BLOCK* NameSystem.getAdditionalBlock: file \"\n          +src+\" for \"+clientName);\n    }\n\n    // Part I. Analyze the state of the file with respect to the input data.\n    checkOperation(OperationCategory.READ);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      final INode[] inodes \u003d analyzeFileState(\n          src, fileId, clientName, previous, onRetryBlock).getINodes();\n      final INodeFile pendingFile \u003d inodes[inodes.length - 1].asFile();\n\n      if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n        // This is a retry. Just return the last block if having locations.\n        return onRetryBlock[0];\n      }\n      if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n        throw new IOException(\"File has reached the limit on maximum number of\"\n            + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n            + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n            + maxBlocksPerFile);\n      }\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d pendingFile.getFileUnderConstructionFeature().getClientNode();\n      replication \u003d pendingFile.getFileReplication();\n    } finally {\n      readUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeDescriptor targets[] \u003d getBlockManager().chooseTarget( \n        src, replication, clientNode, excludedNodes, blockSize, favoredNodes);\n\n    // Part II.\n    // Allocate a new block, add it to the INode and the BlocksMap. \n    Block newBlock \u003d null;\n    long offset;\n    checkOperation(OperationCategory.WRITE);\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      // Run the full analysis again, since things could have changed\n      // while chooseTarget() was executing.\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      INodesInPath inodesInPath \u003d\n          analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n      INode[] inodes \u003d inodesInPath.getINodes();\n      final INodeFile pendingFile \u003d inodes[inodes.length - 1].asFile();\n\n      if (onRetryBlock[0] !\u003d null) {\n        if (onRetryBlock[0].getLocations().length \u003e 0) {\n          // This is a retry. Just return the last block if having locations.\n          return onRetryBlock[0];\n        } else {\n          // add new chosen targets to already allocated block and return\n          BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n          ((BlockInfoUnderConstruction) lastBlockInFile)\n              .setExpectedLocations(targets);\n          offset \u003d pendingFile.computeFileSize();\n          return makeLocatedBlock(lastBlockInFile, targets, offset);\n        }\n      }\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile,\n                                ExtendedBlock.getLocalBlock(previous));\n\n      // allocate new block, record block locations in INode.\n      newBlock \u003d createNewBlock();\n      saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n\n      dir.persistBlocks(src, pendingFile, false);\n      offset \u003d pendingFile.computeFileSize();\n    } finally {\n      writeUnlock();\n    }\n    if (persistBlocks) {\n      getEditLog().logSync();\n    }\n\n    // Return located block\n    return makeLocatedBlock(newBlock, targets, offset);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "8162fdcdbc23d749fdb188ae8419e173c59cb1ed": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5425. Renaming underconstruction file with snapshots can make NN failure on restart. Contributed by Vinay and Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1541261 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/11/13 2:10 PM",
      "commitName": "8162fdcdbc23d749fdb188ae8419e173c59cb1ed",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "07/11/13 2:07 PM",
      "commitNameOld": "f79b3e6b17450e9d34c483046b7437b09dd72016",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 5.0,
      "commitsBetweenForRepo": 19,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,101 +1,101 @@\n   LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n       ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n       List\u003cString\u003e favoredNodes)\n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n     long blockSize;\n     int replication;\n     DatanodeDescriptor clientNode \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\n           \"BLOCK* NameSystem.getAdditionalBlock: file \"\n           +src+\" for \"+clientName);\n     }\n \n     // Part I. Analyze the state of the file with respect to the input data.\n     checkOperation(OperationCategory.READ);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       final INode[] inodes \u003d analyzeFileState(\n           src, fileId, clientName, previous, onRetryBlock).getINodes();\n       final INodeFileUnderConstruction pendingFile \u003d\n-          (INodeFileUnderConstruction) inodes[inodes.length - 1];\n+          (INodeFileUnderConstruction) inodes[inodes.length - 1].asFile();\n \n       if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n         // This is a retry. Just return the last block if having locations.\n         return onRetryBlock[0];\n       }\n       if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n         throw new IOException(\"File has reached the limit on maximum number of\"\n             + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n             + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n             + maxBlocksPerFile);\n       }\n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientNode \u003d pendingFile.getClientNode();\n       replication \u003d pendingFile.getFileReplication();\n     } finally {\n       readUnlock();\n     }\n \n     // choose targets for the new block to be allocated.\n     final DatanodeDescriptor targets[] \u003d getBlockManager().chooseTarget( \n         src, replication, clientNode, excludedNodes, blockSize, favoredNodes);\n \n     // Part II.\n     // Allocate a new block, add it to the INode and the BlocksMap. \n     Block newBlock \u003d null;\n     long offset;\n     checkOperation(OperationCategory.WRITE);\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       // Run the full analysis again, since things could have changed\n       // while chooseTarget() was executing.\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       INodesInPath inodesInPath \u003d\n           analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n       INode[] inodes \u003d inodesInPath.getINodes();\n       final INodeFileUnderConstruction pendingFile \u003d\n-          (INodeFileUnderConstruction) inodes[inodes.length - 1];\n+          (INodeFileUnderConstruction) inodes[inodes.length - 1].asFile();\n \n       if (onRetryBlock[0] !\u003d null) {\n         if (onRetryBlock[0].getLocations().length \u003e 0) {\n           // This is a retry. Just return the last block if having locations.\n           return onRetryBlock[0];\n         } else {\n           // add new chosen targets to already allocated block and return\n           BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n           ((BlockInfoUnderConstruction) lastBlockInFile)\n               .setExpectedLocations(targets);\n           offset \u003d pendingFile.computeFileSize();\n           return makeLocatedBlock(lastBlockInFile, targets, offset);\n         }\n       }\n \n       // commit the last block and complete it if it has minimum replicas\n       commitOrCompleteLastBlock(pendingFile,\n                                 ExtendedBlock.getLocalBlock(previous));\n \n       // allocate new block, record block locations in INode.\n       newBlock \u003d createNewBlock();\n       saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n \n       dir.persistBlocks(src, pendingFile, false);\n       offset \u003d pendingFile.computeFileSize();\n     } finally {\n       writeUnlock();\n     }\n     if (persistBlocks) {\n       getEditLog().logSync();\n     }\n \n     // Return located block\n     return makeLocatedBlock(newBlock, targets, offset);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n      ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n      List\u003cString\u003e favoredNodes)\n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    long blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\n          \"BLOCK* NameSystem.getAdditionalBlock: file \"\n          +src+\" for \"+clientName);\n    }\n\n    // Part I. Analyze the state of the file with respect to the input data.\n    checkOperation(OperationCategory.READ);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      final INode[] inodes \u003d analyzeFileState(\n          src, fileId, clientName, previous, onRetryBlock).getINodes();\n      final INodeFileUnderConstruction pendingFile \u003d\n          (INodeFileUnderConstruction) inodes[inodes.length - 1].asFile();\n\n      if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n        // This is a retry. Just return the last block if having locations.\n        return onRetryBlock[0];\n      }\n      if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n        throw new IOException(\"File has reached the limit on maximum number of\"\n            + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n            + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n            + maxBlocksPerFile);\n      }\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d pendingFile.getClientNode();\n      replication \u003d pendingFile.getFileReplication();\n    } finally {\n      readUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeDescriptor targets[] \u003d getBlockManager().chooseTarget( \n        src, replication, clientNode, excludedNodes, blockSize, favoredNodes);\n\n    // Part II.\n    // Allocate a new block, add it to the INode and the BlocksMap. \n    Block newBlock \u003d null;\n    long offset;\n    checkOperation(OperationCategory.WRITE);\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      // Run the full analysis again, since things could have changed\n      // while chooseTarget() was executing.\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      INodesInPath inodesInPath \u003d\n          analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n      INode[] inodes \u003d inodesInPath.getINodes();\n      final INodeFileUnderConstruction pendingFile \u003d\n          (INodeFileUnderConstruction) inodes[inodes.length - 1].asFile();\n\n      if (onRetryBlock[0] !\u003d null) {\n        if (onRetryBlock[0].getLocations().length \u003e 0) {\n          // This is a retry. Just return the last block if having locations.\n          return onRetryBlock[0];\n        } else {\n          // add new chosen targets to already allocated block and return\n          BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n          ((BlockInfoUnderConstruction) lastBlockInFile)\n              .setExpectedLocations(targets);\n          offset \u003d pendingFile.computeFileSize();\n          return makeLocatedBlock(lastBlockInFile, targets, offset);\n        }\n      }\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile,\n                                ExtendedBlock.getLocalBlock(previous));\n\n      // allocate new block, record block locations in INode.\n      newBlock \u003d createNewBlock();\n      saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n\n      dir.persistBlocks(src, pendingFile, false);\n      offset \u003d pendingFile.computeFileSize();\n    } finally {\n      writeUnlock();\n    }\n    if (persistBlocks) {\n      getEditLog().logSync();\n    }\n\n    // Return located block\n    return makeLocatedBlock(newBlock, targets, offset);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "5829029154b8e8e02bc6aeb45435046ca080bbe9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5257. addBlock() retry should return LocatedBlock with locations else client will get AIOBE. Contributed by Vinay.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1535811 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/10/13 11:43 AM",
      "commitName": "5829029154b8e8e02bc6aeb45435046ca080bbe9",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "16/10/13 2:14 PM",
      "commitNameOld": "a0fc90ea92c3f060048548e46ad68a0722781d58",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 8.89,
      "commitsBetweenForRepo": 42,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,92 +1,101 @@\n   LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n       ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n       List\u003cString\u003e favoredNodes)\n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n     long blockSize;\n     int replication;\n     DatanodeDescriptor clientNode \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\n           \"BLOCK* NameSystem.getAdditionalBlock: file \"\n           +src+\" for \"+clientName);\n     }\n \n     // Part I. Analyze the state of the file with respect to the input data.\n     checkOperation(OperationCategory.READ);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       final INode[] inodes \u003d analyzeFileState(\n           src, fileId, clientName, previous, onRetryBlock).getINodes();\n       final INodeFileUnderConstruction pendingFile \u003d\n           (INodeFileUnderConstruction) inodes[inodes.length - 1];\n \n-      if(onRetryBlock[0] !\u003d null) {\n-        // This is a retry. Just return the last block.\n+      if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n+        // This is a retry. Just return the last block if having locations.\n         return onRetryBlock[0];\n       }\n       if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n         throw new IOException(\"File has reached the limit on maximum number of\"\n             + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n             + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n             + maxBlocksPerFile);\n       }\n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientNode \u003d pendingFile.getClientNode();\n       replication \u003d pendingFile.getFileReplication();\n     } finally {\n       readUnlock();\n     }\n \n     // choose targets for the new block to be allocated.\n     final DatanodeDescriptor targets[] \u003d getBlockManager().chooseTarget( \n         src, replication, clientNode, excludedNodes, blockSize, favoredNodes);\n \n     // Part II.\n     // Allocate a new block, add it to the INode and the BlocksMap. \n     Block newBlock \u003d null;\n     long offset;\n     checkOperation(OperationCategory.WRITE);\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       // Run the full analysis again, since things could have changed\n       // while chooseTarget() was executing.\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       INodesInPath inodesInPath \u003d\n           analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n       INode[] inodes \u003d inodesInPath.getINodes();\n       final INodeFileUnderConstruction pendingFile \u003d\n           (INodeFileUnderConstruction) inodes[inodes.length - 1];\n \n-      if(onRetryBlock[0] !\u003d null) {\n-        // This is a retry. Just return the last block.\n-        return onRetryBlock[0];\n+      if (onRetryBlock[0] !\u003d null) {\n+        if (onRetryBlock[0].getLocations().length \u003e 0) {\n+          // This is a retry. Just return the last block if having locations.\n+          return onRetryBlock[0];\n+        } else {\n+          // add new chosen targets to already allocated block and return\n+          BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n+          ((BlockInfoUnderConstruction) lastBlockInFile)\n+              .setExpectedLocations(targets);\n+          offset \u003d pendingFile.computeFileSize();\n+          return makeLocatedBlock(lastBlockInFile, targets, offset);\n+        }\n       }\n \n       // commit the last block and complete it if it has minimum replicas\n       commitOrCompleteLastBlock(pendingFile,\n                                 ExtendedBlock.getLocalBlock(previous));\n \n       // allocate new block, record block locations in INode.\n       newBlock \u003d createNewBlock();\n       saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n \n       dir.persistBlocks(src, pendingFile, false);\n       offset \u003d pendingFile.computeFileSize();\n     } finally {\n       writeUnlock();\n     }\n     if (persistBlocks) {\n       getEditLog().logSync();\n     }\n \n     // Return located block\n     return makeLocatedBlock(newBlock, targets, offset);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n      ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n      List\u003cString\u003e favoredNodes)\n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    long blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\n          \"BLOCK* NameSystem.getAdditionalBlock: file \"\n          +src+\" for \"+clientName);\n    }\n\n    // Part I. Analyze the state of the file with respect to the input data.\n    checkOperation(OperationCategory.READ);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      final INode[] inodes \u003d analyzeFileState(\n          src, fileId, clientName, previous, onRetryBlock).getINodes();\n      final INodeFileUnderConstruction pendingFile \u003d\n          (INodeFileUnderConstruction) inodes[inodes.length - 1];\n\n      if (onRetryBlock[0] !\u003d null \u0026\u0026 onRetryBlock[0].getLocations().length \u003e 0) {\n        // This is a retry. Just return the last block if having locations.\n        return onRetryBlock[0];\n      }\n      if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n        throw new IOException(\"File has reached the limit on maximum number of\"\n            + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n            + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n            + maxBlocksPerFile);\n      }\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d pendingFile.getClientNode();\n      replication \u003d pendingFile.getFileReplication();\n    } finally {\n      readUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeDescriptor targets[] \u003d getBlockManager().chooseTarget( \n        src, replication, clientNode, excludedNodes, blockSize, favoredNodes);\n\n    // Part II.\n    // Allocate a new block, add it to the INode and the BlocksMap. \n    Block newBlock \u003d null;\n    long offset;\n    checkOperation(OperationCategory.WRITE);\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      // Run the full analysis again, since things could have changed\n      // while chooseTarget() was executing.\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      INodesInPath inodesInPath \u003d\n          analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n      INode[] inodes \u003d inodesInPath.getINodes();\n      final INodeFileUnderConstruction pendingFile \u003d\n          (INodeFileUnderConstruction) inodes[inodes.length - 1];\n\n      if (onRetryBlock[0] !\u003d null) {\n        if (onRetryBlock[0].getLocations().length \u003e 0) {\n          // This is a retry. Just return the last block if having locations.\n          return onRetryBlock[0];\n        } else {\n          // add new chosen targets to already allocated block and return\n          BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n          ((BlockInfoUnderConstruction) lastBlockInFile)\n              .setExpectedLocations(targets);\n          offset \u003d pendingFile.computeFileSize();\n          return makeLocatedBlock(lastBlockInFile, targets, offset);\n        }\n      }\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile,\n                                ExtendedBlock.getLocalBlock(previous));\n\n      // allocate new block, record block locations in INode.\n      newBlock \u003d createNewBlock();\n      saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n\n      dir.persistBlocks(src, pendingFile, false);\n      offset \u003d pendingFile.computeFileSize();\n    } finally {\n      writeUnlock();\n    }\n    if (persistBlocks) {\n      getEditLog().logSync();\n    }\n\n    // Return located block\n    return makeLocatedBlock(newBlock, targets, offset);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "34f08944b7c8d58f531a3f3bf3d4ee4cd3fa643a": {
      "type": "Yparameterchange",
      "commitMessage": "merge trunk to branch HDFS-4949\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1532952 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/10/13 7:14 PM",
      "commitName": "34f08944b7c8d58f531a3f3bf3d4ee4cd3fa643a",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "16/10/13 3:15 PM",
      "commitNameOld": "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 0.17,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,92 +1,92 @@\n   LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n-      ExtendedBlock previous, HashMap\u003cNode, Node\u003e excludedNodes, \n+      ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n       List\u003cString\u003e favoredNodes)\n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n     long blockSize;\n     int replication;\n     DatanodeDescriptor clientNode \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\n           \"BLOCK* NameSystem.getAdditionalBlock: file \"\n           +src+\" for \"+clientName);\n     }\n \n     // Part I. Analyze the state of the file with respect to the input data.\n     checkOperation(OperationCategory.READ);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       final INode[] inodes \u003d analyzeFileState(\n           src, fileId, clientName, previous, onRetryBlock).getINodes();\n       final INodeFileUnderConstruction pendingFile \u003d\n           (INodeFileUnderConstruction) inodes[inodes.length - 1];\n \n       if(onRetryBlock[0] !\u003d null) {\n         // This is a retry. Just return the last block.\n         return onRetryBlock[0];\n       }\n       if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n         throw new IOException(\"File has reached the limit on maximum number of\"\n             + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n             + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n             + maxBlocksPerFile);\n       }\n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientNode \u003d pendingFile.getClientNode();\n       replication \u003d pendingFile.getFileReplication();\n     } finally {\n       readUnlock();\n     }\n \n     // choose targets for the new block to be allocated.\n     final DatanodeDescriptor targets[] \u003d getBlockManager().chooseTarget( \n         src, replication, clientNode, excludedNodes, blockSize, favoredNodes);\n \n     // Part II.\n     // Allocate a new block, add it to the INode and the BlocksMap. \n     Block newBlock \u003d null;\n     long offset;\n     checkOperation(OperationCategory.WRITE);\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       // Run the full analysis again, since things could have changed\n       // while chooseTarget() was executing.\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       INodesInPath inodesInPath \u003d\n           analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n       INode[] inodes \u003d inodesInPath.getINodes();\n       final INodeFileUnderConstruction pendingFile \u003d\n           (INodeFileUnderConstruction) inodes[inodes.length - 1];\n \n       if(onRetryBlock[0] !\u003d null) {\n         // This is a retry. Just return the last block.\n         return onRetryBlock[0];\n       }\n \n       // commit the last block and complete it if it has minimum replicas\n       commitOrCompleteLastBlock(pendingFile,\n                                 ExtendedBlock.getLocalBlock(previous));\n \n       // allocate new block, record block locations in INode.\n       newBlock \u003d createNewBlock();\n       saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n \n       dir.persistBlocks(src, pendingFile, false);\n       offset \u003d pendingFile.computeFileSize();\n     } finally {\n       writeUnlock();\n     }\n     if (persistBlocks) {\n       getEditLog().logSync();\n     }\n \n     // Return located block\n     return makeLocatedBlock(newBlock, targets, offset);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n      ExtendedBlock previous, Set\u003cNode\u003e excludedNodes, \n      List\u003cString\u003e favoredNodes)\n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    long blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\n          \"BLOCK* NameSystem.getAdditionalBlock: file \"\n          +src+\" for \"+clientName);\n    }\n\n    // Part I. Analyze the state of the file with respect to the input data.\n    checkOperation(OperationCategory.READ);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      final INode[] inodes \u003d analyzeFileState(\n          src, fileId, clientName, previous, onRetryBlock).getINodes();\n      final INodeFileUnderConstruction pendingFile \u003d\n          (INodeFileUnderConstruction) inodes[inodes.length - 1];\n\n      if(onRetryBlock[0] !\u003d null) {\n        // This is a retry. Just return the last block.\n        return onRetryBlock[0];\n      }\n      if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n        throw new IOException(\"File has reached the limit on maximum number of\"\n            + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n            + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n            + maxBlocksPerFile);\n      }\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d pendingFile.getClientNode();\n      replication \u003d pendingFile.getFileReplication();\n    } finally {\n      readUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeDescriptor targets[] \u003d getBlockManager().chooseTarget( \n        src, replication, clientNode, excludedNodes, blockSize, favoredNodes);\n\n    // Part II.\n    // Allocate a new block, add it to the INode and the BlocksMap. \n    Block newBlock \u003d null;\n    long offset;\n    checkOperation(OperationCategory.WRITE);\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      // Run the full analysis again, since things could have changed\n      // while chooseTarget() was executing.\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      INodesInPath inodesInPath \u003d\n          analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n      INode[] inodes \u003d inodesInPath.getINodes();\n      final INodeFileUnderConstruction pendingFile \u003d\n          (INodeFileUnderConstruction) inodes[inodes.length - 1];\n\n      if(onRetryBlock[0] !\u003d null) {\n        // This is a retry. Just return the last block.\n        return onRetryBlock[0];\n      }\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile,\n                                ExtendedBlock.getLocalBlock(previous));\n\n      // allocate new block, record block locations in INode.\n      newBlock \u003d createNewBlock();\n      saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n\n      dir.persistBlocks(src, pendingFile, false);\n      offset \u003d pendingFile.computeFileSize();\n    } finally {\n      writeUnlock();\n    }\n    if (persistBlocks) {\n      getEditLog().logSync();\n    }\n\n    // Return located block\n    return makeLocatedBlock(newBlock, targets, offset);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {
        "oldValue": "[src-String, fileId-long, clientName-String, previous-ExtendedBlock, excludedNodes-HashMap\u003cNode,Node\u003e, favoredNodes-List\u003cString\u003e]",
        "newValue": "[src-String, fileId-long, clientName-String, previous-ExtendedBlock, excludedNodes-Set\u003cNode\u003e, favoredNodes-List\u003cString\u003e]"
      }
    },
    "8c7a7e619699386f9e6991842558d78aa0c8053d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5025. Record ClientId and CallId in EditLog to enable rebuilding retry cache in case of HA failover. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1508332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/07/13 12:51 AM",
      "commitName": "8c7a7e619699386f9e6991842558d78aa0c8053d",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "26/07/13 4:59 PM",
      "commitNameOld": "dc17bda4b677e30c02c2a9a053895a43e41f7a12",
      "commitAuthorOld": "Konstantin Boudnik",
      "daysBetweenCommits": 3.33,
      "commitsBetweenForRepo": 18,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,92 +1,92 @@\n   LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n       ExtendedBlock previous, HashMap\u003cNode, Node\u003e excludedNodes, \n       List\u003cString\u003e favoredNodes)\n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n     long blockSize;\n     int replication;\n     DatanodeDescriptor clientNode \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\n           \"BLOCK* NameSystem.getAdditionalBlock: file \"\n           +src+\" for \"+clientName);\n     }\n \n     // Part I. Analyze the state of the file with respect to the input data.\n     checkOperation(OperationCategory.READ);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       final INode[] inodes \u003d analyzeFileState(\n           src, fileId, clientName, previous, onRetryBlock).getINodes();\n       final INodeFileUnderConstruction pendingFile \u003d\n           (INodeFileUnderConstruction) inodes[inodes.length - 1];\n \n       if(onRetryBlock[0] !\u003d null) {\n         // This is a retry. Just return the last block.\n         return onRetryBlock[0];\n       }\n       if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n         throw new IOException(\"File has reached the limit on maximum number of\"\n             + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n             + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n             + maxBlocksPerFile);\n       }\n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientNode \u003d pendingFile.getClientNode();\n       replication \u003d pendingFile.getFileReplication();\n     } finally {\n       readUnlock();\n     }\n \n     // choose targets for the new block to be allocated.\n     final DatanodeDescriptor targets[] \u003d getBlockManager().chooseTarget( \n         src, replication, clientNode, excludedNodes, blockSize, favoredNodes);\n \n     // Part II.\n     // Allocate a new block, add it to the INode and the BlocksMap. \n     Block newBlock \u003d null;\n     long offset;\n     checkOperation(OperationCategory.WRITE);\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       // Run the full analysis again, since things could have changed\n       // while chooseTarget() was executing.\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       INodesInPath inodesInPath \u003d\n           analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n       INode[] inodes \u003d inodesInPath.getINodes();\n       final INodeFileUnderConstruction pendingFile \u003d\n           (INodeFileUnderConstruction) inodes[inodes.length - 1];\n \n       if(onRetryBlock[0] !\u003d null) {\n         // This is a retry. Just return the last block.\n         return onRetryBlock[0];\n       }\n \n       // commit the last block and complete it if it has minimum replicas\n       commitOrCompleteLastBlock(pendingFile,\n                                 ExtendedBlock.getLocalBlock(previous));\n \n       // allocate new block, record block locations in INode.\n       newBlock \u003d createNewBlock();\n       saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n \n-      dir.persistBlocks(src, pendingFile);\n+      dir.persistBlocks(src, pendingFile, false);\n       offset \u003d pendingFile.computeFileSize();\n     } finally {\n       writeUnlock();\n     }\n     if (persistBlocks) {\n       getEditLog().logSync();\n     }\n \n     // Return located block\n     return makeLocatedBlock(newBlock, targets, offset);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n      ExtendedBlock previous, HashMap\u003cNode, Node\u003e excludedNodes, \n      List\u003cString\u003e favoredNodes)\n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    long blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\n          \"BLOCK* NameSystem.getAdditionalBlock: file \"\n          +src+\" for \"+clientName);\n    }\n\n    // Part I. Analyze the state of the file with respect to the input data.\n    checkOperation(OperationCategory.READ);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      final INode[] inodes \u003d analyzeFileState(\n          src, fileId, clientName, previous, onRetryBlock).getINodes();\n      final INodeFileUnderConstruction pendingFile \u003d\n          (INodeFileUnderConstruction) inodes[inodes.length - 1];\n\n      if(onRetryBlock[0] !\u003d null) {\n        // This is a retry. Just return the last block.\n        return onRetryBlock[0];\n      }\n      if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n        throw new IOException(\"File has reached the limit on maximum number of\"\n            + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n            + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n            + maxBlocksPerFile);\n      }\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d pendingFile.getClientNode();\n      replication \u003d pendingFile.getFileReplication();\n    } finally {\n      readUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeDescriptor targets[] \u003d getBlockManager().chooseTarget( \n        src, replication, clientNode, excludedNodes, blockSize, favoredNodes);\n\n    // Part II.\n    // Allocate a new block, add it to the INode and the BlocksMap. \n    Block newBlock \u003d null;\n    long offset;\n    checkOperation(OperationCategory.WRITE);\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      // Run the full analysis again, since things could have changed\n      // while chooseTarget() was executing.\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      INodesInPath inodesInPath \u003d\n          analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n      INode[] inodes \u003d inodesInPath.getINodes();\n      final INodeFileUnderConstruction pendingFile \u003d\n          (INodeFileUnderConstruction) inodes[inodes.length - 1];\n\n      if(onRetryBlock[0] !\u003d null) {\n        // This is a retry. Just return the last block.\n        return onRetryBlock[0];\n      }\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile,\n                                ExtendedBlock.getLocalBlock(previous));\n\n      // allocate new block, record block locations in INode.\n      newBlock \u003d createNewBlock();\n      saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n\n      dir.persistBlocks(src, pendingFile, false);\n      offset \u003d pendingFile.computeFileSize();\n    } finally {\n      writeUnlock();\n    }\n    if (persistBlocks) {\n      getEditLog().logSync();\n    }\n\n    // Return located block\n    return makeLocatedBlock(newBlock, targets, offset);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "ce7e5565f41eb23975eee1150e00a4cb4842a727": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4305. Add a configurable limit on number of blocks per file, and min block size. Contributed by Andrew Wang.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1477354 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/04/13 2:28 PM",
      "commitName": "ce7e5565f41eb23975eee1150e00a4cb4842a727",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "26/04/13 1:39 PM",
      "commitNameOld": "5d2ffde68e2c14ee33fa2ba4a34cb42fbd14b5ec",
      "commitAuthorOld": "Devaraj Das",
      "daysBetweenCommits": 3.03,
      "commitsBetweenForRepo": 20,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,87 +1,92 @@\n   LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n       ExtendedBlock previous, HashMap\u003cNode, Node\u003e excludedNodes, \n       List\u003cString\u003e favoredNodes)\n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n     long blockSize;\n     int replication;\n     DatanodeDescriptor clientNode \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\n           \"BLOCK* NameSystem.getAdditionalBlock: file \"\n           +src+\" for \"+clientName);\n     }\n \n     // Part I. Analyze the state of the file with respect to the input data.\n     checkOperation(OperationCategory.READ);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       final INode[] inodes \u003d analyzeFileState(\n           src, fileId, clientName, previous, onRetryBlock).getINodes();\n       final INodeFileUnderConstruction pendingFile \u003d\n           (INodeFileUnderConstruction) inodes[inodes.length - 1];\n \n       if(onRetryBlock[0] !\u003d null) {\n         // This is a retry. Just return the last block.\n         return onRetryBlock[0];\n       }\n-\n+      if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n+        throw new IOException(\"File has reached the limit on maximum number of\"\n+            + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n+            + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n+            + maxBlocksPerFile);\n+      }\n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientNode \u003d pendingFile.getClientNode();\n       replication \u003d pendingFile.getBlockReplication();\n     } finally {\n       readUnlock();\n     }\n \n     // choose targets for the new block to be allocated.\n     final DatanodeDescriptor targets[] \u003d getBlockManager().chooseTarget( \n         src, replication, clientNode, excludedNodes, blockSize, favoredNodes);\n \n     // Part II.\n     // Allocate a new block, add it to the INode and the BlocksMap. \n     Block newBlock \u003d null;\n     long offset;\n     checkOperation(OperationCategory.WRITE);\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       // Run the full analysis again, since things could have changed\n       // while chooseTarget() was executing.\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       INodesInPath inodesInPath \u003d\n           analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n       INode[] inodes \u003d inodesInPath.getINodes();\n       final INodeFileUnderConstruction pendingFile \u003d\n           (INodeFileUnderConstruction) inodes[inodes.length - 1];\n \n       if(onRetryBlock[0] !\u003d null) {\n         // This is a retry. Just return the last block.\n         return onRetryBlock[0];\n       }\n \n       // commit the last block and complete it if it has minimum replicas\n       commitOrCompleteLastBlock(pendingFile,\n                                 ExtendedBlock.getLocalBlock(previous));\n \n       // allocate new block, record block locations in INode.\n       newBlock \u003d createNewBlock();\n       saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n \n       dir.persistBlocks(src, pendingFile);\n       offset \u003d pendingFile.computeFileSize(true);\n     } finally {\n       writeUnlock();\n     }\n     if (persistBlocks) {\n       getEditLog().logSync();\n     }\n \n     // Return located block\n     return makeLocatedBlock(newBlock, targets, offset);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n      ExtendedBlock previous, HashMap\u003cNode, Node\u003e excludedNodes, \n      List\u003cString\u003e favoredNodes)\n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    long blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\n          \"BLOCK* NameSystem.getAdditionalBlock: file \"\n          +src+\" for \"+clientName);\n    }\n\n    // Part I. Analyze the state of the file with respect to the input data.\n    checkOperation(OperationCategory.READ);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      final INode[] inodes \u003d analyzeFileState(\n          src, fileId, clientName, previous, onRetryBlock).getINodes();\n      final INodeFileUnderConstruction pendingFile \u003d\n          (INodeFileUnderConstruction) inodes[inodes.length - 1];\n\n      if(onRetryBlock[0] !\u003d null) {\n        // This is a retry. Just return the last block.\n        return onRetryBlock[0];\n      }\n      if (pendingFile.getBlocks().length \u003e\u003d maxBlocksPerFile) {\n        throw new IOException(\"File has reached the limit on maximum number of\"\n            + \" blocks (\" + DFSConfigKeys.DFS_NAMENODE_MAX_BLOCKS_PER_FILE_KEY\n            + \"): \" + pendingFile.getBlocks().length + \" \u003e\u003d \"\n            + maxBlocksPerFile);\n      }\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d pendingFile.getClientNode();\n      replication \u003d pendingFile.getBlockReplication();\n    } finally {\n      readUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeDescriptor targets[] \u003d getBlockManager().chooseTarget( \n        src, replication, clientNode, excludedNodes, blockSize, favoredNodes);\n\n    // Part II.\n    // Allocate a new block, add it to the INode and the BlocksMap. \n    Block newBlock \u003d null;\n    long offset;\n    checkOperation(OperationCategory.WRITE);\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      // Run the full analysis again, since things could have changed\n      // while chooseTarget() was executing.\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      INodesInPath inodesInPath \u003d\n          analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n      INode[] inodes \u003d inodesInPath.getINodes();\n      final INodeFileUnderConstruction pendingFile \u003d\n          (INodeFileUnderConstruction) inodes[inodes.length - 1];\n\n      if(onRetryBlock[0] !\u003d null) {\n        // This is a retry. Just return the last block.\n        return onRetryBlock[0];\n      }\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile,\n                                ExtendedBlock.getLocalBlock(previous));\n\n      // allocate new block, record block locations in INode.\n      newBlock \u003d createNewBlock();\n      saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n\n      dir.persistBlocks(src, pendingFile);\n      offset \u003d pendingFile.computeFileSize(true);\n    } finally {\n      writeUnlock();\n    }\n    if (persistBlocks) {\n      getEditLog().logSync();\n    }\n\n    // Return located block\n    return makeLocatedBlock(newBlock, targets, offset);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "5d2ffde68e2c14ee33fa2ba4a34cb42fbd14b5ec": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-2576. Enhances the DistributedFileSystem\u0027s create API so that clients can specify favored datanodes for a file\u0027s blocks. Contributed by Devaraj Das and Pritam Damania.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1476395 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/04/13 1:39 PM",
      "commitName": "5d2ffde68e2c14ee33fa2ba4a34cb42fbd14b5ec",
      "commitAuthor": "Devaraj Das",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-2576. Enhances the DistributedFileSystem\u0027s create API so that clients can specify favored datanodes for a file\u0027s blocks. Contributed by Devaraj Das and Pritam Damania.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1476395 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "26/04/13 1:39 PM",
          "commitName": "5d2ffde68e2c14ee33fa2ba4a34cb42fbd14b5ec",
          "commitAuthor": "Devaraj Das",
          "commitDateOld": "18/04/13 5:10 PM",
          "commitNameOld": "980e6c54bab4ffc87e168cd5c217fef44c72a878",
          "commitAuthorOld": "Suresh Srinivas",
          "daysBetweenCommits": 7.85,
          "commitsBetweenForRepo": 42,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,86 +1,87 @@\n   LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n-      ExtendedBlock previous, HashMap\u003cNode, Node\u003e excludedNodes)\n+      ExtendedBlock previous, HashMap\u003cNode, Node\u003e excludedNodes, \n+      List\u003cString\u003e favoredNodes)\n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n     long blockSize;\n     int replication;\n     DatanodeDescriptor clientNode \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\n           \"BLOCK* NameSystem.getAdditionalBlock: file \"\n           +src+\" for \"+clientName);\n     }\n \n     // Part I. Analyze the state of the file with respect to the input data.\n     checkOperation(OperationCategory.READ);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       final INode[] inodes \u003d analyzeFileState(\n           src, fileId, clientName, previous, onRetryBlock).getINodes();\n       final INodeFileUnderConstruction pendingFile \u003d\n           (INodeFileUnderConstruction) inodes[inodes.length - 1];\n \n       if(onRetryBlock[0] !\u003d null) {\n         // This is a retry. Just return the last block.\n         return onRetryBlock[0];\n       }\n \n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientNode \u003d pendingFile.getClientNode();\n       replication \u003d pendingFile.getBlockReplication();\n     } finally {\n       readUnlock();\n     }\n \n     // choose targets for the new block to be allocated.\n-    final DatanodeDescriptor targets[] \u003d getBlockManager().chooseTarget(\n-        src, replication, clientNode, excludedNodes, blockSize);\n+    final DatanodeDescriptor targets[] \u003d getBlockManager().chooseTarget( \n+        src, replication, clientNode, excludedNodes, blockSize, favoredNodes);\n \n     // Part II.\n     // Allocate a new block, add it to the INode and the BlocksMap. \n     Block newBlock \u003d null;\n     long offset;\n     checkOperation(OperationCategory.WRITE);\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       // Run the full analysis again, since things could have changed\n       // while chooseTarget() was executing.\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       INodesInPath inodesInPath \u003d\n           analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n       INode[] inodes \u003d inodesInPath.getINodes();\n       final INodeFileUnderConstruction pendingFile \u003d\n           (INodeFileUnderConstruction) inodes[inodes.length - 1];\n \n       if(onRetryBlock[0] !\u003d null) {\n         // This is a retry. Just return the last block.\n         return onRetryBlock[0];\n       }\n \n       // commit the last block and complete it if it has minimum replicas\n       commitOrCompleteLastBlock(pendingFile,\n                                 ExtendedBlock.getLocalBlock(previous));\n \n       // allocate new block, record block locations in INode.\n       newBlock \u003d createNewBlock();\n       saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n \n       dir.persistBlocks(src, pendingFile);\n       offset \u003d pendingFile.computeFileSize(true);\n     } finally {\n       writeUnlock();\n     }\n     if (persistBlocks) {\n       getEditLog().logSync();\n     }\n \n     // Return located block\n     return makeLocatedBlock(newBlock, targets, offset);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n      ExtendedBlock previous, HashMap\u003cNode, Node\u003e excludedNodes, \n      List\u003cString\u003e favoredNodes)\n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    long blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\n          \"BLOCK* NameSystem.getAdditionalBlock: file \"\n          +src+\" for \"+clientName);\n    }\n\n    // Part I. Analyze the state of the file with respect to the input data.\n    checkOperation(OperationCategory.READ);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      final INode[] inodes \u003d analyzeFileState(\n          src, fileId, clientName, previous, onRetryBlock).getINodes();\n      final INodeFileUnderConstruction pendingFile \u003d\n          (INodeFileUnderConstruction) inodes[inodes.length - 1];\n\n      if(onRetryBlock[0] !\u003d null) {\n        // This is a retry. Just return the last block.\n        return onRetryBlock[0];\n      }\n\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d pendingFile.getClientNode();\n      replication \u003d pendingFile.getBlockReplication();\n    } finally {\n      readUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeDescriptor targets[] \u003d getBlockManager().chooseTarget( \n        src, replication, clientNode, excludedNodes, blockSize, favoredNodes);\n\n    // Part II.\n    // Allocate a new block, add it to the INode and the BlocksMap. \n    Block newBlock \u003d null;\n    long offset;\n    checkOperation(OperationCategory.WRITE);\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      // Run the full analysis again, since things could have changed\n      // while chooseTarget() was executing.\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      INodesInPath inodesInPath \u003d\n          analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n      INode[] inodes \u003d inodesInPath.getINodes();\n      final INodeFileUnderConstruction pendingFile \u003d\n          (INodeFileUnderConstruction) inodes[inodes.length - 1];\n\n      if(onRetryBlock[0] !\u003d null) {\n        // This is a retry. Just return the last block.\n        return onRetryBlock[0];\n      }\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile,\n                                ExtendedBlock.getLocalBlock(previous));\n\n      // allocate new block, record block locations in INode.\n      newBlock \u003d createNewBlock();\n      saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n\n      dir.persistBlocks(src, pendingFile);\n      offset \u003d pendingFile.computeFileSize(true);\n    } finally {\n      writeUnlock();\n    }\n    if (persistBlocks) {\n      getEditLog().logSync();\n    }\n\n    // Return located block\n    return makeLocatedBlock(newBlock, targets, offset);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {
            "oldValue": "[src-String, fileId-long, clientName-String, previous-ExtendedBlock, excludedNodes-HashMap\u003cNode,Node\u003e]",
            "newValue": "[src-String, fileId-long, clientName-String, previous-ExtendedBlock, excludedNodes-HashMap\u003cNode,Node\u003e, favoredNodes-List\u003cString\u003e]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-2576. Enhances the DistributedFileSystem\u0027s create API so that clients can specify favored datanodes for a file\u0027s blocks. Contributed by Devaraj Das and Pritam Damania.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1476395 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "26/04/13 1:39 PM",
          "commitName": "5d2ffde68e2c14ee33fa2ba4a34cb42fbd14b5ec",
          "commitAuthor": "Devaraj Das",
          "commitDateOld": "18/04/13 5:10 PM",
          "commitNameOld": "980e6c54bab4ffc87e168cd5c217fef44c72a878",
          "commitAuthorOld": "Suresh Srinivas",
          "daysBetweenCommits": 7.85,
          "commitsBetweenForRepo": 42,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,86 +1,87 @@\n   LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n-      ExtendedBlock previous, HashMap\u003cNode, Node\u003e excludedNodes)\n+      ExtendedBlock previous, HashMap\u003cNode, Node\u003e excludedNodes, \n+      List\u003cString\u003e favoredNodes)\n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n     long blockSize;\n     int replication;\n     DatanodeDescriptor clientNode \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\n           \"BLOCK* NameSystem.getAdditionalBlock: file \"\n           +src+\" for \"+clientName);\n     }\n \n     // Part I. Analyze the state of the file with respect to the input data.\n     checkOperation(OperationCategory.READ);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       final INode[] inodes \u003d analyzeFileState(\n           src, fileId, clientName, previous, onRetryBlock).getINodes();\n       final INodeFileUnderConstruction pendingFile \u003d\n           (INodeFileUnderConstruction) inodes[inodes.length - 1];\n \n       if(onRetryBlock[0] !\u003d null) {\n         // This is a retry. Just return the last block.\n         return onRetryBlock[0];\n       }\n \n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientNode \u003d pendingFile.getClientNode();\n       replication \u003d pendingFile.getBlockReplication();\n     } finally {\n       readUnlock();\n     }\n \n     // choose targets for the new block to be allocated.\n-    final DatanodeDescriptor targets[] \u003d getBlockManager().chooseTarget(\n-        src, replication, clientNode, excludedNodes, blockSize);\n+    final DatanodeDescriptor targets[] \u003d getBlockManager().chooseTarget( \n+        src, replication, clientNode, excludedNodes, blockSize, favoredNodes);\n \n     // Part II.\n     // Allocate a new block, add it to the INode and the BlocksMap. \n     Block newBlock \u003d null;\n     long offset;\n     checkOperation(OperationCategory.WRITE);\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       // Run the full analysis again, since things could have changed\n       // while chooseTarget() was executing.\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       INodesInPath inodesInPath \u003d\n           analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n       INode[] inodes \u003d inodesInPath.getINodes();\n       final INodeFileUnderConstruction pendingFile \u003d\n           (INodeFileUnderConstruction) inodes[inodes.length - 1];\n \n       if(onRetryBlock[0] !\u003d null) {\n         // This is a retry. Just return the last block.\n         return onRetryBlock[0];\n       }\n \n       // commit the last block and complete it if it has minimum replicas\n       commitOrCompleteLastBlock(pendingFile,\n                                 ExtendedBlock.getLocalBlock(previous));\n \n       // allocate new block, record block locations in INode.\n       newBlock \u003d createNewBlock();\n       saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n \n       dir.persistBlocks(src, pendingFile);\n       offset \u003d pendingFile.computeFileSize(true);\n     } finally {\n       writeUnlock();\n     }\n     if (persistBlocks) {\n       getEditLog().logSync();\n     }\n \n     // Return located block\n     return makeLocatedBlock(newBlock, targets, offset);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n      ExtendedBlock previous, HashMap\u003cNode, Node\u003e excludedNodes, \n      List\u003cString\u003e favoredNodes)\n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    long blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\n          \"BLOCK* NameSystem.getAdditionalBlock: file \"\n          +src+\" for \"+clientName);\n    }\n\n    // Part I. Analyze the state of the file with respect to the input data.\n    checkOperation(OperationCategory.READ);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      final INode[] inodes \u003d analyzeFileState(\n          src, fileId, clientName, previous, onRetryBlock).getINodes();\n      final INodeFileUnderConstruction pendingFile \u003d\n          (INodeFileUnderConstruction) inodes[inodes.length - 1];\n\n      if(onRetryBlock[0] !\u003d null) {\n        // This is a retry. Just return the last block.\n        return onRetryBlock[0];\n      }\n\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d pendingFile.getClientNode();\n      replication \u003d pendingFile.getBlockReplication();\n    } finally {\n      readUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeDescriptor targets[] \u003d getBlockManager().chooseTarget( \n        src, replication, clientNode, excludedNodes, blockSize, favoredNodes);\n\n    // Part II.\n    // Allocate a new block, add it to the INode and the BlocksMap. \n    Block newBlock \u003d null;\n    long offset;\n    checkOperation(OperationCategory.WRITE);\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      // Run the full analysis again, since things could have changed\n      // while chooseTarget() was executing.\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      INodesInPath inodesInPath \u003d\n          analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n      INode[] inodes \u003d inodesInPath.getINodes();\n      final INodeFileUnderConstruction pendingFile \u003d\n          (INodeFileUnderConstruction) inodes[inodes.length - 1];\n\n      if(onRetryBlock[0] !\u003d null) {\n        // This is a retry. Just return the last block.\n        return onRetryBlock[0];\n      }\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile,\n                                ExtendedBlock.getLocalBlock(previous));\n\n      // allocate new block, record block locations in INode.\n      newBlock \u003d createNewBlock();\n      saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n\n      dir.persistBlocks(src, pendingFile);\n      offset \u003d pendingFile.computeFileSize(true);\n    } finally {\n      writeUnlock();\n    }\n    if (persistBlocks) {\n      getEditLog().logSync();\n    }\n\n    // Return located block\n    return makeLocatedBlock(newBlock, targets, offset);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "980e6c54bab4ffc87e168cd5c217fef44c72a878": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4434. Provide a mapping from INodeId to INode. Contributed by Suresh Srinivas.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1469644 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/04/13 5:10 PM",
      "commitName": "980e6c54bab4ffc87e168cd5c217fef44c72a878",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "12/04/13 6:35 PM",
      "commitNameOld": "242028a3fb887708dea5ef557c0ded22e014ac7d",
      "commitAuthorOld": "Konstantin Shvachko",
      "daysBetweenCommits": 5.94,
      "commitsBetweenForRepo": 22,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,84 +1,86 @@\n   LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n       ExtendedBlock previous, HashMap\u003cNode, Node\u003e excludedNodes)\n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n     long blockSize;\n     int replication;\n     DatanodeDescriptor clientNode \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\n           \"BLOCK* NameSystem.getAdditionalBlock: file \"\n           +src+\" for \"+clientName);\n     }\n \n     // Part I. Analyze the state of the file with respect to the input data.\n     checkOperation(OperationCategory.READ);\n+    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n+      src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       final INode[] inodes \u003d analyzeFileState(\n           src, fileId, clientName, previous, onRetryBlock).getINodes();\n       final INodeFileUnderConstruction pendingFile \u003d\n           (INodeFileUnderConstruction) inodes[inodes.length - 1];\n \n       if(onRetryBlock[0] !\u003d null) {\n         // This is a retry. Just return the last block.\n         return onRetryBlock[0];\n       }\n \n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientNode \u003d pendingFile.getClientNode();\n       replication \u003d pendingFile.getBlockReplication();\n     } finally {\n       readUnlock();\n     }\n \n     // choose targets for the new block to be allocated.\n     final DatanodeDescriptor targets[] \u003d getBlockManager().chooseTarget(\n         src, replication, clientNode, excludedNodes, blockSize);\n \n     // Part II.\n     // Allocate a new block, add it to the INode and the BlocksMap. \n     Block newBlock \u003d null;\n     long offset;\n     checkOperation(OperationCategory.WRITE);\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       // Run the full analysis again, since things could have changed\n       // while chooseTarget() was executing.\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       INodesInPath inodesInPath \u003d\n           analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n       INode[] inodes \u003d inodesInPath.getINodes();\n       final INodeFileUnderConstruction pendingFile \u003d\n           (INodeFileUnderConstruction) inodes[inodes.length - 1];\n \n       if(onRetryBlock[0] !\u003d null) {\n         // This is a retry. Just return the last block.\n         return onRetryBlock[0];\n       }\n \n       // commit the last block and complete it if it has minimum replicas\n       commitOrCompleteLastBlock(pendingFile,\n                                 ExtendedBlock.getLocalBlock(previous));\n \n       // allocate new block, record block locations in INode.\n       newBlock \u003d createNewBlock();\n       saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n \n       dir.persistBlocks(src, pendingFile);\n       offset \u003d pendingFile.computeFileSize(true);\n     } finally {\n       writeUnlock();\n     }\n     if (persistBlocks) {\n       getEditLog().logSync();\n     }\n \n     // Return located block\n     return makeLocatedBlock(newBlock, targets, offset);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n      ExtendedBlock previous, HashMap\u003cNode, Node\u003e excludedNodes)\n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    long blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\n          \"BLOCK* NameSystem.getAdditionalBlock: file \"\n          +src+\" for \"+clientName);\n    }\n\n    // Part I. Analyze the state of the file with respect to the input data.\n    checkOperation(OperationCategory.READ);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      final INode[] inodes \u003d analyzeFileState(\n          src, fileId, clientName, previous, onRetryBlock).getINodes();\n      final INodeFileUnderConstruction pendingFile \u003d\n          (INodeFileUnderConstruction) inodes[inodes.length - 1];\n\n      if(onRetryBlock[0] !\u003d null) {\n        // This is a retry. Just return the last block.\n        return onRetryBlock[0];\n      }\n\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d pendingFile.getClientNode();\n      replication \u003d pendingFile.getBlockReplication();\n    } finally {\n      readUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeDescriptor targets[] \u003d getBlockManager().chooseTarget(\n        src, replication, clientNode, excludedNodes, blockSize);\n\n    // Part II.\n    // Allocate a new block, add it to the INode and the BlocksMap. \n    Block newBlock \u003d null;\n    long offset;\n    checkOperation(OperationCategory.WRITE);\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      // Run the full analysis again, since things could have changed\n      // while chooseTarget() was executing.\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      INodesInPath inodesInPath \u003d\n          analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n      INode[] inodes \u003d inodesInPath.getINodes();\n      final INodeFileUnderConstruction pendingFile \u003d\n          (INodeFileUnderConstruction) inodes[inodes.length - 1];\n\n      if(onRetryBlock[0] !\u003d null) {\n        // This is a retry. Just return the last block.\n        return onRetryBlock[0];\n      }\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile,\n                                ExtendedBlock.getLocalBlock(previous));\n\n      // allocate new block, record block locations in INode.\n      newBlock \u003d createNewBlock();\n      saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n\n      dir.persistBlocks(src, pendingFile);\n      offset \u003d pendingFile.computeFileSize(true);\n    } finally {\n      writeUnlock();\n    }\n    if (persistBlocks) {\n      getEditLog().logSync();\n    }\n\n    // Return located block\n    return makeLocatedBlock(newBlock, targets, offset);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "3bf09c51501a23b7fa28fd0a0c4c0965858d026c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4591. HA clients can fail to fail over while Standby NN is performing long checkpoint. Contributed by Aaron T. Myers.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1456107 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/03/13 12:51 PM",
      "commitName": "3bf09c51501a23b7fa28fd0a0c4c0965858d026c",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "12/03/13 7:32 PM",
      "commitNameOld": "86a940f7adc5bd9c9eaea2283df5e014e5079ab6",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 0.72,
      "commitsBetweenForRepo": 9,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,80 +1,84 @@\n   LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n       ExtendedBlock previous, HashMap\u003cNode, Node\u003e excludedNodes)\n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n     long blockSize;\n     int replication;\n     DatanodeDescriptor clientNode \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\n           \"BLOCK* NameSystem.getAdditionalBlock: file \"\n           +src+\" for \"+clientName);\n     }\n \n     // Part I. Analyze the state of the file with respect to the input data.\n+    checkOperation(OperationCategory.READ);\n     readLock();\n     try {\n+      checkOperation(OperationCategory.READ);\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       final INode[] inodes \u003d analyzeFileState(\n           src, fileId, clientName, previous, onRetryBlock).getINodes();\n       final INodeFileUnderConstruction pendingFile \u003d\n           (INodeFileUnderConstruction) inodes[inodes.length - 1];\n \n       if(onRetryBlock[0] !\u003d null) {\n         // This is a retry. Just return the last block.\n         return onRetryBlock[0];\n       }\n \n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientNode \u003d pendingFile.getClientNode();\n       replication \u003d pendingFile.getBlockReplication();\n     } finally {\n       readUnlock();\n     }\n \n     // choose targets for the new block to be allocated.\n     final DatanodeDescriptor targets[] \u003d getBlockManager().chooseTarget(\n         src, replication, clientNode, excludedNodes, blockSize);\n \n     // Part II.\n     // Allocate a new block, add it to the INode and the BlocksMap. \n     Block newBlock \u003d null;\n     long offset;\n+    checkOperation(OperationCategory.WRITE);\n     writeLock();\n     try {\n+      checkOperation(OperationCategory.WRITE);\n       // Run the full analysis again, since things could have changed\n       // while chooseTarget() was executing.\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       INodesInPath inodesInPath \u003d\n           analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n       INode[] inodes \u003d inodesInPath.getINodes();\n       final INodeFileUnderConstruction pendingFile \u003d\n           (INodeFileUnderConstruction) inodes[inodes.length - 1];\n \n       if(onRetryBlock[0] !\u003d null) {\n         // This is a retry. Just return the last block.\n         return onRetryBlock[0];\n       }\n \n       // commit the last block and complete it if it has minimum replicas\n       commitOrCompleteLastBlock(pendingFile,\n                                 ExtendedBlock.getLocalBlock(previous));\n \n       // allocate new block, record block locations in INode.\n       newBlock \u003d createNewBlock();\n       saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n \n       dir.persistBlocks(src, pendingFile);\n       offset \u003d pendingFile.computeFileSize(true);\n     } finally {\n       writeUnlock();\n     }\n     if (persistBlocks) {\n       getEditLog().logSync();\n     }\n \n     // Return located block\n     return makeLocatedBlock(newBlock, targets, offset);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n      ExtendedBlock previous, HashMap\u003cNode, Node\u003e excludedNodes)\n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    long blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\n          \"BLOCK* NameSystem.getAdditionalBlock: file \"\n          +src+\" for \"+clientName);\n    }\n\n    // Part I. Analyze the state of the file with respect to the input data.\n    checkOperation(OperationCategory.READ);\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      final INode[] inodes \u003d analyzeFileState(\n          src, fileId, clientName, previous, onRetryBlock).getINodes();\n      final INodeFileUnderConstruction pendingFile \u003d\n          (INodeFileUnderConstruction) inodes[inodes.length - 1];\n\n      if(onRetryBlock[0] !\u003d null) {\n        // This is a retry. Just return the last block.\n        return onRetryBlock[0];\n      }\n\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d pendingFile.getClientNode();\n      replication \u003d pendingFile.getBlockReplication();\n    } finally {\n      readUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeDescriptor targets[] \u003d getBlockManager().chooseTarget(\n        src, replication, clientNode, excludedNodes, blockSize);\n\n    // Part II.\n    // Allocate a new block, add it to the INode and the BlocksMap. \n    Block newBlock \u003d null;\n    long offset;\n    checkOperation(OperationCategory.WRITE);\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      // Run the full analysis again, since things could have changed\n      // while chooseTarget() was executing.\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      INodesInPath inodesInPath \u003d\n          analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n      INode[] inodes \u003d inodesInPath.getINodes();\n      final INodeFileUnderConstruction pendingFile \u003d\n          (INodeFileUnderConstruction) inodes[inodes.length - 1];\n\n      if(onRetryBlock[0] !\u003d null) {\n        // This is a retry. Just return the last block.\n        return onRetryBlock[0];\n      }\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile,\n                                ExtendedBlock.getLocalBlock(previous));\n\n      // allocate new block, record block locations in INode.\n      newBlock \u003d createNewBlock();\n      saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n\n      dir.persistBlocks(src, pendingFile);\n      offset \u003d pendingFile.computeFileSize(true);\n    } finally {\n      writeUnlock();\n    }\n    if (persistBlocks) {\n      getEditLog().logSync();\n    }\n\n    // Return located block\n    return makeLocatedBlock(newBlock, targets, offset);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "4525c4a25ba90163c9543116e2bd54239e0dd097": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-4340. Update addBlock() to inculde inode id as additional argument. Contributed Brandon Li.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1443169 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/02/13 11:52 AM",
      "commitName": "4525c4a25ba90163c9543116e2bd54239e0dd097",
      "commitAuthor": "Suresh Srinivas",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-4340. Update addBlock() to inculde inode id as additional argument. Contributed Brandon Li.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1443169 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "06/02/13 11:52 AM",
          "commitName": "4525c4a25ba90163c9543116e2bd54239e0dd097",
          "commitAuthor": "Suresh Srinivas",
          "commitDateOld": "02/02/13 2:18 PM",
          "commitNameOld": "8590564dc56195cb2caa245e3ee1c06eca3938d3",
          "commitAuthorOld": "Suresh Srinivas",
          "daysBetweenCommits": 3.9,
          "commitsBetweenForRepo": 20,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,83 +1,80 @@\n-  LocatedBlock getAdditionalBlock(String src,\n-                                         String clientName,\n-                                         ExtendedBlock previous,\n-                                         HashMap\u003cNode, Node\u003e excludedNodes\n-                                         ) \n+  LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n+      ExtendedBlock previous, HashMap\u003cNode, Node\u003e excludedNodes)\n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n     long blockSize;\n     int replication;\n     DatanodeDescriptor clientNode \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\n           \"BLOCK* NameSystem.getAdditionalBlock: file \"\n           +src+\" for \"+clientName);\n     }\n \n     // Part I. Analyze the state of the file with respect to the input data.\n     readLock();\n     try {\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       final INode[] inodes \u003d analyzeFileState(\n-          src, clientName, previous, onRetryBlock).getINodes();\n+          src, fileId, clientName, previous, onRetryBlock).getINodes();\n       final INodeFileUnderConstruction pendingFile \u003d\n           (INodeFileUnderConstruction) inodes[inodes.length - 1];\n \n       if(onRetryBlock[0] !\u003d null) {\n         // This is a retry. Just return the last block.\n         return onRetryBlock[0];\n       }\n \n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientNode \u003d pendingFile.getClientNode();\n       replication \u003d pendingFile.getBlockReplication();\n     } finally {\n       readUnlock();\n     }\n \n     // choose targets for the new block to be allocated.\n     final DatanodeDescriptor targets[] \u003d getBlockManager().chooseTarget(\n         src, replication, clientNode, excludedNodes, blockSize);\n \n     // Part II.\n     // Allocate a new block, add it to the INode and the BlocksMap. \n     Block newBlock \u003d null;\n     long offset;\n     writeLock();\n     try {\n       // Run the full analysis again, since things could have changed\n       // while chooseTarget() was executing.\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       INodesInPath inodesInPath \u003d\n-          analyzeFileState(src, clientName, previous, onRetryBlock);\n+          analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n       INode[] inodes \u003d inodesInPath.getINodes();\n       final INodeFileUnderConstruction pendingFile \u003d\n           (INodeFileUnderConstruction) inodes[inodes.length - 1];\n \n       if(onRetryBlock[0] !\u003d null) {\n         // This is a retry. Just return the last block.\n         return onRetryBlock[0];\n       }\n \n       // commit the last block and complete it if it has minimum replicas\n       commitOrCompleteLastBlock(pendingFile,\n                                 ExtendedBlock.getLocalBlock(previous));\n \n       // allocate new block, record block locations in INode.\n       newBlock \u003d createNewBlock();\n       saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n \n       dir.persistBlocks(src, pendingFile);\n       offset \u003d pendingFile.computeFileSize(true);\n     } finally {\n       writeUnlock();\n     }\n     if (persistBlocks) {\n       getEditLog().logSync();\n     }\n \n     // Return located block\n     return makeLocatedBlock(newBlock, targets, offset);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n      ExtendedBlock previous, HashMap\u003cNode, Node\u003e excludedNodes)\n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    long blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\n          \"BLOCK* NameSystem.getAdditionalBlock: file \"\n          +src+\" for \"+clientName);\n    }\n\n    // Part I. Analyze the state of the file with respect to the input data.\n    readLock();\n    try {\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      final INode[] inodes \u003d analyzeFileState(\n          src, fileId, clientName, previous, onRetryBlock).getINodes();\n      final INodeFileUnderConstruction pendingFile \u003d\n          (INodeFileUnderConstruction) inodes[inodes.length - 1];\n\n      if(onRetryBlock[0] !\u003d null) {\n        // This is a retry. Just return the last block.\n        return onRetryBlock[0];\n      }\n\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d pendingFile.getClientNode();\n      replication \u003d pendingFile.getBlockReplication();\n    } finally {\n      readUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeDescriptor targets[] \u003d getBlockManager().chooseTarget(\n        src, replication, clientNode, excludedNodes, blockSize);\n\n    // Part II.\n    // Allocate a new block, add it to the INode and the BlocksMap. \n    Block newBlock \u003d null;\n    long offset;\n    writeLock();\n    try {\n      // Run the full analysis again, since things could have changed\n      // while chooseTarget() was executing.\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      INodesInPath inodesInPath \u003d\n          analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n      INode[] inodes \u003d inodesInPath.getINodes();\n      final INodeFileUnderConstruction pendingFile \u003d\n          (INodeFileUnderConstruction) inodes[inodes.length - 1];\n\n      if(onRetryBlock[0] !\u003d null) {\n        // This is a retry. Just return the last block.\n        return onRetryBlock[0];\n      }\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile,\n                                ExtendedBlock.getLocalBlock(previous));\n\n      // allocate new block, record block locations in INode.\n      newBlock \u003d createNewBlock();\n      saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n\n      dir.persistBlocks(src, pendingFile);\n      offset \u003d pendingFile.computeFileSize(true);\n    } finally {\n      writeUnlock();\n    }\n    if (persistBlocks) {\n      getEditLog().logSync();\n    }\n\n    // Return located block\n    return makeLocatedBlock(newBlock, targets, offset);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {
            "oldValue": "[src-String, clientName-String, previous-ExtendedBlock, excludedNodes-HashMap\u003cNode,Node\u003e]",
            "newValue": "[src-String, fileId-long, clientName-String, previous-ExtendedBlock, excludedNodes-HashMap\u003cNode,Node\u003e]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-4340. Update addBlock() to inculde inode id as additional argument. Contributed Brandon Li.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1443169 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "06/02/13 11:52 AM",
          "commitName": "4525c4a25ba90163c9543116e2bd54239e0dd097",
          "commitAuthor": "Suresh Srinivas",
          "commitDateOld": "02/02/13 2:18 PM",
          "commitNameOld": "8590564dc56195cb2caa245e3ee1c06eca3938d3",
          "commitAuthorOld": "Suresh Srinivas",
          "daysBetweenCommits": 3.9,
          "commitsBetweenForRepo": 20,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,83 +1,80 @@\n-  LocatedBlock getAdditionalBlock(String src,\n-                                         String clientName,\n-                                         ExtendedBlock previous,\n-                                         HashMap\u003cNode, Node\u003e excludedNodes\n-                                         ) \n+  LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n+      ExtendedBlock previous, HashMap\u003cNode, Node\u003e excludedNodes)\n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n     long blockSize;\n     int replication;\n     DatanodeDescriptor clientNode \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\n           \"BLOCK* NameSystem.getAdditionalBlock: file \"\n           +src+\" for \"+clientName);\n     }\n \n     // Part I. Analyze the state of the file with respect to the input data.\n     readLock();\n     try {\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       final INode[] inodes \u003d analyzeFileState(\n-          src, clientName, previous, onRetryBlock).getINodes();\n+          src, fileId, clientName, previous, onRetryBlock).getINodes();\n       final INodeFileUnderConstruction pendingFile \u003d\n           (INodeFileUnderConstruction) inodes[inodes.length - 1];\n \n       if(onRetryBlock[0] !\u003d null) {\n         // This is a retry. Just return the last block.\n         return onRetryBlock[0];\n       }\n \n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientNode \u003d pendingFile.getClientNode();\n       replication \u003d pendingFile.getBlockReplication();\n     } finally {\n       readUnlock();\n     }\n \n     // choose targets for the new block to be allocated.\n     final DatanodeDescriptor targets[] \u003d getBlockManager().chooseTarget(\n         src, replication, clientNode, excludedNodes, blockSize);\n \n     // Part II.\n     // Allocate a new block, add it to the INode and the BlocksMap. \n     Block newBlock \u003d null;\n     long offset;\n     writeLock();\n     try {\n       // Run the full analysis again, since things could have changed\n       // while chooseTarget() was executing.\n       LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n       INodesInPath inodesInPath \u003d\n-          analyzeFileState(src, clientName, previous, onRetryBlock);\n+          analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n       INode[] inodes \u003d inodesInPath.getINodes();\n       final INodeFileUnderConstruction pendingFile \u003d\n           (INodeFileUnderConstruction) inodes[inodes.length - 1];\n \n       if(onRetryBlock[0] !\u003d null) {\n         // This is a retry. Just return the last block.\n         return onRetryBlock[0];\n       }\n \n       // commit the last block and complete it if it has minimum replicas\n       commitOrCompleteLastBlock(pendingFile,\n                                 ExtendedBlock.getLocalBlock(previous));\n \n       // allocate new block, record block locations in INode.\n       newBlock \u003d createNewBlock();\n       saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n \n       dir.persistBlocks(src, pendingFile);\n       offset \u003d pendingFile.computeFileSize(true);\n     } finally {\n       writeUnlock();\n     }\n     if (persistBlocks) {\n       getEditLog().logSync();\n     }\n \n     // Return located block\n     return makeLocatedBlock(newBlock, targets, offset);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  LocatedBlock getAdditionalBlock(String src, long fileId, String clientName,\n      ExtendedBlock previous, HashMap\u003cNode, Node\u003e excludedNodes)\n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    long blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\n          \"BLOCK* NameSystem.getAdditionalBlock: file \"\n          +src+\" for \"+clientName);\n    }\n\n    // Part I. Analyze the state of the file with respect to the input data.\n    readLock();\n    try {\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      final INode[] inodes \u003d analyzeFileState(\n          src, fileId, clientName, previous, onRetryBlock).getINodes();\n      final INodeFileUnderConstruction pendingFile \u003d\n          (INodeFileUnderConstruction) inodes[inodes.length - 1];\n\n      if(onRetryBlock[0] !\u003d null) {\n        // This is a retry. Just return the last block.\n        return onRetryBlock[0];\n      }\n\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d pendingFile.getClientNode();\n      replication \u003d pendingFile.getBlockReplication();\n    } finally {\n      readUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeDescriptor targets[] \u003d getBlockManager().chooseTarget(\n        src, replication, clientNode, excludedNodes, blockSize);\n\n    // Part II.\n    // Allocate a new block, add it to the INode and the BlocksMap. \n    Block newBlock \u003d null;\n    long offset;\n    writeLock();\n    try {\n      // Run the full analysis again, since things could have changed\n      // while chooseTarget() was executing.\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      INodesInPath inodesInPath \u003d\n          analyzeFileState(src, fileId, clientName, previous, onRetryBlock);\n      INode[] inodes \u003d inodesInPath.getINodes();\n      final INodeFileUnderConstruction pendingFile \u003d\n          (INodeFileUnderConstruction) inodes[inodes.length - 1];\n\n      if(onRetryBlock[0] !\u003d null) {\n        // This is a retry. Just return the last block.\n        return onRetryBlock[0];\n      }\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile,\n                                ExtendedBlock.getLocalBlock(previous));\n\n      // allocate new block, record block locations in INode.\n      newBlock \u003d createNewBlock();\n      saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n\n      dir.persistBlocks(src, pendingFile);\n      offset \u003d pendingFile.computeFileSize(true);\n    } finally {\n      writeUnlock();\n    }\n    if (persistBlocks) {\n      getEditLog().logSync();\n    }\n\n    // Return located block\n    return makeLocatedBlock(newBlock, targets, offset);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "61a262757ca70f30956b467ea8e40e73bf7dc634": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4452. getAdditionalBlock() can create multiple blocks if the client times out and retries. Contributed by Konstantin Shvachko.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1441681 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "01/02/13 6:07 PM",
      "commitName": "61a262757ca70f30956b467ea8e40e73bf7dc634",
      "commitAuthor": "Konstantin Shvachko",
      "commitDateOld": "12/01/13 5:13 PM",
      "commitNameOld": "06406d705677845e1e303550e3bb0e2d4ccdbf70",
      "commitAuthorOld": "Konstantin Shvachko",
      "daysBetweenCommits": 20.04,
      "commitsBetweenForRepo": 106,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,146 +1,83 @@\n   LocatedBlock getAdditionalBlock(String src,\n                                          String clientName,\n                                          ExtendedBlock previous,\n                                          HashMap\u003cNode, Node\u003e excludedNodes\n                                          ) \n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n-    checkBlock(previous);\n-    Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n-    long fileLength, blockSize;\n+    long blockSize;\n     int replication;\n     DatanodeDescriptor clientNode \u003d null;\n-    Block newBlock \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\n           \"BLOCK* NameSystem.getAdditionalBlock: file \"\n           +src+\" for \"+clientName);\n     }\n \n-    writeLock();\n+    // Part I. Analyze the state of the file with respect to the input data.\n+    readLock();\n     try {\n-      checkOperation(OperationCategory.WRITE);\n+      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n+      final INode[] inodes \u003d analyzeFileState(\n+          src, clientName, previous, onRetryBlock).getINodes();\n+      final INodeFileUnderConstruction pendingFile \u003d\n+          (INodeFileUnderConstruction) inodes[inodes.length - 1];\n \n-      if (isInSafeMode()) {\n-        throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n+      if(onRetryBlock[0] !\u003d null) {\n+        // This is a retry. Just return the last block.\n+        return onRetryBlock[0];\n       }\n \n-      // have we exceeded the configured limit of fs objects.\n-      checkFsObjectLimit();\n-\n-      INodeFileUnderConstruction pendingFile \u003d checkLease(src, clientName);\n-      BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n-      if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n-        // The block that the client claims is the current last block\n-        // doesn\u0027t match up with what we think is the last block. There are\n-        // three possibilities:\n-        // 1) This is the first block allocation of an append() pipeline\n-        //    which started appending exactly at a block boundary.\n-        //    In this case, the client isn\u0027t passed the previous block,\n-        //    so it makes the allocateBlock() call with previous\u003dnull.\n-        //    We can distinguish this since the last block of the file\n-        //    will be exactly a full block.\n-        // 2) This is a retry from a client that missed the response of a\n-        //    prior getAdditionalBlock() call, perhaps because of a network\n-        //    timeout, or because of an HA failover. In that case, we know\n-        //    by the fact that the client is re-issuing the RPC that it\n-        //    never began to write to the old block. Hence it is safe to\n-        //    abandon it and allocate a new one.\n-        // 3) This is an entirely bogus request/bug -- we should error out\n-        //    rather than potentially appending a new block with an empty\n-        //    one in the middle, etc\n-\n-        BlockInfo penultimateBlock \u003d pendingFile.getPenultimateBlock();\n-        if (previous \u003d\u003d null \u0026\u0026\n-            lastBlockInFile !\u003d null \u0026\u0026\n-            lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n-            lastBlockInFile.isComplete()) {\n-          // Case 1\n-          if (NameNode.stateChangeLog.isDebugEnabled()) {\n-             NameNode.stateChangeLog.debug(\n-                 \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n-                 \" writing to a file with a complete previous block: src\u003d\" +\n-                 src + \" lastBlock\u003d\" + lastBlockInFile);\n-          }\n-        } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n-          // Case 2\n-          if (lastBlockInFile.getNumBytes() !\u003d 0) {\n-            throw new IOException(\n-                \"Request looked like a retry to allocate block \" +\n-                lastBlockInFile + \" but it already contains \" +\n-                lastBlockInFile.getNumBytes() + \" bytes\");\n-          }\n-\n-          // The retry case (\"b\" above) -- abandon the old block.\n-          NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n-              \"caught retry for allocation of a new block in \" +\n-              src + \". Abandoning old block \" + lastBlockInFile);\n-          dir.removeBlock(src, pendingFile, lastBlockInFile);\n-          dir.persistBlocks(src, pendingFile);\n-        } else {\n-          \n-          throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n-              \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n-              \"last block in file \" + lastBlockInFile);\n-        }\n-      }\n-\n-      // commit the last block and complete it if it has minimum replicas\n-      commitOrCompleteLastBlock(pendingFile, previousBlock);\n-\n-      //\n-      // If we fail this, bad things happen!\n-      //\n-      if (!checkFileProgress(pendingFile, false)) {\n-        throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n-      }\n-      fileLength \u003d pendingFile.computeContentSummary().getLength();\n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientNode \u003d pendingFile.getClientNode();\n       replication \u003d pendingFile.getBlockReplication();\n     } finally {\n-      writeUnlock();\n+      readUnlock();\n     }\n \n     // choose targets for the new block to be allocated.\n-    final DatanodeDescriptor targets[] \u003d blockManager.chooseTarget(\n+    final DatanodeDescriptor targets[] \u003d getBlockManager().chooseTarget(\n         src, replication, clientNode, excludedNodes, blockSize);\n \n-    // Allocate a new block and record it in the INode. \n+    // Part II.\n+    // Allocate a new block, add it to the INode and the BlocksMap. \n+    Block newBlock \u003d null;\n+    long offset;\n     writeLock();\n     try {\n-      checkOperation(OperationCategory.WRITE);\n-      if (isInSafeMode()) {\n-        throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n+      // Run the full analysis again, since things could have changed\n+      // while chooseTarget() was executing.\n+      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n+      INodesInPath inodesInPath \u003d\n+          analyzeFileState(src, clientName, previous, onRetryBlock);\n+      INode[] inodes \u003d inodesInPath.getINodes();\n+      final INodeFileUnderConstruction pendingFile \u003d\n+          (INodeFileUnderConstruction) inodes[inodes.length - 1];\n+\n+      if(onRetryBlock[0] !\u003d null) {\n+        // This is a retry. Just return the last block.\n+        return onRetryBlock[0];\n       }\n \n-      final INodesInPath inodesInPath \u003d dir.rootDir.getExistingPathINodes(src, true);\n-      final INode[] inodes \u003d inodesInPath.getINodes();\n-      final INodeFileUnderConstruction pendingFile\n-          \u003d checkLease(src, clientName, inodes[inodes.length - 1]);\n-                                                           \n-      if (!checkFileProgress(pendingFile, false)) {\n-        throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n-      }\n+      // commit the last block and complete it if it has minimum replicas\n+      commitOrCompleteLastBlock(pendingFile,\n+                                ExtendedBlock.getLocalBlock(previous));\n \n-      // allocate new block record block locations in INode.\n-      newBlock \u003d allocateBlock(src, inodesInPath, targets);\n-      \n-      for (DatanodeDescriptor dn : targets) {\n-        dn.incBlocksScheduled();\n-      }\n+      // allocate new block, record block locations in INode.\n+      newBlock \u003d createNewBlock();\n+      saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n+\n       dir.persistBlocks(src, pendingFile);\n+      offset \u003d pendingFile.computeFileSize(true);\n     } finally {\n       writeUnlock();\n     }\n     if (persistBlocks) {\n       getEditLog().logSync();\n     }\n \n-    // Create next block\n-    LocatedBlock b \u003d new LocatedBlock(getExtendedBlock(newBlock), targets, fileLength);\n-    blockManager.setBlockToken(b, BlockTokenSecretManager.AccessMode.WRITE);\n-    return b;\n+    // Return located block\n+    return makeLocatedBlock(newBlock, targets, offset);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(String src,\n                                         String clientName,\n                                         ExtendedBlock previous,\n                                         HashMap\u003cNode, Node\u003e excludedNodes\n                                         ) \n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    long blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\n          \"BLOCK* NameSystem.getAdditionalBlock: file \"\n          +src+\" for \"+clientName);\n    }\n\n    // Part I. Analyze the state of the file with respect to the input data.\n    readLock();\n    try {\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      final INode[] inodes \u003d analyzeFileState(\n          src, clientName, previous, onRetryBlock).getINodes();\n      final INodeFileUnderConstruction pendingFile \u003d\n          (INodeFileUnderConstruction) inodes[inodes.length - 1];\n\n      if(onRetryBlock[0] !\u003d null) {\n        // This is a retry. Just return the last block.\n        return onRetryBlock[0];\n      }\n\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d pendingFile.getClientNode();\n      replication \u003d pendingFile.getBlockReplication();\n    } finally {\n      readUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeDescriptor targets[] \u003d getBlockManager().chooseTarget(\n        src, replication, clientNode, excludedNodes, blockSize);\n\n    // Part II.\n    // Allocate a new block, add it to the INode and the BlocksMap. \n    Block newBlock \u003d null;\n    long offset;\n    writeLock();\n    try {\n      // Run the full analysis again, since things could have changed\n      // while chooseTarget() was executing.\n      LocatedBlock[] onRetryBlock \u003d new LocatedBlock[1];\n      INodesInPath inodesInPath \u003d\n          analyzeFileState(src, clientName, previous, onRetryBlock);\n      INode[] inodes \u003d inodesInPath.getINodes();\n      final INodeFileUnderConstruction pendingFile \u003d\n          (INodeFileUnderConstruction) inodes[inodes.length - 1];\n\n      if(onRetryBlock[0] !\u003d null) {\n        // This is a retry. Just return the last block.\n        return onRetryBlock[0];\n      }\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile,\n                                ExtendedBlock.getLocalBlock(previous));\n\n      // allocate new block, record block locations in INode.\n      newBlock \u003d createNewBlock();\n      saveAllocatedBlock(src, inodesInPath, newBlock, targets);\n\n      dir.persistBlocks(src, pendingFile);\n      offset \u003d pendingFile.computeFileSize(true);\n    } finally {\n      writeUnlock();\n    }\n    if (persistBlocks) {\n      getEditLog().logSync();\n    }\n\n    // Return located block\n    return makeLocatedBlock(newBlock, targets, offset);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "7ee5ce3176a74d217551b5981f809a56c719424b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4151. Change the methods in FSDirectory to pass INodesInPath instead of INode[] as a parameter.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1406006 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "05/11/12 3:26 PM",
      "commitName": "7ee5ce3176a74d217551b5981f809a56c719424b",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "02/11/12 5:20 PM",
      "commitNameOld": "d174f574bafcfefc635c64a47f258b1ce5d5c84e",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 2.96,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,146 +1,146 @@\n   LocatedBlock getAdditionalBlock(String src,\n                                          String clientName,\n                                          ExtendedBlock previous,\n                                          HashMap\u003cNode, Node\u003e excludedNodes\n                                          ) \n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n     checkBlock(previous);\n     Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n     long fileLength, blockSize;\n     int replication;\n     DatanodeDescriptor clientNode \u003d null;\n     Block newBlock \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\n           \"BLOCK* NameSystem.getAdditionalBlock: file \"\n           +src+\" for \"+clientName);\n     }\n \n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n \n       if (isInSafeMode()) {\n         throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n       }\n \n       // have we exceeded the configured limit of fs objects.\n       checkFsObjectLimit();\n \n       INodeFileUnderConstruction pendingFile \u003d checkLease(src, clientName);\n       BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n       if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n         // The block that the client claims is the current last block\n         // doesn\u0027t match up with what we think is the last block. There are\n         // three possibilities:\n         // 1) This is the first block allocation of an append() pipeline\n         //    which started appending exactly at a block boundary.\n         //    In this case, the client isn\u0027t passed the previous block,\n         //    so it makes the allocateBlock() call with previous\u003dnull.\n         //    We can distinguish this since the last block of the file\n         //    will be exactly a full block.\n         // 2) This is a retry from a client that missed the response of a\n         //    prior getAdditionalBlock() call, perhaps because of a network\n         //    timeout, or because of an HA failover. In that case, we know\n         //    by the fact that the client is re-issuing the RPC that it\n         //    never began to write to the old block. Hence it is safe to\n         //    abandon it and allocate a new one.\n         // 3) This is an entirely bogus request/bug -- we should error out\n         //    rather than potentially appending a new block with an empty\n         //    one in the middle, etc\n \n         BlockInfo penultimateBlock \u003d pendingFile.getPenultimateBlock();\n         if (previous \u003d\u003d null \u0026\u0026\n             lastBlockInFile !\u003d null \u0026\u0026\n             lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n             lastBlockInFile.isComplete()) {\n           // Case 1\n           if (NameNode.stateChangeLog.isDebugEnabled()) {\n              NameNode.stateChangeLog.debug(\n                  \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                  \" writing to a file with a complete previous block: src\u003d\" +\n                  src + \" lastBlock\u003d\" + lastBlockInFile);\n           }\n         } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n           // Case 2\n           if (lastBlockInFile.getNumBytes() !\u003d 0) {\n             throw new IOException(\n                 \"Request looked like a retry to allocate block \" +\n                 lastBlockInFile + \" but it already contains \" +\n                 lastBlockInFile.getNumBytes() + \" bytes\");\n           }\n \n           // The retry case (\"b\" above) -- abandon the old block.\n           NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n               \"caught retry for allocation of a new block in \" +\n               src + \". Abandoning old block \" + lastBlockInFile);\n           dir.removeBlock(src, pendingFile, lastBlockInFile);\n           dir.persistBlocks(src, pendingFile);\n         } else {\n           \n           throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n               \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n               \"last block in file \" + lastBlockInFile);\n         }\n       }\n \n       // commit the last block and complete it if it has minimum replicas\n       commitOrCompleteLastBlock(pendingFile, previousBlock);\n \n       //\n       // If we fail this, bad things happen!\n       //\n       if (!checkFileProgress(pendingFile, false)) {\n         throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n       }\n       fileLength \u003d pendingFile.computeContentSummary().getLength();\n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientNode \u003d pendingFile.getClientNode();\n       replication \u003d pendingFile.getBlockReplication();\n     } finally {\n       writeUnlock();\n     }\n \n     // choose targets for the new block to be allocated.\n     final DatanodeDescriptor targets[] \u003d blockManager.chooseTarget(\n         src, replication, clientNode, excludedNodes, blockSize);\n \n     // Allocate a new block and record it in the INode. \n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       if (isInSafeMode()) {\n         throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n       }\n-      INode[] pathINodes \u003d dir.getExistingPathINodes(src);\n-      int inodesLen \u003d pathINodes.length;\n-      checkLease(src, clientName, pathINodes[inodesLen-1]);\n-      INodeFileUnderConstruction pendingFile  \u003d (INodeFileUnderConstruction) \n-                                                pathINodes[inodesLen - 1];\n+\n+      final INodesInPath inodesInPath \u003d dir.rootDir.getExistingPathINodes(src, true);\n+      final INode[] inodes \u003d inodesInPath.getINodes();\n+      final INodeFileUnderConstruction pendingFile\n+          \u003d checkLease(src, clientName, inodes[inodes.length - 1]);\n                                                            \n       if (!checkFileProgress(pendingFile, false)) {\n         throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n       }\n \n       // allocate new block record block locations in INode.\n-      newBlock \u003d allocateBlock(src, pathINodes, targets);\n+      newBlock \u003d allocateBlock(src, inodesInPath, targets);\n       \n       for (DatanodeDescriptor dn : targets) {\n         dn.incBlocksScheduled();\n       }\n       dir.persistBlocks(src, pendingFile);\n     } finally {\n       writeUnlock();\n     }\n     if (persistBlocks) {\n       getEditLog().logSync();\n     }\n \n     // Create next block\n     LocatedBlock b \u003d new LocatedBlock(getExtendedBlock(newBlock), targets, fileLength);\n     blockManager.setBlockToken(b, BlockTokenSecretManager.AccessMode.WRITE);\n     return b;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(String src,\n                                         String clientName,\n                                         ExtendedBlock previous,\n                                         HashMap\u003cNode, Node\u003e excludedNodes\n                                         ) \n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    checkBlock(previous);\n    Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n    long fileLength, blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n    Block newBlock \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\n          \"BLOCK* NameSystem.getAdditionalBlock: file \"\n          +src+\" for \"+clientName);\n    }\n\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n      }\n\n      // have we exceeded the configured limit of fs objects.\n      checkFsObjectLimit();\n\n      INodeFileUnderConstruction pendingFile \u003d checkLease(src, clientName);\n      BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n      if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n        // The block that the client claims is the current last block\n        // doesn\u0027t match up with what we think is the last block. There are\n        // three possibilities:\n        // 1) This is the first block allocation of an append() pipeline\n        //    which started appending exactly at a block boundary.\n        //    In this case, the client isn\u0027t passed the previous block,\n        //    so it makes the allocateBlock() call with previous\u003dnull.\n        //    We can distinguish this since the last block of the file\n        //    will be exactly a full block.\n        // 2) This is a retry from a client that missed the response of a\n        //    prior getAdditionalBlock() call, perhaps because of a network\n        //    timeout, or because of an HA failover. In that case, we know\n        //    by the fact that the client is re-issuing the RPC that it\n        //    never began to write to the old block. Hence it is safe to\n        //    abandon it and allocate a new one.\n        // 3) This is an entirely bogus request/bug -- we should error out\n        //    rather than potentially appending a new block with an empty\n        //    one in the middle, etc\n\n        BlockInfo penultimateBlock \u003d pendingFile.getPenultimateBlock();\n        if (previous \u003d\u003d null \u0026\u0026\n            lastBlockInFile !\u003d null \u0026\u0026\n            lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n            lastBlockInFile.isComplete()) {\n          // Case 1\n          if (NameNode.stateChangeLog.isDebugEnabled()) {\n             NameNode.stateChangeLog.debug(\n                 \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                 \" writing to a file with a complete previous block: src\u003d\" +\n                 src + \" lastBlock\u003d\" + lastBlockInFile);\n          }\n        } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n          // Case 2\n          if (lastBlockInFile.getNumBytes() !\u003d 0) {\n            throw new IOException(\n                \"Request looked like a retry to allocate block \" +\n                lastBlockInFile + \" but it already contains \" +\n                lastBlockInFile.getNumBytes() + \" bytes\");\n          }\n\n          // The retry case (\"b\" above) -- abandon the old block.\n          NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n              \"caught retry for allocation of a new block in \" +\n              src + \". Abandoning old block \" + lastBlockInFile);\n          dir.removeBlock(src, pendingFile, lastBlockInFile);\n          dir.persistBlocks(src, pendingFile);\n        } else {\n          \n          throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n              \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n              \"last block in file \" + lastBlockInFile);\n        }\n      }\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile, previousBlock);\n\n      //\n      // If we fail this, bad things happen!\n      //\n      if (!checkFileProgress(pendingFile, false)) {\n        throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n      }\n      fileLength \u003d pendingFile.computeContentSummary().getLength();\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d pendingFile.getClientNode();\n      replication \u003d pendingFile.getBlockReplication();\n    } finally {\n      writeUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeDescriptor targets[] \u003d blockManager.chooseTarget(\n        src, replication, clientNode, excludedNodes, blockSize);\n\n    // Allocate a new block and record it in the INode. \n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n      }\n\n      final INodesInPath inodesInPath \u003d dir.rootDir.getExistingPathINodes(src, true);\n      final INode[] inodes \u003d inodesInPath.getINodes();\n      final INodeFileUnderConstruction pendingFile\n          \u003d checkLease(src, clientName, inodes[inodes.length - 1]);\n                                                           \n      if (!checkFileProgress(pendingFile, false)) {\n        throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n      }\n\n      // allocate new block record block locations in INode.\n      newBlock \u003d allocateBlock(src, inodesInPath, targets);\n      \n      for (DatanodeDescriptor dn : targets) {\n        dn.incBlocksScheduled();\n      }\n      dir.persistBlocks(src, pendingFile);\n    } finally {\n      writeUnlock();\n    }\n    if (persistBlocks) {\n      getEditLog().logSync();\n    }\n\n    // Create next block\n    LocatedBlock b \u003d new LocatedBlock(getExtendedBlock(newBlock), targets, fileLength);\n    blockManager.setBlockToken(b, BlockTokenSecretManager.AccessMode.WRITE);\n    return b;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4122. Cleanup HDFS logs and reduce the size of logged messages. Contributed by Suresh Srinivas.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1403120 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/10/12 4:10 PM",
      "commitName": "cea7bbc630deede93dbe6a1bbda56ad49de4f3de",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "26/10/12 11:08 AM",
      "commitNameOld": "0e796b61e829c4bf763caf13b0f53cb1bcefdeee",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 2.21,
      "commitsBetweenForRepo": 10,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,146 +1,146 @@\n   LocatedBlock getAdditionalBlock(String src,\n                                          String clientName,\n                                          ExtendedBlock previous,\n                                          HashMap\u003cNode, Node\u003e excludedNodes\n                                          ) \n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n     checkBlock(previous);\n     Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n     long fileLength, blockSize;\n     int replication;\n     DatanodeDescriptor clientNode \u003d null;\n     Block newBlock \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\n           \"BLOCK* NameSystem.getAdditionalBlock: file \"\n           +src+\" for \"+clientName);\n     }\n \n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n \n       if (isInSafeMode()) {\n         throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n       }\n \n       // have we exceeded the configured limit of fs objects.\n       checkFsObjectLimit();\n \n       INodeFileUnderConstruction pendingFile \u003d checkLease(src, clientName);\n       BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n       if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n         // The block that the client claims is the current last block\n         // doesn\u0027t match up with what we think is the last block. There are\n         // three possibilities:\n         // 1) This is the first block allocation of an append() pipeline\n         //    which started appending exactly at a block boundary.\n         //    In this case, the client isn\u0027t passed the previous block,\n         //    so it makes the allocateBlock() call with previous\u003dnull.\n         //    We can distinguish this since the last block of the file\n         //    will be exactly a full block.\n         // 2) This is a retry from a client that missed the response of a\n         //    prior getAdditionalBlock() call, perhaps because of a network\n         //    timeout, or because of an HA failover. In that case, we know\n         //    by the fact that the client is re-issuing the RPC that it\n         //    never began to write to the old block. Hence it is safe to\n         //    abandon it and allocate a new one.\n         // 3) This is an entirely bogus request/bug -- we should error out\n         //    rather than potentially appending a new block with an empty\n         //    one in the middle, etc\n \n         BlockInfo penultimateBlock \u003d pendingFile.getPenultimateBlock();\n         if (previous \u003d\u003d null \u0026\u0026\n             lastBlockInFile !\u003d null \u0026\u0026\n             lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n             lastBlockInFile.isComplete()) {\n           // Case 1\n           if (NameNode.stateChangeLog.isDebugEnabled()) {\n              NameNode.stateChangeLog.debug(\n                  \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                  \" writing to a file with a complete previous block: src\u003d\" +\n                  src + \" lastBlock\u003d\" + lastBlockInFile);\n           }\n         } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n           // Case 2\n           if (lastBlockInFile.getNumBytes() !\u003d 0) {\n             throw new IOException(\n                 \"Request looked like a retry to allocate block \" +\n                 lastBlockInFile + \" but it already contains \" +\n                 lastBlockInFile.getNumBytes() + \" bytes\");\n           }\n \n           // The retry case (\"b\" above) -- abandon the old block.\n-          NameNode.stateChangeLog.info(\"BLOCK* NameSystem.allocateBlock: \" +\n+          NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n               \"caught retry for allocation of a new block in \" +\n               src + \". Abandoning old block \" + lastBlockInFile);\n           dir.removeBlock(src, pendingFile, lastBlockInFile);\n           dir.persistBlocks(src, pendingFile);\n         } else {\n           \n           throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n               \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n               \"last block in file \" + lastBlockInFile);\n         }\n       }\n \n       // commit the last block and complete it if it has minimum replicas\n       commitOrCompleteLastBlock(pendingFile, previousBlock);\n \n       //\n       // If we fail this, bad things happen!\n       //\n       if (!checkFileProgress(pendingFile, false)) {\n         throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n       }\n       fileLength \u003d pendingFile.computeContentSummary().getLength();\n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientNode \u003d pendingFile.getClientNode();\n       replication \u003d pendingFile.getBlockReplication();\n     } finally {\n       writeUnlock();\n     }\n \n     // choose targets for the new block to be allocated.\n     final DatanodeDescriptor targets[] \u003d blockManager.chooseTarget(\n         src, replication, clientNode, excludedNodes, blockSize);\n \n     // Allocate a new block and record it in the INode. \n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       if (isInSafeMode()) {\n         throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n       }\n       INode[] pathINodes \u003d dir.getExistingPathINodes(src);\n       int inodesLen \u003d pathINodes.length;\n       checkLease(src, clientName, pathINodes[inodesLen-1]);\n       INodeFileUnderConstruction pendingFile  \u003d (INodeFileUnderConstruction) \n                                                 pathINodes[inodesLen - 1];\n                                                            \n       if (!checkFileProgress(pendingFile, false)) {\n         throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n       }\n \n       // allocate new block record block locations in INode.\n       newBlock \u003d allocateBlock(src, pathINodes, targets);\n       \n       for (DatanodeDescriptor dn : targets) {\n         dn.incBlocksScheduled();\n       }\n       dir.persistBlocks(src, pendingFile);\n     } finally {\n       writeUnlock();\n     }\n     if (persistBlocks) {\n       getEditLog().logSync();\n     }\n \n     // Create next block\n     LocatedBlock b \u003d new LocatedBlock(getExtendedBlock(newBlock), targets, fileLength);\n     blockManager.setBlockToken(b, BlockTokenSecretManager.AccessMode.WRITE);\n     return b;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(String src,\n                                         String clientName,\n                                         ExtendedBlock previous,\n                                         HashMap\u003cNode, Node\u003e excludedNodes\n                                         ) \n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    checkBlock(previous);\n    Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n    long fileLength, blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n    Block newBlock \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\n          \"BLOCK* NameSystem.getAdditionalBlock: file \"\n          +src+\" for \"+clientName);\n    }\n\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n      }\n\n      // have we exceeded the configured limit of fs objects.\n      checkFsObjectLimit();\n\n      INodeFileUnderConstruction pendingFile \u003d checkLease(src, clientName);\n      BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n      if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n        // The block that the client claims is the current last block\n        // doesn\u0027t match up with what we think is the last block. There are\n        // three possibilities:\n        // 1) This is the first block allocation of an append() pipeline\n        //    which started appending exactly at a block boundary.\n        //    In this case, the client isn\u0027t passed the previous block,\n        //    so it makes the allocateBlock() call with previous\u003dnull.\n        //    We can distinguish this since the last block of the file\n        //    will be exactly a full block.\n        // 2) This is a retry from a client that missed the response of a\n        //    prior getAdditionalBlock() call, perhaps because of a network\n        //    timeout, or because of an HA failover. In that case, we know\n        //    by the fact that the client is re-issuing the RPC that it\n        //    never began to write to the old block. Hence it is safe to\n        //    abandon it and allocate a new one.\n        // 3) This is an entirely bogus request/bug -- we should error out\n        //    rather than potentially appending a new block with an empty\n        //    one in the middle, etc\n\n        BlockInfo penultimateBlock \u003d pendingFile.getPenultimateBlock();\n        if (previous \u003d\u003d null \u0026\u0026\n            lastBlockInFile !\u003d null \u0026\u0026\n            lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n            lastBlockInFile.isComplete()) {\n          // Case 1\n          if (NameNode.stateChangeLog.isDebugEnabled()) {\n             NameNode.stateChangeLog.debug(\n                 \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                 \" writing to a file with a complete previous block: src\u003d\" +\n                 src + \" lastBlock\u003d\" + lastBlockInFile);\n          }\n        } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n          // Case 2\n          if (lastBlockInFile.getNumBytes() !\u003d 0) {\n            throw new IOException(\n                \"Request looked like a retry to allocate block \" +\n                lastBlockInFile + \" but it already contains \" +\n                lastBlockInFile.getNumBytes() + \" bytes\");\n          }\n\n          // The retry case (\"b\" above) -- abandon the old block.\n          NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n              \"caught retry for allocation of a new block in \" +\n              src + \". Abandoning old block \" + lastBlockInFile);\n          dir.removeBlock(src, pendingFile, lastBlockInFile);\n          dir.persistBlocks(src, pendingFile);\n        } else {\n          \n          throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n              \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n              \"last block in file \" + lastBlockInFile);\n        }\n      }\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile, previousBlock);\n\n      //\n      // If we fail this, bad things happen!\n      //\n      if (!checkFileProgress(pendingFile, false)) {\n        throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n      }\n      fileLength \u003d pendingFile.computeContentSummary().getLength();\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d pendingFile.getClientNode();\n      replication \u003d pendingFile.getBlockReplication();\n    } finally {\n      writeUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeDescriptor targets[] \u003d blockManager.chooseTarget(\n        src, replication, clientNode, excludedNodes, blockSize);\n\n    // Allocate a new block and record it in the INode. \n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n      }\n      INode[] pathINodes \u003d dir.getExistingPathINodes(src);\n      int inodesLen \u003d pathINodes.length;\n      checkLease(src, clientName, pathINodes[inodesLen-1]);\n      INodeFileUnderConstruction pendingFile  \u003d (INodeFileUnderConstruction) \n                                                pathINodes[inodesLen - 1];\n                                                           \n      if (!checkFileProgress(pendingFile, false)) {\n        throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n      }\n\n      // allocate new block record block locations in INode.\n      newBlock \u003d allocateBlock(src, pathINodes, targets);\n      \n      for (DatanodeDescriptor dn : targets) {\n        dn.incBlocksScheduled();\n      }\n      dir.persistBlocks(src, pendingFile);\n    } finally {\n      writeUnlock();\n    }\n    if (persistBlocks) {\n      getEditLog().logSync();\n    }\n\n    // Create next block\n    LocatedBlock b \u003d new LocatedBlock(getExtendedBlock(newBlock), targets, fileLength);\n    blockManager.setBlockToken(b, BlockTokenSecretManager.AccessMode.WRITE);\n    return b;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "ad06a087131d69d173d8e03dce5c97650a530f2e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4037. Rename the getReplication() method in BlockCollection to getBlockReplication(). \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1398288 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "15/10/12 6:48 AM",
      "commitName": "ad06a087131d69d173d8e03dce5c97650a530f2e",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "11/10/12 11:08 AM",
      "commitNameOld": "2887bbb33cefaac0c548eb2450a1f8e3e60f5ea7",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 3.82,
      "commitsBetweenForRepo": 12,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,146 +1,146 @@\n   LocatedBlock getAdditionalBlock(String src,\n                                          String clientName,\n                                          ExtendedBlock previous,\n                                          HashMap\u003cNode, Node\u003e excludedNodes\n                                          ) \n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n     checkBlock(previous);\n     Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n     long fileLength, blockSize;\n     int replication;\n     DatanodeDescriptor clientNode \u003d null;\n     Block newBlock \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\n           \"BLOCK* NameSystem.getAdditionalBlock: file \"\n           +src+\" for \"+clientName);\n     }\n \n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n \n       if (isInSafeMode()) {\n         throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n       }\n \n       // have we exceeded the configured limit of fs objects.\n       checkFsObjectLimit();\n \n       INodeFileUnderConstruction pendingFile \u003d checkLease(src, clientName);\n       BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n       if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n         // The block that the client claims is the current last block\n         // doesn\u0027t match up with what we think is the last block. There are\n         // three possibilities:\n         // 1) This is the first block allocation of an append() pipeline\n         //    which started appending exactly at a block boundary.\n         //    In this case, the client isn\u0027t passed the previous block,\n         //    so it makes the allocateBlock() call with previous\u003dnull.\n         //    We can distinguish this since the last block of the file\n         //    will be exactly a full block.\n         // 2) This is a retry from a client that missed the response of a\n         //    prior getAdditionalBlock() call, perhaps because of a network\n         //    timeout, or because of an HA failover. In that case, we know\n         //    by the fact that the client is re-issuing the RPC that it\n         //    never began to write to the old block. Hence it is safe to\n         //    abandon it and allocate a new one.\n         // 3) This is an entirely bogus request/bug -- we should error out\n         //    rather than potentially appending a new block with an empty\n         //    one in the middle, etc\n \n         BlockInfo penultimateBlock \u003d pendingFile.getPenultimateBlock();\n         if (previous \u003d\u003d null \u0026\u0026\n             lastBlockInFile !\u003d null \u0026\u0026\n             lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n             lastBlockInFile.isComplete()) {\n           // Case 1\n           if (NameNode.stateChangeLog.isDebugEnabled()) {\n              NameNode.stateChangeLog.debug(\n                  \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                  \" writing to a file with a complete previous block: src\u003d\" +\n                  src + \" lastBlock\u003d\" + lastBlockInFile);\n           }\n         } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n           // Case 2\n           if (lastBlockInFile.getNumBytes() !\u003d 0) {\n             throw new IOException(\n                 \"Request looked like a retry to allocate block \" +\n                 lastBlockInFile + \" but it already contains \" +\n                 lastBlockInFile.getNumBytes() + \" bytes\");\n           }\n \n           // The retry case (\"b\" above) -- abandon the old block.\n           NameNode.stateChangeLog.info(\"BLOCK* NameSystem.allocateBlock: \" +\n               \"caught retry for allocation of a new block in \" +\n               src + \". Abandoning old block \" + lastBlockInFile);\n           dir.removeBlock(src, pendingFile, lastBlockInFile);\n           dir.persistBlocks(src, pendingFile);\n         } else {\n           \n           throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n               \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n               \"last block in file \" + lastBlockInFile);\n         }\n       }\n \n       // commit the last block and complete it if it has minimum replicas\n       commitOrCompleteLastBlock(pendingFile, previousBlock);\n \n       //\n       // If we fail this, bad things happen!\n       //\n       if (!checkFileProgress(pendingFile, false)) {\n         throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n       }\n       fileLength \u003d pendingFile.computeContentSummary().getLength();\n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientNode \u003d pendingFile.getClientNode();\n-      replication \u003d pendingFile.getReplication();\n+      replication \u003d pendingFile.getBlockReplication();\n     } finally {\n       writeUnlock();\n     }\n \n     // choose targets for the new block to be allocated.\n     final DatanodeDescriptor targets[] \u003d blockManager.chooseTarget(\n         src, replication, clientNode, excludedNodes, blockSize);\n \n     // Allocate a new block and record it in the INode. \n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       if (isInSafeMode()) {\n         throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n       }\n       INode[] pathINodes \u003d dir.getExistingPathINodes(src);\n       int inodesLen \u003d pathINodes.length;\n       checkLease(src, clientName, pathINodes[inodesLen-1]);\n       INodeFileUnderConstruction pendingFile  \u003d (INodeFileUnderConstruction) \n                                                 pathINodes[inodesLen - 1];\n                                                            \n       if (!checkFileProgress(pendingFile, false)) {\n         throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n       }\n \n       // allocate new block record block locations in INode.\n       newBlock \u003d allocateBlock(src, pathINodes, targets);\n       \n       for (DatanodeDescriptor dn : targets) {\n         dn.incBlocksScheduled();\n       }\n       dir.persistBlocks(src, pendingFile);\n     } finally {\n       writeUnlock();\n     }\n     if (persistBlocks) {\n       getEditLog().logSync();\n     }\n \n     // Create next block\n     LocatedBlock b \u003d new LocatedBlock(getExtendedBlock(newBlock), targets, fileLength);\n     blockManager.setBlockToken(b, BlockTokenSecretManager.AccessMode.WRITE);\n     return b;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(String src,\n                                         String clientName,\n                                         ExtendedBlock previous,\n                                         HashMap\u003cNode, Node\u003e excludedNodes\n                                         ) \n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    checkBlock(previous);\n    Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n    long fileLength, blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n    Block newBlock \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\n          \"BLOCK* NameSystem.getAdditionalBlock: file \"\n          +src+\" for \"+clientName);\n    }\n\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n      }\n\n      // have we exceeded the configured limit of fs objects.\n      checkFsObjectLimit();\n\n      INodeFileUnderConstruction pendingFile \u003d checkLease(src, clientName);\n      BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n      if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n        // The block that the client claims is the current last block\n        // doesn\u0027t match up with what we think is the last block. There are\n        // three possibilities:\n        // 1) This is the first block allocation of an append() pipeline\n        //    which started appending exactly at a block boundary.\n        //    In this case, the client isn\u0027t passed the previous block,\n        //    so it makes the allocateBlock() call with previous\u003dnull.\n        //    We can distinguish this since the last block of the file\n        //    will be exactly a full block.\n        // 2) This is a retry from a client that missed the response of a\n        //    prior getAdditionalBlock() call, perhaps because of a network\n        //    timeout, or because of an HA failover. In that case, we know\n        //    by the fact that the client is re-issuing the RPC that it\n        //    never began to write to the old block. Hence it is safe to\n        //    abandon it and allocate a new one.\n        // 3) This is an entirely bogus request/bug -- we should error out\n        //    rather than potentially appending a new block with an empty\n        //    one in the middle, etc\n\n        BlockInfo penultimateBlock \u003d pendingFile.getPenultimateBlock();\n        if (previous \u003d\u003d null \u0026\u0026\n            lastBlockInFile !\u003d null \u0026\u0026\n            lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n            lastBlockInFile.isComplete()) {\n          // Case 1\n          if (NameNode.stateChangeLog.isDebugEnabled()) {\n             NameNode.stateChangeLog.debug(\n                 \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                 \" writing to a file with a complete previous block: src\u003d\" +\n                 src + \" lastBlock\u003d\" + lastBlockInFile);\n          }\n        } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n          // Case 2\n          if (lastBlockInFile.getNumBytes() !\u003d 0) {\n            throw new IOException(\n                \"Request looked like a retry to allocate block \" +\n                lastBlockInFile + \" but it already contains \" +\n                lastBlockInFile.getNumBytes() + \" bytes\");\n          }\n\n          // The retry case (\"b\" above) -- abandon the old block.\n          NameNode.stateChangeLog.info(\"BLOCK* NameSystem.allocateBlock: \" +\n              \"caught retry for allocation of a new block in \" +\n              src + \". Abandoning old block \" + lastBlockInFile);\n          dir.removeBlock(src, pendingFile, lastBlockInFile);\n          dir.persistBlocks(src, pendingFile);\n        } else {\n          \n          throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n              \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n              \"last block in file \" + lastBlockInFile);\n        }\n      }\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile, previousBlock);\n\n      //\n      // If we fail this, bad things happen!\n      //\n      if (!checkFileProgress(pendingFile, false)) {\n        throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n      }\n      fileLength \u003d pendingFile.computeContentSummary().getLength();\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d pendingFile.getClientNode();\n      replication \u003d pendingFile.getBlockReplication();\n    } finally {\n      writeUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeDescriptor targets[] \u003d blockManager.chooseTarget(\n        src, replication, clientNode, excludedNodes, blockSize);\n\n    // Allocate a new block and record it in the INode. \n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n      }\n      INode[] pathINodes \u003d dir.getExistingPathINodes(src);\n      int inodesLen \u003d pathINodes.length;\n      checkLease(src, clientName, pathINodes[inodesLen-1]);\n      INodeFileUnderConstruction pendingFile  \u003d (INodeFileUnderConstruction) \n                                                pathINodes[inodesLen - 1];\n                                                           \n      if (!checkFileProgress(pendingFile, false)) {\n        throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n      }\n\n      // allocate new block record block locations in INode.\n      newBlock \u003d allocateBlock(src, pathINodes, targets);\n      \n      for (DatanodeDescriptor dn : targets) {\n        dn.incBlocksScheduled();\n      }\n      dir.persistBlocks(src, pendingFile);\n    } finally {\n      writeUnlock();\n    }\n    if (persistBlocks) {\n      getEditLog().logSync();\n    }\n\n    // Create next block\n    LocatedBlock b \u003d new LocatedBlock(getExtendedBlock(newBlock), targets, fileLength);\n    blockManager.setBlockToken(b, BlockTokenSecretManager.AccessMode.WRITE);\n    return b;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "bcdb125643d4ec834f6bd5d4fafb079391f31fc6": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3031. Fix complete() and getAdditionalBlock() RPCs to be idempotent. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1338466 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/05/12 3:35 PM",
      "commitName": "bcdb125643d4ec834f6bd5d4fafb079391f31fc6",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "12/05/12 8:33 PM",
      "commitNameOld": "f1560d379d314e0702e878a0ea5fcf2e99884c7c",
      "commitAuthorOld": "Harsh J",
      "daysBetweenCommits": 1.79,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,90 +1,146 @@\n   LocatedBlock getAdditionalBlock(String src,\n                                          String clientName,\n                                          ExtendedBlock previous,\n                                          HashMap\u003cNode, Node\u003e excludedNodes\n                                          ) \n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n     checkBlock(previous);\n+    Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n     long fileLength, blockSize;\n     int replication;\n     DatanodeDescriptor clientNode \u003d null;\n     Block newBlock \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\n           \"BLOCK* NameSystem.getAdditionalBlock: file \"\n           +src+\" for \"+clientName);\n     }\n \n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n \n       if (isInSafeMode()) {\n         throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n       }\n \n       // have we exceeded the configured limit of fs objects.\n       checkFsObjectLimit();\n \n-      INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n+      INodeFileUnderConstruction pendingFile \u003d checkLease(src, clientName);\n+      BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n+      if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n+        // The block that the client claims is the current last block\n+        // doesn\u0027t match up with what we think is the last block. There are\n+        // three possibilities:\n+        // 1) This is the first block allocation of an append() pipeline\n+        //    which started appending exactly at a block boundary.\n+        //    In this case, the client isn\u0027t passed the previous block,\n+        //    so it makes the allocateBlock() call with previous\u003dnull.\n+        //    We can distinguish this since the last block of the file\n+        //    will be exactly a full block.\n+        // 2) This is a retry from a client that missed the response of a\n+        //    prior getAdditionalBlock() call, perhaps because of a network\n+        //    timeout, or because of an HA failover. In that case, we know\n+        //    by the fact that the client is re-issuing the RPC that it\n+        //    never began to write to the old block. Hence it is safe to\n+        //    abandon it and allocate a new one.\n+        // 3) This is an entirely bogus request/bug -- we should error out\n+        //    rather than potentially appending a new block with an empty\n+        //    one in the middle, etc\n+\n+        BlockInfo penultimateBlock \u003d pendingFile.getPenultimateBlock();\n+        if (previous \u003d\u003d null \u0026\u0026\n+            lastBlockInFile !\u003d null \u0026\u0026\n+            lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n+            lastBlockInFile.isComplete()) {\n+          // Case 1\n+          if (NameNode.stateChangeLog.isDebugEnabled()) {\n+             NameNode.stateChangeLog.debug(\n+                 \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n+                 \" writing to a file with a complete previous block: src\u003d\" +\n+                 src + \" lastBlock\u003d\" + lastBlockInFile);\n+          }\n+        } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n+          // Case 2\n+          if (lastBlockInFile.getNumBytes() !\u003d 0) {\n+            throw new IOException(\n+                \"Request looked like a retry to allocate block \" +\n+                lastBlockInFile + \" but it already contains \" +\n+                lastBlockInFile.getNumBytes() + \" bytes\");\n+          }\n+\n+          // The retry case (\"b\" above) -- abandon the old block.\n+          NameNode.stateChangeLog.info(\"BLOCK* NameSystem.allocateBlock: \" +\n+              \"caught retry for allocation of a new block in \" +\n+              src + \". Abandoning old block \" + lastBlockInFile);\n+          dir.removeBlock(src, pendingFile, lastBlockInFile);\n+          dir.persistBlocks(src, pendingFile);\n+        } else {\n+          \n+          throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n+              \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n+              \"last block in file \" + lastBlockInFile);\n+        }\n+      }\n \n       // commit the last block and complete it if it has minimum replicas\n-      commitOrCompleteLastBlock(pendingFile, ExtendedBlock.getLocalBlock(previous));\n+      commitOrCompleteLastBlock(pendingFile, previousBlock);\n \n       //\n       // If we fail this, bad things happen!\n       //\n       if (!checkFileProgress(pendingFile, false)) {\n         throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n       }\n       fileLength \u003d pendingFile.computeContentSummary().getLength();\n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientNode \u003d pendingFile.getClientNode();\n       replication \u003d pendingFile.getReplication();\n     } finally {\n       writeUnlock();\n     }\n \n     // choose targets for the new block to be allocated.\n     final DatanodeDescriptor targets[] \u003d blockManager.chooseTarget(\n         src, replication, clientNode, excludedNodes, blockSize);\n \n     // Allocate a new block and record it in the INode. \n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       if (isInSafeMode()) {\n         throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n       }\n       INode[] pathINodes \u003d dir.getExistingPathINodes(src);\n       int inodesLen \u003d pathINodes.length;\n       checkLease(src, clientName, pathINodes[inodesLen-1]);\n       INodeFileUnderConstruction pendingFile  \u003d (INodeFileUnderConstruction) \n                                                 pathINodes[inodesLen - 1];\n                                                            \n       if (!checkFileProgress(pendingFile, false)) {\n         throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n       }\n \n       // allocate new block record block locations in INode.\n       newBlock \u003d allocateBlock(src, pathINodes, targets);\n       \n       for (DatanodeDescriptor dn : targets) {\n         dn.incBlocksScheduled();\n       }\n       dir.persistBlocks(src, pendingFile);\n     } finally {\n       writeUnlock();\n     }\n     if (persistBlocks) {\n       getEditLog().logSync();\n     }\n \n     // Create next block\n     LocatedBlock b \u003d new LocatedBlock(getExtendedBlock(newBlock), targets, fileLength);\n     blockManager.setBlockToken(b, BlockTokenSecretManager.AccessMode.WRITE);\n     return b;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(String src,\n                                         String clientName,\n                                         ExtendedBlock previous,\n                                         HashMap\u003cNode, Node\u003e excludedNodes\n                                         ) \n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    checkBlock(previous);\n    Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n    long fileLength, blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n    Block newBlock \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\n          \"BLOCK* NameSystem.getAdditionalBlock: file \"\n          +src+\" for \"+clientName);\n    }\n\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n      }\n\n      // have we exceeded the configured limit of fs objects.\n      checkFsObjectLimit();\n\n      INodeFileUnderConstruction pendingFile \u003d checkLease(src, clientName);\n      BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n      if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n        // The block that the client claims is the current last block\n        // doesn\u0027t match up with what we think is the last block. There are\n        // three possibilities:\n        // 1) This is the first block allocation of an append() pipeline\n        //    which started appending exactly at a block boundary.\n        //    In this case, the client isn\u0027t passed the previous block,\n        //    so it makes the allocateBlock() call with previous\u003dnull.\n        //    We can distinguish this since the last block of the file\n        //    will be exactly a full block.\n        // 2) This is a retry from a client that missed the response of a\n        //    prior getAdditionalBlock() call, perhaps because of a network\n        //    timeout, or because of an HA failover. In that case, we know\n        //    by the fact that the client is re-issuing the RPC that it\n        //    never began to write to the old block. Hence it is safe to\n        //    abandon it and allocate a new one.\n        // 3) This is an entirely bogus request/bug -- we should error out\n        //    rather than potentially appending a new block with an empty\n        //    one in the middle, etc\n\n        BlockInfo penultimateBlock \u003d pendingFile.getPenultimateBlock();\n        if (previous \u003d\u003d null \u0026\u0026\n            lastBlockInFile !\u003d null \u0026\u0026\n            lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n            lastBlockInFile.isComplete()) {\n          // Case 1\n          if (NameNode.stateChangeLog.isDebugEnabled()) {\n             NameNode.stateChangeLog.debug(\n                 \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                 \" writing to a file with a complete previous block: src\u003d\" +\n                 src + \" lastBlock\u003d\" + lastBlockInFile);\n          }\n        } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n          // Case 2\n          if (lastBlockInFile.getNumBytes() !\u003d 0) {\n            throw new IOException(\n                \"Request looked like a retry to allocate block \" +\n                lastBlockInFile + \" but it already contains \" +\n                lastBlockInFile.getNumBytes() + \" bytes\");\n          }\n\n          // The retry case (\"b\" above) -- abandon the old block.\n          NameNode.stateChangeLog.info(\"BLOCK* NameSystem.allocateBlock: \" +\n              \"caught retry for allocation of a new block in \" +\n              src + \". Abandoning old block \" + lastBlockInFile);\n          dir.removeBlock(src, pendingFile, lastBlockInFile);\n          dir.persistBlocks(src, pendingFile);\n        } else {\n          \n          throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n              \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n              \"last block in file \" + lastBlockInFile);\n        }\n      }\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile, previousBlock);\n\n      //\n      // If we fail this, bad things happen!\n      //\n      if (!checkFileProgress(pendingFile, false)) {\n        throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n      }\n      fileLength \u003d pendingFile.computeContentSummary().getLength();\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d pendingFile.getClientNode();\n      replication \u003d pendingFile.getReplication();\n    } finally {\n      writeUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeDescriptor targets[] \u003d blockManager.chooseTarget(\n        src, replication, clientNode, excludedNodes, blockSize);\n\n    // Allocate a new block and record it in the INode. \n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n      }\n      INode[] pathINodes \u003d dir.getExistingPathINodes(src);\n      int inodesLen \u003d pathINodes.length;\n      checkLease(src, clientName, pathINodes[inodesLen-1]);\n      INodeFileUnderConstruction pendingFile  \u003d (INodeFileUnderConstruction) \n                                                pathINodes[inodesLen - 1];\n                                                           \n      if (!checkFileProgress(pendingFile, false)) {\n        throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n      }\n\n      // allocate new block record block locations in INode.\n      newBlock \u003d allocateBlock(src, pathINodes, targets);\n      \n      for (DatanodeDescriptor dn : targets) {\n        dn.incBlocksScheduled();\n      }\n      dir.persistBlocks(src, pendingFile);\n    } finally {\n      writeUnlock();\n    }\n    if (persistBlocks) {\n      getEditLog().logSync();\n    }\n\n    // Create next block\n    LocatedBlock b \u003d new LocatedBlock(getExtendedBlock(newBlock), targets, fileLength);\n    blockManager.setBlockToken(b, BlockTokenSecretManager.AccessMode.WRITE);\n    return b;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "36d1c49486587c2dbb193e8538b1d4510c462fa6": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2693. Fix synchronization issues around state transition. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1221582 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/12/11 7:03 PM",
      "commitName": "36d1c49486587c2dbb193e8538b1d4510c462fa6",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "16/12/11 10:36 AM",
      "commitNameOld": "371f4228e86f5ebffb3d8647fb30b8bdc2b777c4",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 4.35,
      "commitsBetweenForRepo": 20,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,87 +1,90 @@\n   LocatedBlock getAdditionalBlock(String src,\n                                          String clientName,\n                                          ExtendedBlock previous,\n                                          HashMap\u003cNode, Node\u003e excludedNodes\n                                          ) \n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n     checkBlock(previous);\n     long fileLength, blockSize;\n     int replication;\n     DatanodeDescriptor clientNode \u003d null;\n     Block newBlock \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\n           \"BLOCK* NameSystem.getAdditionalBlock: file \"\n           +src+\" for \"+clientName);\n     }\n \n     writeLock();\n     try {\n+      checkOperation(OperationCategory.WRITE);\n+\n       if (isInSafeMode()) {\n         throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n       }\n \n       // have we exceeded the configured limit of fs objects.\n       checkFsObjectLimit();\n \n       INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n \n       // commit the last block and complete it if it has minimum replicas\n       commitOrCompleteLastBlock(pendingFile, ExtendedBlock.getLocalBlock(previous));\n \n       //\n       // If we fail this, bad things happen!\n       //\n       if (!checkFileProgress(pendingFile, false)) {\n         throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n       }\n       fileLength \u003d pendingFile.computeContentSummary().getLength();\n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientNode \u003d pendingFile.getClientNode();\n       replication \u003d pendingFile.getReplication();\n     } finally {\n       writeUnlock();\n     }\n \n     // choose targets for the new block to be allocated.\n     final DatanodeDescriptor targets[] \u003d blockManager.chooseTarget(\n         src, replication, clientNode, excludedNodes, blockSize);\n \n     // Allocate a new block and record it in the INode. \n     writeLock();\n     try {\n+      checkOperation(OperationCategory.WRITE);\n       if (isInSafeMode()) {\n         throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n       }\n       INode[] pathINodes \u003d dir.getExistingPathINodes(src);\n       int inodesLen \u003d pathINodes.length;\n       checkLease(src, clientName, pathINodes[inodesLen-1]);\n       INodeFileUnderConstruction pendingFile  \u003d (INodeFileUnderConstruction) \n                                                 pathINodes[inodesLen - 1];\n                                                            \n       if (!checkFileProgress(pendingFile, false)) {\n         throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n       }\n \n       // allocate new block record block locations in INode.\n       newBlock \u003d allocateBlock(src, pathINodes, targets);\n       \n       for (DatanodeDescriptor dn : targets) {\n         dn.incBlocksScheduled();\n       }\n       dir.persistBlocks(src, pendingFile);\n     } finally {\n       writeUnlock();\n     }\n     if (persistBlocks) {\n       getEditLog().logSync();\n     }\n \n     // Create next block\n     LocatedBlock b \u003d new LocatedBlock(getExtendedBlock(newBlock), targets, fileLength);\n     blockManager.setBlockToken(b, BlockTokenSecretManager.AccessMode.WRITE);\n     return b;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(String src,\n                                         String clientName,\n                                         ExtendedBlock previous,\n                                         HashMap\u003cNode, Node\u003e excludedNodes\n                                         ) \n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    checkBlock(previous);\n    long fileLength, blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n    Block newBlock \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\n          \"BLOCK* NameSystem.getAdditionalBlock: file \"\n          +src+\" for \"+clientName);\n    }\n\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n      }\n\n      // have we exceeded the configured limit of fs objects.\n      checkFsObjectLimit();\n\n      INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile, ExtendedBlock.getLocalBlock(previous));\n\n      //\n      // If we fail this, bad things happen!\n      //\n      if (!checkFileProgress(pendingFile, false)) {\n        throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n      }\n      fileLength \u003d pendingFile.computeContentSummary().getLength();\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d pendingFile.getClientNode();\n      replication \u003d pendingFile.getReplication();\n    } finally {\n      writeUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeDescriptor targets[] \u003d blockManager.chooseTarget(\n        src, replication, clientNode, excludedNodes, blockSize);\n\n    // Allocate a new block and record it in the INode. \n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n      }\n      INode[] pathINodes \u003d dir.getExistingPathINodes(src);\n      int inodesLen \u003d pathINodes.length;\n      checkLease(src, clientName, pathINodes[inodesLen-1]);\n      INodeFileUnderConstruction pendingFile  \u003d (INodeFileUnderConstruction) \n                                                pathINodes[inodesLen - 1];\n                                                           \n      if (!checkFileProgress(pendingFile, false)) {\n        throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n      }\n\n      // allocate new block record block locations in INode.\n      newBlock \u003d allocateBlock(src, pathINodes, targets);\n      \n      for (DatanodeDescriptor dn : targets) {\n        dn.incBlocksScheduled();\n      }\n      dir.persistBlocks(src, pendingFile);\n    } finally {\n      writeUnlock();\n    }\n    if (persistBlocks) {\n      getEditLog().logSync();\n    }\n\n    // Create next block\n    LocatedBlock b \u003d new LocatedBlock(getExtendedBlock(newBlock), targets, fileLength);\n    blockManager.setBlockToken(b, BlockTokenSecretManager.AccessMode.WRITE);\n    return b;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "71071b904d0c9aec7b3713d41740f24182e81c36": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2602. NN should log newly-allocated blocks without losing BlockInfo. Contributed by Aaron T. Myers\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1215036 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "15/12/11 8:18 PM",
      "commitName": "71071b904d0c9aec7b3713d41740f24182e81c36",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "08/12/11 3:55 PM",
      "commitNameOld": "2481474bd9c50a23e4fd2eea67ac2dea11ca1f58",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 7.18,
      "commitsBetweenForRepo": 77,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,83 +1,87 @@\n   LocatedBlock getAdditionalBlock(String src,\n                                          String clientName,\n                                          ExtendedBlock previous,\n                                          HashMap\u003cNode, Node\u003e excludedNodes\n                                          ) \n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n     checkBlock(previous);\n     long fileLength, blockSize;\n     int replication;\n     DatanodeDescriptor clientNode \u003d null;\n     Block newBlock \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\n           \"BLOCK* NameSystem.getAdditionalBlock: file \"\n           +src+\" for \"+clientName);\n     }\n \n     writeLock();\n     try {\n       if (isInSafeMode()) {\n         throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n       }\n \n       // have we exceeded the configured limit of fs objects.\n       checkFsObjectLimit();\n \n       INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n \n       // commit the last block and complete it if it has minimum replicas\n       commitOrCompleteLastBlock(pendingFile, ExtendedBlock.getLocalBlock(previous));\n \n       //\n       // If we fail this, bad things happen!\n       //\n       if (!checkFileProgress(pendingFile, false)) {\n         throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n       }\n       fileLength \u003d pendingFile.computeContentSummary().getLength();\n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientNode \u003d pendingFile.getClientNode();\n       replication \u003d pendingFile.getReplication();\n     } finally {\n       writeUnlock();\n     }\n \n     // choose targets for the new block to be allocated.\n     final DatanodeDescriptor targets[] \u003d blockManager.chooseTarget(\n         src, replication, clientNode, excludedNodes, blockSize);\n \n     // Allocate a new block and record it in the INode. \n     writeLock();\n     try {\n       if (isInSafeMode()) {\n         throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n       }\n       INode[] pathINodes \u003d dir.getExistingPathINodes(src);\n       int inodesLen \u003d pathINodes.length;\n       checkLease(src, clientName, pathINodes[inodesLen-1]);\n       INodeFileUnderConstruction pendingFile  \u003d (INodeFileUnderConstruction) \n                                                 pathINodes[inodesLen - 1];\n                                                            \n       if (!checkFileProgress(pendingFile, false)) {\n         throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n       }\n \n       // allocate new block record block locations in INode.\n       newBlock \u003d allocateBlock(src, pathINodes, targets);\n       \n       for (DatanodeDescriptor dn : targets) {\n         dn.incBlocksScheduled();\n-      }      \n+      }\n+      dir.persistBlocks(src, pendingFile);\n     } finally {\n       writeUnlock();\n     }\n+    if (persistBlocks) {\n+      getEditLog().logSync();\n+    }\n \n     // Create next block\n     LocatedBlock b \u003d new LocatedBlock(getExtendedBlock(newBlock), targets, fileLength);\n     blockManager.setBlockToken(b, BlockTokenSecretManager.AccessMode.WRITE);\n     return b;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(String src,\n                                         String clientName,\n                                         ExtendedBlock previous,\n                                         HashMap\u003cNode, Node\u003e excludedNodes\n                                         ) \n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    checkBlock(previous);\n    long fileLength, blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n    Block newBlock \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\n          \"BLOCK* NameSystem.getAdditionalBlock: file \"\n          +src+\" for \"+clientName);\n    }\n\n    writeLock();\n    try {\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n      }\n\n      // have we exceeded the configured limit of fs objects.\n      checkFsObjectLimit();\n\n      INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile, ExtendedBlock.getLocalBlock(previous));\n\n      //\n      // If we fail this, bad things happen!\n      //\n      if (!checkFileProgress(pendingFile, false)) {\n        throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n      }\n      fileLength \u003d pendingFile.computeContentSummary().getLength();\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d pendingFile.getClientNode();\n      replication \u003d pendingFile.getReplication();\n    } finally {\n      writeUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeDescriptor targets[] \u003d blockManager.chooseTarget(\n        src, replication, clientNode, excludedNodes, blockSize);\n\n    // Allocate a new block and record it in the INode. \n    writeLock();\n    try {\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n      }\n      INode[] pathINodes \u003d dir.getExistingPathINodes(src);\n      int inodesLen \u003d pathINodes.length;\n      checkLease(src, clientName, pathINodes[inodesLen-1]);\n      INodeFileUnderConstruction pendingFile  \u003d (INodeFileUnderConstruction) \n                                                pathINodes[inodesLen - 1];\n                                                           \n      if (!checkFileProgress(pendingFile, false)) {\n        throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n      }\n\n      // allocate new block record block locations in INode.\n      newBlock \u003d allocateBlock(src, pathINodes, targets);\n      \n      for (DatanodeDescriptor dn : targets) {\n        dn.incBlocksScheduled();\n      }\n      dir.persistBlocks(src, pendingFile);\n    } finally {\n      writeUnlock();\n    }\n    if (persistBlocks) {\n      getEditLog().logSync();\n    }\n\n    // Create next block\n    LocatedBlock b \u003d new LocatedBlock(getExtendedBlock(newBlock), targets, fileLength);\n    blockManager.setBlockToken(b, BlockTokenSecretManager.AccessMode.WRITE);\n    return b;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "b7cd8c0f865e88e40eee75fd2690b1fdc4155071": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2564. Cleanup unnecessary exceptions thrown and unnecessary casts. Contributed by Hari Mankude\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1203950 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/11/11 6:34 PM",
      "commitName": "b7cd8c0f865e88e40eee75fd2690b1fdc4155071",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "14/11/11 5:13 PM",
      "commitNameOld": "9a3f147fdd5421460889b266ead3a2300323cda2",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 4.06,
      "commitsBetweenForRepo": 19,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,83 +1,83 @@\n   LocatedBlock getAdditionalBlock(String src,\n                                          String clientName,\n                                          ExtendedBlock previous,\n                                          HashMap\u003cNode, Node\u003e excludedNodes\n                                          ) \n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n     checkBlock(previous);\n     long fileLength, blockSize;\n     int replication;\n     DatanodeDescriptor clientNode \u003d null;\n     Block newBlock \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\n           \"BLOCK* NameSystem.getAdditionalBlock: file \"\n           +src+\" for \"+clientName);\n     }\n \n     writeLock();\n     try {\n       if (isInSafeMode()) {\n         throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n       }\n \n       // have we exceeded the configured limit of fs objects.\n       checkFsObjectLimit();\n \n       INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n \n       // commit the last block and complete it if it has minimum replicas\n       commitOrCompleteLastBlock(pendingFile, ExtendedBlock.getLocalBlock(previous));\n \n       //\n       // If we fail this, bad things happen!\n       //\n       if (!checkFileProgress(pendingFile, false)) {\n         throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n       }\n       fileLength \u003d pendingFile.computeContentSummary().getLength();\n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientNode \u003d pendingFile.getClientNode();\n-      replication \u003d (int)pendingFile.getReplication();\n+      replication \u003d pendingFile.getReplication();\n     } finally {\n       writeUnlock();\n     }\n \n     // choose targets for the new block to be allocated.\n     final DatanodeDescriptor targets[] \u003d blockManager.chooseTarget(\n         src, replication, clientNode, excludedNodes, blockSize);\n \n     // Allocate a new block and record it in the INode. \n     writeLock();\n     try {\n       if (isInSafeMode()) {\n         throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n       }\n       INode[] pathINodes \u003d dir.getExistingPathINodes(src);\n       int inodesLen \u003d pathINodes.length;\n       checkLease(src, clientName, pathINodes[inodesLen-1]);\n       INodeFileUnderConstruction pendingFile  \u003d (INodeFileUnderConstruction) \n                                                 pathINodes[inodesLen - 1];\n                                                            \n       if (!checkFileProgress(pendingFile, false)) {\n         throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n       }\n \n       // allocate new block record block locations in INode.\n       newBlock \u003d allocateBlock(src, pathINodes, targets);\n       \n       for (DatanodeDescriptor dn : targets) {\n         dn.incBlocksScheduled();\n       }      \n     } finally {\n       writeUnlock();\n     }\n \n     // Create next block\n     LocatedBlock b \u003d new LocatedBlock(getExtendedBlock(newBlock), targets, fileLength);\n     blockManager.setBlockToken(b, BlockTokenSecretManager.AccessMode.WRITE);\n     return b;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(String src,\n                                         String clientName,\n                                         ExtendedBlock previous,\n                                         HashMap\u003cNode, Node\u003e excludedNodes\n                                         ) \n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    checkBlock(previous);\n    long fileLength, blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n    Block newBlock \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\n          \"BLOCK* NameSystem.getAdditionalBlock: file \"\n          +src+\" for \"+clientName);\n    }\n\n    writeLock();\n    try {\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n      }\n\n      // have we exceeded the configured limit of fs objects.\n      checkFsObjectLimit();\n\n      INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile, ExtendedBlock.getLocalBlock(previous));\n\n      //\n      // If we fail this, bad things happen!\n      //\n      if (!checkFileProgress(pendingFile, false)) {\n        throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n      }\n      fileLength \u003d pendingFile.computeContentSummary().getLength();\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d pendingFile.getClientNode();\n      replication \u003d pendingFile.getReplication();\n    } finally {\n      writeUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeDescriptor targets[] \u003d blockManager.chooseTarget(\n        src, replication, clientNode, excludedNodes, blockSize);\n\n    // Allocate a new block and record it in the INode. \n    writeLock();\n    try {\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n      }\n      INode[] pathINodes \u003d dir.getExistingPathINodes(src);\n      int inodesLen \u003d pathINodes.length;\n      checkLease(src, clientName, pathINodes[inodesLen-1]);\n      INodeFileUnderConstruction pendingFile  \u003d (INodeFileUnderConstruction) \n                                                pathINodes[inodesLen - 1];\n                                                           \n      if (!checkFileProgress(pendingFile, false)) {\n        throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n      }\n\n      // allocate new block record block locations in INode.\n      newBlock \u003d allocateBlock(src, pathINodes, targets);\n      \n      for (DatanodeDescriptor dn : targets) {\n        dn.incBlocksScheduled();\n      }      \n    } finally {\n      writeUnlock();\n    }\n\n    // Create next block\n    LocatedBlock b \u003d new LocatedBlock(getExtendedBlock(newBlock), targets, fileLength);\n    blockManager.setBlockToken(b, BlockTokenSecretManager.AccessMode.WRITE);\n    return b;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "f00198b16c529bafeb8460427f12de69401941c3": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2301. Start/stop appropriate namenode services when transition to active and standby states. Contributed by Suresh Srinivas.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1182080 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/10/11 1:44 PM",
      "commitName": "f00198b16c529bafeb8460427f12de69401941c3",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "28/09/11 5:42 PM",
      "commitNameOld": "ab0402bc1def44e3d52eea517f4132c460bd5f87",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 12.83,
      "commitsBetweenForRepo": 53,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,83 +1,83 @@\n   LocatedBlock getAdditionalBlock(String src,\n                                          String clientName,\n                                          ExtendedBlock previous,\n                                          HashMap\u003cNode, Node\u003e excludedNodes\n                                          ) \n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n     checkBlock(previous);\n     long fileLength, blockSize;\n     int replication;\n     DatanodeDescriptor clientNode \u003d null;\n     Block newBlock \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\n           \"BLOCK* NameSystem.getAdditionalBlock: file \"\n           +src+\" for \"+clientName);\n     }\n \n     writeLock();\n     try {\n       if (isInSafeMode()) {\n         throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n       }\n \n       // have we exceeded the configured limit of fs objects.\n       checkFsObjectLimit();\n \n       INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n \n       // commit the last block and complete it if it has minimum replicas\n       commitOrCompleteLastBlock(pendingFile, ExtendedBlock.getLocalBlock(previous));\n \n       //\n       // If we fail this, bad things happen!\n       //\n       if (!checkFileProgress(pendingFile, false)) {\n         throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n       }\n       fileLength \u003d pendingFile.computeContentSummary().getLength();\n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientNode \u003d pendingFile.getClientNode();\n-      replication \u003d (int)pendingFile.getReplication();\n+      replication \u003d pendingFile.getReplication();\n     } finally {\n       writeUnlock();\n     }\n \n     // choose targets for the new block to be allocated.\n     final DatanodeDescriptor targets[] \u003d blockManager.chooseTarget(\n         src, replication, clientNode, excludedNodes, blockSize);\n \n     // Allocate a new block and record it in the INode. \n     writeLock();\n     try {\n       if (isInSafeMode()) {\n         throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n       }\n       INode[] pathINodes \u003d dir.getExistingPathINodes(src);\n       int inodesLen \u003d pathINodes.length;\n       checkLease(src, clientName, pathINodes[inodesLen-1]);\n       INodeFileUnderConstruction pendingFile  \u003d (INodeFileUnderConstruction) \n                                                 pathINodes[inodesLen - 1];\n                                                            \n       if (!checkFileProgress(pendingFile, false)) {\n         throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n       }\n \n       // allocate new block record block locations in INode.\n       newBlock \u003d allocateBlock(src, pathINodes, targets);\n       \n       for (DatanodeDescriptor dn : targets) {\n         dn.incBlocksScheduled();\n       }      \n     } finally {\n       writeUnlock();\n     }\n \n     // Create next block\n     LocatedBlock b \u003d new LocatedBlock(getExtendedBlock(newBlock), targets, fileLength);\n     blockManager.setBlockToken(b, BlockTokenSecretManager.AccessMode.WRITE);\n     return b;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(String src,\n                                         String clientName,\n                                         ExtendedBlock previous,\n                                         HashMap\u003cNode, Node\u003e excludedNodes\n                                         ) \n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    checkBlock(previous);\n    long fileLength, blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n    Block newBlock \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\n          \"BLOCK* NameSystem.getAdditionalBlock: file \"\n          +src+\" for \"+clientName);\n    }\n\n    writeLock();\n    try {\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n      }\n\n      // have we exceeded the configured limit of fs objects.\n      checkFsObjectLimit();\n\n      INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile, ExtendedBlock.getLocalBlock(previous));\n\n      //\n      // If we fail this, bad things happen!\n      //\n      if (!checkFileProgress(pendingFile, false)) {\n        throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n      }\n      fileLength \u003d pendingFile.computeContentSummary().getLength();\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d pendingFile.getClientNode();\n      replication \u003d pendingFile.getReplication();\n    } finally {\n      writeUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeDescriptor targets[] \u003d blockManager.chooseTarget(\n        src, replication, clientNode, excludedNodes, blockSize);\n\n    // Allocate a new block and record it in the INode. \n    writeLock();\n    try {\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n      }\n      INode[] pathINodes \u003d dir.getExistingPathINodes(src);\n      int inodesLen \u003d pathINodes.length;\n      checkLease(src, clientName, pathINodes[inodesLen-1]);\n      INodeFileUnderConstruction pendingFile  \u003d (INodeFileUnderConstruction) \n                                                pathINodes[inodesLen - 1];\n                                                           \n      if (!checkFileProgress(pendingFile, false)) {\n        throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n      }\n\n      // allocate new block record block locations in INode.\n      newBlock \u003d allocateBlock(src, pathINodes, targets);\n      \n      for (DatanodeDescriptor dn : targets) {\n        dn.incBlocksScheduled();\n      }      \n    } finally {\n      writeUnlock();\n    }\n\n    // Create next block\n    LocatedBlock b \u003d new LocatedBlock(getExtendedBlock(newBlock), targets, fileLength);\n    blockManager.setBlockToken(b, BlockTokenSecretManager.AccessMode.WRITE);\n    return b;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "9992cae54120d2742922745c1f513c6bfbde67a9": {
      "type": "Ybodychange",
      "commitMessage": "Reverting the previous trunk merge since it added other unintended changes in addition\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1177127 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/09/11 5:33 PM",
      "commitName": "9992cae54120d2742922745c1f513c6bfbde67a9",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "28/09/11 5:09 PM",
      "commitNameOld": "122113922fd398b1a76c1664b58a61661e936e30",
      "commitAuthorOld": "",
      "daysBetweenCommits": 0.02,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,83 +1,83 @@\n   LocatedBlock getAdditionalBlock(String src,\n                                          String clientName,\n                                          ExtendedBlock previous,\n                                          HashMap\u003cNode, Node\u003e excludedNodes\n                                          ) \n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n     checkBlock(previous);\n     long fileLength, blockSize;\n     int replication;\n     DatanodeDescriptor clientNode \u003d null;\n     Block newBlock \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\n           \"BLOCK* NameSystem.getAdditionalBlock: file \"\n           +src+\" for \"+clientName);\n     }\n \n     writeLock();\n     try {\n       if (isInSafeMode()) {\n         throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n       }\n \n       // have we exceeded the configured limit of fs objects.\n       checkFsObjectLimit();\n \n       INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n \n       // commit the last block and complete it if it has minimum replicas\n       commitOrCompleteLastBlock(pendingFile, ExtendedBlock.getLocalBlock(previous));\n \n       //\n       // If we fail this, bad things happen!\n       //\n       if (!checkFileProgress(pendingFile, false)) {\n         throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n       }\n       fileLength \u003d pendingFile.computeContentSummary().getLength();\n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientNode \u003d pendingFile.getClientNode();\n-      replication \u003d pendingFile.getReplication();\n+      replication \u003d (int)pendingFile.getReplication();\n     } finally {\n       writeUnlock();\n     }\n \n     // choose targets for the new block to be allocated.\n     final DatanodeDescriptor targets[] \u003d blockManager.chooseTarget(\n         src, replication, clientNode, excludedNodes, blockSize);\n \n     // Allocate a new block and record it in the INode. \n     writeLock();\n     try {\n       if (isInSafeMode()) {\n         throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n       }\n       INode[] pathINodes \u003d dir.getExistingPathINodes(src);\n       int inodesLen \u003d pathINodes.length;\n       checkLease(src, clientName, pathINodes[inodesLen-1]);\n       INodeFileUnderConstruction pendingFile  \u003d (INodeFileUnderConstruction) \n                                                 pathINodes[inodesLen - 1];\n                                                            \n       if (!checkFileProgress(pendingFile, false)) {\n         throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n       }\n \n       // allocate new block record block locations in INode.\n       newBlock \u003d allocateBlock(src, pathINodes, targets);\n       \n       for (DatanodeDescriptor dn : targets) {\n         dn.incBlocksScheduled();\n       }      \n     } finally {\n       writeUnlock();\n     }\n \n     // Create next block\n     LocatedBlock b \u003d new LocatedBlock(getExtendedBlock(newBlock), targets, fileLength);\n     blockManager.setBlockToken(b, BlockTokenSecretManager.AccessMode.WRITE);\n     return b;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(String src,\n                                         String clientName,\n                                         ExtendedBlock previous,\n                                         HashMap\u003cNode, Node\u003e excludedNodes\n                                         ) \n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    checkBlock(previous);\n    long fileLength, blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n    Block newBlock \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\n          \"BLOCK* NameSystem.getAdditionalBlock: file \"\n          +src+\" for \"+clientName);\n    }\n\n    writeLock();\n    try {\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n      }\n\n      // have we exceeded the configured limit of fs objects.\n      checkFsObjectLimit();\n\n      INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile, ExtendedBlock.getLocalBlock(previous));\n\n      //\n      // If we fail this, bad things happen!\n      //\n      if (!checkFileProgress(pendingFile, false)) {\n        throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n      }\n      fileLength \u003d pendingFile.computeContentSummary().getLength();\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d pendingFile.getClientNode();\n      replication \u003d (int)pendingFile.getReplication();\n    } finally {\n      writeUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeDescriptor targets[] \u003d blockManager.chooseTarget(\n        src, replication, clientNode, excludedNodes, blockSize);\n\n    // Allocate a new block and record it in the INode. \n    writeLock();\n    try {\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n      }\n      INode[] pathINodes \u003d dir.getExistingPathINodes(src);\n      int inodesLen \u003d pathINodes.length;\n      checkLease(src, clientName, pathINodes[inodesLen-1]);\n      INodeFileUnderConstruction pendingFile  \u003d (INodeFileUnderConstruction) \n                                                pathINodes[inodesLen - 1];\n                                                           \n      if (!checkFileProgress(pendingFile, false)) {\n        throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n      }\n\n      // allocate new block record block locations in INode.\n      newBlock \u003d allocateBlock(src, pathINodes, targets);\n      \n      for (DatanodeDescriptor dn : targets) {\n        dn.incBlocksScheduled();\n      }      \n    } finally {\n      writeUnlock();\n    }\n\n    // Create next block\n    LocatedBlock b \u003d new LocatedBlock(getExtendedBlock(newBlock), targets, fileLength);\n    blockManager.setBlockToken(b, BlockTokenSecretManager.AccessMode.WRITE);\n    return b;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  LocatedBlock getAdditionalBlock(String src,\n                                         String clientName,\n                                         ExtendedBlock previous,\n                                         HashMap\u003cNode, Node\u003e excludedNodes\n                                         ) \n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    checkBlock(previous);\n    long fileLength, blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n    Block newBlock \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\n          \"BLOCK* NameSystem.getAdditionalBlock: file \"\n          +src+\" for \"+clientName);\n    }\n\n    writeLock();\n    try {\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n      }\n\n      // have we exceeded the configured limit of fs objects.\n      checkFsObjectLimit();\n\n      INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile, ExtendedBlock.getLocalBlock(previous));\n\n      //\n      // If we fail this, bad things happen!\n      //\n      if (!checkFileProgress(pendingFile, false)) {\n        throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n      }\n      fileLength \u003d pendingFile.computeContentSummary().getLength();\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d pendingFile.getClientNode();\n      replication \u003d (int)pendingFile.getReplication();\n    } finally {\n      writeUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeDescriptor targets[] \u003d blockManager.chooseTarget(\n        src, replication, clientNode, excludedNodes, blockSize);\n\n    // Allocate a new block and record it in the INode. \n    writeLock();\n    try {\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n      }\n      INode[] pathINodes \u003d dir.getExistingPathINodes(src);\n      int inodesLen \u003d pathINodes.length;\n      checkLease(src, clientName, pathINodes[inodesLen-1]);\n      INodeFileUnderConstruction pendingFile  \u003d (INodeFileUnderConstruction) \n                                                pathINodes[inodesLen - 1];\n                                                           \n      if (!checkFileProgress(pendingFile, false)) {\n        throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n      }\n\n      // allocate new block record block locations in INode.\n      newBlock \u003d allocateBlock(src, pathINodes, targets);\n      \n      for (DatanodeDescriptor dn : targets) {\n        dn.incBlocksScheduled();\n      }      \n    } finally {\n      writeUnlock();\n    }\n\n    // Create next block\n    LocatedBlock b \u003d new LocatedBlock(getExtendedBlock(newBlock), targets, fileLength);\n    blockManager.setBlockToken(b, BlockTokenSecretManager.AccessMode.WRITE);\n    return b;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java"
      }
    },
    "2892f6d817d74e90ff50073cd3721ed4ec75ba92": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2266.  Add Namesystem and SafeMode interfaces to avoid directly referring to FSNamesystem in BlockManager.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1160493 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/08/11 4:14 PM",
      "commitName": "2892f6d817d74e90ff50073cd3721ed4ec75ba92",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "19/08/11 10:36 AM",
      "commitNameOld": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 3.23,
      "commitsBetweenForRepo": 12,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,84 +1,83 @@\n   LocatedBlock getAdditionalBlock(String src,\n                                          String clientName,\n                                          ExtendedBlock previous,\n                                          HashMap\u003cNode, Node\u003e excludedNodes\n                                          ) \n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n     checkBlock(previous);\n     long fileLength, blockSize;\n     int replication;\n     DatanodeDescriptor clientNode \u003d null;\n     Block newBlock \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\n           \"BLOCK* NameSystem.getAdditionalBlock: file \"\n           +src+\" for \"+clientName);\n     }\n \n     writeLock();\n     try {\n       if (isInSafeMode()) {\n         throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n       }\n \n       // have we exceeded the configured limit of fs objects.\n       checkFsObjectLimit();\n \n       INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n \n       // commit the last block and complete it if it has minimum replicas\n-      blockManager.commitOrCompleteLastBlock(pendingFile, ExtendedBlock\n-          .getLocalBlock(previous));\n+      commitOrCompleteLastBlock(pendingFile, ExtendedBlock.getLocalBlock(previous));\n \n       //\n       // If we fail this, bad things happen!\n       //\n       if (!checkFileProgress(pendingFile, false)) {\n         throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n       }\n       fileLength \u003d pendingFile.computeContentSummary().getLength();\n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientNode \u003d pendingFile.getClientNode();\n       replication \u003d (int)pendingFile.getReplication();\n     } finally {\n       writeUnlock();\n     }\n \n     // choose targets for the new block to be allocated.\n     final DatanodeDescriptor targets[] \u003d blockManager.chooseTarget(\n         src, replication, clientNode, excludedNodes, blockSize);\n \n     // Allocate a new block and record it in the INode. \n     writeLock();\n     try {\n       if (isInSafeMode()) {\n         throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n       }\n       INode[] pathINodes \u003d dir.getExistingPathINodes(src);\n       int inodesLen \u003d pathINodes.length;\n       checkLease(src, clientName, pathINodes[inodesLen-1]);\n       INodeFileUnderConstruction pendingFile  \u003d (INodeFileUnderConstruction) \n                                                 pathINodes[inodesLen - 1];\n                                                            \n       if (!checkFileProgress(pendingFile, false)) {\n         throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n       }\n \n       // allocate new block record block locations in INode.\n       newBlock \u003d allocateBlock(src, pathINodes, targets);\n       \n       for (DatanodeDescriptor dn : targets) {\n         dn.incBlocksScheduled();\n       }      \n     } finally {\n       writeUnlock();\n     }\n \n     // Create next block\n     LocatedBlock b \u003d new LocatedBlock(getExtendedBlock(newBlock), targets, fileLength);\n     blockManager.setBlockToken(b, BlockTokenSecretManager.AccessMode.WRITE);\n     return b;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(String src,\n                                         String clientName,\n                                         ExtendedBlock previous,\n                                         HashMap\u003cNode, Node\u003e excludedNodes\n                                         ) \n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    checkBlock(previous);\n    long fileLength, blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n    Block newBlock \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\n          \"BLOCK* NameSystem.getAdditionalBlock: file \"\n          +src+\" for \"+clientName);\n    }\n\n    writeLock();\n    try {\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n      }\n\n      // have we exceeded the configured limit of fs objects.\n      checkFsObjectLimit();\n\n      INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n\n      // commit the last block and complete it if it has minimum replicas\n      commitOrCompleteLastBlock(pendingFile, ExtendedBlock.getLocalBlock(previous));\n\n      //\n      // If we fail this, bad things happen!\n      //\n      if (!checkFileProgress(pendingFile, false)) {\n        throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n      }\n      fileLength \u003d pendingFile.computeContentSummary().getLength();\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d pendingFile.getClientNode();\n      replication \u003d (int)pendingFile.getReplication();\n    } finally {\n      writeUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeDescriptor targets[] \u003d blockManager.chooseTarget(\n        src, replication, clientNode, excludedNodes, blockSize);\n\n    // Allocate a new block and record it in the INode. \n    writeLock();\n    try {\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n      }\n      INode[] pathINodes \u003d dir.getExistingPathINodes(src);\n      int inodesLen \u003d pathINodes.length;\n      checkLease(src, clientName, pathINodes[inodesLen-1]);\n      INodeFileUnderConstruction pendingFile  \u003d (INodeFileUnderConstruction) \n                                                pathINodes[inodesLen - 1];\n                                                           \n      if (!checkFileProgress(pendingFile, false)) {\n        throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n      }\n\n      // allocate new block record block locations in INode.\n      newBlock \u003d allocateBlock(src, pathINodes, targets);\n      \n      for (DatanodeDescriptor dn : targets) {\n        dn.incBlocksScheduled();\n      }      \n    } finally {\n      writeUnlock();\n    }\n\n    // Create next block\n    LocatedBlock b \u003d new LocatedBlock(getExtendedBlock(newBlock), targets, fileLength);\n    blockManager.setBlockToken(b, BlockTokenSecretManager.AccessMode.WRITE);\n    return b;\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  LocatedBlock getAdditionalBlock(String src,\n                                         String clientName,\n                                         ExtendedBlock previous,\n                                         HashMap\u003cNode, Node\u003e excludedNodes\n                                         ) \n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    checkBlock(previous);\n    long fileLength, blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n    Block newBlock \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\n          \"BLOCK* NameSystem.getAdditionalBlock: file \"\n          +src+\" for \"+clientName);\n    }\n\n    writeLock();\n    try {\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n      }\n\n      // have we exceeded the configured limit of fs objects.\n      checkFsObjectLimit();\n\n      INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n\n      // commit the last block and complete it if it has minimum replicas\n      blockManager.commitOrCompleteLastBlock(pendingFile, ExtendedBlock\n          .getLocalBlock(previous));\n\n      //\n      // If we fail this, bad things happen!\n      //\n      if (!checkFileProgress(pendingFile, false)) {\n        throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n      }\n      fileLength \u003d pendingFile.computeContentSummary().getLength();\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d pendingFile.getClientNode();\n      replication \u003d (int)pendingFile.getReplication();\n    } finally {\n      writeUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeDescriptor targets[] \u003d blockManager.chooseTarget(\n        src, replication, clientNode, excludedNodes, blockSize);\n\n    // Allocate a new block and record it in the INode. \n    writeLock();\n    try {\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n      }\n      INode[] pathINodes \u003d dir.getExistingPathINodes(src);\n      int inodesLen \u003d pathINodes.length;\n      checkLease(src, clientName, pathINodes[inodesLen-1]);\n      INodeFileUnderConstruction pendingFile  \u003d (INodeFileUnderConstruction) \n                                                pathINodes[inodesLen - 1];\n                                                           \n      if (!checkFileProgress(pendingFile, false)) {\n        throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n      }\n\n      // allocate new block record block locations in INode.\n      newBlock \u003d allocateBlock(src, pathINodes, targets);\n      \n      for (DatanodeDescriptor dn : targets) {\n        dn.incBlocksScheduled();\n      }      \n    } finally {\n      writeUnlock();\n    }\n\n    // Create next block\n    LocatedBlock b \u003d new LocatedBlock(getExtendedBlock(newBlock), targets, fileLength);\n    blockManager.setBlockToken(b, BlockTokenSecretManager.AccessMode.WRITE);\n    return b;\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java"
      }
    },
    "5d5b1c6c10c66c6a17b483a3e1a98d59d3d0bdee": {
      "type": "Ymodifierchange",
      "commitMessage": "HDFS-2239. Reduce access levels of the fields and methods in FSNamesystem.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1155998 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/08/11 6:50 PM",
      "commitName": "5d5b1c6c10c66c6a17b483a3e1a98d59d3d0bdee",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "08/08/11 3:06 AM",
      "commitNameOld": "371f4a59059322000a40eb4bdf5386b96b626ece",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 1.66,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,84 +1,84 @@\n-  public LocatedBlock getAdditionalBlock(String src,\n+  LocatedBlock getAdditionalBlock(String src,\n                                          String clientName,\n                                          ExtendedBlock previous,\n                                          HashMap\u003cNode, Node\u003e excludedNodes\n                                          ) \n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n     checkBlock(previous);\n     long fileLength, blockSize;\n     int replication;\n     DatanodeDescriptor clientNode \u003d null;\n     Block newBlock \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\n           \"BLOCK* NameSystem.getAdditionalBlock: file \"\n           +src+\" for \"+clientName);\n     }\n \n     writeLock();\n     try {\n       if (isInSafeMode()) {\n         throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n       }\n \n       // have we exceeded the configured limit of fs objects.\n       checkFsObjectLimit();\n \n       INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n \n       // commit the last block and complete it if it has minimum replicas\n       blockManager.commitOrCompleteLastBlock(pendingFile, ExtendedBlock\n           .getLocalBlock(previous));\n \n       //\n       // If we fail this, bad things happen!\n       //\n       if (!checkFileProgress(pendingFile, false)) {\n         throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n       }\n       fileLength \u003d pendingFile.computeContentSummary().getLength();\n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientNode \u003d pendingFile.getClientNode();\n       replication \u003d (int)pendingFile.getReplication();\n     } finally {\n       writeUnlock();\n     }\n \n     // choose targets for the new block to be allocated.\n     final DatanodeDescriptor targets[] \u003d blockManager.chooseTarget(\n         src, replication, clientNode, excludedNodes, blockSize);\n \n     // Allocate a new block and record it in the INode. \n     writeLock();\n     try {\n       if (isInSafeMode()) {\n         throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n       }\n       INode[] pathINodes \u003d dir.getExistingPathINodes(src);\n       int inodesLen \u003d pathINodes.length;\n       checkLease(src, clientName, pathINodes[inodesLen-1]);\n       INodeFileUnderConstruction pendingFile  \u003d (INodeFileUnderConstruction) \n                                                 pathINodes[inodesLen - 1];\n                                                            \n       if (!checkFileProgress(pendingFile, false)) {\n         throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n       }\n \n       // allocate new block record block locations in INode.\n       newBlock \u003d allocateBlock(src, pathINodes, targets);\n       \n       for (DatanodeDescriptor dn : targets) {\n         dn.incBlocksScheduled();\n       }      \n     } finally {\n       writeUnlock();\n     }\n \n     // Create next block\n     LocatedBlock b \u003d new LocatedBlock(getExtendedBlock(newBlock), targets, fileLength);\n     blockManager.setBlockToken(b, BlockTokenSecretManager.AccessMode.WRITE);\n     return b;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlock getAdditionalBlock(String src,\n                                         String clientName,\n                                         ExtendedBlock previous,\n                                         HashMap\u003cNode, Node\u003e excludedNodes\n                                         ) \n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    checkBlock(previous);\n    long fileLength, blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n    Block newBlock \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\n          \"BLOCK* NameSystem.getAdditionalBlock: file \"\n          +src+\" for \"+clientName);\n    }\n\n    writeLock();\n    try {\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n      }\n\n      // have we exceeded the configured limit of fs objects.\n      checkFsObjectLimit();\n\n      INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n\n      // commit the last block and complete it if it has minimum replicas\n      blockManager.commitOrCompleteLastBlock(pendingFile, ExtendedBlock\n          .getLocalBlock(previous));\n\n      //\n      // If we fail this, bad things happen!\n      //\n      if (!checkFileProgress(pendingFile, false)) {\n        throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n      }\n      fileLength \u003d pendingFile.computeContentSummary().getLength();\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d pendingFile.getClientNode();\n      replication \u003d (int)pendingFile.getReplication();\n    } finally {\n      writeUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeDescriptor targets[] \u003d blockManager.chooseTarget(\n        src, replication, clientNode, excludedNodes, blockSize);\n\n    // Allocate a new block and record it in the INode. \n    writeLock();\n    try {\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n      }\n      INode[] pathINodes \u003d dir.getExistingPathINodes(src);\n      int inodesLen \u003d pathINodes.length;\n      checkLease(src, clientName, pathINodes[inodesLen-1]);\n      INodeFileUnderConstruction pendingFile  \u003d (INodeFileUnderConstruction) \n                                                pathINodes[inodesLen - 1];\n                                                           \n      if (!checkFileProgress(pendingFile, false)) {\n        throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n      }\n\n      // allocate new block record block locations in INode.\n      newBlock \u003d allocateBlock(src, pathINodes, targets);\n      \n      for (DatanodeDescriptor dn : targets) {\n        dn.incBlocksScheduled();\n      }      \n    } finally {\n      writeUnlock();\n    }\n\n    // Create next block\n    LocatedBlock b \u003d new LocatedBlock(getExtendedBlock(newBlock), targets, fileLength);\n    blockManager.setBlockToken(b, BlockTokenSecretManager.AccessMode.WRITE);\n    return b;\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {
        "oldValue": "[public]",
        "newValue": "[]"
      }
    },
    "371f4a59059322000a40eb4bdf5386b96b626ece": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2228. Move block and datanode code from FSNamesystem to BlockManager and DatanodeManager.  (szetszwo)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1154899 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/08/11 3:06 AM",
      "commitName": "371f4a59059322000a40eb4bdf5386b96b626ece",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "04/08/11 3:55 PM",
      "commitNameOld": "7fac946ac983e31613fd62836c8ac9c4a579210a",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 3.47,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,87 +1,84 @@\n   public LocatedBlock getAdditionalBlock(String src,\n                                          String clientName,\n                                          ExtendedBlock previous,\n                                          HashMap\u003cNode, Node\u003e excludedNodes\n                                          ) \n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n     checkBlock(previous);\n     long fileLength, blockSize;\n     int replication;\n     DatanodeDescriptor clientNode \u003d null;\n     Block newBlock \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\n           \"BLOCK* NameSystem.getAdditionalBlock: file \"\n           +src+\" for \"+clientName);\n     }\n \n     writeLock();\n     try {\n       if (isInSafeMode()) {\n         throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n       }\n \n       // have we exceeded the configured limit of fs objects.\n       checkFsObjectLimit();\n \n       INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n \n       // commit the last block and complete it if it has minimum replicas\n       blockManager.commitOrCompleteLastBlock(pendingFile, ExtendedBlock\n           .getLocalBlock(previous));\n \n       //\n       // If we fail this, bad things happen!\n       //\n       if (!checkFileProgress(pendingFile, false)) {\n         throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n       }\n       fileLength \u003d pendingFile.computeContentSummary().getLength();\n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientNode \u003d pendingFile.getClientNode();\n       replication \u003d (int)pendingFile.getReplication();\n     } finally {\n       writeUnlock();\n     }\n \n     // choose targets for the new block to be allocated.\n     final DatanodeDescriptor targets[] \u003d blockManager.chooseTarget(\n         src, replication, clientNode, excludedNodes, blockSize);\n \n     // Allocate a new block and record it in the INode. \n     writeLock();\n     try {\n       if (isInSafeMode()) {\n         throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n       }\n       INode[] pathINodes \u003d dir.getExistingPathINodes(src);\n       int inodesLen \u003d pathINodes.length;\n       checkLease(src, clientName, pathINodes[inodesLen-1]);\n       INodeFileUnderConstruction pendingFile  \u003d (INodeFileUnderConstruction) \n                                                 pathINodes[inodesLen - 1];\n                                                            \n       if (!checkFileProgress(pendingFile, false)) {\n         throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n       }\n \n       // allocate new block record block locations in INode.\n       newBlock \u003d allocateBlock(src, pathINodes, targets);\n       \n       for (DatanodeDescriptor dn : targets) {\n         dn.incBlocksScheduled();\n       }      \n     } finally {\n       writeUnlock();\n     }\n \n     // Create next block\n     LocatedBlock b \u003d new LocatedBlock(getExtendedBlock(newBlock), targets, fileLength);\n-    if (blockManager.isBlockTokenEnabled()) {\n-      b.setBlockToken(blockManager.getBlockTokenSecretManager().generateToken(b.getBlock(), \n-          EnumSet.of(BlockTokenSecretManager.AccessMode.WRITE)));\n-    }\n+    blockManager.setBlockToken(b, BlockTokenSecretManager.AccessMode.WRITE);\n     return b;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public LocatedBlock getAdditionalBlock(String src,\n                                         String clientName,\n                                         ExtendedBlock previous,\n                                         HashMap\u003cNode, Node\u003e excludedNodes\n                                         ) \n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    checkBlock(previous);\n    long fileLength, blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n    Block newBlock \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\n          \"BLOCK* NameSystem.getAdditionalBlock: file \"\n          +src+\" for \"+clientName);\n    }\n\n    writeLock();\n    try {\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n      }\n\n      // have we exceeded the configured limit of fs objects.\n      checkFsObjectLimit();\n\n      INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n\n      // commit the last block and complete it if it has minimum replicas\n      blockManager.commitOrCompleteLastBlock(pendingFile, ExtendedBlock\n          .getLocalBlock(previous));\n\n      //\n      // If we fail this, bad things happen!\n      //\n      if (!checkFileProgress(pendingFile, false)) {\n        throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n      }\n      fileLength \u003d pendingFile.computeContentSummary().getLength();\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d pendingFile.getClientNode();\n      replication \u003d (int)pendingFile.getReplication();\n    } finally {\n      writeUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeDescriptor targets[] \u003d blockManager.chooseTarget(\n        src, replication, clientNode, excludedNodes, blockSize);\n\n    // Allocate a new block and record it in the INode. \n    writeLock();\n    try {\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n      }\n      INode[] pathINodes \u003d dir.getExistingPathINodes(src);\n      int inodesLen \u003d pathINodes.length;\n      checkLease(src, clientName, pathINodes[inodesLen-1]);\n      INodeFileUnderConstruction pendingFile  \u003d (INodeFileUnderConstruction) \n                                                pathINodes[inodesLen - 1];\n                                                           \n      if (!checkFileProgress(pendingFile, false)) {\n        throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n      }\n\n      // allocate new block record block locations in INode.\n      newBlock \u003d allocateBlock(src, pathINodes, targets);\n      \n      for (DatanodeDescriptor dn : targets) {\n        dn.incBlocksScheduled();\n      }      \n    } finally {\n      writeUnlock();\n    }\n\n    // Create next block\n    LocatedBlock b \u003d new LocatedBlock(getExtendedBlock(newBlock), targets, fileLength);\n    blockManager.setBlockToken(b, BlockTokenSecretManager.AccessMode.WRITE);\n    return b;\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "d68e38b78d9687987c4de2046ce9aa0016685e98": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2199. Move blockTokenSecretManager from FSNamesystem to BlockManager.  Contributed by Uma Maheswara Rao G\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1152776 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "01/08/11 6:57 AM",
      "commitName": "d68e38b78d9687987c4de2046ce9aa0016685e98",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "29/07/11 5:10 PM",
      "commitNameOld": "8390152d08306caad31b78abbd509e5ea8580671",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 2.57,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,87 +1,87 @@\n   public LocatedBlock getAdditionalBlock(String src,\n                                          String clientName,\n                                          ExtendedBlock previous,\n                                          HashMap\u003cNode, Node\u003e excludedNodes\n                                          ) \n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n     checkBlock(previous);\n     long fileLength, blockSize;\n     int replication;\n     DatanodeDescriptor clientNode \u003d null;\n     Block newBlock \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\n           \"BLOCK* NameSystem.getAdditionalBlock: file \"\n           +src+\" for \"+clientName);\n     }\n \n     writeLock();\n     try {\n       if (isInSafeMode()) {\n         throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n       }\n \n       // have we exceeded the configured limit of fs objects.\n       checkFsObjectLimit();\n \n       INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n \n       // commit the last block and complete it if it has minimum replicas\n       blockManager.commitOrCompleteLastBlock(pendingFile, ExtendedBlock\n           .getLocalBlock(previous));\n \n       //\n       // If we fail this, bad things happen!\n       //\n       if (!checkFileProgress(pendingFile, false)) {\n         throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n       }\n       fileLength \u003d pendingFile.computeContentSummary().getLength();\n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientNode \u003d pendingFile.getClientNode();\n       replication \u003d (int)pendingFile.getReplication();\n     } finally {\n       writeUnlock();\n     }\n \n     // choose targets for the new block to be allocated.\n     final DatanodeDescriptor targets[] \u003d blockManager.chooseTarget(\n         src, replication, clientNode, excludedNodes, blockSize);\n \n     // Allocate a new block and record it in the INode. \n     writeLock();\n     try {\n       if (isInSafeMode()) {\n         throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n       }\n       INode[] pathINodes \u003d dir.getExistingPathINodes(src);\n       int inodesLen \u003d pathINodes.length;\n       checkLease(src, clientName, pathINodes[inodesLen-1]);\n       INodeFileUnderConstruction pendingFile  \u003d (INodeFileUnderConstruction) \n                                                 pathINodes[inodesLen - 1];\n                                                            \n       if (!checkFileProgress(pendingFile, false)) {\n         throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n       }\n \n       // allocate new block record block locations in INode.\n       newBlock \u003d allocateBlock(src, pathINodes, targets);\n       \n       for (DatanodeDescriptor dn : targets) {\n         dn.incBlocksScheduled();\n       }      \n     } finally {\n       writeUnlock();\n     }\n \n     // Create next block\n     LocatedBlock b \u003d new LocatedBlock(getExtendedBlock(newBlock), targets, fileLength);\n-    if (isBlockTokenEnabled) {\n-      b.setBlockToken(blockTokenSecretManager.generateToken(b.getBlock(), \n+    if (blockManager.isBlockTokenEnabled()) {\n+      b.setBlockToken(blockManager.getBlockTokenSecretManager().generateToken(b.getBlock(), \n           EnumSet.of(BlockTokenSecretManager.AccessMode.WRITE)));\n     }\n     return b;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public LocatedBlock getAdditionalBlock(String src,\n                                         String clientName,\n                                         ExtendedBlock previous,\n                                         HashMap\u003cNode, Node\u003e excludedNodes\n                                         ) \n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    checkBlock(previous);\n    long fileLength, blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n    Block newBlock \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\n          \"BLOCK* NameSystem.getAdditionalBlock: file \"\n          +src+\" for \"+clientName);\n    }\n\n    writeLock();\n    try {\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n      }\n\n      // have we exceeded the configured limit of fs objects.\n      checkFsObjectLimit();\n\n      INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n\n      // commit the last block and complete it if it has minimum replicas\n      blockManager.commitOrCompleteLastBlock(pendingFile, ExtendedBlock\n          .getLocalBlock(previous));\n\n      //\n      // If we fail this, bad things happen!\n      //\n      if (!checkFileProgress(pendingFile, false)) {\n        throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n      }\n      fileLength \u003d pendingFile.computeContentSummary().getLength();\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d pendingFile.getClientNode();\n      replication \u003d (int)pendingFile.getReplication();\n    } finally {\n      writeUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeDescriptor targets[] \u003d blockManager.chooseTarget(\n        src, replication, clientNode, excludedNodes, blockSize);\n\n    // Allocate a new block and record it in the INode. \n    writeLock();\n    try {\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n      }\n      INode[] pathINodes \u003d dir.getExistingPathINodes(src);\n      int inodesLen \u003d pathINodes.length;\n      checkLease(src, clientName, pathINodes[inodesLen-1]);\n      INodeFileUnderConstruction pendingFile  \u003d (INodeFileUnderConstruction) \n                                                pathINodes[inodesLen - 1];\n                                                           \n      if (!checkFileProgress(pendingFile, false)) {\n        throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n      }\n\n      // allocate new block record block locations in INode.\n      newBlock \u003d allocateBlock(src, pathINodes, targets);\n      \n      for (DatanodeDescriptor dn : targets) {\n        dn.incBlocksScheduled();\n      }      \n    } finally {\n      writeUnlock();\n    }\n\n    // Create next block\n    LocatedBlock b \u003d new LocatedBlock(getExtendedBlock(newBlock), targets, fileLength);\n    if (blockManager.isBlockTokenEnabled()) {\n      b.setBlockToken(blockManager.getBlockTokenSecretManager().generateToken(b.getBlock(), \n          EnumSet.of(BlockTokenSecretManager.AccessMode.WRITE)));\n    }\n    return b;\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "c3f6575ca44e8ad803d0b46991472465b595cdeb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2147. Move cluster network topology to block management and fix some javac warnings.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1148112 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/07/11 5:26 PM",
      "commitName": "c3f6575ca44e8ad803d0b46991472465b595cdeb",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "13/07/11 4:24 PM",
      "commitNameOld": "8327e70be87990c37ac14dcc1cb1a4d209c65593",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 5.04,
      "commitsBetweenForRepo": 17,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,95 +1,87 @@\n   public LocatedBlock getAdditionalBlock(String src,\n                                          String clientName,\n                                          ExtendedBlock previous,\n                                          HashMap\u003cNode, Node\u003e excludedNodes\n                                          ) \n       throws LeaseExpiredException, NotReplicatedYetException,\n       QuotaExceededException, SafeModeException, UnresolvedLinkException,\n       IOException {\n     checkBlock(previous);\n     long fileLength, blockSize;\n     int replication;\n     DatanodeDescriptor clientNode \u003d null;\n     Block newBlock \u003d null;\n \n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\n           \"BLOCK* NameSystem.getAdditionalBlock: file \"\n           +src+\" for \"+clientName);\n     }\n \n     writeLock();\n     try {\n       if (isInSafeMode()) {\n         throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n       }\n \n       // have we exceeded the configured limit of fs objects.\n       checkFsObjectLimit();\n \n       INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n \n       // commit the last block and complete it if it has minimum replicas\n       blockManager.commitOrCompleteLastBlock(pendingFile, ExtendedBlock\n           .getLocalBlock(previous));\n \n       //\n       // If we fail this, bad things happen!\n       //\n       if (!checkFileProgress(pendingFile, false)) {\n         throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n       }\n       fileLength \u003d pendingFile.computeContentSummary().getLength();\n       blockSize \u003d pendingFile.getPreferredBlockSize();\n       clientNode \u003d pendingFile.getClientNode();\n       replication \u003d (int)pendingFile.getReplication();\n     } finally {\n       writeUnlock();\n     }\n \n     // choose targets for the new block to be allocated.\n-    DatanodeDescriptor targets[] \u003d blockManager.replicator.chooseTarget(\n+    final DatanodeDescriptor targets[] \u003d blockManager.chooseTarget(\n         src, replication, clientNode, excludedNodes, blockSize);\n-    if (targets.length \u003c blockManager.minReplication) {\n-      throw new IOException(\"File \" + src + \" could only be replicated to \" +\n-                            targets.length + \" nodes, instead of \" +\n-                            blockManager.minReplication + \". There are \"\n-                            +clusterMap.getNumOfLeaves()+\" datanode(s) running\"\n-                            +\" but \"+excludedNodes.size() +\n-                            \" node(s) are excluded in this operation.\");\n-    }\n \n     // Allocate a new block and record it in the INode. \n     writeLock();\n     try {\n       if (isInSafeMode()) {\n         throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n       }\n       INode[] pathINodes \u003d dir.getExistingPathINodes(src);\n       int inodesLen \u003d pathINodes.length;\n       checkLease(src, clientName, pathINodes[inodesLen-1]);\n       INodeFileUnderConstruction pendingFile  \u003d (INodeFileUnderConstruction) \n                                                 pathINodes[inodesLen - 1];\n                                                            \n       if (!checkFileProgress(pendingFile, false)) {\n         throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n       }\n \n       // allocate new block record block locations in INode.\n       newBlock \u003d allocateBlock(src, pathINodes, targets);\n       \n       for (DatanodeDescriptor dn : targets) {\n         dn.incBlocksScheduled();\n       }      \n     } finally {\n       writeUnlock();\n     }\n \n     // Create next block\n     LocatedBlock b \u003d new LocatedBlock(getExtendedBlock(newBlock), targets, fileLength);\n     if (isBlockTokenEnabled) {\n       b.setBlockToken(blockTokenSecretManager.generateToken(b.getBlock(), \n           EnumSet.of(BlockTokenSecretManager.AccessMode.WRITE)));\n     }\n     return b;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public LocatedBlock getAdditionalBlock(String src,\n                                         String clientName,\n                                         ExtendedBlock previous,\n                                         HashMap\u003cNode, Node\u003e excludedNodes\n                                         ) \n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    checkBlock(previous);\n    long fileLength, blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n    Block newBlock \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\n          \"BLOCK* NameSystem.getAdditionalBlock: file \"\n          +src+\" for \"+clientName);\n    }\n\n    writeLock();\n    try {\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n      }\n\n      // have we exceeded the configured limit of fs objects.\n      checkFsObjectLimit();\n\n      INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n\n      // commit the last block and complete it if it has minimum replicas\n      blockManager.commitOrCompleteLastBlock(pendingFile, ExtendedBlock\n          .getLocalBlock(previous));\n\n      //\n      // If we fail this, bad things happen!\n      //\n      if (!checkFileProgress(pendingFile, false)) {\n        throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n      }\n      fileLength \u003d pendingFile.computeContentSummary().getLength();\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d pendingFile.getClientNode();\n      replication \u003d (int)pendingFile.getReplication();\n    } finally {\n      writeUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    final DatanodeDescriptor targets[] \u003d blockManager.chooseTarget(\n        src, replication, clientNode, excludedNodes, blockSize);\n\n    // Allocate a new block and record it in the INode. \n    writeLock();\n    try {\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n      }\n      INode[] pathINodes \u003d dir.getExistingPathINodes(src);\n      int inodesLen \u003d pathINodes.length;\n      checkLease(src, clientName, pathINodes[inodesLen-1]);\n      INodeFileUnderConstruction pendingFile  \u003d (INodeFileUnderConstruction) \n                                                pathINodes[inodesLen - 1];\n                                                           \n      if (!checkFileProgress(pendingFile, false)) {\n        throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n      }\n\n      // allocate new block record block locations in INode.\n      newBlock \u003d allocateBlock(src, pathINodes, targets);\n      \n      for (DatanodeDescriptor dn : targets) {\n        dn.incBlocksScheduled();\n      }      \n    } finally {\n      writeUnlock();\n    }\n\n    // Create next block\n    LocatedBlock b \u003d new LocatedBlock(getExtendedBlock(newBlock), targets, fileLength);\n    if (isBlockTokenEnabled) {\n      b.setBlockToken(blockTokenSecretManager.generateToken(b.getBlock(), \n          EnumSet.of(BlockTokenSecretManager.AccessMode.WRITE)));\n    }\n    return b;\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,95 @@\n+  public LocatedBlock getAdditionalBlock(String src,\n+                                         String clientName,\n+                                         ExtendedBlock previous,\n+                                         HashMap\u003cNode, Node\u003e excludedNodes\n+                                         ) \n+      throws LeaseExpiredException, NotReplicatedYetException,\n+      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n+      IOException {\n+    checkBlock(previous);\n+    long fileLength, blockSize;\n+    int replication;\n+    DatanodeDescriptor clientNode \u003d null;\n+    Block newBlock \u003d null;\n+\n+    if(NameNode.stateChangeLog.isDebugEnabled()) {\n+      NameNode.stateChangeLog.debug(\n+          \"BLOCK* NameSystem.getAdditionalBlock: file \"\n+          +src+\" for \"+clientName);\n+    }\n+\n+    writeLock();\n+    try {\n+      if (isInSafeMode()) {\n+        throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n+      }\n+\n+      // have we exceeded the configured limit of fs objects.\n+      checkFsObjectLimit();\n+\n+      INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n+\n+      // commit the last block and complete it if it has minimum replicas\n+      blockManager.commitOrCompleteLastBlock(pendingFile, ExtendedBlock\n+          .getLocalBlock(previous));\n+\n+      //\n+      // If we fail this, bad things happen!\n+      //\n+      if (!checkFileProgress(pendingFile, false)) {\n+        throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n+      }\n+      fileLength \u003d pendingFile.computeContentSummary().getLength();\n+      blockSize \u003d pendingFile.getPreferredBlockSize();\n+      clientNode \u003d pendingFile.getClientNode();\n+      replication \u003d (int)pendingFile.getReplication();\n+    } finally {\n+      writeUnlock();\n+    }\n+\n+    // choose targets for the new block to be allocated.\n+    DatanodeDescriptor targets[] \u003d blockManager.replicator.chooseTarget(\n+        src, replication, clientNode, excludedNodes, blockSize);\n+    if (targets.length \u003c blockManager.minReplication) {\n+      throw new IOException(\"File \" + src + \" could only be replicated to \" +\n+                            targets.length + \" nodes, instead of \" +\n+                            blockManager.minReplication + \". There are \"\n+                            +clusterMap.getNumOfLeaves()+\" datanode(s) running\"\n+                            +\" but \"+excludedNodes.size() +\n+                            \" node(s) are excluded in this operation.\");\n+    }\n+\n+    // Allocate a new block and record it in the INode. \n+    writeLock();\n+    try {\n+      if (isInSafeMode()) {\n+        throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n+      }\n+      INode[] pathINodes \u003d dir.getExistingPathINodes(src);\n+      int inodesLen \u003d pathINodes.length;\n+      checkLease(src, clientName, pathINodes[inodesLen-1]);\n+      INodeFileUnderConstruction pendingFile  \u003d (INodeFileUnderConstruction) \n+                                                pathINodes[inodesLen - 1];\n+                                                           \n+      if (!checkFileProgress(pendingFile, false)) {\n+        throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n+      }\n+\n+      // allocate new block record block locations in INode.\n+      newBlock \u003d allocateBlock(src, pathINodes, targets);\n+      \n+      for (DatanodeDescriptor dn : targets) {\n+        dn.incBlocksScheduled();\n+      }      \n+    } finally {\n+      writeUnlock();\n+    }\n+\n+    // Create next block\n+    LocatedBlock b \u003d new LocatedBlock(getExtendedBlock(newBlock), targets, fileLength);\n+    if (isBlockTokenEnabled) {\n+      b.setBlockToken(blockTokenSecretManager.generateToken(b.getBlock(), \n+          EnumSet.of(BlockTokenSecretManager.AccessMode.WRITE)));\n+    }\n+    return b;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public LocatedBlock getAdditionalBlock(String src,\n                                         String clientName,\n                                         ExtendedBlock previous,\n                                         HashMap\u003cNode, Node\u003e excludedNodes\n                                         ) \n      throws LeaseExpiredException, NotReplicatedYetException,\n      QuotaExceededException, SafeModeException, UnresolvedLinkException,\n      IOException {\n    checkBlock(previous);\n    long fileLength, blockSize;\n    int replication;\n    DatanodeDescriptor clientNode \u003d null;\n    Block newBlock \u003d null;\n\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\n          \"BLOCK* NameSystem.getAdditionalBlock: file \"\n          +src+\" for \"+clientName);\n    }\n\n    writeLock();\n    try {\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n      }\n\n      // have we exceeded the configured limit of fs objects.\n      checkFsObjectLimit();\n\n      INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n\n      // commit the last block and complete it if it has minimum replicas\n      blockManager.commitOrCompleteLastBlock(pendingFile, ExtendedBlock\n          .getLocalBlock(previous));\n\n      //\n      // If we fail this, bad things happen!\n      //\n      if (!checkFileProgress(pendingFile, false)) {\n        throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n      }\n      fileLength \u003d pendingFile.computeContentSummary().getLength();\n      blockSize \u003d pendingFile.getPreferredBlockSize();\n      clientNode \u003d pendingFile.getClientNode();\n      replication \u003d (int)pendingFile.getReplication();\n    } finally {\n      writeUnlock();\n    }\n\n    // choose targets for the new block to be allocated.\n    DatanodeDescriptor targets[] \u003d blockManager.replicator.chooseTarget(\n        src, replication, clientNode, excludedNodes, blockSize);\n    if (targets.length \u003c blockManager.minReplication) {\n      throw new IOException(\"File \" + src + \" could only be replicated to \" +\n                            targets.length + \" nodes, instead of \" +\n                            blockManager.minReplication + \". There are \"\n                            +clusterMap.getNumOfLeaves()+\" datanode(s) running\"\n                            +\" but \"+excludedNodes.size() +\n                            \" node(s) are excluded in this operation.\");\n    }\n\n    // Allocate a new block and record it in the INode. \n    writeLock();\n    try {\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n      }\n      INode[] pathINodes \u003d dir.getExistingPathINodes(src);\n      int inodesLen \u003d pathINodes.length;\n      checkLease(src, clientName, pathINodes[inodesLen-1]);\n      INodeFileUnderConstruction pendingFile  \u003d (INodeFileUnderConstruction) \n                                                pathINodes[inodesLen - 1];\n                                                           \n      if (!checkFileProgress(pendingFile, false)) {\n        throw new NotReplicatedYetException(\"Not replicated yet:\" + src);\n      }\n\n      // allocate new block record block locations in INode.\n      newBlock \u003d allocateBlock(src, pathINodes, targets);\n      \n      for (DatanodeDescriptor dn : targets) {\n        dn.incBlocksScheduled();\n      }      \n    } finally {\n      writeUnlock();\n    }\n\n    // Create next block\n    LocatedBlock b \u003d new LocatedBlock(getExtendedBlock(newBlock), targets, fileLength);\n    if (isBlockTokenEnabled) {\n      b.setBlockToken(blockTokenSecretManager.generateToken(b.getBlock(), \n          EnumSet.of(BlockTokenSecretManager.AccessMode.WRITE)));\n    }\n    return b;\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java"
    }
  }
}