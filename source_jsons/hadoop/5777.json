{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "NameNodeRpcServer.java",
  "functionName": "updatePipeline",
  "functionId": "updatePipeline___clientName-String__oldBlock-ExtendedBlock__newBlock-ExtendedBlock__newNodes-DatanodeID[]__newStorageIDs-String[]",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java",
  "functionStartLine": 987,
  "functionEndLine": 1005,
  "numCommitsSeen": 296,
  "timeTaken": 5218,
  "changeHistory": [
    "7817674a3a4d097b647dd77f1345787dd376d5ea",
    "db334bb8625da97c7e518cbcf477530c7ba7001e",
    "8e253cb93030642f5a7324bad0f161cd0ad33206"
  ],
  "changeHistoryShort": {
    "7817674a3a4d097b647dd77f1345787dd376d5ea": "Ybodychange",
    "db334bb8625da97c7e518cbcf477530c7ba7001e": "Ybodychange",
    "8e253cb93030642f5a7324bad0f161cd0ad33206": "Ybodychange"
  },
  "changeHistoryDetails": {
    "7817674a3a4d097b647dd77f1345787dd376d5ea": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7609. Avoid retry cache collision when Standby NameNode loading edits. Contributed by Ming Ma.\n",
      "commitDate": "29/05/15 11:05 AM",
      "commitName": "7817674a3a4d097b647dd77f1345787dd376d5ea",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "15/05/15 7:09 PM",
      "commitNameOld": "e5afac5896a1a88e152746598527d91f73cbb724",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 13.66,
      "commitsBetweenForRepo": 105,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,19 @@\n   public void updatePipeline(String clientName, ExtendedBlock oldBlock,\n       ExtendedBlock newBlock, DatanodeID[] newNodes, String[] newStorageIDs)\n       throws IOException {\n     checkNNStartup();\n+    namesystem.checkOperation(OperationCategory.WRITE);\n     CacheEntry cacheEntry \u003d RetryCache.waitForCompletion(retryCache);\n     if (cacheEntry !\u003d null \u0026\u0026 cacheEntry.isSuccess()) {\n       return; // Return previous response\n     }\n \n     boolean success \u003d false;\n     try {\n       namesystem.updatePipeline(clientName, oldBlock, newBlock, newNodes,\n           newStorageIDs, cacheEntry !\u003d null);\n       success \u003d true;\n     } finally {\n       RetryCache.setState(cacheEntry, success);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void updatePipeline(String clientName, ExtendedBlock oldBlock,\n      ExtendedBlock newBlock, DatanodeID[] newNodes, String[] newStorageIDs)\n      throws IOException {\n    checkNNStartup();\n    namesystem.checkOperation(OperationCategory.WRITE);\n    CacheEntry cacheEntry \u003d RetryCache.waitForCompletion(retryCache);\n    if (cacheEntry !\u003d null \u0026\u0026 cacheEntry.isSuccess()) {\n      return; // Return previous response\n    }\n\n    boolean success \u003d false;\n    try {\n      namesystem.updatePipeline(clientName, oldBlock, newBlock, newNodes,\n          newStorageIDs, cacheEntry !\u003d null);\n      success \u003d true;\n    } finally {\n      RetryCache.setState(cacheEntry, success);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java",
      "extendedDetails": {}
    },
    "db334bb8625da97c7e518cbcf477530c7ba7001e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3443. Fix NPE when namenode transition to active during startup by adding checkNNStartup() in NameNodeRpcServer.  Contributed by Vinayakumar B\n",
      "commitDate": "21/01/15 11:33 AM",
      "commitName": "db334bb8625da97c7e518cbcf477530c7ba7001e",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "12/01/15 10:50 PM",
      "commitNameOld": "7e9358feb326d48b8c4f00249e7af5023cebd2e2",
      "commitAuthorOld": "Plamen Jeliazkov",
      "daysBetweenCommits": 8.53,
      "commitsBetweenForRepo": 59,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,18 @@\n   public void updatePipeline(String clientName, ExtendedBlock oldBlock,\n       ExtendedBlock newBlock, DatanodeID[] newNodes, String[] newStorageIDs)\n       throws IOException {\n+    checkNNStartup();\n     CacheEntry cacheEntry \u003d RetryCache.waitForCompletion(retryCache);\n     if (cacheEntry !\u003d null \u0026\u0026 cacheEntry.isSuccess()) {\n       return; // Return previous response\n     }\n \n     boolean success \u003d false;\n     try {\n       namesystem.updatePipeline(clientName, oldBlock, newBlock, newNodes,\n           newStorageIDs, cacheEntry !\u003d null);\n       success \u003d true;\n     } finally {\n       RetryCache.setState(cacheEntry, success);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void updatePipeline(String clientName, ExtendedBlock oldBlock,\n      ExtendedBlock newBlock, DatanodeID[] newNodes, String[] newStorageIDs)\n      throws IOException {\n    checkNNStartup();\n    CacheEntry cacheEntry \u003d RetryCache.waitForCompletion(retryCache);\n    if (cacheEntry !\u003d null \u0026\u0026 cacheEntry.isSuccess()) {\n      return; // Return previous response\n    }\n\n    boolean success \u003d false;\n    try {\n      namesystem.updatePipeline(clientName, oldBlock, newBlock, newNodes,\n          newStorageIDs, cacheEntry !\u003d null);\n      success \u003d true;\n    } finally {\n      RetryCache.setState(cacheEntry, success);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java",
      "extendedDetails": {}
    },
    "8e253cb93030642f5a7324bad0f161cd0ad33206": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7412. Move RetryCache to NameNodeRpcServer. Contributed by Haohui Mai.\n",
      "commitDate": "24/11/14 11:11 AM",
      "commitName": "8e253cb93030642f5a7324bad0f161cd0ad33206",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "04/11/14 4:02 PM",
      "commitNameOld": "5bd3a569f941ffcfc425a55288bec78a37a75aa1",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 19.8,
      "commitsBetweenForRepo": 170,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,5 +1,17 @@\n   public void updatePipeline(String clientName, ExtendedBlock oldBlock,\n       ExtendedBlock newBlock, DatanodeID[] newNodes, String[] newStorageIDs)\n       throws IOException {\n-    namesystem.updatePipeline(clientName, oldBlock, newBlock, newNodes, newStorageIDs);\n+    CacheEntry cacheEntry \u003d RetryCache.waitForCompletion(retryCache);\n+    if (cacheEntry !\u003d null \u0026\u0026 cacheEntry.isSuccess()) {\n+      return; // Return previous response\n+    }\n+\n+    boolean success \u003d false;\n+    try {\n+      namesystem.updatePipeline(clientName, oldBlock, newBlock, newNodes,\n+          newStorageIDs, cacheEntry !\u003d null);\n+      success \u003d true;\n+    } finally {\n+      RetryCache.setState(cacheEntry, success);\n+    }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void updatePipeline(String clientName, ExtendedBlock oldBlock,\n      ExtendedBlock newBlock, DatanodeID[] newNodes, String[] newStorageIDs)\n      throws IOException {\n    CacheEntry cacheEntry \u003d RetryCache.waitForCompletion(retryCache);\n    if (cacheEntry !\u003d null \u0026\u0026 cacheEntry.isSuccess()) {\n      return; // Return previous response\n    }\n\n    boolean success \u003d false;\n    try {\n      namesystem.updatePipeline(clientName, oldBlock, newBlock, newNodes,\n          newStorageIDs, cacheEntry !\u003d null);\n      success \u003d true;\n    } finally {\n      RetryCache.setState(cacheEntry, success);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java",
      "extendedDetails": {}
    }
  }
}