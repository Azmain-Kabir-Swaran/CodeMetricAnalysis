{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ProvidedStorageMap.java",
  "functionName": "newLocatedBlock",
  "functionId": "newLocatedBlock___eb-ExtendedBlock__storages-DatanodeStorageInfo[]__pos-long__isCorrupt-boolean",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ProvidedStorageMap.java",
  "functionStartLine": 247,
  "functionEndLine": 298,
  "numCommitsSeen": 17,
  "timeTaken": 2476,
  "changeHistory": [
    "4d59dabb7f6ef1d8565bf2bb2d38aeb91bf7f7cc",
    "3d3be87e301d9f8ab1a220bc5dbeae0f032c5a86",
    "aa5ec85f7fd2dc6ac568a88716109bab8df8be19",
    "d65df0f27395792c6e25f5e03b6ba1765e2ba925"
  ],
  "changeHistoryShort": {
    "4d59dabb7f6ef1d8565bf2bb2d38aeb91bf7f7cc": "Ybodychange",
    "3d3be87e301d9f8ab1a220bc5dbeae0f032c5a86": "Ybodychange",
    "aa5ec85f7fd2dc6ac568a88716109bab8df8be19": "Ybodychange",
    "d65df0f27395792c6e25f5e03b6ba1765e2ba925": "Yintroduced"
  },
  "changeHistoryDetails": {
    "4d59dabb7f6ef1d8565bf2bb2d38aeb91bf7f7cc": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12809. [READ] Fix the randomized selection of locations in {{ProvidedBlocksBuilder}}.\n",
      "commitDate": "15/12/17 5:51 PM",
      "commitName": "4d59dabb7f6ef1d8565bf2bb2d38aeb91bf7f7cc",
      "commitAuthor": "Virajith Jalaparti",
      "commitDateOld": "15/12/17 5:51 PM",
      "commitNameOld": "3d3be87e301d9f8ab1a220bc5dbeae0f032c5a86",
      "commitAuthorOld": "Virajith Jalaparti",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,49 +1,52 @@\n     LocatedBlock newLocatedBlock(ExtendedBlock eb,\n         DatanodeStorageInfo[] storages, long pos, boolean isCorrupt) {\n \n       List\u003cDatanodeInfoWithStorage\u003e locs \u003d new ArrayList\u003c\u003e();\n       List\u003cString\u003e sids \u003d new ArrayList\u003c\u003e();\n       List\u003cStorageType\u003e types \u003d new ArrayList\u003c\u003e();\n       boolean isProvidedBlock \u003d false;\n       Set\u003cString\u003e excludedUUids \u003d new HashSet\u003c\u003e();\n \n       for (int i \u003d 0; i \u003c storages.length; ++i) {\n         DatanodeStorageInfo currInfo \u003d storages[i];\n         StorageType storageType \u003d currInfo.getStorageType();\n         sids.add(currInfo.getStorageID());\n         types.add(storageType);\n         if (StorageType.PROVIDED.equals(storageType)) {\n-          DatanodeDescriptor dn \u003d chooseProvidedDatanode(excludedUUids);\n-          locs.add(\n-              new DatanodeInfoWithStorage(\n-                  dn, currInfo.getStorageID(), currInfo.getStorageType()));\n-          excludedUUids.add(dn.getDatanodeUuid());\n+          // Provided location will be added to the list of locations after\n+          // examining all local locations.\n           isProvidedBlock \u003d true;\n         } else {\n           locs.add(new DatanodeInfoWithStorage(\n               currInfo.getDatanodeDescriptor(),\n               currInfo.getStorageID(), storageType));\n           excludedUUids.add(currInfo.getDatanodeDescriptor().getDatanodeUuid());\n         }\n       }\n \n       int numLocations \u003d locs.size();\n       if (isProvidedBlock) {\n+        // add the first datanode here\n+        DatanodeDescriptor dn \u003d chooseProvidedDatanode(excludedUUids);\n+        locs.add(\n+            new DatanodeInfoWithStorage(dn, storageId, StorageType.PROVIDED));\n+        excludedUUids.add(dn.getDatanodeUuid());\n+        numLocations++;\n         // add more replicas until we reach the defaultReplication\n         for (int count \u003d numLocations + 1;\n             count \u003c\u003d defaultReplication \u0026\u0026 count \u003c\u003d providedDescriptor\n                 .activeProvidedDatanodes(); count++) {\n-          DatanodeDescriptor dn \u003d chooseProvidedDatanode(excludedUUids);\n+          dn \u003d chooseProvidedDatanode(excludedUUids);\n           locs.add(new DatanodeInfoWithStorage(\n               dn, storageId, StorageType.PROVIDED));\n           sids.add(storageId);\n           types.add(StorageType.PROVIDED);\n           excludedUUids.add(dn.getDatanodeUuid());\n         }\n       }\n       return new LocatedBlock(eb,\n           locs.toArray(new DatanodeInfoWithStorage[locs.size()]),\n           sids.toArray(new String[sids.size()]),\n           types.toArray(new StorageType[types.size()]),\n           pos, isCorrupt, null);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    LocatedBlock newLocatedBlock(ExtendedBlock eb,\n        DatanodeStorageInfo[] storages, long pos, boolean isCorrupt) {\n\n      List\u003cDatanodeInfoWithStorage\u003e locs \u003d new ArrayList\u003c\u003e();\n      List\u003cString\u003e sids \u003d new ArrayList\u003c\u003e();\n      List\u003cStorageType\u003e types \u003d new ArrayList\u003c\u003e();\n      boolean isProvidedBlock \u003d false;\n      Set\u003cString\u003e excludedUUids \u003d new HashSet\u003c\u003e();\n\n      for (int i \u003d 0; i \u003c storages.length; ++i) {\n        DatanodeStorageInfo currInfo \u003d storages[i];\n        StorageType storageType \u003d currInfo.getStorageType();\n        sids.add(currInfo.getStorageID());\n        types.add(storageType);\n        if (StorageType.PROVIDED.equals(storageType)) {\n          // Provided location will be added to the list of locations after\n          // examining all local locations.\n          isProvidedBlock \u003d true;\n        } else {\n          locs.add(new DatanodeInfoWithStorage(\n              currInfo.getDatanodeDescriptor(),\n              currInfo.getStorageID(), storageType));\n          excludedUUids.add(currInfo.getDatanodeDescriptor().getDatanodeUuid());\n        }\n      }\n\n      int numLocations \u003d locs.size();\n      if (isProvidedBlock) {\n        // add the first datanode here\n        DatanodeDescriptor dn \u003d chooseProvidedDatanode(excludedUUids);\n        locs.add(\n            new DatanodeInfoWithStorage(dn, storageId, StorageType.PROVIDED));\n        excludedUUids.add(dn.getDatanodeUuid());\n        numLocations++;\n        // add more replicas until we reach the defaultReplication\n        for (int count \u003d numLocations + 1;\n            count \u003c\u003d defaultReplication \u0026\u0026 count \u003c\u003d providedDescriptor\n                .activeProvidedDatanodes(); count++) {\n          dn \u003d chooseProvidedDatanode(excludedUUids);\n          locs.add(new DatanodeInfoWithStorage(\n              dn, storageId, StorageType.PROVIDED));\n          sids.add(storageId);\n          types.add(StorageType.PROVIDED);\n          excludedUUids.add(dn.getDatanodeUuid());\n        }\n      }\n      return new LocatedBlock(eb,\n          locs.toArray(new DatanodeInfoWithStorage[locs.size()]),\n          sids.toArray(new String[sids.size()]),\n          types.toArray(new StorageType[types.size()]),\n          pos, isCorrupt, null);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ProvidedStorageMap.java",
      "extendedDetails": {}
    },
    "3d3be87e301d9f8ab1a220bc5dbeae0f032c5a86": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12778. [READ] Report multiple locations for PROVIDED blocks\n",
      "commitDate": "15/12/17 5:51 PM",
      "commitName": "3d3be87e301d9f8ab1a220bc5dbeae0f032c5a86",
      "commitAuthor": "Virajith Jalaparti",
      "commitDateOld": "15/12/17 5:51 PM",
      "commitNameOld": "3b1d30301bcd35bbe525a7e122d3e5acfab92c88",
      "commitAuthorOld": "Virajith Jalaparti",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,49 @@\n     LocatedBlock newLocatedBlock(ExtendedBlock eb,\n         DatanodeStorageInfo[] storages, long pos, boolean isCorrupt) {\n \n-      DatanodeInfoWithStorage[] locs \u003d\n-        new DatanodeInfoWithStorage[storages.length];\n-      String[] sids \u003d new String[storages.length];\n-      StorageType[] types \u003d new StorageType[storages.length];\n+      List\u003cDatanodeInfoWithStorage\u003e locs \u003d new ArrayList\u003c\u003e();\n+      List\u003cString\u003e sids \u003d new ArrayList\u003c\u003e();\n+      List\u003cStorageType\u003e types \u003d new ArrayList\u003c\u003e();\n+      boolean isProvidedBlock \u003d false;\n+      Set\u003cString\u003e excludedUUids \u003d new HashSet\u003c\u003e();\n+\n       for (int i \u003d 0; i \u003c storages.length; ++i) {\n-        sids[i] \u003d storages[i].getStorageID();\n-        types[i] \u003d storages[i].getStorageType();\n-        if (StorageType.PROVIDED.equals(storages[i].getStorageType())) {\n-          locs[i] \u003d pending;\n-          hasProvidedLocations \u003d true;\n+        DatanodeStorageInfo currInfo \u003d storages[i];\n+        StorageType storageType \u003d currInfo.getStorageType();\n+        sids.add(currInfo.getStorageID());\n+        types.add(storageType);\n+        if (StorageType.PROVIDED.equals(storageType)) {\n+          DatanodeDescriptor dn \u003d chooseProvidedDatanode(excludedUUids);\n+          locs.add(\n+              new DatanodeInfoWithStorage(\n+                  dn, currInfo.getStorageID(), currInfo.getStorageType()));\n+          excludedUUids.add(dn.getDatanodeUuid());\n+          isProvidedBlock \u003d true;\n         } else {\n-          locs[i] \u003d new DatanodeInfoWithStorage(\n-              storages[i].getDatanodeDescriptor(), sids[i], types[i]);\n+          locs.add(new DatanodeInfoWithStorage(\n+              currInfo.getDatanodeDescriptor(),\n+              currInfo.getStorageID(), storageType));\n+          excludedUUids.add(currInfo.getDatanodeDescriptor().getDatanodeUuid());\n         }\n       }\n-      return new LocatedBlock(eb, locs, sids, types, pos, isCorrupt, null);\n+\n+      int numLocations \u003d locs.size();\n+      if (isProvidedBlock) {\n+        // add more replicas until we reach the defaultReplication\n+        for (int count \u003d numLocations + 1;\n+            count \u003c\u003d defaultReplication \u0026\u0026 count \u003c\u003d providedDescriptor\n+                .activeProvidedDatanodes(); count++) {\n+          DatanodeDescriptor dn \u003d chooseProvidedDatanode(excludedUUids);\n+          locs.add(new DatanodeInfoWithStorage(\n+              dn, storageId, StorageType.PROVIDED));\n+          sids.add(storageId);\n+          types.add(StorageType.PROVIDED);\n+          excludedUUids.add(dn.getDatanodeUuid());\n+        }\n+      }\n+      return new LocatedBlock(eb,\n+          locs.toArray(new DatanodeInfoWithStorage[locs.size()]),\n+          sids.toArray(new String[sids.size()]),\n+          types.toArray(new StorageType[types.size()]),\n+          pos, isCorrupt, null);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    LocatedBlock newLocatedBlock(ExtendedBlock eb,\n        DatanodeStorageInfo[] storages, long pos, boolean isCorrupt) {\n\n      List\u003cDatanodeInfoWithStorage\u003e locs \u003d new ArrayList\u003c\u003e();\n      List\u003cString\u003e sids \u003d new ArrayList\u003c\u003e();\n      List\u003cStorageType\u003e types \u003d new ArrayList\u003c\u003e();\n      boolean isProvidedBlock \u003d false;\n      Set\u003cString\u003e excludedUUids \u003d new HashSet\u003c\u003e();\n\n      for (int i \u003d 0; i \u003c storages.length; ++i) {\n        DatanodeStorageInfo currInfo \u003d storages[i];\n        StorageType storageType \u003d currInfo.getStorageType();\n        sids.add(currInfo.getStorageID());\n        types.add(storageType);\n        if (StorageType.PROVIDED.equals(storageType)) {\n          DatanodeDescriptor dn \u003d chooseProvidedDatanode(excludedUUids);\n          locs.add(\n              new DatanodeInfoWithStorage(\n                  dn, currInfo.getStorageID(), currInfo.getStorageType()));\n          excludedUUids.add(dn.getDatanodeUuid());\n          isProvidedBlock \u003d true;\n        } else {\n          locs.add(new DatanodeInfoWithStorage(\n              currInfo.getDatanodeDescriptor(),\n              currInfo.getStorageID(), storageType));\n          excludedUUids.add(currInfo.getDatanodeDescriptor().getDatanodeUuid());\n        }\n      }\n\n      int numLocations \u003d locs.size();\n      if (isProvidedBlock) {\n        // add more replicas until we reach the defaultReplication\n        for (int count \u003d numLocations + 1;\n            count \u003c\u003d defaultReplication \u0026\u0026 count \u003c\u003d providedDescriptor\n                .activeProvidedDatanodes(); count++) {\n          DatanodeDescriptor dn \u003d chooseProvidedDatanode(excludedUUids);\n          locs.add(new DatanodeInfoWithStorage(\n              dn, storageId, StorageType.PROVIDED));\n          sids.add(storageId);\n          types.add(StorageType.PROVIDED);\n          excludedUUids.add(dn.getDatanodeUuid());\n        }\n      }\n      return new LocatedBlock(eb,\n          locs.toArray(new DatanodeInfoWithStorage[locs.size()]),\n          sids.toArray(new String[sids.size()]),\n          types.toArray(new StorageType[types.size()]),\n          pos, isCorrupt, null);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ProvidedStorageMap.java",
      "extendedDetails": {}
    },
    "aa5ec85f7fd2dc6ac568a88716109bab8df8be19": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11663. [READ] Fix NullPointerException in ProvidedBlocksBuilder\n",
      "commitDate": "15/12/17 5:51 PM",
      "commitName": "aa5ec85f7fd2dc6ac568a88716109bab8df8be19",
      "commitAuthor": "Virajith Jalaparti",
      "commitDateOld": "15/12/17 5:51 PM",
      "commitNameOld": "d65df0f27395792c6e25f5e03b6ba1765e2ba925",
      "commitAuthorOld": "Virajith Jalaparti",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,20 @@\n     LocatedBlock newLocatedBlock(ExtendedBlock eb,\n         DatanodeStorageInfo[] storages, long pos, boolean isCorrupt) {\n \n       DatanodeInfoWithStorage[] locs \u003d\n         new DatanodeInfoWithStorage[storages.length];\n       String[] sids \u003d new String[storages.length];\n       StorageType[] types \u003d new StorageType[storages.length];\n       for (int i \u003d 0; i \u003c storages.length; ++i) {\n         sids[i] \u003d storages[i].getStorageID();\n         types[i] \u003d storages[i].getStorageType();\n         if (StorageType.PROVIDED.equals(storages[i].getStorageType())) {\n           locs[i] \u003d pending;\n+          hasProvidedLocations \u003d true;\n         } else {\n           locs[i] \u003d new DatanodeInfoWithStorage(\n               storages[i].getDatanodeDescriptor(), sids[i], types[i]);\n         }\n       }\n       return new LocatedBlock(eb, locs, sids, types, pos, isCorrupt, null);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    LocatedBlock newLocatedBlock(ExtendedBlock eb,\n        DatanodeStorageInfo[] storages, long pos, boolean isCorrupt) {\n\n      DatanodeInfoWithStorage[] locs \u003d\n        new DatanodeInfoWithStorage[storages.length];\n      String[] sids \u003d new String[storages.length];\n      StorageType[] types \u003d new StorageType[storages.length];\n      for (int i \u003d 0; i \u003c storages.length; ++i) {\n        sids[i] \u003d storages[i].getStorageID();\n        types[i] \u003d storages[i].getStorageType();\n        if (StorageType.PROVIDED.equals(storages[i].getStorageType())) {\n          locs[i] \u003d pending;\n          hasProvidedLocations \u003d true;\n        } else {\n          locs[i] \u003d new DatanodeInfoWithStorage(\n              storages[i].getDatanodeDescriptor(), sids[i], types[i]);\n        }\n      }\n      return new LocatedBlock(eb, locs, sids, types, pos, isCorrupt, null);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ProvidedStorageMap.java",
      "extendedDetails": {}
    },
    "d65df0f27395792c6e25f5e03b6ba1765e2ba925": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-11190. [READ] Namenode support for data stored in external stores.\n",
      "commitDate": "15/12/17 5:51 PM",
      "commitName": "d65df0f27395792c6e25f5e03b6ba1765e2ba925",
      "commitAuthor": "Virajith Jalaparti",
      "diff": "@@ -0,0 +1,19 @@\n+    LocatedBlock newLocatedBlock(ExtendedBlock eb,\n+        DatanodeStorageInfo[] storages, long pos, boolean isCorrupt) {\n+\n+      DatanodeInfoWithStorage[] locs \u003d\n+        new DatanodeInfoWithStorage[storages.length];\n+      String[] sids \u003d new String[storages.length];\n+      StorageType[] types \u003d new StorageType[storages.length];\n+      for (int i \u003d 0; i \u003c storages.length; ++i) {\n+        sids[i] \u003d storages[i].getStorageID();\n+        types[i] \u003d storages[i].getStorageType();\n+        if (StorageType.PROVIDED.equals(storages[i].getStorageType())) {\n+          locs[i] \u003d pending;\n+        } else {\n+          locs[i] \u003d new DatanodeInfoWithStorage(\n+              storages[i].getDatanodeDescriptor(), sids[i], types[i]);\n+        }\n+      }\n+      return new LocatedBlock(eb, locs, sids, types, pos, isCorrupt, null);\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    LocatedBlock newLocatedBlock(ExtendedBlock eb,\n        DatanodeStorageInfo[] storages, long pos, boolean isCorrupt) {\n\n      DatanodeInfoWithStorage[] locs \u003d\n        new DatanodeInfoWithStorage[storages.length];\n      String[] sids \u003d new String[storages.length];\n      StorageType[] types \u003d new StorageType[storages.length];\n      for (int i \u003d 0; i \u003c storages.length; ++i) {\n        sids[i] \u003d storages[i].getStorageID();\n        types[i] \u003d storages[i].getStorageType();\n        if (StorageType.PROVIDED.equals(storages[i].getStorageType())) {\n          locs[i] \u003d pending;\n        } else {\n          locs[i] \u003d new DatanodeInfoWithStorage(\n              storages[i].getDatanodeDescriptor(), sids[i], types[i]);\n        }\n      }\n      return new LocatedBlock(eb, locs, sids, types, pos, isCorrupt, null);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ProvidedStorageMap.java"
    }
  }
}