{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ClientDatanodeProtocolTranslatorPB.java",
  "functionName": "getVolumeReport",
  "functionId": "getVolumeReport",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolTranslatorPB.java",
  "functionStartLine": 438,
  "functionEndLine": 455,
  "numCommitsSeen": 21,
  "timeTaken": 1055,
  "changeHistory": [
    "93fa48fcf243dc759db1736af145633da760f937"
  ],
  "changeHistoryShort": {
    "93fa48fcf243dc759db1736af145633da760f937": "Yintroduced"
  },
  "changeHistoryDetails": {
    "93fa48fcf243dc759db1736af145633da760f937": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-11417. Add datanode admin command to get the storage info. Contributed by Surendra Singh Lilhore.\n",
      "commitDate": "26/04/17 1:43 AM",
      "commitName": "93fa48fcf243dc759db1736af145633da760f937",
      "commitAuthor": "Akira Ajisaka",
      "diff": "@@ -0,0 +1,18 @@\n+  public List\u003cDatanodeVolumeInfo\u003e getVolumeReport() throws IOException {\n+    try {\n+      List\u003cDatanodeVolumeInfo\u003e volumeInfoList \u003d new ArrayList\u003c\u003e();\n+      GetVolumeReportResponseProto volumeReport \u003d rpcProxy.getVolumeReport(\n+          NULL_CONTROLLER, VOID_GET_DATANODE_STORAGE_INFO);\n+      List\u003cDatanodeVolumeInfoProto\u003e volumeProtoList \u003d volumeReport\n+          .getVolumeInfoList();\n+      for (DatanodeVolumeInfoProto proto : volumeProtoList) {\n+        volumeInfoList.add(new DatanodeVolumeInfo(proto.getPath(), proto\n+            .getUsedSpace(), proto.getFreeSpace(), proto.getReservedSpace(),\n+            proto.getReservedSpaceForReplicas(), proto.getNumBlocks(),\n+            PBHelperClient.convertStorageType(proto.getStorageType())));\n+      }\n+      return volumeInfoList;\n+    } catch (ServiceException e) {\n+      throw ProtobufHelper.getRemoteException(e);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public List\u003cDatanodeVolumeInfo\u003e getVolumeReport() throws IOException {\n    try {\n      List\u003cDatanodeVolumeInfo\u003e volumeInfoList \u003d new ArrayList\u003c\u003e();\n      GetVolumeReportResponseProto volumeReport \u003d rpcProxy.getVolumeReport(\n          NULL_CONTROLLER, VOID_GET_DATANODE_STORAGE_INFO);\n      List\u003cDatanodeVolumeInfoProto\u003e volumeProtoList \u003d volumeReport\n          .getVolumeInfoList();\n      for (DatanodeVolumeInfoProto proto : volumeProtoList) {\n        volumeInfoList.add(new DatanodeVolumeInfo(proto.getPath(), proto\n            .getUsedSpace(), proto.getFreeSpace(), proto.getReservedSpace(),\n            proto.getReservedSpaceForReplicas(), proto.getNumBlocks(),\n            PBHelperClient.convertStorageType(proto.getStorageType())));\n      }\n      return volumeInfoList;\n    } catch (ServiceException e) {\n      throw ProtobufHelper.getRemoteException(e);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolTranslatorPB.java"
    }
  }
}