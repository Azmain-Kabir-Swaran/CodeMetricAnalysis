{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "RamDiskAsyncLazyPersistService.java",
  "functionName": "run",
  "functionId": "run",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/RamDiskAsyncLazyPersistService.java",
  "functionStartLine": 237,
  "functionEndLine": 260,
  "numCommitsSeen": 11,
  "timeTaken": 4015,
  "changeHistory": [
    "96b12662ea76e3ded4ef13944fc8df206cfb4613",
    "86c9862bec0248d671e657aa56094a2919b8ac14",
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
    "c992bcf9c136d3df686655a80e636bb7bb0664da",
    "4da8490b512a33a255ed27309860859388d7c168",
    "b7f4a3156c0f5c600816c469637237ba6c9b330c",
    "4a4450836c8972480b9387b5e31bab57ae2b5baa",
    "058af60c56207907f2bedf76df4284e86d923e0c",
    "463aec11718e47d4aabb86a7a539cb973460aae6",
    "1efd9c98258fbb973d2058dcf0850042e53bd02f"
  ],
  "changeHistoryShort": {
    "96b12662ea76e3ded4ef13944fc8df206cfb4613": "Ybodychange",
    "86c9862bec0248d671e657aa56094a2919b8ac14": "Ybodychange",
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": "Ybodychange",
    "c992bcf9c136d3df686655a80e636bb7bb0664da": "Ybodychange",
    "4da8490b512a33a255ed27309860859388d7c168": "Ybodychange",
    "b7f4a3156c0f5c600816c469637237ba6c9b330c": "Ybodychange",
    "4a4450836c8972480b9387b5e31bab57ae2b5baa": "Ybodychange",
    "058af60c56207907f2bedf76df4284e86d923e0c": "Ybodychange",
    "463aec11718e47d4aabb86a7a539cb973460aae6": "Ybodychange",
    "1efd9c98258fbb973d2058dcf0850042e53bd02f": "Yintroduced"
  },
  "changeHistoryDetails": {
    "96b12662ea76e3ded4ef13944fc8df206cfb4613": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10637. Modifications to remove the assumption that FsVolumes are backed by java.io.File. (Virajith Jalaparti via lei)\n",
      "commitDate": "10/10/16 3:30 PM",
      "commitName": "96b12662ea76e3ded4ef13944fc8df206cfb4613",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "13/09/16 12:54 PM",
      "commitNameOld": "86c9862bec0248d671e657aa56094a2919b8ac14",
      "commitAuthorOld": "Lei Xu",
      "daysBetweenCommits": 27.11,
      "commitsBetweenForRepo": 180,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,24 @@\n     public void run() {\n       boolean succeeded \u003d false;\n       final FsDatasetImpl dataset \u003d (FsDatasetImpl)datanode.getFSDataset();\n       try (FsVolumeReference ref \u003d this.targetVolume) {\n         int smallBufferSize \u003d DFSUtilClient.getSmallBufferSize(EMPTY_HDFS_CONF);\n-        // No FsDatasetImpl lock for the file copy\n-        File targetFiles[] \u003d FsDatasetImpl.copyBlockFiles(\n-            blockId, genStamp, replicaInfo, lazyPersistDir, true,\n-            smallBufferSize, conf);\n+\n+        FsVolumeImpl volume \u003d (FsVolumeImpl)ref.getVolume();\n+        File[] targetFiles \u003d volume.copyBlockToLazyPersistLocation(bpId,\n+            blockId, genStamp, replicaInfo, smallBufferSize, conf);\n \n         // Lock FsDataSetImpl during onCompleteLazyPersist callback\n         dataset.onCompleteLazyPersist(bpId, blockId,\n-                creationTime, targetFiles, (FsVolumeImpl)ref.getVolume());\n+                creationTime, targetFiles, volume);\n         succeeded \u003d true;\n       } catch (Exception e){\n         FsDatasetImpl.LOG.warn(\n             \"LazyWriter failed to async persist RamDisk block pool id: \"\n             + bpId + \"block Id: \" + blockId, e);\n       } finally {\n         if (!succeeded) {\n           dataset.onFailLazyPersist(bpId, blockId);\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      boolean succeeded \u003d false;\n      final FsDatasetImpl dataset \u003d (FsDatasetImpl)datanode.getFSDataset();\n      try (FsVolumeReference ref \u003d this.targetVolume) {\n        int smallBufferSize \u003d DFSUtilClient.getSmallBufferSize(EMPTY_HDFS_CONF);\n\n        FsVolumeImpl volume \u003d (FsVolumeImpl)ref.getVolume();\n        File[] targetFiles \u003d volume.copyBlockToLazyPersistLocation(bpId,\n            blockId, genStamp, replicaInfo, smallBufferSize, conf);\n\n        // Lock FsDataSetImpl during onCompleteLazyPersist callback\n        dataset.onCompleteLazyPersist(bpId, blockId,\n                creationTime, targetFiles, volume);\n        succeeded \u003d true;\n      } catch (Exception e){\n        FsDatasetImpl.LOG.warn(\n            \"LazyWriter failed to async persist RamDisk block pool id: \"\n            + bpId + \"block Id: \" + blockId, e);\n      } finally {\n        if (!succeeded) {\n          dataset.onFailLazyPersist(bpId, blockId);\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/RamDiskAsyncLazyPersistService.java",
      "extendedDetails": {}
    },
    "86c9862bec0248d671e657aa56094a2919b8ac14": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10636. Modify ReplicaInfo to remove the assumption that replica metadata and data are stored in java.io.File. (Virajith Jalaparti via lei)\n",
      "commitDate": "13/09/16 12:54 PM",
      "commitName": "86c9862bec0248d671e657aa56094a2919b8ac14",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "26/09/15 11:08 AM",
      "commitNameOld": "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 353.07,
      "commitsBetweenForRepo": 2454,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,24 @@\n     public void run() {\n       boolean succeeded \u003d false;\n       final FsDatasetImpl dataset \u003d (FsDatasetImpl)datanode.getFSDataset();\n       try (FsVolumeReference ref \u003d this.targetVolume) {\n         int smallBufferSize \u003d DFSUtilClient.getSmallBufferSize(EMPTY_HDFS_CONF);\n         // No FsDatasetImpl lock for the file copy\n         File targetFiles[] \u003d FsDatasetImpl.copyBlockFiles(\n-            blockId, genStamp, metaFile, blockFile, lazyPersistDir, true,\n+            blockId, genStamp, replicaInfo, lazyPersistDir, true,\n             smallBufferSize, conf);\n \n         // Lock FsDataSetImpl during onCompleteLazyPersist callback\n         dataset.onCompleteLazyPersist(bpId, blockId,\n                 creationTime, targetFiles, (FsVolumeImpl)ref.getVolume());\n         succeeded \u003d true;\n       } catch (Exception e){\n         FsDatasetImpl.LOG.warn(\n             \"LazyWriter failed to async persist RamDisk block pool id: \"\n             + bpId + \"block Id: \" + blockId, e);\n       } finally {\n         if (!succeeded) {\n           dataset.onFailLazyPersist(bpId, blockId);\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      boolean succeeded \u003d false;\n      final FsDatasetImpl dataset \u003d (FsDatasetImpl)datanode.getFSDataset();\n      try (FsVolumeReference ref \u003d this.targetVolume) {\n        int smallBufferSize \u003d DFSUtilClient.getSmallBufferSize(EMPTY_HDFS_CONF);\n        // No FsDatasetImpl lock for the file copy\n        File targetFiles[] \u003d FsDatasetImpl.copyBlockFiles(\n            blockId, genStamp, replicaInfo, lazyPersistDir, true,\n            smallBufferSize, conf);\n\n        // Lock FsDataSetImpl during onCompleteLazyPersist callback\n        dataset.onCompleteLazyPersist(bpId, blockId,\n                creationTime, targetFiles, (FsVolumeImpl)ref.getVolume());\n        succeeded \u003d true;\n      } catch (Exception e){\n        FsDatasetImpl.LOG.warn(\n            \"LazyWriter failed to async persist RamDisk block pool id: \"\n            + bpId + \"block Id: \" + blockId, e);\n      } finally {\n        if (!succeeded) {\n          dataset.onFailLazyPersist(bpId, blockId);\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/RamDiskAsyncLazyPersistService.java",
      "extendedDetails": {}
    },
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8053. Move DFSIn/OutputStream and related classes to hadoop-hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "26/09/15 11:08 AM",
      "commitName": "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "26/08/15 2:02 PM",
      "commitNameOld": "c992bcf9c136d3df686655a80e636bb7bb0664da",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 30.88,
      "commitsBetweenForRepo": 209,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,24 @@\n     public void run() {\n       boolean succeeded \u003d false;\n       final FsDatasetImpl dataset \u003d (FsDatasetImpl)datanode.getFSDataset();\n       try (FsVolumeReference ref \u003d this.targetVolume) {\n-        int smallBufferSize \u003d DFSUtil.getSmallBufferSize(EMPTY_HDFS_CONF);\n+        int smallBufferSize \u003d DFSUtilClient.getSmallBufferSize(EMPTY_HDFS_CONF);\n         // No FsDatasetImpl lock for the file copy\n         File targetFiles[] \u003d FsDatasetImpl.copyBlockFiles(\n             blockId, genStamp, metaFile, blockFile, lazyPersistDir, true,\n             smallBufferSize, conf);\n \n         // Lock FsDataSetImpl during onCompleteLazyPersist callback\n         dataset.onCompleteLazyPersist(bpId, blockId,\n                 creationTime, targetFiles, (FsVolumeImpl)ref.getVolume());\n         succeeded \u003d true;\n       } catch (Exception e){\n         FsDatasetImpl.LOG.warn(\n             \"LazyWriter failed to async persist RamDisk block pool id: \"\n             + bpId + \"block Id: \" + blockId, e);\n       } finally {\n         if (!succeeded) {\n           dataset.onFailLazyPersist(bpId, blockId);\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      boolean succeeded \u003d false;\n      final FsDatasetImpl dataset \u003d (FsDatasetImpl)datanode.getFSDataset();\n      try (FsVolumeReference ref \u003d this.targetVolume) {\n        int smallBufferSize \u003d DFSUtilClient.getSmallBufferSize(EMPTY_HDFS_CONF);\n        // No FsDatasetImpl lock for the file copy\n        File targetFiles[] \u003d FsDatasetImpl.copyBlockFiles(\n            blockId, genStamp, metaFile, blockFile, lazyPersistDir, true,\n            smallBufferSize, conf);\n\n        // Lock FsDataSetImpl during onCompleteLazyPersist callback\n        dataset.onCompleteLazyPersist(bpId, blockId,\n                creationTime, targetFiles, (FsVolumeImpl)ref.getVolume());\n        succeeded \u003d true;\n      } catch (Exception e){\n        FsDatasetImpl.LOG.warn(\n            \"LazyWriter failed to async persist RamDisk block pool id: \"\n            + bpId + \"block Id: \" + blockId, e);\n      } finally {\n        if (!succeeded) {\n          dataset.onFailLazyPersist(bpId, blockId);\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/RamDiskAsyncLazyPersistService.java",
      "extendedDetails": {}
    },
    "c992bcf9c136d3df686655a80e636bb7bb0664da": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8951. Move the shortcircuit package to hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "26/08/15 2:02 PM",
      "commitName": "c992bcf9c136d3df686655a80e636bb7bb0664da",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "05/05/15 3:41 PM",
      "commitNameOld": "4da8490b512a33a255ed27309860859388d7c168",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 112.93,
      "commitsBetweenForRepo": 803,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,24 @@\n     public void run() {\n       boolean succeeded \u003d false;\n       final FsDatasetImpl dataset \u003d (FsDatasetImpl)datanode.getFSDataset();\n       try (FsVolumeReference ref \u003d this.targetVolume) {\n         int smallBufferSize \u003d DFSUtil.getSmallBufferSize(EMPTY_HDFS_CONF);\n         // No FsDatasetImpl lock for the file copy\n         File targetFiles[] \u003d FsDatasetImpl.copyBlockFiles(\n             blockId, genStamp, metaFile, blockFile, lazyPersistDir, true,\n-            smallBufferSize);\n+            smallBufferSize, conf);\n \n         // Lock FsDataSetImpl during onCompleteLazyPersist callback\n         dataset.onCompleteLazyPersist(bpId, blockId,\n                 creationTime, targetFiles, (FsVolumeImpl)ref.getVolume());\n         succeeded \u003d true;\n       } catch (Exception e){\n         FsDatasetImpl.LOG.warn(\n             \"LazyWriter failed to async persist RamDisk block pool id: \"\n             + bpId + \"block Id: \" + blockId, e);\n       } finally {\n         if (!succeeded) {\n           dataset.onFailLazyPersist(bpId, blockId);\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      boolean succeeded \u003d false;\n      final FsDatasetImpl dataset \u003d (FsDatasetImpl)datanode.getFSDataset();\n      try (FsVolumeReference ref \u003d this.targetVolume) {\n        int smallBufferSize \u003d DFSUtil.getSmallBufferSize(EMPTY_HDFS_CONF);\n        // No FsDatasetImpl lock for the file copy\n        File targetFiles[] \u003d FsDatasetImpl.copyBlockFiles(\n            blockId, genStamp, metaFile, blockFile, lazyPersistDir, true,\n            smallBufferSize, conf);\n\n        // Lock FsDataSetImpl during onCompleteLazyPersist callback\n        dataset.onCompleteLazyPersist(bpId, blockId,\n                creationTime, targetFiles, (FsVolumeImpl)ref.getVolume());\n        succeeded \u003d true;\n      } catch (Exception e){\n        FsDatasetImpl.LOG.warn(\n            \"LazyWriter failed to async persist RamDisk block pool id: \"\n            + bpId + \"block Id: \" + blockId, e);\n      } finally {\n        if (!succeeded) {\n          dataset.onFailLazyPersist(bpId, blockId);\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/RamDiskAsyncLazyPersistService.java",
      "extendedDetails": {}
    },
    "4da8490b512a33a255ed27309860859388d7c168": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8314. Move HdfsServerConstants#IO_FILE_BUFFER_SIZE and SMALL_BUFFER_SIZE to the users. Contributed by Li Lu.\n",
      "commitDate": "05/05/15 3:41 PM",
      "commitName": "4da8490b512a33a255ed27309860859388d7c168",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "20/01/15 7:05 PM",
      "commitNameOld": "b7f4a3156c0f5c600816c469637237ba6c9b330c",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 104.82,
      "commitsBetweenForRepo": 965,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,24 @@\n     public void run() {\n       boolean succeeded \u003d false;\n       final FsDatasetImpl dataset \u003d (FsDatasetImpl)datanode.getFSDataset();\n       try (FsVolumeReference ref \u003d this.targetVolume) {\n+        int smallBufferSize \u003d DFSUtil.getSmallBufferSize(EMPTY_HDFS_CONF);\n         // No FsDatasetImpl lock for the file copy\n         File targetFiles[] \u003d FsDatasetImpl.copyBlockFiles(\n-            blockId, genStamp, metaFile, blockFile, lazyPersistDir, true);\n+            blockId, genStamp, metaFile, blockFile, lazyPersistDir, true,\n+            smallBufferSize);\n \n         // Lock FsDataSetImpl during onCompleteLazyPersist callback\n         dataset.onCompleteLazyPersist(bpId, blockId,\n                 creationTime, targetFiles, (FsVolumeImpl)ref.getVolume());\n         succeeded \u003d true;\n       } catch (Exception e){\n         FsDatasetImpl.LOG.warn(\n             \"LazyWriter failed to async persist RamDisk block pool id: \"\n             + bpId + \"block Id: \" + blockId, e);\n       } finally {\n         if (!succeeded) {\n           dataset.onFailLazyPersist(bpId, blockId);\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      boolean succeeded \u003d false;\n      final FsDatasetImpl dataset \u003d (FsDatasetImpl)datanode.getFSDataset();\n      try (FsVolumeReference ref \u003d this.targetVolume) {\n        int smallBufferSize \u003d DFSUtil.getSmallBufferSize(EMPTY_HDFS_CONF);\n        // No FsDatasetImpl lock for the file copy\n        File targetFiles[] \u003d FsDatasetImpl.copyBlockFiles(\n            blockId, genStamp, metaFile, blockFile, lazyPersistDir, true,\n            smallBufferSize);\n\n        // Lock FsDataSetImpl during onCompleteLazyPersist callback\n        dataset.onCompleteLazyPersist(bpId, blockId,\n                creationTime, targetFiles, (FsVolumeImpl)ref.getVolume());\n        succeeded \u003d true;\n      } catch (Exception e){\n        FsDatasetImpl.LOG.warn(\n            \"LazyWriter failed to async persist RamDisk block pool id: \"\n            + bpId + \"block Id: \" + blockId, e);\n      } finally {\n        if (!succeeded) {\n          dataset.onFailLazyPersist(bpId, blockId);\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/RamDiskAsyncLazyPersistService.java",
      "extendedDetails": {}
    },
    "b7f4a3156c0f5c600816c469637237ba6c9b330c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7496. Fix FsVolume removal race conditions on the DataNode by reference-counting the volume instances (lei via cmccabe)\n",
      "commitDate": "20/01/15 7:05 PM",
      "commitName": "b7f4a3156c0f5c600816c469637237ba6c9b330c",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "19/01/15 1:49 PM",
      "commitNameOld": "4a4450836c8972480b9387b5e31bab57ae2b5baa",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 1.22,
      "commitsBetweenForRepo": 7,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,22 @@\n     public void run() {\n       boolean succeeded \u003d false;\n       final FsDatasetImpl dataset \u003d (FsDatasetImpl)datanode.getFSDataset();\n-      try {\n+      try (FsVolumeReference ref \u003d this.targetVolume) {\n         // No FsDatasetImpl lock for the file copy\n         File targetFiles[] \u003d FsDatasetImpl.copyBlockFiles(\n             blockId, genStamp, metaFile, blockFile, lazyPersistDir, true);\n \n         // Lock FsDataSetImpl during onCompleteLazyPersist callback\n         dataset.onCompleteLazyPersist(bpId, blockId,\n-                creationTime, targetFiles, targetVolume);\n+                creationTime, targetFiles, (FsVolumeImpl)ref.getVolume());\n         succeeded \u003d true;\n       } catch (Exception e){\n         FsDatasetImpl.LOG.warn(\n             \"LazyWriter failed to async persist RamDisk block pool id: \"\n             + bpId + \"block Id: \" + blockId, e);\n       } finally {\n         if (!succeeded) {\n           dataset.onFailLazyPersist(bpId, blockId);\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      boolean succeeded \u003d false;\n      final FsDatasetImpl dataset \u003d (FsDatasetImpl)datanode.getFSDataset();\n      try (FsVolumeReference ref \u003d this.targetVolume) {\n        // No FsDatasetImpl lock for the file copy\n        File targetFiles[] \u003d FsDatasetImpl.copyBlockFiles(\n            blockId, genStamp, metaFile, blockFile, lazyPersistDir, true);\n\n        // Lock FsDataSetImpl during onCompleteLazyPersist callback\n        dataset.onCompleteLazyPersist(bpId, blockId,\n                creationTime, targetFiles, (FsVolumeImpl)ref.getVolume());\n        succeeded \u003d true;\n      } catch (Exception e){\n        FsDatasetImpl.LOG.warn(\n            \"LazyWriter failed to async persist RamDisk block pool id: \"\n            + bpId + \"block Id: \" + blockId, e);\n      } finally {\n        if (!succeeded) {\n          dataset.onFailLazyPersist(bpId, blockId);\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/RamDiskAsyncLazyPersistService.java",
      "extendedDetails": {}
    },
    "4a4450836c8972480b9387b5e31bab57ae2b5baa": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5631. Change BlockMetadataHeader.readHeader(..), ChunkChecksum class and constructor to public; and fix FsDatasetSpi to use generic type instead of FsVolumeImpl.  Contributed by David Powell and Joe Pallas\n",
      "commitDate": "19/01/15 1:49 PM",
      "commitName": "4a4450836c8972480b9387b5e31bab57ae2b5baa",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "26/11/14 9:57 AM",
      "commitNameOld": "058af60c56207907f2bedf76df4284e86d923e0c",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 54.16,
      "commitsBetweenForRepo": 304,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,22 @@\n     public void run() {\n       boolean succeeded \u003d false;\n+      final FsDatasetImpl dataset \u003d (FsDatasetImpl)datanode.getFSDataset();\n       try {\n         // No FsDatasetImpl lock for the file copy\n         File targetFiles[] \u003d FsDatasetImpl.copyBlockFiles(\n             blockId, genStamp, metaFile, blockFile, lazyPersistDir, true);\n \n         // Lock FsDataSetImpl during onCompleteLazyPersist callback\n-        datanode.getFSDataset().onCompleteLazyPersist(bpId, blockId,\n-            creationTime, targetFiles, targetVolume);\n+        dataset.onCompleteLazyPersist(bpId, blockId,\n+                creationTime, targetFiles, targetVolume);\n         succeeded \u003d true;\n       } catch (Exception e){\n         FsDatasetImpl.LOG.warn(\n             \"LazyWriter failed to async persist RamDisk block pool id: \"\n             + bpId + \"block Id: \" + blockId, e);\n       } finally {\n         if (!succeeded) {\n-          datanode.getFSDataset().onFailLazyPersist(bpId, blockId);\n+          dataset.onFailLazyPersist(bpId, blockId);\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      boolean succeeded \u003d false;\n      final FsDatasetImpl dataset \u003d (FsDatasetImpl)datanode.getFSDataset();\n      try {\n        // No FsDatasetImpl lock for the file copy\n        File targetFiles[] \u003d FsDatasetImpl.copyBlockFiles(\n            blockId, genStamp, metaFile, blockFile, lazyPersistDir, true);\n\n        // Lock FsDataSetImpl during onCompleteLazyPersist callback\n        dataset.onCompleteLazyPersist(bpId, blockId,\n                creationTime, targetFiles, targetVolume);\n        succeeded \u003d true;\n      } catch (Exception e){\n        FsDatasetImpl.LOG.warn(\n            \"LazyWriter failed to async persist RamDisk block pool id: \"\n            + bpId + \"block Id: \" + blockId, e);\n      } finally {\n        if (!succeeded) {\n          dataset.onFailLazyPersist(bpId, blockId);\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/RamDiskAsyncLazyPersistService.java",
      "extendedDetails": {}
    },
    "058af60c56207907f2bedf76df4284e86d923e0c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7310. Mover can give first priority to local DN if it has target storage type available in local DN. (Vinayakumar B via umamahesh)\n",
      "commitDate": "26/11/14 9:57 AM",
      "commitName": "058af60c56207907f2bedf76df4284e86d923e0c",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "27/10/14 9:38 AM",
      "commitNameOld": "463aec11718e47d4aabb86a7a539cb973460aae6",
      "commitAuthorOld": "cnauroth",
      "daysBetweenCommits": 30.05,
      "commitsBetweenForRepo": 285,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,21 @@\n     public void run() {\n       boolean succeeded \u003d false;\n       try {\n         // No FsDatasetImpl lock for the file copy\n         File targetFiles[] \u003d FsDatasetImpl.copyBlockFiles(\n-            blockId, genStamp, metaFile, blockFile, lazyPersistDir);\n+            blockId, genStamp, metaFile, blockFile, lazyPersistDir, true);\n \n         // Lock FsDataSetImpl during onCompleteLazyPersist callback\n         datanode.getFSDataset().onCompleteLazyPersist(bpId, blockId,\n             creationTime, targetFiles, targetVolume);\n         succeeded \u003d true;\n       } catch (Exception e){\n         FsDatasetImpl.LOG.warn(\n             \"LazyWriter failed to async persist RamDisk block pool id: \"\n             + bpId + \"block Id: \" + blockId, e);\n       } finally {\n         if (!succeeded) {\n           datanode.getFSDataset().onFailLazyPersist(bpId, blockId);\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      boolean succeeded \u003d false;\n      try {\n        // No FsDatasetImpl lock for the file copy\n        File targetFiles[] \u003d FsDatasetImpl.copyBlockFiles(\n            blockId, genStamp, metaFile, blockFile, lazyPersistDir, true);\n\n        // Lock FsDataSetImpl during onCompleteLazyPersist callback\n        datanode.getFSDataset().onCompleteLazyPersist(bpId, blockId,\n            creationTime, targetFiles, targetVolume);\n        succeeded \u003d true;\n      } catch (Exception e){\n        FsDatasetImpl.LOG.warn(\n            \"LazyWriter failed to async persist RamDisk block pool id: \"\n            + bpId + \"block Id: \" + blockId, e);\n      } finally {\n        if (!succeeded) {\n          datanode.getFSDataset().onFailLazyPersist(bpId, blockId);\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/RamDiskAsyncLazyPersistService.java",
      "extendedDetails": {}
    },
    "463aec11718e47d4aabb86a7a539cb973460aae6": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6934. Move checksum computation off the hot path when writing to RAM disk. Contributed by Chris Nauroth.\n",
      "commitDate": "27/10/14 9:38 AM",
      "commitName": "463aec11718e47d4aabb86a7a539cb973460aae6",
      "commitAuthor": "cnauroth",
      "commitDateOld": "07/10/14 8:25 PM",
      "commitNameOld": "1efd9c98258fbb973d2058dcf0850042e53bd02f",
      "commitAuthorOld": "cnauroth",
      "daysBetweenCommits": 19.55,
      "commitsBetweenForRepo": 152,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,21 @@\n     public void run() {\n       boolean succeeded \u003d false;\n       try {\n         // No FsDatasetImpl lock for the file copy\n         File targetFiles[] \u003d FsDatasetImpl.copyBlockFiles(\n             blockId, genStamp, metaFile, blockFile, lazyPersistDir);\n \n         // Lock FsDataSetImpl during onCompleteLazyPersist callback\n         datanode.getFSDataset().onCompleteLazyPersist(bpId, blockId,\n             creationTime, targetFiles, targetVolume);\n         succeeded \u003d true;\n       } catch (Exception e){\n         FsDatasetImpl.LOG.warn(\n             \"LazyWriter failed to async persist RamDisk block pool id: \"\n-            + bpId + \"block Id: \" + blockId);\n+            + bpId + \"block Id: \" + blockId, e);\n       } finally {\n         if (!succeeded) {\n           datanode.getFSDataset().onFailLazyPersist(bpId, blockId);\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      boolean succeeded \u003d false;\n      try {\n        // No FsDatasetImpl lock for the file copy\n        File targetFiles[] \u003d FsDatasetImpl.copyBlockFiles(\n            blockId, genStamp, metaFile, blockFile, lazyPersistDir);\n\n        // Lock FsDataSetImpl during onCompleteLazyPersist callback\n        datanode.getFSDataset().onCompleteLazyPersist(bpId, blockId,\n            creationTime, targetFiles, targetVolume);\n        succeeded \u003d true;\n      } catch (Exception e){\n        FsDatasetImpl.LOG.warn(\n            \"LazyWriter failed to async persist RamDisk block pool id: \"\n            + bpId + \"block Id: \" + blockId, e);\n      } finally {\n        if (!succeeded) {\n          datanode.getFSDataset().onFailLazyPersist(bpId, blockId);\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/RamDiskAsyncLazyPersistService.java",
      "extendedDetails": {}
    },
    "1efd9c98258fbb973d2058dcf0850042e53bd02f": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-7112. LazyWriter should use either async IO or one thread per physical disk. Contributed by Xiaoyu Yao.\n",
      "commitDate": "07/10/14 8:25 PM",
      "commitName": "1efd9c98258fbb973d2058dcf0850042e53bd02f",
      "commitAuthor": "cnauroth",
      "diff": "@@ -0,0 +1,21 @@\n+    public void run() {\n+      boolean succeeded \u003d false;\n+      try {\n+        // No FsDatasetImpl lock for the file copy\n+        File targetFiles[] \u003d FsDatasetImpl.copyBlockFiles(\n+            blockId, genStamp, metaFile, blockFile, lazyPersistDir);\n+\n+        // Lock FsDataSetImpl during onCompleteLazyPersist callback\n+        datanode.getFSDataset().onCompleteLazyPersist(bpId, blockId,\n+            creationTime, targetFiles, targetVolume);\n+        succeeded \u003d true;\n+      } catch (Exception e){\n+        FsDatasetImpl.LOG.warn(\n+            \"LazyWriter failed to async persist RamDisk block pool id: \"\n+            + bpId + \"block Id: \" + blockId);\n+      } finally {\n+        if (!succeeded) {\n+          datanode.getFSDataset().onFailLazyPersist(bpId, blockId);\n+        }\n+      }\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      boolean succeeded \u003d false;\n      try {\n        // No FsDatasetImpl lock for the file copy\n        File targetFiles[] \u003d FsDatasetImpl.copyBlockFiles(\n            blockId, genStamp, metaFile, blockFile, lazyPersistDir);\n\n        // Lock FsDataSetImpl during onCompleteLazyPersist callback\n        datanode.getFSDataset().onCompleteLazyPersist(bpId, blockId,\n            creationTime, targetFiles, targetVolume);\n        succeeded \u003d true;\n      } catch (Exception e){\n        FsDatasetImpl.LOG.warn(\n            \"LazyWriter failed to async persist RamDisk block pool id: \"\n            + bpId + \"block Id: \" + blockId);\n      } finally {\n        if (!succeeded) {\n          datanode.getFSDataset().onFailLazyPersist(bpId, blockId);\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/RamDiskAsyncLazyPersistService.java"
    }
  }
}