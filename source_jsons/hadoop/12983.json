{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DatanodeDescriptor.java",
  "functionName": "updateFailedStorage",
  "functionId": "updateFailedStorage___failedStorageInfos-Set__DatanodeStorageInfo__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java",
  "functionStartLine": 563,
  "functionEndLine": 571,
  "numCommitsSeen": 118,
  "timeTaken": 2220,
  "changeHistory": [
    "2e7b7e2cda67eba4c03e0a2c7892d868d235b0cf",
    "41980c56d3c01d7a0ddc7deea2d89b7f28026722"
  ],
  "changeHistoryShort": {
    "2e7b7e2cda67eba4c03e0a2c7892d868d235b0cf": "Ybodychange",
    "41980c56d3c01d7a0ddc7deea2d89b7f28026722": "Yintroduced"
  },
  "changeHistoryDetails": {
    "2e7b7e2cda67eba4c03e0a2c7892d868d235b0cf": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8713. Convert DatanodeDescriptor to use SLF4J logging.\n",
      "commitDate": "17/08/15 10:17 AM",
      "commitName": "2e7b7e2cda67eba4c03e0a2c7892d868d235b0cf",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "06/08/15 10:21 AM",
      "commitNameOld": "f4c523b69ba55b1fd35e8995c3011a9f546ac835",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 11.0,
      "commitsBetweenForRepo": 44,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,9 +1,9 @@\n   private void updateFailedStorage(\n       Set\u003cDatanodeStorageInfo\u003e failedStorageInfos) {\n     for (DatanodeStorageInfo storageInfo : failedStorageInfos) {\n       if (storageInfo.getState() !\u003d DatanodeStorage.State.FAILED) {\n-        LOG.info(storageInfo + \" failed.\");\n+        LOG.info(\"{} failed.\", storageInfo);\n         storageInfo.setState(DatanodeStorage.State.FAILED);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void updateFailedStorage(\n      Set\u003cDatanodeStorageInfo\u003e failedStorageInfos) {\n    for (DatanodeStorageInfo storageInfo : failedStorageInfos) {\n      if (storageInfo.getState() !\u003d DatanodeStorage.State.FAILED) {\n        LOG.info(\"{} failed.\", storageInfo);\n        storageInfo.setState(DatanodeStorage.State.FAILED);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java",
      "extendedDetails": {}
    },
    "41980c56d3c01d7a0ddc7deea2d89b7f28026722": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-7208. NN doesn\u0027t schedule replication when a DN storage fails.  Contributed by Ming Ma\n",
      "commitDate": "15/10/14 8:44 PM",
      "commitName": "41980c56d3c01d7a0ddc7deea2d89b7f28026722",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "diff": "@@ -0,0 +1,9 @@\n+  private void updateFailedStorage(\n+      Set\u003cDatanodeStorageInfo\u003e failedStorageInfos) {\n+    for (DatanodeStorageInfo storageInfo : failedStorageInfos) {\n+      if (storageInfo.getState() !\u003d DatanodeStorage.State.FAILED) {\n+        LOG.info(storageInfo + \" failed.\");\n+        storageInfo.setState(DatanodeStorage.State.FAILED);\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void updateFailedStorage(\n      Set\u003cDatanodeStorageInfo\u003e failedStorageInfos) {\n    for (DatanodeStorageInfo storageInfo : failedStorageInfos) {\n      if (storageInfo.getState() !\u003d DatanodeStorage.State.FAILED) {\n        LOG.info(storageInfo + \" failed.\");\n        storageInfo.setState(DatanodeStorage.State.FAILED);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java"
    }
  }
}