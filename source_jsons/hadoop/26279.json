{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DefaultSpeculator.java",
  "functionName": "statusUpdate",
  "functionId": "statusUpdate___reportedStatus-TaskAttemptStatus__timestamp-long",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/speculate/DefaultSpeculator.java",
  "functionStartLine": 322,
  "functionEndLine": 350,
  "numCommitsSeen": 25,
  "timeTaken": 9011,
  "changeHistory": [
    "e94ed91114e934c3f3c2bff426cdd3734a31c082",
    "d4324eef14782d3cde6570ee910c45d8fdfce6ba",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "e94ed91114e934c3f3c2bff426cdd3734a31c082": "Ybodychange",
    "d4324eef14782d3cde6570ee910c45d8fdfce6ba": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Ymultichange(Ymovefromfile,Ymodifierchange,Yexceptionschange,Ybodychange,Yparameterchange)",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "e94ed91114e934c3f3c2bff426cdd3734a31c082": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5613. DefaultSpeculator holds and checks hashmap that is alway empty (Gera Shegalov via Sandy Ryza)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1541433 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/11/13 1:23 AM",
      "commitName": "e94ed91114e934c3f3c2bff426cdd3734a31c082",
      "commitAuthor": "Sanford Ryza",
      "commitDateOld": "04/10/13 10:26 AM",
      "commitNameOld": "d4324eef14782d3cde6570ee910c45d8fdfce6ba",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 39.66,
      "commitsBetweenForRepo": 234,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,36 +1,29 @@\n   protected void statusUpdate(TaskAttemptStatus reportedStatus, long timestamp) {\n \n     String stateString \u003d reportedStatus.taskState.toString();\n \n     TaskAttemptId attemptID \u003d reportedStatus.id;\n     TaskId taskID \u003d attemptID.getTaskId();\n     Job job \u003d context.getJob(taskID.getJobId());\n \n     if (job \u003d\u003d null) {\n       return;\n     }\n \n     Task task \u003d job.getTask(taskID);\n \n     if (task \u003d\u003d null) {\n       return;\n     }\n \n     estimator.updateAttempt(reportedStatus, timestamp);\n \n-    // If the task is already known to be speculation-bait, don\u0027t do anything\n-    if (pendingSpeculations.get(task) !\u003d null) {\n-      if (pendingSpeculations.get(task).get()) {\n-        return;\n-      }\n-    }\n-\n     if (stateString.equals(TaskAttemptState.RUNNING.name())) {\n       runningTasks.putIfAbsent(taskID, Boolean.TRUE);\n     } else {\n       runningTasks.remove(taskID, Boolean.TRUE);\n       if (!stateString.equals(TaskAttemptState.STARTING.name())) {\n         runningTaskAttemptStatistics.remove(attemptID);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void statusUpdate(TaskAttemptStatus reportedStatus, long timestamp) {\n\n    String stateString \u003d reportedStatus.taskState.toString();\n\n    TaskAttemptId attemptID \u003d reportedStatus.id;\n    TaskId taskID \u003d attemptID.getTaskId();\n    Job job \u003d context.getJob(taskID.getJobId());\n\n    if (job \u003d\u003d null) {\n      return;\n    }\n\n    Task task \u003d job.getTask(taskID);\n\n    if (task \u003d\u003d null) {\n      return;\n    }\n\n    estimator.updateAttempt(reportedStatus, timestamp);\n\n    if (stateString.equals(TaskAttemptState.RUNNING.name())) {\n      runningTasks.putIfAbsent(taskID, Boolean.TRUE);\n    } else {\n      runningTasks.remove(taskID, Boolean.TRUE);\n      if (!stateString.equals(TaskAttemptState.STARTING.name())) {\n        runningTaskAttemptStatistics.remove(attemptID);\n      }\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/speculate/DefaultSpeculator.java",
      "extendedDetails": {}
    },
    "d4324eef14782d3cde6570ee910c45d8fdfce6ba": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5533. Fixed MR speculation code to track any TaskAttempts that aren\u0027t heart-beating for a while, so that we can aggressively speculate instead of waiting for task-timeout. Contributed by Xuan Gong.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1529229 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/10/13 10:26 AM",
      "commitName": "d4324eef14782d3cde6570ee910c45d8fdfce6ba",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "16/06/13 11:39 PM",
      "commitNameOld": "b9efe6bd4a1277b4067ecde715a7713a85968886",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 109.45,
      "commitsBetweenForRepo": 641,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,33 +1,36 @@\n   protected void statusUpdate(TaskAttemptStatus reportedStatus, long timestamp) {\n \n     String stateString \u003d reportedStatus.taskState.toString();\n \n     TaskAttemptId attemptID \u003d reportedStatus.id;\n     TaskId taskID \u003d attemptID.getTaskId();\n     Job job \u003d context.getJob(taskID.getJobId());\n \n     if (job \u003d\u003d null) {\n       return;\n     }\n \n     Task task \u003d job.getTask(taskID);\n \n     if (task \u003d\u003d null) {\n       return;\n     }\n \n     estimator.updateAttempt(reportedStatus, timestamp);\n \n     // If the task is already known to be speculation-bait, don\u0027t do anything\n     if (pendingSpeculations.get(task) !\u003d null) {\n       if (pendingSpeculations.get(task).get()) {\n         return;\n       }\n     }\n \n     if (stateString.equals(TaskAttemptState.RUNNING.name())) {\n       runningTasks.putIfAbsent(taskID, Boolean.TRUE);\n     } else {\n       runningTasks.remove(taskID, Boolean.TRUE);\n+      if (!stateString.equals(TaskAttemptState.STARTING.name())) {\n+        runningTaskAttemptStatistics.remove(attemptID);\n+      }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void statusUpdate(TaskAttemptStatus reportedStatus, long timestamp) {\n\n    String stateString \u003d reportedStatus.taskState.toString();\n\n    TaskAttemptId attemptID \u003d reportedStatus.id;\n    TaskId taskID \u003d attemptID.getTaskId();\n    Job job \u003d context.getJob(taskID.getJobId());\n\n    if (job \u003d\u003d null) {\n      return;\n    }\n\n    Task task \u003d job.getTask(taskID);\n\n    if (task \u003d\u003d null) {\n      return;\n    }\n\n    estimator.updateAttempt(reportedStatus, timestamp);\n\n    // If the task is already known to be speculation-bait, don\u0027t do anything\n    if (pendingSpeculations.get(task) !\u003d null) {\n      if (pendingSpeculations.get(task).get()) {\n        return;\n      }\n    }\n\n    if (stateString.equals(TaskAttemptState.RUNNING.name())) {\n      runningTasks.putIfAbsent(taskID, Boolean.TRUE);\n    } else {\n      runningTasks.remove(taskID, Boolean.TRUE);\n      if (!stateString.equals(TaskAttemptState.STARTING.name())) {\n        runningTaskAttemptStatistics.remove(attemptID);\n      }\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/speculate/DefaultSpeculator.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  protected void statusUpdate(TaskAttemptStatus reportedStatus, long timestamp) {\n\n    String stateString \u003d reportedStatus.taskState.toString();\n\n    TaskAttemptId attemptID \u003d reportedStatus.id;\n    TaskId taskID \u003d attemptID.getTaskId();\n    Job job \u003d context.getJob(taskID.getJobId());\n\n    if (job \u003d\u003d null) {\n      return;\n    }\n\n    Task task \u003d job.getTask(taskID);\n\n    if (task \u003d\u003d null) {\n      return;\n    }\n\n    estimator.updateAttempt(reportedStatus, timestamp);\n\n    // If the task is already known to be speculation-bait, don\u0027t do anything\n    if (pendingSpeculations.get(task) !\u003d null) {\n      if (pendingSpeculations.get(task).get()) {\n        return;\n      }\n    }\n\n    if (stateString.equals(TaskAttemptState.RUNNING.name())) {\n      runningTasks.putIfAbsent(taskID, Boolean.TRUE);\n    } else {\n      runningTasks.remove(taskID, Boolean.TRUE);\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/speculate/DefaultSpeculator.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/speculate/DefaultSpeculator.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/speculate/DefaultSpeculator.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Ymultichange(Ymovefromfile,Ymodifierchange,Yexceptionschange,Ybodychange,Yparameterchange)",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/08/11 4:07 AM",
          "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "17/08/11 8:02 PM",
          "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.34,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,22 +1,33 @@\n-  public void statusUpdate(TaskUmbilicalProtocol umbilical) \n-  throws IOException {\n-    int retries \u003d MAX_RETRIES;\n-    while (true) {\n-      try {\n-        if (!umbilical.statusUpdate(getTaskID(), taskStatus)) {\n-          LOG.warn(\"Parent died.  Exiting \"+taskId);\n-          System.exit(66);\n-        }\n-        taskStatus.clearStatus();\n+  protected void statusUpdate(TaskAttemptStatus reportedStatus, long timestamp) {\n+\n+    String stateString \u003d reportedStatus.taskState.toString();\n+\n+    TaskAttemptId attemptID \u003d reportedStatus.id;\n+    TaskId taskID \u003d attemptID.getTaskId();\n+    Job job \u003d context.getJob(taskID.getJobId());\n+\n+    if (job \u003d\u003d null) {\n+      return;\n+    }\n+\n+    Task task \u003d job.getTask(taskID);\n+\n+    if (task \u003d\u003d null) {\n+      return;\n+    }\n+\n+    estimator.updateAttempt(reportedStatus, timestamp);\n+\n+    // If the task is already known to be speculation-bait, don\u0027t do anything\n+    if (pendingSpeculations.get(task) !\u003d null) {\n+      if (pendingSpeculations.get(task).get()) {\n         return;\n-      } catch (InterruptedException ie) {\n-        Thread.currentThread().interrupt(); // interrupt ourself\n-      } catch (IOException ie) {\n-        LOG.warn(\"Failure sending status update: \" + \n-                  StringUtils.stringifyException(ie));\n-        if (--retries \u003d\u003d 0) {\n-          throw ie;\n-        }\n       }\n     }\n+\n+    if (stateString.equals(TaskAttemptState.RUNNING.name())) {\n+      runningTasks.putIfAbsent(taskID, Boolean.TRUE);\n+    } else {\n+      runningTasks.remove(taskID, Boolean.TRUE);\n+    }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void statusUpdate(TaskAttemptStatus reportedStatus, long timestamp) {\n\n    String stateString \u003d reportedStatus.taskState.toString();\n\n    TaskAttemptId attemptID \u003d reportedStatus.id;\n    TaskId taskID \u003d attemptID.getTaskId();\n    Job job \u003d context.getJob(taskID.getJobId());\n\n    if (job \u003d\u003d null) {\n      return;\n    }\n\n    Task task \u003d job.getTask(taskID);\n\n    if (task \u003d\u003d null) {\n      return;\n    }\n\n    estimator.updateAttempt(reportedStatus, timestamp);\n\n    // If the task is already known to be speculation-bait, don\u0027t do anything\n    if (pendingSpeculations.get(task) !\u003d null) {\n      if (pendingSpeculations.get(task).get()) {\n        return;\n      }\n    }\n\n    if (stateString.equals(TaskAttemptState.RUNNING.name())) {\n      runningTasks.putIfAbsent(taskID, Boolean.TRUE);\n    } else {\n      runningTasks.remove(taskID, Boolean.TRUE);\n    }\n  }",
          "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/speculate/DefaultSpeculator.java",
          "extendedDetails": {
            "oldPath": "mapreduce/src/java/org/apache/hadoop/mapred/Task.java",
            "newPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/speculate/DefaultSpeculator.java",
            "oldMethodName": "statusUpdate",
            "newMethodName": "statusUpdate"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/08/11 4:07 AM",
          "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "17/08/11 8:02 PM",
          "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.34,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,22 +1,33 @@\n-  public void statusUpdate(TaskUmbilicalProtocol umbilical) \n-  throws IOException {\n-    int retries \u003d MAX_RETRIES;\n-    while (true) {\n-      try {\n-        if (!umbilical.statusUpdate(getTaskID(), taskStatus)) {\n-          LOG.warn(\"Parent died.  Exiting \"+taskId);\n-          System.exit(66);\n-        }\n-        taskStatus.clearStatus();\n+  protected void statusUpdate(TaskAttemptStatus reportedStatus, long timestamp) {\n+\n+    String stateString \u003d reportedStatus.taskState.toString();\n+\n+    TaskAttemptId attemptID \u003d reportedStatus.id;\n+    TaskId taskID \u003d attemptID.getTaskId();\n+    Job job \u003d context.getJob(taskID.getJobId());\n+\n+    if (job \u003d\u003d null) {\n+      return;\n+    }\n+\n+    Task task \u003d job.getTask(taskID);\n+\n+    if (task \u003d\u003d null) {\n+      return;\n+    }\n+\n+    estimator.updateAttempt(reportedStatus, timestamp);\n+\n+    // If the task is already known to be speculation-bait, don\u0027t do anything\n+    if (pendingSpeculations.get(task) !\u003d null) {\n+      if (pendingSpeculations.get(task).get()) {\n         return;\n-      } catch (InterruptedException ie) {\n-        Thread.currentThread().interrupt(); // interrupt ourself\n-      } catch (IOException ie) {\n-        LOG.warn(\"Failure sending status update: \" + \n-                  StringUtils.stringifyException(ie));\n-        if (--retries \u003d\u003d 0) {\n-          throw ie;\n-        }\n       }\n     }\n+\n+    if (stateString.equals(TaskAttemptState.RUNNING.name())) {\n+      runningTasks.putIfAbsent(taskID, Boolean.TRUE);\n+    } else {\n+      runningTasks.remove(taskID, Boolean.TRUE);\n+    }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void statusUpdate(TaskAttemptStatus reportedStatus, long timestamp) {\n\n    String stateString \u003d reportedStatus.taskState.toString();\n\n    TaskAttemptId attemptID \u003d reportedStatus.id;\n    TaskId taskID \u003d attemptID.getTaskId();\n    Job job \u003d context.getJob(taskID.getJobId());\n\n    if (job \u003d\u003d null) {\n      return;\n    }\n\n    Task task \u003d job.getTask(taskID);\n\n    if (task \u003d\u003d null) {\n      return;\n    }\n\n    estimator.updateAttempt(reportedStatus, timestamp);\n\n    // If the task is already known to be speculation-bait, don\u0027t do anything\n    if (pendingSpeculations.get(task) !\u003d null) {\n      if (pendingSpeculations.get(task).get()) {\n        return;\n      }\n    }\n\n    if (stateString.equals(TaskAttemptState.RUNNING.name())) {\n      runningTasks.putIfAbsent(taskID, Boolean.TRUE);\n    } else {\n      runningTasks.remove(taskID, Boolean.TRUE);\n    }\n  }",
          "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/speculate/DefaultSpeculator.java",
          "extendedDetails": {
            "oldValue": "[public]",
            "newValue": "[protected]"
          }
        },
        {
          "type": "Yexceptionschange",
          "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/08/11 4:07 AM",
          "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "17/08/11 8:02 PM",
          "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.34,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,22 +1,33 @@\n-  public void statusUpdate(TaskUmbilicalProtocol umbilical) \n-  throws IOException {\n-    int retries \u003d MAX_RETRIES;\n-    while (true) {\n-      try {\n-        if (!umbilical.statusUpdate(getTaskID(), taskStatus)) {\n-          LOG.warn(\"Parent died.  Exiting \"+taskId);\n-          System.exit(66);\n-        }\n-        taskStatus.clearStatus();\n+  protected void statusUpdate(TaskAttemptStatus reportedStatus, long timestamp) {\n+\n+    String stateString \u003d reportedStatus.taskState.toString();\n+\n+    TaskAttemptId attemptID \u003d reportedStatus.id;\n+    TaskId taskID \u003d attemptID.getTaskId();\n+    Job job \u003d context.getJob(taskID.getJobId());\n+\n+    if (job \u003d\u003d null) {\n+      return;\n+    }\n+\n+    Task task \u003d job.getTask(taskID);\n+\n+    if (task \u003d\u003d null) {\n+      return;\n+    }\n+\n+    estimator.updateAttempt(reportedStatus, timestamp);\n+\n+    // If the task is already known to be speculation-bait, don\u0027t do anything\n+    if (pendingSpeculations.get(task) !\u003d null) {\n+      if (pendingSpeculations.get(task).get()) {\n         return;\n-      } catch (InterruptedException ie) {\n-        Thread.currentThread().interrupt(); // interrupt ourself\n-      } catch (IOException ie) {\n-        LOG.warn(\"Failure sending status update: \" + \n-                  StringUtils.stringifyException(ie));\n-        if (--retries \u003d\u003d 0) {\n-          throw ie;\n-        }\n       }\n     }\n+\n+    if (stateString.equals(TaskAttemptState.RUNNING.name())) {\n+      runningTasks.putIfAbsent(taskID, Boolean.TRUE);\n+    } else {\n+      runningTasks.remove(taskID, Boolean.TRUE);\n+    }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void statusUpdate(TaskAttemptStatus reportedStatus, long timestamp) {\n\n    String stateString \u003d reportedStatus.taskState.toString();\n\n    TaskAttemptId attemptID \u003d reportedStatus.id;\n    TaskId taskID \u003d attemptID.getTaskId();\n    Job job \u003d context.getJob(taskID.getJobId());\n\n    if (job \u003d\u003d null) {\n      return;\n    }\n\n    Task task \u003d job.getTask(taskID);\n\n    if (task \u003d\u003d null) {\n      return;\n    }\n\n    estimator.updateAttempt(reportedStatus, timestamp);\n\n    // If the task is already known to be speculation-bait, don\u0027t do anything\n    if (pendingSpeculations.get(task) !\u003d null) {\n      if (pendingSpeculations.get(task).get()) {\n        return;\n      }\n    }\n\n    if (stateString.equals(TaskAttemptState.RUNNING.name())) {\n      runningTasks.putIfAbsent(taskID, Boolean.TRUE);\n    } else {\n      runningTasks.remove(taskID, Boolean.TRUE);\n    }\n  }",
          "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/speculate/DefaultSpeculator.java",
          "extendedDetails": {
            "oldValue": "[IOException]",
            "newValue": "[]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/08/11 4:07 AM",
          "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "17/08/11 8:02 PM",
          "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.34,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,22 +1,33 @@\n-  public void statusUpdate(TaskUmbilicalProtocol umbilical) \n-  throws IOException {\n-    int retries \u003d MAX_RETRIES;\n-    while (true) {\n-      try {\n-        if (!umbilical.statusUpdate(getTaskID(), taskStatus)) {\n-          LOG.warn(\"Parent died.  Exiting \"+taskId);\n-          System.exit(66);\n-        }\n-        taskStatus.clearStatus();\n+  protected void statusUpdate(TaskAttemptStatus reportedStatus, long timestamp) {\n+\n+    String stateString \u003d reportedStatus.taskState.toString();\n+\n+    TaskAttemptId attemptID \u003d reportedStatus.id;\n+    TaskId taskID \u003d attemptID.getTaskId();\n+    Job job \u003d context.getJob(taskID.getJobId());\n+\n+    if (job \u003d\u003d null) {\n+      return;\n+    }\n+\n+    Task task \u003d job.getTask(taskID);\n+\n+    if (task \u003d\u003d null) {\n+      return;\n+    }\n+\n+    estimator.updateAttempt(reportedStatus, timestamp);\n+\n+    // If the task is already known to be speculation-bait, don\u0027t do anything\n+    if (pendingSpeculations.get(task) !\u003d null) {\n+      if (pendingSpeculations.get(task).get()) {\n         return;\n-      } catch (InterruptedException ie) {\n-        Thread.currentThread().interrupt(); // interrupt ourself\n-      } catch (IOException ie) {\n-        LOG.warn(\"Failure sending status update: \" + \n-                  StringUtils.stringifyException(ie));\n-        if (--retries \u003d\u003d 0) {\n-          throw ie;\n-        }\n       }\n     }\n+\n+    if (stateString.equals(TaskAttemptState.RUNNING.name())) {\n+      runningTasks.putIfAbsent(taskID, Boolean.TRUE);\n+    } else {\n+      runningTasks.remove(taskID, Boolean.TRUE);\n+    }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void statusUpdate(TaskAttemptStatus reportedStatus, long timestamp) {\n\n    String stateString \u003d reportedStatus.taskState.toString();\n\n    TaskAttemptId attemptID \u003d reportedStatus.id;\n    TaskId taskID \u003d attemptID.getTaskId();\n    Job job \u003d context.getJob(taskID.getJobId());\n\n    if (job \u003d\u003d null) {\n      return;\n    }\n\n    Task task \u003d job.getTask(taskID);\n\n    if (task \u003d\u003d null) {\n      return;\n    }\n\n    estimator.updateAttempt(reportedStatus, timestamp);\n\n    // If the task is already known to be speculation-bait, don\u0027t do anything\n    if (pendingSpeculations.get(task) !\u003d null) {\n      if (pendingSpeculations.get(task).get()) {\n        return;\n      }\n    }\n\n    if (stateString.equals(TaskAttemptState.RUNNING.name())) {\n      runningTasks.putIfAbsent(taskID, Boolean.TRUE);\n    } else {\n      runningTasks.remove(taskID, Boolean.TRUE);\n    }\n  }",
          "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/speculate/DefaultSpeculator.java",
          "extendedDetails": {}
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/08/11 4:07 AM",
          "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "17/08/11 8:02 PM",
          "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.34,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,22 +1,33 @@\n-  public void statusUpdate(TaskUmbilicalProtocol umbilical) \n-  throws IOException {\n-    int retries \u003d MAX_RETRIES;\n-    while (true) {\n-      try {\n-        if (!umbilical.statusUpdate(getTaskID(), taskStatus)) {\n-          LOG.warn(\"Parent died.  Exiting \"+taskId);\n-          System.exit(66);\n-        }\n-        taskStatus.clearStatus();\n+  protected void statusUpdate(TaskAttemptStatus reportedStatus, long timestamp) {\n+\n+    String stateString \u003d reportedStatus.taskState.toString();\n+\n+    TaskAttemptId attemptID \u003d reportedStatus.id;\n+    TaskId taskID \u003d attemptID.getTaskId();\n+    Job job \u003d context.getJob(taskID.getJobId());\n+\n+    if (job \u003d\u003d null) {\n+      return;\n+    }\n+\n+    Task task \u003d job.getTask(taskID);\n+\n+    if (task \u003d\u003d null) {\n+      return;\n+    }\n+\n+    estimator.updateAttempt(reportedStatus, timestamp);\n+\n+    // If the task is already known to be speculation-bait, don\u0027t do anything\n+    if (pendingSpeculations.get(task) !\u003d null) {\n+      if (pendingSpeculations.get(task).get()) {\n         return;\n-      } catch (InterruptedException ie) {\n-        Thread.currentThread().interrupt(); // interrupt ourself\n-      } catch (IOException ie) {\n-        LOG.warn(\"Failure sending status update: \" + \n-                  StringUtils.stringifyException(ie));\n-        if (--retries \u003d\u003d 0) {\n-          throw ie;\n-        }\n       }\n     }\n+\n+    if (stateString.equals(TaskAttemptState.RUNNING.name())) {\n+      runningTasks.putIfAbsent(taskID, Boolean.TRUE);\n+    } else {\n+      runningTasks.remove(taskID, Boolean.TRUE);\n+    }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void statusUpdate(TaskAttemptStatus reportedStatus, long timestamp) {\n\n    String stateString \u003d reportedStatus.taskState.toString();\n\n    TaskAttemptId attemptID \u003d reportedStatus.id;\n    TaskId taskID \u003d attemptID.getTaskId();\n    Job job \u003d context.getJob(taskID.getJobId());\n\n    if (job \u003d\u003d null) {\n      return;\n    }\n\n    Task task \u003d job.getTask(taskID);\n\n    if (task \u003d\u003d null) {\n      return;\n    }\n\n    estimator.updateAttempt(reportedStatus, timestamp);\n\n    // If the task is already known to be speculation-bait, don\u0027t do anything\n    if (pendingSpeculations.get(task) !\u003d null) {\n      if (pendingSpeculations.get(task).get()) {\n        return;\n      }\n    }\n\n    if (stateString.equals(TaskAttemptState.RUNNING.name())) {\n      runningTasks.putIfAbsent(taskID, Boolean.TRUE);\n    } else {\n      runningTasks.remove(taskID, Boolean.TRUE);\n    }\n  }",
          "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/speculate/DefaultSpeculator.java",
          "extendedDetails": {
            "oldValue": "[umbilical-TaskUmbilicalProtocol]",
            "newValue": "[reportedStatus-TaskAttemptStatus, timestamp-long]"
          }
        }
      ]
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,22 @@\n+  public void statusUpdate(TaskUmbilicalProtocol umbilical) \n+  throws IOException {\n+    int retries \u003d MAX_RETRIES;\n+    while (true) {\n+      try {\n+        if (!umbilical.statusUpdate(getTaskID(), taskStatus)) {\n+          LOG.warn(\"Parent died.  Exiting \"+taskId);\n+          System.exit(66);\n+        }\n+        taskStatus.clearStatus();\n+        return;\n+      } catch (InterruptedException ie) {\n+        Thread.currentThread().interrupt(); // interrupt ourself\n+      } catch (IOException ie) {\n+        LOG.warn(\"Failure sending status update: \" + \n+                  StringUtils.stringifyException(ie));\n+        if (--retries \u003d\u003d 0) {\n+          throw ie;\n+        }\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void statusUpdate(TaskUmbilicalProtocol umbilical) \n  throws IOException {\n    int retries \u003d MAX_RETRIES;\n    while (true) {\n      try {\n        if (!umbilical.statusUpdate(getTaskID(), taskStatus)) {\n          LOG.warn(\"Parent died.  Exiting \"+taskId);\n          System.exit(66);\n        }\n        taskStatus.clearStatus();\n        return;\n      } catch (InterruptedException ie) {\n        Thread.currentThread().interrupt(); // interrupt ourself\n      } catch (IOException ie) {\n        LOG.warn(\"Failure sending status update: \" + \n                  StringUtils.stringifyException(ie));\n        if (--retries \u003d\u003d 0) {\n          throw ie;\n        }\n      }\n    }\n  }",
      "path": "mapreduce/src/java/org/apache/hadoop/mapred/Task.java"
    }
  }
}