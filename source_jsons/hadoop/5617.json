{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "CacheManager.java",
  "functionName": "listCachePools",
  "functionId": "listCachePools___pc-FSPermissionChecker__prevKey-String",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
  "functionStartLine": 914,
  "functionEndLine": 928,
  "numCommitsSeen": 61,
  "timeTaken": 3750,
  "changeHistory": [
    "d85c017d0488930d806f267141057fc73e68c728",
    "991c453ca3ac141a3f286f74af8401f83c38b230",
    "13edb391d06c479720202eb5ac81f1c71fe64748",
    "e3d7ef36ef7dd31b295b1f1d86a1bfa7887ca771",
    "ce35e0950cef9250ce2ceffb3b8bfcff533c6b92",
    "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
    "f41f8b8842c3f26d19f7fa928070c7c07f760e4c",
    "d56d0b46e1b82ae068083ddb99872d314684dc82",
    "97b7267977ef42201e5844df49bc37ec3d10ce16"
  ],
  "changeHistoryShort": {
    "d85c017d0488930d806f267141057fc73e68c728": "Ybodychange",
    "991c453ca3ac141a3f286f74af8401f83c38b230": "Ybodychange",
    "13edb391d06c479720202eb5ac81f1c71fe64748": "Ymultichange(Yreturntypechange,Ybodychange)",
    "e3d7ef36ef7dd31b295b1f1d86a1bfa7887ca771": "Ybodychange",
    "ce35e0950cef9250ce2ceffb3b8bfcff533c6b92": "Ybodychange",
    "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a": "Ymultichange(Ymodifierchange,Ybodychange)",
    "f41f8b8842c3f26d19f7fa928070c7c07f760e4c": "Ymultichange(Yparameterchange,Yreturntypechange,Ybodychange)",
    "d56d0b46e1b82ae068083ddb99872d314684dc82": "Ymultichange(Yparameterchange,Yreturntypechange,Ybodychange)",
    "97b7267977ef42201e5844df49bc37ec3d10ce16": "Yintroduced"
  },
  "changeHistoryDetails": {
    "d85c017d0488930d806f267141057fc73e68c728": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5651. Remove dfs.namenode.caching.enabled and improve CRM locking. Contributed by Colin Patrick McCabe.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1555002 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/01/14 6:45 PM",
      "commitName": "d85c017d0488930d806f267141057fc73e68c728",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "31/12/13 4:01 PM",
      "commitNameOld": "07e4fb1455abc33584fc666ef745abe256ebd7d1",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 2.11,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,15 @@\n       listCachePools(FSPermissionChecker pc, String prevKey) {\n     assert namesystem.hasReadLock();\n-    if (monitor !\u003d null) {\n-      monitor.waitForRescanIfNeeded();\n-    }\n     final int NUM_PRE_ALLOCATED_ENTRIES \u003d 16;\n     ArrayList\u003cCachePoolEntry\u003e results \u003d \n         new ArrayList\u003cCachePoolEntry\u003e(NUM_PRE_ALLOCATED_ENTRIES);\n     SortedMap\u003cString, CachePool\u003e tailMap \u003d cachePools.tailMap(prevKey, false);\n     int numListed \u003d 0;\n     for (Entry\u003cString, CachePool\u003e cur : tailMap.entrySet()) {\n       if (numListed++ \u003e\u003d maxListCachePoolsResponses) {\n         return new BatchedListEntries\u003cCachePoolEntry\u003e(results, true);\n       }\n       results.add(cur.getValue().getEntry(pc));\n     }\n     return new BatchedListEntries\u003cCachePoolEntry\u003e(results, false);\n   }\n\\ No newline at end of file\n",
      "actualSource": "      listCachePools(FSPermissionChecker pc, String prevKey) {\n    assert namesystem.hasReadLock();\n    final int NUM_PRE_ALLOCATED_ENTRIES \u003d 16;\n    ArrayList\u003cCachePoolEntry\u003e results \u003d \n        new ArrayList\u003cCachePoolEntry\u003e(NUM_PRE_ALLOCATED_ENTRIES);\n    SortedMap\u003cString, CachePool\u003e tailMap \u003d cachePools.tailMap(prevKey, false);\n    int numListed \u003d 0;\n    for (Entry\u003cString, CachePool\u003e cur : tailMap.entrySet()) {\n      if (numListed++ \u003e\u003d maxListCachePoolsResponses) {\n        return new BatchedListEntries\u003cCachePoolEntry\u003e(results, true);\n      }\n      results.add(cur.getValue().getEntry(pc));\n    }\n    return new BatchedListEntries\u003cCachePoolEntry\u003e(results, false);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
      "extendedDetails": {}
    },
    "991c453ca3ac141a3f286f74af8401f83c38b230": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5431. Support cachepool-based limit management in path-based caching. (awang via cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1551651 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/12/13 10:47 AM",
      "commitName": "991c453ca3ac141a3f286f74af8401f83c38b230",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "05/12/13 1:09 PM",
      "commitNameOld": "55e5b0653c34a5f4146ce5a97a5b4a88a976d88a",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 11.9,
      "commitsBetweenForRepo": 67,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,18 @@\n       listCachePools(FSPermissionChecker pc, String prevKey) {\n     assert namesystem.hasReadLock();\n+    if (monitor !\u003d null) {\n+      monitor.waitForRescanIfNeeded();\n+    }\n     final int NUM_PRE_ALLOCATED_ENTRIES \u003d 16;\n     ArrayList\u003cCachePoolEntry\u003e results \u003d \n         new ArrayList\u003cCachePoolEntry\u003e(NUM_PRE_ALLOCATED_ENTRIES);\n     SortedMap\u003cString, CachePool\u003e tailMap \u003d cachePools.tailMap(prevKey, false);\n     int numListed \u003d 0;\n     for (Entry\u003cString, CachePool\u003e cur : tailMap.entrySet()) {\n       if (numListed++ \u003e\u003d maxListCachePoolsResponses) {\n         return new BatchedListEntries\u003cCachePoolEntry\u003e(results, true);\n       }\n       results.add(cur.getValue().getEntry(pc));\n     }\n     return new BatchedListEntries\u003cCachePoolEntry\u003e(results, false);\n   }\n\\ No newline at end of file\n",
      "actualSource": "      listCachePools(FSPermissionChecker pc, String prevKey) {\n    assert namesystem.hasReadLock();\n    if (monitor !\u003d null) {\n      monitor.waitForRescanIfNeeded();\n    }\n    final int NUM_PRE_ALLOCATED_ENTRIES \u003d 16;\n    ArrayList\u003cCachePoolEntry\u003e results \u003d \n        new ArrayList\u003cCachePoolEntry\u003e(NUM_PRE_ALLOCATED_ENTRIES);\n    SortedMap\u003cString, CachePool\u003e tailMap \u003d cachePools.tailMap(prevKey, false);\n    int numListed \u003d 0;\n    for (Entry\u003cString, CachePool\u003e cur : tailMap.entrySet()) {\n      if (numListed++ \u003e\u003d maxListCachePoolsResponses) {\n        return new BatchedListEntries\u003cCachePoolEntry\u003e(results, true);\n      }\n      results.add(cur.getValue().getEntry(pc));\n    }\n    return new BatchedListEntries\u003cCachePoolEntry\u003e(results, false);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
      "extendedDetails": {}
    },
    "13edb391d06c479720202eb5ac81f1c71fe64748": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-5556. Add some more NameNode cache statistics, cache pool stats (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1546143 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/11/13 9:55 AM",
      "commitName": "13edb391d06c479720202eb5ac81f1c71fe64748",
      "commitAuthor": "Colin McCabe",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-5556. Add some more NameNode cache statistics, cache pool stats (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1546143 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "27/11/13 9:55 AM",
          "commitName": "13edb391d06c479720202eb5ac81f1c71fe64748",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "21/11/13 9:12 AM",
          "commitNameOld": "f91a45a96c21db9e5d40097c7d3f5d005ae10dde",
          "commitAuthorOld": "Colin McCabe",
          "daysBetweenCommits": 6.03,
          "commitsBetweenForRepo": 22,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,15 +1,15 @@\n       listCachePools(FSPermissionChecker pc, String prevKey) {\n     assert namesystem.hasReadLock();\n     final int NUM_PRE_ALLOCATED_ENTRIES \u003d 16;\n-    ArrayList\u003cCachePoolInfo\u003e results \u003d \n-        new ArrayList\u003cCachePoolInfo\u003e(NUM_PRE_ALLOCATED_ENTRIES);\n+    ArrayList\u003cCachePoolEntry\u003e results \u003d \n+        new ArrayList\u003cCachePoolEntry\u003e(NUM_PRE_ALLOCATED_ENTRIES);\n     SortedMap\u003cString, CachePool\u003e tailMap \u003d cachePools.tailMap(prevKey, false);\n     int numListed \u003d 0;\n     for (Entry\u003cString, CachePool\u003e cur : tailMap.entrySet()) {\n       if (numListed++ \u003e\u003d maxListCachePoolsResponses) {\n-        return new BatchedListEntries\u003cCachePoolInfo\u003e(results, true);\n+        return new BatchedListEntries\u003cCachePoolEntry\u003e(results, true);\n       }\n-      results.add(cur.getValue().getInfo(pc));\n+      results.add(cur.getValue().getEntry(pc));\n     }\n-    return new BatchedListEntries\u003cCachePoolInfo\u003e(results, false);\n+    return new BatchedListEntries\u003cCachePoolEntry\u003e(results, false);\n   }\n\\ No newline at end of file\n",
          "actualSource": "      listCachePools(FSPermissionChecker pc, String prevKey) {\n    assert namesystem.hasReadLock();\n    final int NUM_PRE_ALLOCATED_ENTRIES \u003d 16;\n    ArrayList\u003cCachePoolEntry\u003e results \u003d \n        new ArrayList\u003cCachePoolEntry\u003e(NUM_PRE_ALLOCATED_ENTRIES);\n    SortedMap\u003cString, CachePool\u003e tailMap \u003d cachePools.tailMap(prevKey, false);\n    int numListed \u003d 0;\n    for (Entry\u003cString, CachePool\u003e cur : tailMap.entrySet()) {\n      if (numListed++ \u003e\u003d maxListCachePoolsResponses) {\n        return new BatchedListEntries\u003cCachePoolEntry\u003e(results, true);\n      }\n      results.add(cur.getValue().getEntry(pc));\n    }\n    return new BatchedListEntries\u003cCachePoolEntry\u003e(results, false);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
          "extendedDetails": {
            "oldValue": "BatchedListEntries\u003cCachePoolInfo\u003e",
            "newValue": "BatchedListEntries\u003cCachePoolEntry\u003e"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5556. Add some more NameNode cache statistics, cache pool stats (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1546143 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "27/11/13 9:55 AM",
          "commitName": "13edb391d06c479720202eb5ac81f1c71fe64748",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "21/11/13 9:12 AM",
          "commitNameOld": "f91a45a96c21db9e5d40097c7d3f5d005ae10dde",
          "commitAuthorOld": "Colin McCabe",
          "daysBetweenCommits": 6.03,
          "commitsBetweenForRepo": 22,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,15 +1,15 @@\n       listCachePools(FSPermissionChecker pc, String prevKey) {\n     assert namesystem.hasReadLock();\n     final int NUM_PRE_ALLOCATED_ENTRIES \u003d 16;\n-    ArrayList\u003cCachePoolInfo\u003e results \u003d \n-        new ArrayList\u003cCachePoolInfo\u003e(NUM_PRE_ALLOCATED_ENTRIES);\n+    ArrayList\u003cCachePoolEntry\u003e results \u003d \n+        new ArrayList\u003cCachePoolEntry\u003e(NUM_PRE_ALLOCATED_ENTRIES);\n     SortedMap\u003cString, CachePool\u003e tailMap \u003d cachePools.tailMap(prevKey, false);\n     int numListed \u003d 0;\n     for (Entry\u003cString, CachePool\u003e cur : tailMap.entrySet()) {\n       if (numListed++ \u003e\u003d maxListCachePoolsResponses) {\n-        return new BatchedListEntries\u003cCachePoolInfo\u003e(results, true);\n+        return new BatchedListEntries\u003cCachePoolEntry\u003e(results, true);\n       }\n-      results.add(cur.getValue().getInfo(pc));\n+      results.add(cur.getValue().getEntry(pc));\n     }\n-    return new BatchedListEntries\u003cCachePoolInfo\u003e(results, false);\n+    return new BatchedListEntries\u003cCachePoolEntry\u003e(results, false);\n   }\n\\ No newline at end of file\n",
          "actualSource": "      listCachePools(FSPermissionChecker pc, String prevKey) {\n    assert namesystem.hasReadLock();\n    final int NUM_PRE_ALLOCATED_ENTRIES \u003d 16;\n    ArrayList\u003cCachePoolEntry\u003e results \u003d \n        new ArrayList\u003cCachePoolEntry\u003e(NUM_PRE_ALLOCATED_ENTRIES);\n    SortedMap\u003cString, CachePool\u003e tailMap \u003d cachePools.tailMap(prevKey, false);\n    int numListed \u003d 0;\n    for (Entry\u003cString, CachePool\u003e cur : tailMap.entrySet()) {\n      if (numListed++ \u003e\u003d maxListCachePoolsResponses) {\n        return new BatchedListEntries\u003cCachePoolEntry\u003e(results, true);\n      }\n      results.add(cur.getValue().getEntry(pc));\n    }\n    return new BatchedListEntries\u003cCachePoolEntry\u003e(results, false);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "e3d7ef36ef7dd31b295b1f1d86a1bfa7887ca771": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5372. In FSNamesystem, hasReadLock() returns false if the current thread holds the write lock (Contributed by Vinay)\n\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1542887 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/11/13 8:18 PM",
      "commitName": "e3d7ef36ef7dd31b295b1f1d86a1bfa7887ca771",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/11/13 3:52 PM",
      "commitNameOld": "ce35e0950cef9250ce2ceffb3b8bfcff533c6b92",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 5.18,
      "commitsBetweenForRepo": 42,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,15 @@\n       listCachePools(FSPermissionChecker pc, String prevKey) {\n-    assert namesystem.hasReadOrWriteLock();\n+    assert namesystem.hasReadLock();\n     final int NUM_PRE_ALLOCATED_ENTRIES \u003d 16;\n     ArrayList\u003cCachePoolInfo\u003e results \u003d \n         new ArrayList\u003cCachePoolInfo\u003e(NUM_PRE_ALLOCATED_ENTRIES);\n     SortedMap\u003cString, CachePool\u003e tailMap \u003d cachePools.tailMap(prevKey, false);\n     int numListed \u003d 0;\n     for (Entry\u003cString, CachePool\u003e cur : tailMap.entrySet()) {\n       if (numListed++ \u003e\u003d maxListCachePoolsResponses) {\n         return new BatchedListEntries\u003cCachePoolInfo\u003e(results, true);\n       }\n       results.add(cur.getValue().getInfo(pc));\n     }\n     return new BatchedListEntries\u003cCachePoolInfo\u003e(results, false);\n   }\n\\ No newline at end of file\n",
      "actualSource": "      listCachePools(FSPermissionChecker pc, String prevKey) {\n    assert namesystem.hasReadLock();\n    final int NUM_PRE_ALLOCATED_ENTRIES \u003d 16;\n    ArrayList\u003cCachePoolInfo\u003e results \u003d \n        new ArrayList\u003cCachePoolInfo\u003e(NUM_PRE_ALLOCATED_ENTRIES);\n    SortedMap\u003cString, CachePool\u003e tailMap \u003d cachePools.tailMap(prevKey, false);\n    int numListed \u003d 0;\n    for (Entry\u003cString, CachePool\u003e cur : tailMap.entrySet()) {\n      if (numListed++ \u003e\u003d maxListCachePoolsResponses) {\n        return new BatchedListEntries\u003cCachePoolInfo\u003e(results, true);\n      }\n      results.add(cur.getValue().getInfo(pc));\n    }\n    return new BatchedListEntries\u003cCachePoolInfo\u003e(results, false);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
      "extendedDetails": {}
    },
    "ce35e0950cef9250ce2ceffb3b8bfcff533c6b92": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5471. CacheAdmin -listPools fails when user lacks permissions to view all pools (Andrew Wang via Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1541323 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/11/13 3:52 PM",
      "commitName": "ce35e0950cef9250ce2ceffb3b8bfcff533c6b92",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "07/11/13 2:07 PM",
      "commitNameOld": "f79b3e6b17450e9d34c483046b7437b09dd72016",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 5.07,
      "commitsBetweenForRepo": 20,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,15 @@\n       listCachePools(FSPermissionChecker pc, String prevKey) {\n     assert namesystem.hasReadOrWriteLock();\n     final int NUM_PRE_ALLOCATED_ENTRIES \u003d 16;\n     ArrayList\u003cCachePoolInfo\u003e results \u003d \n         new ArrayList\u003cCachePoolInfo\u003e(NUM_PRE_ALLOCATED_ENTRIES);\n     SortedMap\u003cString, CachePool\u003e tailMap \u003d cachePools.tailMap(prevKey, false);\n     int numListed \u003d 0;\n     for (Entry\u003cString, CachePool\u003e cur : tailMap.entrySet()) {\n       if (numListed++ \u003e\u003d maxListCachePoolsResponses) {\n         return new BatchedListEntries\u003cCachePoolInfo\u003e(results, true);\n       }\n-      if (pc \u003d\u003d null) {\n-        results.add(cur.getValue().getInfo(true));\n-      } else {\n-        results.add(cur.getValue().getInfo(pc));\n-      }\n+      results.add(cur.getValue().getInfo(pc));\n     }\n     return new BatchedListEntries\u003cCachePoolInfo\u003e(results, false);\n   }\n\\ No newline at end of file\n",
      "actualSource": "      listCachePools(FSPermissionChecker pc, String prevKey) {\n    assert namesystem.hasReadOrWriteLock();\n    final int NUM_PRE_ALLOCATED_ENTRIES \u003d 16;\n    ArrayList\u003cCachePoolInfo\u003e results \u003d \n        new ArrayList\u003cCachePoolInfo\u003e(NUM_PRE_ALLOCATED_ENTRIES);\n    SortedMap\u003cString, CachePool\u003e tailMap \u003d cachePools.tailMap(prevKey, false);\n    int numListed \u003d 0;\n    for (Entry\u003cString, CachePool\u003e cur : tailMap.entrySet()) {\n      if (numListed++ \u003e\u003d maxListCachePoolsResponses) {\n        return new BatchedListEntries\u003cCachePoolInfo\u003e(results, true);\n      }\n      results.add(cur.getValue().getInfo(pc));\n    }\n    return new BatchedListEntries\u003cCachePoolInfo\u003e(results, false);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
      "extendedDetails": {}
    },
    "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-5096. Automatically cache new data added to a cached path (contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1532924 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/10/13 3:15 PM",
      "commitName": "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
      "commitAuthor": "Colin McCabe",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-5096. Automatically cache new data added to a cached path (contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1532924 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "16/10/13 3:15 PM",
          "commitName": "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "14/10/13 3:56 PM",
          "commitNameOld": "efe545b0c219eeba61ac5259aee4d518beb74316",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 1.97,
          "commitsBetweenForRepo": 4,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,18 +1,19 @@\n       listCachePools(FSPermissionChecker pc, String prevKey) {\n+    assert namesystem.hasReadOrWriteLock();\n     final int NUM_PRE_ALLOCATED_ENTRIES \u003d 16;\n     ArrayList\u003cCachePoolInfo\u003e results \u003d \n         new ArrayList\u003cCachePoolInfo\u003e(NUM_PRE_ALLOCATED_ENTRIES);\n     SortedMap\u003cString, CachePool\u003e tailMap \u003d cachePools.tailMap(prevKey, false);\n     int numListed \u003d 0;\n     for (Entry\u003cString, CachePool\u003e cur : tailMap.entrySet()) {\n       if (numListed++ \u003e\u003d maxListCachePoolsResponses) {\n         return new BatchedListEntries\u003cCachePoolInfo\u003e(results, true);\n       }\n       if (pc \u003d\u003d null) {\n         results.add(cur.getValue().getInfo(true));\n       } else {\n         results.add(cur.getValue().getInfo(pc));\n       }\n     }\n     return new BatchedListEntries\u003cCachePoolInfo\u003e(results, false);\n   }\n\\ No newline at end of file\n",
          "actualSource": "      listCachePools(FSPermissionChecker pc, String prevKey) {\n    assert namesystem.hasReadOrWriteLock();\n    final int NUM_PRE_ALLOCATED_ENTRIES \u003d 16;\n    ArrayList\u003cCachePoolInfo\u003e results \u003d \n        new ArrayList\u003cCachePoolInfo\u003e(NUM_PRE_ALLOCATED_ENTRIES);\n    SortedMap\u003cString, CachePool\u003e tailMap \u003d cachePools.tailMap(prevKey, false);\n    int numListed \u003d 0;\n    for (Entry\u003cString, CachePool\u003e cur : tailMap.entrySet()) {\n      if (numListed++ \u003e\u003d maxListCachePoolsResponses) {\n        return new BatchedListEntries\u003cCachePoolInfo\u003e(results, true);\n      }\n      if (pc \u003d\u003d null) {\n        results.add(cur.getValue().getInfo(true));\n      } else {\n        results.add(cur.getValue().getInfo(pc));\n      }\n    }\n    return new BatchedListEntries\u003cCachePoolInfo\u003e(results, false);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
          "extendedDetails": {
            "oldValue": "[public, synchronized]",
            "newValue": "[public]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5096. Automatically cache new data added to a cached path (contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1532924 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "16/10/13 3:15 PM",
          "commitName": "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "14/10/13 3:56 PM",
          "commitNameOld": "efe545b0c219eeba61ac5259aee4d518beb74316",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 1.97,
          "commitsBetweenForRepo": 4,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,18 +1,19 @@\n       listCachePools(FSPermissionChecker pc, String prevKey) {\n+    assert namesystem.hasReadOrWriteLock();\n     final int NUM_PRE_ALLOCATED_ENTRIES \u003d 16;\n     ArrayList\u003cCachePoolInfo\u003e results \u003d \n         new ArrayList\u003cCachePoolInfo\u003e(NUM_PRE_ALLOCATED_ENTRIES);\n     SortedMap\u003cString, CachePool\u003e tailMap \u003d cachePools.tailMap(prevKey, false);\n     int numListed \u003d 0;\n     for (Entry\u003cString, CachePool\u003e cur : tailMap.entrySet()) {\n       if (numListed++ \u003e\u003d maxListCachePoolsResponses) {\n         return new BatchedListEntries\u003cCachePoolInfo\u003e(results, true);\n       }\n       if (pc \u003d\u003d null) {\n         results.add(cur.getValue().getInfo(true));\n       } else {\n         results.add(cur.getValue().getInfo(pc));\n       }\n     }\n     return new BatchedListEntries\u003cCachePoolInfo\u003e(results, false);\n   }\n\\ No newline at end of file\n",
          "actualSource": "      listCachePools(FSPermissionChecker pc, String prevKey) {\n    assert namesystem.hasReadOrWriteLock();\n    final int NUM_PRE_ALLOCATED_ENTRIES \u003d 16;\n    ArrayList\u003cCachePoolInfo\u003e results \u003d \n        new ArrayList\u003cCachePoolInfo\u003e(NUM_PRE_ALLOCATED_ENTRIES);\n    SortedMap\u003cString, CachePool\u003e tailMap \u003d cachePools.tailMap(prevKey, false);\n    int numListed \u003d 0;\n    for (Entry\u003cString, CachePool\u003e cur : tailMap.entrySet()) {\n      if (numListed++ \u003e\u003d maxListCachePoolsResponses) {\n        return new BatchedListEntries\u003cCachePoolInfo\u003e(results, true);\n      }\n      if (pc \u003d\u003d null) {\n        results.add(cur.getValue().getInfo(true));\n      } else {\n        results.add(cur.getValue().getInfo(pc));\n      }\n    }\n    return new BatchedListEntries\u003cCachePoolInfo\u003e(results, false);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "f41f8b8842c3f26d19f7fa928070c7c07f760e4c": {
      "type": "Ymultichange(Yparameterchange,Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-5163. Miscellaneous cache pool RPC fixes (Contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1520665 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/09/13 11:52 AM",
      "commitName": "f41f8b8842c3f26d19f7fa928070c7c07f760e4c",
      "commitAuthor": "Colin McCabe",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-5163. Miscellaneous cache pool RPC fixes (Contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1520665 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "06/09/13 11:52 AM",
          "commitName": "f41f8b8842c3f26d19f7fa928070c7c07f760e4c",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "04/09/13 11:23 AM",
          "commitNameOld": "d56d0b46e1b82ae068083ddb99872d314684dc82",
          "commitAuthorOld": "Colin McCabe",
          "daysBetweenCommits": 2.02,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,13 +1,18 @@\n-  public synchronized List\u003cCachePool\u003e listCachePools(Long prevKey,\n-      int maxRepliesPerRequest) {\n-    final int MAX_PREALLOCATED_REPLIES \u003d 16;\n-    ArrayList\u003cCachePool\u003e results \u003d \n-        new ArrayList\u003cCachePool\u003e(Math.min(MAX_PREALLOCATED_REPLIES,\n-            maxRepliesPerRequest));\n-    SortedMap\u003cLong, CachePool\u003e tailMap \u003d\n-        cachePoolsById.tailMap(prevKey, false);\n-    for (CachePool pool : tailMap.values()) {\n-      results.add(pool);\n+      listCachePools(FSPermissionChecker pc, String prevKey) {\n+    final int NUM_PRE_ALLOCATED_ENTRIES \u003d 16;\n+    ArrayList\u003cCachePoolInfo\u003e results \u003d \n+        new ArrayList\u003cCachePoolInfo\u003e(NUM_PRE_ALLOCATED_ENTRIES);\n+    SortedMap\u003cString, CachePool\u003e tailMap \u003d cachePools.tailMap(prevKey, false);\n+    int numListed \u003d 0;\n+    for (Entry\u003cString, CachePool\u003e cur : tailMap.entrySet()) {\n+      if (numListed++ \u003e\u003d maxListCachePoolsResponses) {\n+        return new BatchedListEntries\u003cCachePoolInfo\u003e(results, true);\n+      }\n+      if (pc \u003d\u003d null) {\n+        results.add(cur.getValue().getInfo(true));\n+      } else {\n+        results.add(cur.getValue().getInfo(pc));\n+      }\n     }\n-    return results;\n+    return new BatchedListEntries\u003cCachePoolInfo\u003e(results, false);\n   }\n\\ No newline at end of file\n",
          "actualSource": "      listCachePools(FSPermissionChecker pc, String prevKey) {\n    final int NUM_PRE_ALLOCATED_ENTRIES \u003d 16;\n    ArrayList\u003cCachePoolInfo\u003e results \u003d \n        new ArrayList\u003cCachePoolInfo\u003e(NUM_PRE_ALLOCATED_ENTRIES);\n    SortedMap\u003cString, CachePool\u003e tailMap \u003d cachePools.tailMap(prevKey, false);\n    int numListed \u003d 0;\n    for (Entry\u003cString, CachePool\u003e cur : tailMap.entrySet()) {\n      if (numListed++ \u003e\u003d maxListCachePoolsResponses) {\n        return new BatchedListEntries\u003cCachePoolInfo\u003e(results, true);\n      }\n      if (pc \u003d\u003d null) {\n        results.add(cur.getValue().getInfo(true));\n      } else {\n        results.add(cur.getValue().getInfo(pc));\n      }\n    }\n    return new BatchedListEntries\u003cCachePoolInfo\u003e(results, false);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
          "extendedDetails": {
            "oldValue": "[prevKey-Long, maxRepliesPerRequest-int]",
            "newValue": "[pc-FSPermissionChecker, prevKey-String]"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-5163. Miscellaneous cache pool RPC fixes (Contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1520665 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "06/09/13 11:52 AM",
          "commitName": "f41f8b8842c3f26d19f7fa928070c7c07f760e4c",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "04/09/13 11:23 AM",
          "commitNameOld": "d56d0b46e1b82ae068083ddb99872d314684dc82",
          "commitAuthorOld": "Colin McCabe",
          "daysBetweenCommits": 2.02,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,13 +1,18 @@\n-  public synchronized List\u003cCachePool\u003e listCachePools(Long prevKey,\n-      int maxRepliesPerRequest) {\n-    final int MAX_PREALLOCATED_REPLIES \u003d 16;\n-    ArrayList\u003cCachePool\u003e results \u003d \n-        new ArrayList\u003cCachePool\u003e(Math.min(MAX_PREALLOCATED_REPLIES,\n-            maxRepliesPerRequest));\n-    SortedMap\u003cLong, CachePool\u003e tailMap \u003d\n-        cachePoolsById.tailMap(prevKey, false);\n-    for (CachePool pool : tailMap.values()) {\n-      results.add(pool);\n+      listCachePools(FSPermissionChecker pc, String prevKey) {\n+    final int NUM_PRE_ALLOCATED_ENTRIES \u003d 16;\n+    ArrayList\u003cCachePoolInfo\u003e results \u003d \n+        new ArrayList\u003cCachePoolInfo\u003e(NUM_PRE_ALLOCATED_ENTRIES);\n+    SortedMap\u003cString, CachePool\u003e tailMap \u003d cachePools.tailMap(prevKey, false);\n+    int numListed \u003d 0;\n+    for (Entry\u003cString, CachePool\u003e cur : tailMap.entrySet()) {\n+      if (numListed++ \u003e\u003d maxListCachePoolsResponses) {\n+        return new BatchedListEntries\u003cCachePoolInfo\u003e(results, true);\n+      }\n+      if (pc \u003d\u003d null) {\n+        results.add(cur.getValue().getInfo(true));\n+      } else {\n+        results.add(cur.getValue().getInfo(pc));\n+      }\n     }\n-    return results;\n+    return new BatchedListEntries\u003cCachePoolInfo\u003e(results, false);\n   }\n\\ No newline at end of file\n",
          "actualSource": "      listCachePools(FSPermissionChecker pc, String prevKey) {\n    final int NUM_PRE_ALLOCATED_ENTRIES \u003d 16;\n    ArrayList\u003cCachePoolInfo\u003e results \u003d \n        new ArrayList\u003cCachePoolInfo\u003e(NUM_PRE_ALLOCATED_ENTRIES);\n    SortedMap\u003cString, CachePool\u003e tailMap \u003d cachePools.tailMap(prevKey, false);\n    int numListed \u003d 0;\n    for (Entry\u003cString, CachePool\u003e cur : tailMap.entrySet()) {\n      if (numListed++ \u003e\u003d maxListCachePoolsResponses) {\n        return new BatchedListEntries\u003cCachePoolInfo\u003e(results, true);\n      }\n      if (pc \u003d\u003d null) {\n        results.add(cur.getValue().getInfo(true));\n      } else {\n        results.add(cur.getValue().getInfo(pc));\n      }\n    }\n    return new BatchedListEntries\u003cCachePoolInfo\u003e(results, false);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
          "extendedDetails": {
            "oldValue": "List\u003cCachePool\u003e",
            "newValue": "BatchedListEntries\u003cCachePoolInfo\u003e"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5163. Miscellaneous cache pool RPC fixes (Contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1520665 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "06/09/13 11:52 AM",
          "commitName": "f41f8b8842c3f26d19f7fa928070c7c07f760e4c",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "04/09/13 11:23 AM",
          "commitNameOld": "d56d0b46e1b82ae068083ddb99872d314684dc82",
          "commitAuthorOld": "Colin McCabe",
          "daysBetweenCommits": 2.02,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,13 +1,18 @@\n-  public synchronized List\u003cCachePool\u003e listCachePools(Long prevKey,\n-      int maxRepliesPerRequest) {\n-    final int MAX_PREALLOCATED_REPLIES \u003d 16;\n-    ArrayList\u003cCachePool\u003e results \u003d \n-        new ArrayList\u003cCachePool\u003e(Math.min(MAX_PREALLOCATED_REPLIES,\n-            maxRepliesPerRequest));\n-    SortedMap\u003cLong, CachePool\u003e tailMap \u003d\n-        cachePoolsById.tailMap(prevKey, false);\n-    for (CachePool pool : tailMap.values()) {\n-      results.add(pool);\n+      listCachePools(FSPermissionChecker pc, String prevKey) {\n+    final int NUM_PRE_ALLOCATED_ENTRIES \u003d 16;\n+    ArrayList\u003cCachePoolInfo\u003e results \u003d \n+        new ArrayList\u003cCachePoolInfo\u003e(NUM_PRE_ALLOCATED_ENTRIES);\n+    SortedMap\u003cString, CachePool\u003e tailMap \u003d cachePools.tailMap(prevKey, false);\n+    int numListed \u003d 0;\n+    for (Entry\u003cString, CachePool\u003e cur : tailMap.entrySet()) {\n+      if (numListed++ \u003e\u003d maxListCachePoolsResponses) {\n+        return new BatchedListEntries\u003cCachePoolInfo\u003e(results, true);\n+      }\n+      if (pc \u003d\u003d null) {\n+        results.add(cur.getValue().getInfo(true));\n+      } else {\n+        results.add(cur.getValue().getInfo(pc));\n+      }\n     }\n-    return results;\n+    return new BatchedListEntries\u003cCachePoolInfo\u003e(results, false);\n   }\n\\ No newline at end of file\n",
          "actualSource": "      listCachePools(FSPermissionChecker pc, String prevKey) {\n    final int NUM_PRE_ALLOCATED_ENTRIES \u003d 16;\n    ArrayList\u003cCachePoolInfo\u003e results \u003d \n        new ArrayList\u003cCachePoolInfo\u003e(NUM_PRE_ALLOCATED_ENTRIES);\n    SortedMap\u003cString, CachePool\u003e tailMap \u003d cachePools.tailMap(prevKey, false);\n    int numListed \u003d 0;\n    for (Entry\u003cString, CachePool\u003e cur : tailMap.entrySet()) {\n      if (numListed++ \u003e\u003d maxListCachePoolsResponses) {\n        return new BatchedListEntries\u003cCachePoolInfo\u003e(results, true);\n      }\n      if (pc \u003d\u003d null) {\n        results.add(cur.getValue().getInfo(true));\n      } else {\n        results.add(cur.getValue().getInfo(pc));\n      }\n    }\n    return new BatchedListEntries\u003cCachePoolInfo\u003e(results, false);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "d56d0b46e1b82ae068083ddb99872d314684dc82": {
      "type": "Ymultichange(Yparameterchange,Yreturntypechange,Ybodychange)",
      "commitMessage": "commit correct version of HDFS-5121\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1520090 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/09/13 11:23 AM",
      "commitName": "d56d0b46e1b82ae068083ddb99872d314684dc82",
      "commitAuthor": "Colin McCabe",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "commit correct version of HDFS-5121\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1520090 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "04/09/13 11:23 AM",
          "commitName": "d56d0b46e1b82ae068083ddb99872d314684dc82",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "03/09/13 1:38 PM",
          "commitNameOld": "97b7267977ef42201e5844df49bc37ec3d10ce16",
          "commitAuthorOld": "Colin McCabe",
          "daysBetweenCommits": 0.91,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,12 +1,13 @@\n-      listCachePools(FSPermissionChecker pc, String prevKey,\n-          int maxRepliesPerRequest) {\n+  public synchronized List\u003cCachePool\u003e listCachePools(Long prevKey,\n+      int maxRepliesPerRequest) {\n     final int MAX_PREALLOCATED_REPLIES \u003d 16;\n-    ArrayList\u003cCachePoolInfo\u003e results \u003d \n-        new ArrayList\u003cCachePoolInfo\u003e(Math.min(MAX_PREALLOCATED_REPLIES,\n+    ArrayList\u003cCachePool\u003e results \u003d \n+        new ArrayList\u003cCachePool\u003e(Math.min(MAX_PREALLOCATED_REPLIES,\n             maxRepliesPerRequest));\n-    SortedMap\u003cString, CachePool\u003e tailMap \u003d cachePools.tailMap(prevKey, false);\n-    for (Entry\u003cString, CachePool\u003e cur : tailMap.entrySet()) {\n-      results.add(cur.getValue().getInfo(pc));\n+    SortedMap\u003cLong, CachePool\u003e tailMap \u003d\n+        cachePoolsById.tailMap(prevKey, false);\n+    for (CachePool pool : tailMap.values()) {\n+      results.add(pool);\n     }\n     return results;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized List\u003cCachePool\u003e listCachePools(Long prevKey,\n      int maxRepliesPerRequest) {\n    final int MAX_PREALLOCATED_REPLIES \u003d 16;\n    ArrayList\u003cCachePool\u003e results \u003d \n        new ArrayList\u003cCachePool\u003e(Math.min(MAX_PREALLOCATED_REPLIES,\n            maxRepliesPerRequest));\n    SortedMap\u003cLong, CachePool\u003e tailMap \u003d\n        cachePoolsById.tailMap(prevKey, false);\n    for (CachePool pool : tailMap.values()) {\n      results.add(pool);\n    }\n    return results;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
          "extendedDetails": {
            "oldValue": "[pc-FSPermissionChecker, prevKey-String, maxRepliesPerRequest-int]",
            "newValue": "[prevKey-Long, maxRepliesPerRequest-int]"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "commit correct version of HDFS-5121\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1520090 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "04/09/13 11:23 AM",
          "commitName": "d56d0b46e1b82ae068083ddb99872d314684dc82",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "03/09/13 1:38 PM",
          "commitNameOld": "97b7267977ef42201e5844df49bc37ec3d10ce16",
          "commitAuthorOld": "Colin McCabe",
          "daysBetweenCommits": 0.91,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,12 +1,13 @@\n-      listCachePools(FSPermissionChecker pc, String prevKey,\n-          int maxRepliesPerRequest) {\n+  public synchronized List\u003cCachePool\u003e listCachePools(Long prevKey,\n+      int maxRepliesPerRequest) {\n     final int MAX_PREALLOCATED_REPLIES \u003d 16;\n-    ArrayList\u003cCachePoolInfo\u003e results \u003d \n-        new ArrayList\u003cCachePoolInfo\u003e(Math.min(MAX_PREALLOCATED_REPLIES,\n+    ArrayList\u003cCachePool\u003e results \u003d \n+        new ArrayList\u003cCachePool\u003e(Math.min(MAX_PREALLOCATED_REPLIES,\n             maxRepliesPerRequest));\n-    SortedMap\u003cString, CachePool\u003e tailMap \u003d cachePools.tailMap(prevKey, false);\n-    for (Entry\u003cString, CachePool\u003e cur : tailMap.entrySet()) {\n-      results.add(cur.getValue().getInfo(pc));\n+    SortedMap\u003cLong, CachePool\u003e tailMap \u003d\n+        cachePoolsById.tailMap(prevKey, false);\n+    for (CachePool pool : tailMap.values()) {\n+      results.add(pool);\n     }\n     return results;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized List\u003cCachePool\u003e listCachePools(Long prevKey,\n      int maxRepliesPerRequest) {\n    final int MAX_PREALLOCATED_REPLIES \u003d 16;\n    ArrayList\u003cCachePool\u003e results \u003d \n        new ArrayList\u003cCachePool\u003e(Math.min(MAX_PREALLOCATED_REPLIES,\n            maxRepliesPerRequest));\n    SortedMap\u003cLong, CachePool\u003e tailMap \u003d\n        cachePoolsById.tailMap(prevKey, false);\n    for (CachePool pool : tailMap.values()) {\n      results.add(pool);\n    }\n    return results;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
          "extendedDetails": {
            "oldValue": "List\u003cCachePoolInfo\u003e",
            "newValue": "List\u003cCachePool\u003e"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "commit correct version of HDFS-5121\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1520090 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "04/09/13 11:23 AM",
          "commitName": "d56d0b46e1b82ae068083ddb99872d314684dc82",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "03/09/13 1:38 PM",
          "commitNameOld": "97b7267977ef42201e5844df49bc37ec3d10ce16",
          "commitAuthorOld": "Colin McCabe",
          "daysBetweenCommits": 0.91,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,12 +1,13 @@\n-      listCachePools(FSPermissionChecker pc, String prevKey,\n-          int maxRepliesPerRequest) {\n+  public synchronized List\u003cCachePool\u003e listCachePools(Long prevKey,\n+      int maxRepliesPerRequest) {\n     final int MAX_PREALLOCATED_REPLIES \u003d 16;\n-    ArrayList\u003cCachePoolInfo\u003e results \u003d \n-        new ArrayList\u003cCachePoolInfo\u003e(Math.min(MAX_PREALLOCATED_REPLIES,\n+    ArrayList\u003cCachePool\u003e results \u003d \n+        new ArrayList\u003cCachePool\u003e(Math.min(MAX_PREALLOCATED_REPLIES,\n             maxRepliesPerRequest));\n-    SortedMap\u003cString, CachePool\u003e tailMap \u003d cachePools.tailMap(prevKey, false);\n-    for (Entry\u003cString, CachePool\u003e cur : tailMap.entrySet()) {\n-      results.add(cur.getValue().getInfo(pc));\n+    SortedMap\u003cLong, CachePool\u003e tailMap \u003d\n+        cachePoolsById.tailMap(prevKey, false);\n+    for (CachePool pool : tailMap.values()) {\n+      results.add(pool);\n     }\n     return results;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized List\u003cCachePool\u003e listCachePools(Long prevKey,\n      int maxRepliesPerRequest) {\n    final int MAX_PREALLOCATED_REPLIES \u003d 16;\n    ArrayList\u003cCachePool\u003e results \u003d \n        new ArrayList\u003cCachePool\u003e(Math.min(MAX_PREALLOCATED_REPLIES,\n            maxRepliesPerRequest));\n    SortedMap\u003cLong, CachePool\u003e tailMap \u003d\n        cachePoolsById.tailMap(prevKey, false);\n    for (CachePool pool : tailMap.values()) {\n      results.add(pool);\n    }\n    return results;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "97b7267977ef42201e5844df49bc37ec3d10ce16": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5121.  Add RPCs for creating and manipulating cache pools.  (Contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1519841 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/09/13 1:38 PM",
      "commitName": "97b7267977ef42201e5844df49bc37ec3d10ce16",
      "commitAuthor": "Colin McCabe",
      "diff": "@@ -0,0 +1,12 @@\n+      listCachePools(FSPermissionChecker pc, String prevKey,\n+          int maxRepliesPerRequest) {\n+    final int MAX_PREALLOCATED_REPLIES \u003d 16;\n+    ArrayList\u003cCachePoolInfo\u003e results \u003d \n+        new ArrayList\u003cCachePoolInfo\u003e(Math.min(MAX_PREALLOCATED_REPLIES,\n+            maxRepliesPerRequest));\n+    SortedMap\u003cString, CachePool\u003e tailMap \u003d cachePools.tailMap(prevKey, false);\n+    for (Entry\u003cString, CachePool\u003e cur : tailMap.entrySet()) {\n+      results.add(cur.getValue().getInfo(pc));\n+    }\n+    return results;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "      listCachePools(FSPermissionChecker pc, String prevKey,\n          int maxRepliesPerRequest) {\n    final int MAX_PREALLOCATED_REPLIES \u003d 16;\n    ArrayList\u003cCachePoolInfo\u003e results \u003d \n        new ArrayList\u003cCachePoolInfo\u003e(Math.min(MAX_PREALLOCATED_REPLIES,\n            maxRepliesPerRequest));\n    SortedMap\u003cString, CachePool\u003e tailMap \u003d cachePools.tailMap(prevKey, false);\n    for (Entry\u003cString, CachePool\u003e cur : tailMap.entrySet()) {\n      results.add(cur.getValue().getInfo(pc));\n    }\n    return results;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java"
    }
  }
}