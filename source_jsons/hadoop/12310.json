{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "VolumeScanner.java",
  "functionName": "run",
  "functionId": "run",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/VolumeScanner.java",
  "functionStartLine": 636,
  "functionEndLine": 683,
  "numCommitsSeen": 39,
  "timeTaken": 7011,
  "changeHistory": [
    "aebb9127bae872835d057e1c6a6e6b3c6a8be6cd",
    "8bb9a5000ed06856abbad268c43ce1d5ad5bdd43",
    "115428176e1d919fe7d54d01b34dfda57d1b3950",
    "6e62a1a6728b1f782f64065424f92b292c3f163a",
    "8aee71d1bca342b92b1856d14a8d4b0f2a4fda31",
    "01db4d2bb2f92ef881830ff20ffe1d1e8b4d06bb",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "aebb9127bae872835d057e1c6a6e6b3c6a8be6cd": "Ybodychange",
    "8bb9a5000ed06856abbad268c43ce1d5ad5bdd43": "Ybodychange",
    "115428176e1d919fe7d54d01b34dfda57d1b3950": "Ybodychange",
    "6e62a1a6728b1f782f64065424f92b292c3f163a": "Ymultichange(Ymovefromfile,Ybodychange)",
    "8aee71d1bca342b92b1856d14a8d4b0f2a4fda31": "Ybodychange",
    "01db4d2bb2f92ef881830ff20ffe1d1e8b4d06bb": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "aebb9127bae872835d057e1c6a6e6b3c6a8be6cd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11160. VolumeScanner reports write-in-progress replicas as corrupt incorrectly. Contributed by Wei-Chiu Chuang and Yongjun Zhang.\n",
      "commitDate": "15/12/16 4:32 PM",
      "commitName": "aebb9127bae872835d057e1c6a6e6b3c6a8be6cd",
      "commitAuthor": "Wei-Chiu Chuang",
      "commitDateOld": "10/10/16 3:30 PM",
      "commitNameOld": "96b12662ea76e3ded4ef13944fc8df206cfb4613",
      "commitAuthorOld": "Lei Xu",
      "daysBetweenCommits": 66.09,
      "commitsBetweenForRepo": 518,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,47 +1,48 @@\n   public void run() {\n     // Record the minute on which the scanner started.\n     this.startMinute \u003d\n         TimeUnit.MINUTES.convert(Time.monotonicNow(), TimeUnit.MILLISECONDS);\n     this.curMinute \u003d startMinute;\n     try {\n       LOG.trace(\"{}: thread starting.\", this);\n       resultHandler.setup(this);\n       try {\n         long timeout \u003d 0;\n         while (true) {\n           ExtendedBlock suspectBlock \u003d null;\n           // Take the lock to check if we should stop, and access the\n           // suspect block list.\n           synchronized (this) {\n             if (stopping) {\n               break;\n             }\n             if (timeout \u003e 0) {\n+              LOG.debug(\"{}: wait for {} milliseconds\", this, timeout);\n               wait(timeout);\n               if (stopping) {\n                 break;\n               }\n             }\n             suspectBlock \u003d popNextSuspectBlock();\n           }\n           timeout \u003d runLoop(suspectBlock);\n         }\n       } catch (InterruptedException e) {\n         // We are exiting because of an InterruptedException,\n         // probably sent by VolumeScanner#shutdown.\n         LOG.trace(\"{} exiting because of InterruptedException.\", this);\n       } catch (Throwable e) {\n         LOG.error(\"{} exiting because of exception \", this, e);\n       }\n       LOG.info(\"{} exiting.\", this);\n       // Save the current position of all block iterators and close them.\n       for (BlockIterator iter : blockIters) {\n         saveBlockIterator(iter);\n         IOUtils.cleanup(null, iter);\n       }\n     } finally {\n       // When the VolumeScanner exits, release the reference we were holding\n       // on the volume.  This will allow the volume to be removed later.\n       IOUtils.cleanup(null, ref);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run() {\n    // Record the minute on which the scanner started.\n    this.startMinute \u003d\n        TimeUnit.MINUTES.convert(Time.monotonicNow(), TimeUnit.MILLISECONDS);\n    this.curMinute \u003d startMinute;\n    try {\n      LOG.trace(\"{}: thread starting.\", this);\n      resultHandler.setup(this);\n      try {\n        long timeout \u003d 0;\n        while (true) {\n          ExtendedBlock suspectBlock \u003d null;\n          // Take the lock to check if we should stop, and access the\n          // suspect block list.\n          synchronized (this) {\n            if (stopping) {\n              break;\n            }\n            if (timeout \u003e 0) {\n              LOG.debug(\"{}: wait for {} milliseconds\", this, timeout);\n              wait(timeout);\n              if (stopping) {\n                break;\n              }\n            }\n            suspectBlock \u003d popNextSuspectBlock();\n          }\n          timeout \u003d runLoop(suspectBlock);\n        }\n      } catch (InterruptedException e) {\n        // We are exiting because of an InterruptedException,\n        // probably sent by VolumeScanner#shutdown.\n        LOG.trace(\"{} exiting because of InterruptedException.\", this);\n      } catch (Throwable e) {\n        LOG.error(\"{} exiting because of exception \", this, e);\n      }\n      LOG.info(\"{} exiting.\", this);\n      // Save the current position of all block iterators and close them.\n      for (BlockIterator iter : blockIters) {\n        saveBlockIterator(iter);\n        IOUtils.cleanup(null, iter);\n      }\n    } finally {\n      // When the VolumeScanner exits, release the reference we were holding\n      // on the volume.  This will allow the volume to be removed later.\n      IOUtils.cleanup(null, ref);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/VolumeScanner.java",
      "extendedDetails": {}
    },
    "8bb9a5000ed06856abbad268c43ce1d5ad5bdd43": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7686. Re-add rapid rescan of possibly corrupt block feature to the block scanner (cmccabe)\n",
      "commitDate": "13/02/15 2:35 PM",
      "commitName": "8bb9a5000ed06856abbad268c43ce1d5ad5bdd43",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "03/02/15 11:05 AM",
      "commitNameOld": "115428176e1d919fe7d54d01b34dfda57d1b3950",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 10.15,
      "commitsBetweenForRepo": 158,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,44 +1,47 @@\n   public void run() {\n     // Record the minute on which the scanner started.\n     this.startMinute \u003d\n         TimeUnit.MINUTES.convert(Time.monotonicNow(), TimeUnit.MILLISECONDS);\n     this.curMinute \u003d startMinute;\n     try {\n       LOG.trace(\"{}: thread starting.\", this);\n       resultHandler.setup(this);\n       try {\n         long timeout \u003d 0;\n         while (true) {\n-          // Take the lock to check if we should stop.\n+          ExtendedBlock suspectBlock \u003d null;\n+          // Take the lock to check if we should stop, and access the\n+          // suspect block list.\n           synchronized (this) {\n             if (stopping) {\n               break;\n             }\n             if (timeout \u003e 0) {\n               wait(timeout);\n               if (stopping) {\n                 break;\n               }\n             }\n+            suspectBlock \u003d popNextSuspectBlock();\n           }\n-          timeout \u003d runLoop();\n+          timeout \u003d runLoop(suspectBlock);\n         }\n       } catch (InterruptedException e) {\n         // We are exiting because of an InterruptedException,\n         // probably sent by VolumeScanner#shutdown.\n         LOG.trace(\"{} exiting because of InterruptedException.\", this);\n       } catch (Throwable e) {\n         LOG.error(\"{} exiting because of exception \", this, e);\n       }\n       LOG.info(\"{} exiting.\", this);\n       // Save the current position of all block iterators and close them.\n       for (BlockIterator iter : blockIters) {\n         saveBlockIterator(iter);\n         IOUtils.cleanup(null, iter);\n       }\n     } finally {\n       // When the VolumeScanner exits, release the reference we were holding\n       // on the volume.  This will allow the volume to be removed later.\n       IOUtils.cleanup(null, ref);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run() {\n    // Record the minute on which the scanner started.\n    this.startMinute \u003d\n        TimeUnit.MINUTES.convert(Time.monotonicNow(), TimeUnit.MILLISECONDS);\n    this.curMinute \u003d startMinute;\n    try {\n      LOG.trace(\"{}: thread starting.\", this);\n      resultHandler.setup(this);\n      try {\n        long timeout \u003d 0;\n        while (true) {\n          ExtendedBlock suspectBlock \u003d null;\n          // Take the lock to check if we should stop, and access the\n          // suspect block list.\n          synchronized (this) {\n            if (stopping) {\n              break;\n            }\n            if (timeout \u003e 0) {\n              wait(timeout);\n              if (stopping) {\n                break;\n              }\n            }\n            suspectBlock \u003d popNextSuspectBlock();\n          }\n          timeout \u003d runLoop(suspectBlock);\n        }\n      } catch (InterruptedException e) {\n        // We are exiting because of an InterruptedException,\n        // probably sent by VolumeScanner#shutdown.\n        LOG.trace(\"{} exiting because of InterruptedException.\", this);\n      } catch (Throwable e) {\n        LOG.error(\"{} exiting because of exception \", this, e);\n      }\n      LOG.info(\"{} exiting.\", this);\n      // Save the current position of all block iterators and close them.\n      for (BlockIterator iter : blockIters) {\n        saveBlockIterator(iter);\n        IOUtils.cleanup(null, iter);\n      }\n    } finally {\n      // When the VolumeScanner exits, release the reference we were holding\n      // on the volume.  This will allow the volume to be removed later.\n      IOUtils.cleanup(null, ref);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/VolumeScanner.java",
      "extendedDetails": {}
    },
    "115428176e1d919fe7d54d01b34dfda57d1b3950": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7721. The HDFS BlockScanner may run fast during the first hour (cmccabe)\n",
      "commitDate": "03/02/15 11:05 AM",
      "commitName": "115428176e1d919fe7d54d01b34dfda57d1b3950",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "21/01/15 7:00 PM",
      "commitNameOld": "6e62a1a6728b1f782f64065424f92b292c3f163a",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 12.67,
      "commitsBetweenForRepo": 89,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,40 +1,44 @@\n   public void run() {\n+    // Record the minute on which the scanner started.\n+    this.startMinute \u003d\n+        TimeUnit.MINUTES.convert(Time.monotonicNow(), TimeUnit.MILLISECONDS);\n+    this.curMinute \u003d startMinute;\n     try {\n       LOG.trace(\"{}: thread starting.\", this);\n       resultHandler.setup(this);\n       try {\n         long timeout \u003d 0;\n         while (true) {\n           // Take the lock to check if we should stop.\n           synchronized (this) {\n             if (stopping) {\n               break;\n             }\n             if (timeout \u003e 0) {\n               wait(timeout);\n               if (stopping) {\n                 break;\n               }\n             }\n           }\n           timeout \u003d runLoop();\n         }\n       } catch (InterruptedException e) {\n         // We are exiting because of an InterruptedException,\n         // probably sent by VolumeScanner#shutdown.\n         LOG.trace(\"{} exiting because of InterruptedException.\", this);\n       } catch (Throwable e) {\n         LOG.error(\"{} exiting because of exception \", this, e);\n       }\n       LOG.info(\"{} exiting.\", this);\n       // Save the current position of all block iterators and close them.\n       for (BlockIterator iter : blockIters) {\n         saveBlockIterator(iter);\n         IOUtils.cleanup(null, iter);\n       }\n     } finally {\n       // When the VolumeScanner exits, release the reference we were holding\n       // on the volume.  This will allow the volume to be removed later.\n       IOUtils.cleanup(null, ref);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run() {\n    // Record the minute on which the scanner started.\n    this.startMinute \u003d\n        TimeUnit.MINUTES.convert(Time.monotonicNow(), TimeUnit.MILLISECONDS);\n    this.curMinute \u003d startMinute;\n    try {\n      LOG.trace(\"{}: thread starting.\", this);\n      resultHandler.setup(this);\n      try {\n        long timeout \u003d 0;\n        while (true) {\n          // Take the lock to check if we should stop.\n          synchronized (this) {\n            if (stopping) {\n              break;\n            }\n            if (timeout \u003e 0) {\n              wait(timeout);\n              if (stopping) {\n                break;\n              }\n            }\n          }\n          timeout \u003d runLoop();\n        }\n      } catch (InterruptedException e) {\n        // We are exiting because of an InterruptedException,\n        // probably sent by VolumeScanner#shutdown.\n        LOG.trace(\"{} exiting because of InterruptedException.\", this);\n      } catch (Throwable e) {\n        LOG.error(\"{} exiting because of exception \", this, e);\n      }\n      LOG.info(\"{} exiting.\", this);\n      // Save the current position of all block iterators and close them.\n      for (BlockIterator iter : blockIters) {\n        saveBlockIterator(iter);\n        IOUtils.cleanup(null, iter);\n      }\n    } finally {\n      // When the VolumeScanner exits, release the reference we were holding\n      // on the volume.  This will allow the volume to be removed later.\n      IOUtils.cleanup(null, ref);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/VolumeScanner.java",
      "extendedDetails": {}
    },
    "6e62a1a6728b1f782f64065424f92b292c3f163a": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange)",
      "commitMessage": "HDFS-7430. Refactor the BlockScanner to use O(1) memory and use multiple threads (cmccabe)\n",
      "commitDate": "21/01/15 7:00 PM",
      "commitName": "6e62a1a6728b1f782f64065424f92b292c3f163a",
      "commitAuthor": "Colin Patrick Mccabe",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-7430. Refactor the BlockScanner to use O(1) memory and use multiple threads (cmccabe)\n",
          "commitDate": "21/01/15 7:00 PM",
          "commitName": "6e62a1a6728b1f782f64065424f92b292c3f163a",
          "commitAuthor": "Colin Patrick Mccabe",
          "commitDateOld": "21/01/15 6:42 PM",
          "commitNameOld": "a003f71cacd35834a1abbc2ffb5446a1166caf73",
          "commitAuthorOld": "Gera Shegalov",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,38 +1,40 @@\n   public void run() {\n-    String currentBpId \u003d \"\";\n-    boolean firstRun \u003d true;\n-    while (datanode.shouldRun \u0026\u0026 !Thread.interrupted()) {\n-      //Sleep everytime except in the first iteration.\n-      if (!firstRun) {\n-        try {\n-          Thread.sleep(SLEEP_PERIOD_MS);\n-        } catch (InterruptedException ex) {\n-          // Interrupt itself again to set the interrupt status\n-          blockScannerThread.interrupt();\n-          continue;\n+    try {\n+      LOG.trace(\"{}: thread starting.\", this);\n+      resultHandler.setup(this);\n+      try {\n+        long timeout \u003d 0;\n+        while (true) {\n+          // Take the lock to check if we should stop.\n+          synchronized (this) {\n+            if (stopping) {\n+              break;\n+            }\n+            if (timeout \u003e 0) {\n+              wait(timeout);\n+              if (stopping) {\n+                break;\n+              }\n+            }\n+          }\n+          timeout \u003d runLoop();\n         }\n-      } else {\n-        firstRun \u003d false;\n+      } catch (InterruptedException e) {\n+        // We are exiting because of an InterruptedException,\n+        // probably sent by VolumeScanner#shutdown.\n+        LOG.trace(\"{} exiting because of InterruptedException.\", this);\n+      } catch (Throwable e) {\n+        LOG.error(\"{} exiting because of exception \", this, e);\n       }\n-      \n-      BlockPoolSliceScanner bpScanner \u003d getNextBPScanner(currentBpId);\n-      if (bpScanner \u003d\u003d null) {\n-        // Possible if thread is interrupted\n-        continue;\n+      LOG.info(\"{} exiting.\", this);\n+      // Save the current position of all block iterators and close them.\n+      for (BlockIterator iter : blockIters) {\n+        saveBlockIterator(iter);\n+        IOUtils.cleanup(null, iter);\n       }\n-      currentBpId \u003d bpScanner.getBlockPoolId();\n-      // If BPOfferService for this pool is not alive, don\u0027t process it\n-      if (!datanode.isBPServiceAlive(currentBpId)) {\n-        LOG.warn(\"Block Pool \" + currentBpId + \" is not alive\");\n-        // Remove in case BP service died abruptly without proper shutdown\n-        removeBlockPool(currentBpId);\n-        continue;\n-      }\n-      bpScanner.scanBlockPoolSlice();\n-    }\n-\n-    // Call shutdown for each allocated BlockPoolSliceScanner.\n-    for (BlockPoolSliceScanner bpss: blockPoolScannerMap.values()) {\n-      bpss.shutdown();\n+    } finally {\n+      // When the VolumeScanner exits, release the reference we were holding\n+      // on the volume.  This will allow the volume to be removed later.\n+      IOUtils.cleanup(null, ref);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void run() {\n    try {\n      LOG.trace(\"{}: thread starting.\", this);\n      resultHandler.setup(this);\n      try {\n        long timeout \u003d 0;\n        while (true) {\n          // Take the lock to check if we should stop.\n          synchronized (this) {\n            if (stopping) {\n              break;\n            }\n            if (timeout \u003e 0) {\n              wait(timeout);\n              if (stopping) {\n                break;\n              }\n            }\n          }\n          timeout \u003d runLoop();\n        }\n      } catch (InterruptedException e) {\n        // We are exiting because of an InterruptedException,\n        // probably sent by VolumeScanner#shutdown.\n        LOG.trace(\"{} exiting because of InterruptedException.\", this);\n      } catch (Throwable e) {\n        LOG.error(\"{} exiting because of exception \", this, e);\n      }\n      LOG.info(\"{} exiting.\", this);\n      // Save the current position of all block iterators and close them.\n      for (BlockIterator iter : blockIters) {\n        saveBlockIterator(iter);\n        IOUtils.cleanup(null, iter);\n      }\n    } finally {\n      // When the VolumeScanner exits, release the reference we were holding\n      // on the volume.  This will allow the volume to be removed later.\n      IOUtils.cleanup(null, ref);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/VolumeScanner.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataBlockScanner.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/VolumeScanner.java",
            "oldMethodName": "run",
            "newMethodName": "run"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7430. Refactor the BlockScanner to use O(1) memory and use multiple threads (cmccabe)\n",
          "commitDate": "21/01/15 7:00 PM",
          "commitName": "6e62a1a6728b1f782f64065424f92b292c3f163a",
          "commitAuthor": "Colin Patrick Mccabe",
          "commitDateOld": "21/01/15 6:42 PM",
          "commitNameOld": "a003f71cacd35834a1abbc2ffb5446a1166caf73",
          "commitAuthorOld": "Gera Shegalov",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,38 +1,40 @@\n   public void run() {\n-    String currentBpId \u003d \"\";\n-    boolean firstRun \u003d true;\n-    while (datanode.shouldRun \u0026\u0026 !Thread.interrupted()) {\n-      //Sleep everytime except in the first iteration.\n-      if (!firstRun) {\n-        try {\n-          Thread.sleep(SLEEP_PERIOD_MS);\n-        } catch (InterruptedException ex) {\n-          // Interrupt itself again to set the interrupt status\n-          blockScannerThread.interrupt();\n-          continue;\n+    try {\n+      LOG.trace(\"{}: thread starting.\", this);\n+      resultHandler.setup(this);\n+      try {\n+        long timeout \u003d 0;\n+        while (true) {\n+          // Take the lock to check if we should stop.\n+          synchronized (this) {\n+            if (stopping) {\n+              break;\n+            }\n+            if (timeout \u003e 0) {\n+              wait(timeout);\n+              if (stopping) {\n+                break;\n+              }\n+            }\n+          }\n+          timeout \u003d runLoop();\n         }\n-      } else {\n-        firstRun \u003d false;\n+      } catch (InterruptedException e) {\n+        // We are exiting because of an InterruptedException,\n+        // probably sent by VolumeScanner#shutdown.\n+        LOG.trace(\"{} exiting because of InterruptedException.\", this);\n+      } catch (Throwable e) {\n+        LOG.error(\"{} exiting because of exception \", this, e);\n       }\n-      \n-      BlockPoolSliceScanner bpScanner \u003d getNextBPScanner(currentBpId);\n-      if (bpScanner \u003d\u003d null) {\n-        // Possible if thread is interrupted\n-        continue;\n+      LOG.info(\"{} exiting.\", this);\n+      // Save the current position of all block iterators and close them.\n+      for (BlockIterator iter : blockIters) {\n+        saveBlockIterator(iter);\n+        IOUtils.cleanup(null, iter);\n       }\n-      currentBpId \u003d bpScanner.getBlockPoolId();\n-      // If BPOfferService for this pool is not alive, don\u0027t process it\n-      if (!datanode.isBPServiceAlive(currentBpId)) {\n-        LOG.warn(\"Block Pool \" + currentBpId + \" is not alive\");\n-        // Remove in case BP service died abruptly without proper shutdown\n-        removeBlockPool(currentBpId);\n-        continue;\n-      }\n-      bpScanner.scanBlockPoolSlice();\n-    }\n-\n-    // Call shutdown for each allocated BlockPoolSliceScanner.\n-    for (BlockPoolSliceScanner bpss: blockPoolScannerMap.values()) {\n-      bpss.shutdown();\n+    } finally {\n+      // When the VolumeScanner exits, release the reference we were holding\n+      // on the volume.  This will allow the volume to be removed later.\n+      IOUtils.cleanup(null, ref);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void run() {\n    try {\n      LOG.trace(\"{}: thread starting.\", this);\n      resultHandler.setup(this);\n      try {\n        long timeout \u003d 0;\n        while (true) {\n          // Take the lock to check if we should stop.\n          synchronized (this) {\n            if (stopping) {\n              break;\n            }\n            if (timeout \u003e 0) {\n              wait(timeout);\n              if (stopping) {\n                break;\n              }\n            }\n          }\n          timeout \u003d runLoop();\n        }\n      } catch (InterruptedException e) {\n        // We are exiting because of an InterruptedException,\n        // probably sent by VolumeScanner#shutdown.\n        LOG.trace(\"{} exiting because of InterruptedException.\", this);\n      } catch (Throwable e) {\n        LOG.error(\"{} exiting because of exception \", this, e);\n      }\n      LOG.info(\"{} exiting.\", this);\n      // Save the current position of all block iterators and close them.\n      for (BlockIterator iter : blockIters) {\n        saveBlockIterator(iter);\n        IOUtils.cleanup(null, iter);\n      }\n    } finally {\n      // When the VolumeScanner exits, release the reference we were holding\n      // on the volume.  This will allow the volume to be removed later.\n      IOUtils.cleanup(null, ref);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/VolumeScanner.java",
          "extendedDetails": {}
        }
      ]
    },
    "8aee71d1bca342b92b1856d14a8d4b0f2a4fda31": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4274. BlockPoolSliceScanner does not close verification log during shutdown. Contributed by Chris Nauroth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1422276 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "15/12/12 7:31 AM",
      "commitName": "8aee71d1bca342b92b1856d14a8d4b0f2a4fda31",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "12/09/12 11:36 AM",
      "commitNameOld": "2ba149f85c94d1f2a1d8833b8b9c3b36c5600ce2",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 93.87,
      "commitsBetweenForRepo": 469,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,33 +1,38 @@\n   public void run() {\n     String currentBpId \u003d \"\";\n     boolean firstRun \u003d true;\n     while (datanode.shouldRun \u0026\u0026 !Thread.interrupted()) {\n       //Sleep everytime except in the first iteration.\n       if (!firstRun) {\n         try {\n           Thread.sleep(SLEEP_PERIOD_MS);\n         } catch (InterruptedException ex) {\n           // Interrupt itself again to set the interrupt status\n           blockScannerThread.interrupt();\n           continue;\n         }\n       } else {\n         firstRun \u003d false;\n       }\n       \n       BlockPoolSliceScanner bpScanner \u003d getNextBPScanner(currentBpId);\n       if (bpScanner \u003d\u003d null) {\n         // Possible if thread is interrupted\n         continue;\n       }\n       currentBpId \u003d bpScanner.getBlockPoolId();\n       // If BPOfferService for this pool is not alive, don\u0027t process it\n       if (!datanode.isBPServiceAlive(currentBpId)) {\n         LOG.warn(\"Block Pool \" + currentBpId + \" is not alive\");\n         // Remove in case BP service died abruptly without proper shutdown\n         removeBlockPool(currentBpId);\n         continue;\n       }\n       bpScanner.scanBlockPoolSlice();\n     }\n+\n+    // Call shutdown for each allocated BlockPoolSliceScanner.\n+    for (BlockPoolSliceScanner bpss: blockPoolScannerMap.values()) {\n+      bpss.shutdown();\n+    }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run() {\n    String currentBpId \u003d \"\";\n    boolean firstRun \u003d true;\n    while (datanode.shouldRun \u0026\u0026 !Thread.interrupted()) {\n      //Sleep everytime except in the first iteration.\n      if (!firstRun) {\n        try {\n          Thread.sleep(SLEEP_PERIOD_MS);\n        } catch (InterruptedException ex) {\n          // Interrupt itself again to set the interrupt status\n          blockScannerThread.interrupt();\n          continue;\n        }\n      } else {\n        firstRun \u003d false;\n      }\n      \n      BlockPoolSliceScanner bpScanner \u003d getNextBPScanner(currentBpId);\n      if (bpScanner \u003d\u003d null) {\n        // Possible if thread is interrupted\n        continue;\n      }\n      currentBpId \u003d bpScanner.getBlockPoolId();\n      // If BPOfferService for this pool is not alive, don\u0027t process it\n      if (!datanode.isBPServiceAlive(currentBpId)) {\n        LOG.warn(\"Block Pool \" + currentBpId + \" is not alive\");\n        // Remove in case BP service died abruptly without proper shutdown\n        removeBlockPool(currentBpId);\n        continue;\n      }\n      bpScanner.scanBlockPoolSlice();\n    }\n\n    // Call shutdown for each allocated BlockPoolSliceScanner.\n    for (BlockPoolSliceScanner bpss: blockPoolScannerMap.values()) {\n      bpss.shutdown();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataBlockScanner.java",
      "extendedDetails": {}
    },
    "01db4d2bb2f92ef881830ff20ffe1d1e8b4d06bb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3828. Block Scanner rescans blocks too frequently. Contributed by Andy Isaacson\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1381472 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "05/09/12 11:19 PM",
      "commitName": "01db4d2bb2f92ef881830ff20ffe1d1e8b4d06bb",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "21/08/12 2:18 PM",
      "commitNameOld": "6c0ccb5989c2053f5a1ebab0dd9fdb7b4019fda8",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 15.38,
      "commitsBetweenForRepo": 103,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,33 +1,33 @@\n   public void run() {\n     String currentBpId \u003d \"\";\n     boolean firstRun \u003d true;\n     while (datanode.shouldRun \u0026\u0026 !Thread.interrupted()) {\n-      //Sleep everytime except in the first interation.\n+      //Sleep everytime except in the first iteration.\n       if (!firstRun) {\n         try {\n-          Thread.sleep(5000);\n+          Thread.sleep(SLEEP_PERIOD_MS);\n         } catch (InterruptedException ex) {\n           // Interrupt itself again to set the interrupt status\n           blockScannerThread.interrupt();\n           continue;\n         }\n       } else {\n         firstRun \u003d false;\n       }\n       \n       BlockPoolSliceScanner bpScanner \u003d getNextBPScanner(currentBpId);\n       if (bpScanner \u003d\u003d null) {\n         // Possible if thread is interrupted\n         continue;\n       }\n       currentBpId \u003d bpScanner.getBlockPoolId();\n       // If BPOfferService for this pool is not alive, don\u0027t process it\n       if (!datanode.isBPServiceAlive(currentBpId)) {\n         LOG.warn(\"Block Pool \" + currentBpId + \" is not alive\");\n         // Remove in case BP service died abruptly without proper shutdown\n         removeBlockPool(currentBpId);\n         continue;\n       }\n       bpScanner.scanBlockPoolSlice();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run() {\n    String currentBpId \u003d \"\";\n    boolean firstRun \u003d true;\n    while (datanode.shouldRun \u0026\u0026 !Thread.interrupted()) {\n      //Sleep everytime except in the first iteration.\n      if (!firstRun) {\n        try {\n          Thread.sleep(SLEEP_PERIOD_MS);\n        } catch (InterruptedException ex) {\n          // Interrupt itself again to set the interrupt status\n          blockScannerThread.interrupt();\n          continue;\n        }\n      } else {\n        firstRun \u003d false;\n      }\n      \n      BlockPoolSliceScanner bpScanner \u003d getNextBPScanner(currentBpId);\n      if (bpScanner \u003d\u003d null) {\n        // Possible if thread is interrupted\n        continue;\n      }\n      currentBpId \u003d bpScanner.getBlockPoolId();\n      // If BPOfferService for this pool is not alive, don\u0027t process it\n      if (!datanode.isBPServiceAlive(currentBpId)) {\n        LOG.warn(\"Block Pool \" + currentBpId + \" is not alive\");\n        // Remove in case BP service died abruptly without proper shutdown\n        removeBlockPool(currentBpId);\n        continue;\n      }\n      bpScanner.scanBlockPoolSlice();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataBlockScanner.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void run() {\n    String currentBpId \u003d \"\";\n    boolean firstRun \u003d true;\n    while (datanode.shouldRun \u0026\u0026 !Thread.interrupted()) {\n      //Sleep everytime except in the first interation.\n      if (!firstRun) {\n        try {\n          Thread.sleep(5000);\n        } catch (InterruptedException ex) {\n          // Interrupt itself again to set the interrupt status\n          blockScannerThread.interrupt();\n          continue;\n        }\n      } else {\n        firstRun \u003d false;\n      }\n      \n      BlockPoolSliceScanner bpScanner \u003d getNextBPScanner(currentBpId);\n      if (bpScanner \u003d\u003d null) {\n        // Possible if thread is interrupted\n        continue;\n      }\n      currentBpId \u003d bpScanner.getBlockPoolId();\n      // If BPOfferService for this pool is not alive, don\u0027t process it\n      if (!datanode.isBPServiceAlive(currentBpId)) {\n        LOG.warn(\"Block Pool \" + currentBpId + \" is not alive\");\n        // Remove in case BP service died abruptly without proper shutdown\n        removeBlockPool(currentBpId);\n        continue;\n      }\n      bpScanner.scanBlockPoolSlice();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataBlockScanner.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataBlockScanner.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataBlockScanner.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void run() {\n    String currentBpId \u003d \"\";\n    boolean firstRun \u003d true;\n    while (datanode.shouldRun \u0026\u0026 !Thread.interrupted()) {\n      //Sleep everytime except in the first interation.\n      if (!firstRun) {\n        try {\n          Thread.sleep(5000);\n        } catch (InterruptedException ex) {\n          // Interrupt itself again to set the interrupt status\n          blockScannerThread.interrupt();\n          continue;\n        }\n      } else {\n        firstRun \u003d false;\n      }\n      \n      BlockPoolSliceScanner bpScanner \u003d getNextBPScanner(currentBpId);\n      if (bpScanner \u003d\u003d null) {\n        // Possible if thread is interrupted\n        continue;\n      }\n      currentBpId \u003d bpScanner.getBlockPoolId();\n      // If BPOfferService for this pool is not alive, don\u0027t process it\n      if (!datanode.isBPServiceAlive(currentBpId)) {\n        LOG.warn(\"Block Pool \" + currentBpId + \" is not alive\");\n        // Remove in case BP service died abruptly without proper shutdown\n        removeBlockPool(currentBpId);\n        continue;\n      }\n      bpScanner.scanBlockPoolSlice();\n    }\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataBlockScanner.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/datanode/DataBlockScanner.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataBlockScanner.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,33 @@\n+  public void run() {\n+    String currentBpId \u003d \"\";\n+    boolean firstRun \u003d true;\n+    while (datanode.shouldRun \u0026\u0026 !Thread.interrupted()) {\n+      //Sleep everytime except in the first interation.\n+      if (!firstRun) {\n+        try {\n+          Thread.sleep(5000);\n+        } catch (InterruptedException ex) {\n+          // Interrupt itself again to set the interrupt status\n+          blockScannerThread.interrupt();\n+          continue;\n+        }\n+      } else {\n+        firstRun \u003d false;\n+      }\n+      \n+      BlockPoolSliceScanner bpScanner \u003d getNextBPScanner(currentBpId);\n+      if (bpScanner \u003d\u003d null) {\n+        // Possible if thread is interrupted\n+        continue;\n+      }\n+      currentBpId \u003d bpScanner.getBlockPoolId();\n+      // If BPOfferService for this pool is not alive, don\u0027t process it\n+      if (!datanode.isBPServiceAlive(currentBpId)) {\n+        LOG.warn(\"Block Pool \" + currentBpId + \" is not alive\");\n+        // Remove in case BP service died abruptly without proper shutdown\n+        removeBlockPool(currentBpId);\n+        continue;\n+      }\n+      bpScanner.scanBlockPoolSlice();\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void run() {\n    String currentBpId \u003d \"\";\n    boolean firstRun \u003d true;\n    while (datanode.shouldRun \u0026\u0026 !Thread.interrupted()) {\n      //Sleep everytime except in the first interation.\n      if (!firstRun) {\n        try {\n          Thread.sleep(5000);\n        } catch (InterruptedException ex) {\n          // Interrupt itself again to set the interrupt status\n          blockScannerThread.interrupt();\n          continue;\n        }\n      } else {\n        firstRun \u003d false;\n      }\n      \n      BlockPoolSliceScanner bpScanner \u003d getNextBPScanner(currentBpId);\n      if (bpScanner \u003d\u003d null) {\n        // Possible if thread is interrupted\n        continue;\n      }\n      currentBpId \u003d bpScanner.getBlockPoolId();\n      // If BPOfferService for this pool is not alive, don\u0027t process it\n      if (!datanode.isBPServiceAlive(currentBpId)) {\n        LOG.warn(\"Block Pool \" + currentBpId + \" is not alive\");\n        // Remove in case BP service died abruptly without proper shutdown\n        removeBlockPool(currentBpId);\n        continue;\n      }\n      bpScanner.scanBlockPoolSlice();\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/datanode/DataBlockScanner.java"
    }
  }
}