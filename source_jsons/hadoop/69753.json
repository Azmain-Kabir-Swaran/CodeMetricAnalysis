{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "SharedKeyCredentials.java",
  "functionName": "parseQueryString",
  "functionId": "parseQueryString___parseString-String",
  "sourceFilePath": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SharedKeyCredentials.java",
  "functionStartLine": 354,
  "functionEndLine": 397,
  "numCommitsSeen": 4,
  "timeTaken": 921,
  "changeHistory": [
    "ce03a93f78c4d97ccb48a3906fcd77ad0ac756be",
    "f044deedbbfee0812316d587139cb828f27172e9"
  ],
  "changeHistoryShort": {
    "ce03a93f78c4d97ccb48a3906fcd77ad0ac756be": "Ybodychange",
    "f044deedbbfee0812316d587139cb828f27172e9": "Yintroduced"
  },
  "changeHistoryDetails": {
    "ce03a93f78c4d97ccb48a3906fcd77ad0ac756be": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-15446. ABFS: tune imports \u0026 javadocs; stabilise tests.\nContributed by Steve Loughran and Da Zhou.\n",
      "commitDate": "17/09/18 12:54 PM",
      "commitName": "ce03a93f78c4d97ccb48a3906fcd77ad0ac756be",
      "commitAuthor": "Thomas Marquardt",
      "commitDateOld": "17/09/18 12:54 PM",
      "commitNameOld": "f044deedbbfee0812316d587139cb828f27172e9",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,44 +1,44 @@\n   private static HashMap\u003cString, String[]\u003e parseQueryString(String parseString) throws UnsupportedEncodingException {\n-    final HashMap\u003cString, String[]\u003e retVals \u003d new HashMap\u003cString, String[]\u003e();\n+    final HashMap\u003cString, String[]\u003e retVals \u003d new HashMap\u003c\u003e();\n     if (parseString \u003d\u003d null || parseString.isEmpty()) {\n       return retVals;\n     }\n \n     // 1. Remove ? if present\n     final int queryDex \u003d parseString.indexOf(AbfsHttpConstants.QUESTION_MARK);\n     if (queryDex \u003e\u003d 0 \u0026\u0026 parseString.length() \u003e 0) {\n       parseString \u003d parseString.substring(queryDex + 1);\n     }\n \n     // 2. split name value pairs by splitting on the \u0027c\u0026\u0027 character\n     final String[] valuePairs \u003d parseString.contains(AbfsHttpConstants.AND_MARK)\n             ? parseString.split(AbfsHttpConstants.AND_MARK)\n             : parseString.split(AbfsHttpConstants.SEMICOLON);\n \n     // 3. for each field value pair parse into appropriate map entries\n     for (int m \u003d 0; m \u003c valuePairs.length; m++) {\n       final int equalDex \u003d valuePairs[m].indexOf(AbfsHttpConstants.EQUAL);\n \n       if (equalDex \u003c 0 || equalDex \u003d\u003d valuePairs[m].length() - 1) {\n         continue;\n       }\n \n       String key \u003d valuePairs[m].substring(0, equalDex);\n       String value \u003d valuePairs[m].substring(equalDex + 1);\n \n       key \u003d safeDecode(key);\n       value \u003d safeDecode(value);\n \n       // 3.1 add to map\n       String[] values \u003d retVals.get(key);\n \n       if (values \u003d\u003d null) {\n         values \u003d new String[]{value};\n         if (!value.equals(\"\")) {\n           retVals.put(key, values);\n         }\n       }\n     }\n \n     return retVals;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static HashMap\u003cString, String[]\u003e parseQueryString(String parseString) throws UnsupportedEncodingException {\n    final HashMap\u003cString, String[]\u003e retVals \u003d new HashMap\u003c\u003e();\n    if (parseString \u003d\u003d null || parseString.isEmpty()) {\n      return retVals;\n    }\n\n    // 1. Remove ? if present\n    final int queryDex \u003d parseString.indexOf(AbfsHttpConstants.QUESTION_MARK);\n    if (queryDex \u003e\u003d 0 \u0026\u0026 parseString.length() \u003e 0) {\n      parseString \u003d parseString.substring(queryDex + 1);\n    }\n\n    // 2. split name value pairs by splitting on the \u0027c\u0026\u0027 character\n    final String[] valuePairs \u003d parseString.contains(AbfsHttpConstants.AND_MARK)\n            ? parseString.split(AbfsHttpConstants.AND_MARK)\n            : parseString.split(AbfsHttpConstants.SEMICOLON);\n\n    // 3. for each field value pair parse into appropriate map entries\n    for (int m \u003d 0; m \u003c valuePairs.length; m++) {\n      final int equalDex \u003d valuePairs[m].indexOf(AbfsHttpConstants.EQUAL);\n\n      if (equalDex \u003c 0 || equalDex \u003d\u003d valuePairs[m].length() - 1) {\n        continue;\n      }\n\n      String key \u003d valuePairs[m].substring(0, equalDex);\n      String value \u003d valuePairs[m].substring(equalDex + 1);\n\n      key \u003d safeDecode(key);\n      value \u003d safeDecode(value);\n\n      // 3.1 add to map\n      String[] values \u003d retVals.get(key);\n\n      if (values \u003d\u003d null) {\n        values \u003d new String[]{value};\n        if (!value.equals(\"\")) {\n          retVals.put(key, values);\n        }\n      }\n    }\n\n    return retVals;\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SharedKeyCredentials.java",
      "extendedDetails": {}
    },
    "f044deedbbfee0812316d587139cb828f27172e9": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-15407. HADOOP-15540. Support Windows Azure Storage - Blob file system \"ABFS\" in Hadoop: Core Commit.\n\nContributed by Shane Mainali, Thomas Marquardt, Zichen Sun, Georgi Chalakov, Esfandiar Manii, Amit Singh, Dana Kaban, Da Zhou, Junhua Gu, Saher Ahwal, Saurabh Pant, James Baker, Shaoyu Zhang, Lawrence Chen, Kevin Chen and Steve Loughran\n",
      "commitDate": "17/09/18 12:54 PM",
      "commitName": "f044deedbbfee0812316d587139cb828f27172e9",
      "commitAuthor": "Steve Loughran",
      "diff": "@@ -0,0 +1,44 @@\n+  private static HashMap\u003cString, String[]\u003e parseQueryString(String parseString) throws UnsupportedEncodingException {\n+    final HashMap\u003cString, String[]\u003e retVals \u003d new HashMap\u003cString, String[]\u003e();\n+    if (parseString \u003d\u003d null || parseString.isEmpty()) {\n+      return retVals;\n+    }\n+\n+    // 1. Remove ? if present\n+    final int queryDex \u003d parseString.indexOf(AbfsHttpConstants.QUESTION_MARK);\n+    if (queryDex \u003e\u003d 0 \u0026\u0026 parseString.length() \u003e 0) {\n+      parseString \u003d parseString.substring(queryDex + 1);\n+    }\n+\n+    // 2. split name value pairs by splitting on the \u0027c\u0026\u0027 character\n+    final String[] valuePairs \u003d parseString.contains(AbfsHttpConstants.AND_MARK)\n+            ? parseString.split(AbfsHttpConstants.AND_MARK)\n+            : parseString.split(AbfsHttpConstants.SEMICOLON);\n+\n+    // 3. for each field value pair parse into appropriate map entries\n+    for (int m \u003d 0; m \u003c valuePairs.length; m++) {\n+      final int equalDex \u003d valuePairs[m].indexOf(AbfsHttpConstants.EQUAL);\n+\n+      if (equalDex \u003c 0 || equalDex \u003d\u003d valuePairs[m].length() - 1) {\n+        continue;\n+      }\n+\n+      String key \u003d valuePairs[m].substring(0, equalDex);\n+      String value \u003d valuePairs[m].substring(equalDex + 1);\n+\n+      key \u003d safeDecode(key);\n+      value \u003d safeDecode(value);\n+\n+      // 3.1 add to map\n+      String[] values \u003d retVals.get(key);\n+\n+      if (values \u003d\u003d null) {\n+        values \u003d new String[]{value};\n+        if (!value.equals(\"\")) {\n+          retVals.put(key, values);\n+        }\n+      }\n+    }\n+\n+    return retVals;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private static HashMap\u003cString, String[]\u003e parseQueryString(String parseString) throws UnsupportedEncodingException {\n    final HashMap\u003cString, String[]\u003e retVals \u003d new HashMap\u003cString, String[]\u003e();\n    if (parseString \u003d\u003d null || parseString.isEmpty()) {\n      return retVals;\n    }\n\n    // 1. Remove ? if present\n    final int queryDex \u003d parseString.indexOf(AbfsHttpConstants.QUESTION_MARK);\n    if (queryDex \u003e\u003d 0 \u0026\u0026 parseString.length() \u003e 0) {\n      parseString \u003d parseString.substring(queryDex + 1);\n    }\n\n    // 2. split name value pairs by splitting on the \u0027c\u0026\u0027 character\n    final String[] valuePairs \u003d parseString.contains(AbfsHttpConstants.AND_MARK)\n            ? parseString.split(AbfsHttpConstants.AND_MARK)\n            : parseString.split(AbfsHttpConstants.SEMICOLON);\n\n    // 3. for each field value pair parse into appropriate map entries\n    for (int m \u003d 0; m \u003c valuePairs.length; m++) {\n      final int equalDex \u003d valuePairs[m].indexOf(AbfsHttpConstants.EQUAL);\n\n      if (equalDex \u003c 0 || equalDex \u003d\u003d valuePairs[m].length() - 1) {\n        continue;\n      }\n\n      String key \u003d valuePairs[m].substring(0, equalDex);\n      String value \u003d valuePairs[m].substring(equalDex + 1);\n\n      key \u003d safeDecode(key);\n      value \u003d safeDecode(value);\n\n      // 3.1 add to map\n      String[] values \u003d retVals.get(key);\n\n      if (values \u003d\u003d null) {\n        values \u003d new String[]{value};\n        if (!value.equals(\"\")) {\n          retVals.put(key, values);\n        }\n      }\n    }\n\n    return retVals;\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SharedKeyCredentials.java"
    }
  }
}