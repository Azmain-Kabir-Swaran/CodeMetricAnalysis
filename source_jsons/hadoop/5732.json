{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSDirMkdirOp.java",
  "functionName": "mkdirs",
  "functionId": "mkdirs___fsn-FSNamesystem__pc-FSPermissionChecker__src-String__permissions-PermissionStatus__createParent-boolean",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirMkdirOp.java",
  "functionStartLine": 43,
  "functionEndLine": 89,
  "numCommitsSeen": 508,
  "timeTaken": 13197,
  "changeHistory": [
    "84a1321f6aa0af6895564a7c47f8f264656f0294",
    "9b90e52f1ec22c18cd535af2a569defcef65b093",
    "9d175853b0170683ad5f21d9bcdeaac49fe89e04",
    "e57fa81d9559a93d77fd724f7792326c31a490be",
    "8b7adf4ddf420a93c586c4b2eac27dd0f649682e",
    "869393643de23dcb010cc33091c8eb398de0fd6c",
    "03dea65e0b17ca2f9460bb6110f6ab3a321b8bf2",
    "5caebbae8c2fc9ba2e32384657aee21641a1a6d0",
    "65f2a4ee600dfffa5203450261da3c1989de25a9",
    "c78e3a7cdd10c40454e9acb06986ba6d8573cb19",
    "475c6b4978045d55d1ebcea69cc9a2f24355aca2",
    "185e0c7b4c056b88f606362c71e4a22aae7076e0",
    "c95b878abf313507666ea018f9e6033c4c166e10"
  ],
  "changeHistoryShort": {
    "84a1321f6aa0af6895564a7c47f8f264656f0294": "Ymultichange(Yparameterchange,Ybodychange)",
    "9b90e52f1ec22c18cd535af2a569defcef65b093": "Yreturntypechange",
    "9d175853b0170683ad5f21d9bcdeaac49fe89e04": "Ybodychange",
    "e57fa81d9559a93d77fd724f7792326c31a490be": "Ybodychange",
    "8b7adf4ddf420a93c586c4b2eac27dd0f649682e": "Ybodychange",
    "869393643de23dcb010cc33091c8eb398de0fd6c": "Ybodychange",
    "03dea65e0b17ca2f9460bb6110f6ab3a321b8bf2": "Ybodychange",
    "5caebbae8c2fc9ba2e32384657aee21641a1a6d0": "Ybodychange",
    "65f2a4ee600dfffa5203450261da3c1989de25a9": "Ybodychange",
    "c78e3a7cdd10c40454e9acb06986ba6d8573cb19": "Ybodychange",
    "475c6b4978045d55d1ebcea69cc9a2f24355aca2": "Ybodychange",
    "185e0c7b4c056b88f606362c71e4a22aae7076e0": "Ymultichange(Ymovefromfile,Yreturntypechange,Ymodifierchange,Yexceptionschange,Ybodychange,Yrename,Yparameterchange)",
    "c95b878abf313507666ea018f9e6033c4c166e10": "Ybodychange"
  },
  "changeHistoryDetails": {
    "84a1321f6aa0af6895564a7c47f8f264656f0294": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-13136. Avoid taking FSN lock while doing group member lookup for FSD permission check. Contributed by Xiaoyu Yao.\n",
      "commitDate": "22/02/18 11:32 AM",
      "commitName": "84a1321f6aa0af6895564a7c47f8f264656f0294",
      "commitAuthor": "Xiaoyu Yao",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-13136. Avoid taking FSN lock while doing group member lookup for FSD permission check. Contributed by Xiaoyu Yao.\n",
          "commitDate": "22/02/18 11:32 AM",
          "commitName": "84a1321f6aa0af6895564a7c47f8f264656f0294",
          "commitAuthor": "Xiaoyu Yao",
          "commitDateOld": "16/05/17 9:28 AM",
          "commitNameOld": "9b90e52f1ec22c18cd535af2a569defcef65b093",
          "commitAuthorOld": "Kihwal Lee",
          "daysBetweenCommits": 282.13,
          "commitsBetweenForRepo": 1928,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,48 +1,47 @@\n-  static FileStatus mkdirs(FSNamesystem fsn, String src,\n+  static FileStatus mkdirs(FSNamesystem fsn, FSPermissionChecker pc, String src,\n       PermissionStatus permissions, boolean createParent) throws IOException {\n     FSDirectory fsd \u003d fsn.getFSDirectory();\n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n     }\n-    FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n     fsd.writeLock();\n     try {\n       INodesInPath iip \u003d fsd.resolvePath(pc, src, DirOp.CREATE);\n \n       final INode lastINode \u003d iip.getLastINode();\n       if (lastINode !\u003d null \u0026\u0026 lastINode.isFile()) {\n         throw new FileAlreadyExistsException(\"Path is not a directory: \" + src);\n       }\n \n       if (lastINode \u003d\u003d null) {\n         if (fsd.isPermissionEnabled()) {\n           fsd.checkAncestorAccess(pc, iip, FsAction.WRITE);\n         }\n \n         if (!createParent) {\n           fsd.verifyParentDir(iip);\n         }\n \n         // validate that we have enough inodes. This is, at best, a\n         // heuristic because the mkdirs() operation might need to\n         // create multiple inodes.\n         fsn.checkFsObjectLimit();\n \n         // Ensure that the user can traversal the path by adding implicit\n         // u+wx permission to all ancestor directories.\n         INodesInPath existing \u003d\n             createParentDirectories(fsd, iip, permissions, false);\n         if (existing !\u003d null) {\n           existing \u003d createSingleDirectory(\n               fsd, existing, iip.getLastLocalName(), permissions);\n         }\n         if (existing \u003d\u003d null) {\n           throw new IOException(\"Failed to create directory: \" + src);\n         }\n         iip \u003d existing;\n       }\n       return fsd.getAuditFileInfo(iip);\n     } finally {\n       fsd.writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static FileStatus mkdirs(FSNamesystem fsn, FSPermissionChecker pc, String src,\n      PermissionStatus permissions, boolean createParent) throws IOException {\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n    }\n    fsd.writeLock();\n    try {\n      INodesInPath iip \u003d fsd.resolvePath(pc, src, DirOp.CREATE);\n\n      final INode lastINode \u003d iip.getLastINode();\n      if (lastINode !\u003d null \u0026\u0026 lastINode.isFile()) {\n        throw new FileAlreadyExistsException(\"Path is not a directory: \" + src);\n      }\n\n      if (lastINode \u003d\u003d null) {\n        if (fsd.isPermissionEnabled()) {\n          fsd.checkAncestorAccess(pc, iip, FsAction.WRITE);\n        }\n\n        if (!createParent) {\n          fsd.verifyParentDir(iip);\n        }\n\n        // validate that we have enough inodes. This is, at best, a\n        // heuristic because the mkdirs() operation might need to\n        // create multiple inodes.\n        fsn.checkFsObjectLimit();\n\n        // Ensure that the user can traversal the path by adding implicit\n        // u+wx permission to all ancestor directories.\n        INodesInPath existing \u003d\n            createParentDirectories(fsd, iip, permissions, false);\n        if (existing !\u003d null) {\n          existing \u003d createSingleDirectory(\n              fsd, existing, iip.getLastLocalName(), permissions);\n        }\n        if (existing \u003d\u003d null) {\n          throw new IOException(\"Failed to create directory: \" + src);\n        }\n        iip \u003d existing;\n      }\n      return fsd.getAuditFileInfo(iip);\n    } finally {\n      fsd.writeUnlock();\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirMkdirOp.java",
          "extendedDetails": {
            "oldValue": "[fsn-FSNamesystem, src-String, permissions-PermissionStatus, createParent-boolean]",
            "newValue": "[fsn-FSNamesystem, pc-FSPermissionChecker, src-String, permissions-PermissionStatus, createParent-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-13136. Avoid taking FSN lock while doing group member lookup for FSD permission check. Contributed by Xiaoyu Yao.\n",
          "commitDate": "22/02/18 11:32 AM",
          "commitName": "84a1321f6aa0af6895564a7c47f8f264656f0294",
          "commitAuthor": "Xiaoyu Yao",
          "commitDateOld": "16/05/17 9:28 AM",
          "commitNameOld": "9b90e52f1ec22c18cd535af2a569defcef65b093",
          "commitAuthorOld": "Kihwal Lee",
          "daysBetweenCommits": 282.13,
          "commitsBetweenForRepo": 1928,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,48 +1,47 @@\n-  static FileStatus mkdirs(FSNamesystem fsn, String src,\n+  static FileStatus mkdirs(FSNamesystem fsn, FSPermissionChecker pc, String src,\n       PermissionStatus permissions, boolean createParent) throws IOException {\n     FSDirectory fsd \u003d fsn.getFSDirectory();\n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n     }\n-    FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n     fsd.writeLock();\n     try {\n       INodesInPath iip \u003d fsd.resolvePath(pc, src, DirOp.CREATE);\n \n       final INode lastINode \u003d iip.getLastINode();\n       if (lastINode !\u003d null \u0026\u0026 lastINode.isFile()) {\n         throw new FileAlreadyExistsException(\"Path is not a directory: \" + src);\n       }\n \n       if (lastINode \u003d\u003d null) {\n         if (fsd.isPermissionEnabled()) {\n           fsd.checkAncestorAccess(pc, iip, FsAction.WRITE);\n         }\n \n         if (!createParent) {\n           fsd.verifyParentDir(iip);\n         }\n \n         // validate that we have enough inodes. This is, at best, a\n         // heuristic because the mkdirs() operation might need to\n         // create multiple inodes.\n         fsn.checkFsObjectLimit();\n \n         // Ensure that the user can traversal the path by adding implicit\n         // u+wx permission to all ancestor directories.\n         INodesInPath existing \u003d\n             createParentDirectories(fsd, iip, permissions, false);\n         if (existing !\u003d null) {\n           existing \u003d createSingleDirectory(\n               fsd, existing, iip.getLastLocalName(), permissions);\n         }\n         if (existing \u003d\u003d null) {\n           throw new IOException(\"Failed to create directory: \" + src);\n         }\n         iip \u003d existing;\n       }\n       return fsd.getAuditFileInfo(iip);\n     } finally {\n       fsd.writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static FileStatus mkdirs(FSNamesystem fsn, FSPermissionChecker pc, String src,\n      PermissionStatus permissions, boolean createParent) throws IOException {\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n    }\n    fsd.writeLock();\n    try {\n      INodesInPath iip \u003d fsd.resolvePath(pc, src, DirOp.CREATE);\n\n      final INode lastINode \u003d iip.getLastINode();\n      if (lastINode !\u003d null \u0026\u0026 lastINode.isFile()) {\n        throw new FileAlreadyExistsException(\"Path is not a directory: \" + src);\n      }\n\n      if (lastINode \u003d\u003d null) {\n        if (fsd.isPermissionEnabled()) {\n          fsd.checkAncestorAccess(pc, iip, FsAction.WRITE);\n        }\n\n        if (!createParent) {\n          fsd.verifyParentDir(iip);\n        }\n\n        // validate that we have enough inodes. This is, at best, a\n        // heuristic because the mkdirs() operation might need to\n        // create multiple inodes.\n        fsn.checkFsObjectLimit();\n\n        // Ensure that the user can traversal the path by adding implicit\n        // u+wx permission to all ancestor directories.\n        INodesInPath existing \u003d\n            createParentDirectories(fsd, iip, permissions, false);\n        if (existing !\u003d null) {\n          existing \u003d createSingleDirectory(\n              fsd, existing, iip.getLastLocalName(), permissions);\n        }\n        if (existing \u003d\u003d null) {\n          throw new IOException(\"Failed to create directory: \" + src);\n        }\n        iip \u003d existing;\n      }\n      return fsd.getAuditFileInfo(iip);\n    } finally {\n      fsd.writeUnlock();\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirMkdirOp.java",
          "extendedDetails": {}
        }
      ]
    },
    "9b90e52f1ec22c18cd535af2a569defcef65b093": {
      "type": "Yreturntypechange",
      "commitMessage": "HDFS-11641. Reduce cost of audit logging by using FileStatus instead of HdfsFileStatus. Contributed by Daryn Sharp.\n",
      "commitDate": "16/05/17 9:28 AM",
      "commitName": "9b90e52f1ec22c18cd535af2a569defcef65b093",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "24/10/16 3:14 PM",
      "commitNameOld": "9d175853b0170683ad5f21d9bcdeaac49fe89e04",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 203.76,
      "commitsBetweenForRepo": 1218,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,48 +1,48 @@\n-  static HdfsFileStatus mkdirs(FSNamesystem fsn, String src,\n+  static FileStatus mkdirs(FSNamesystem fsn, String src,\n       PermissionStatus permissions, boolean createParent) throws IOException {\n     FSDirectory fsd \u003d fsn.getFSDirectory();\n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n     }\n     FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n     fsd.writeLock();\n     try {\n       INodesInPath iip \u003d fsd.resolvePath(pc, src, DirOp.CREATE);\n \n       final INode lastINode \u003d iip.getLastINode();\n       if (lastINode !\u003d null \u0026\u0026 lastINode.isFile()) {\n         throw new FileAlreadyExistsException(\"Path is not a directory: \" + src);\n       }\n \n       if (lastINode \u003d\u003d null) {\n         if (fsd.isPermissionEnabled()) {\n           fsd.checkAncestorAccess(pc, iip, FsAction.WRITE);\n         }\n \n         if (!createParent) {\n           fsd.verifyParentDir(iip);\n         }\n \n         // validate that we have enough inodes. This is, at best, a\n         // heuristic because the mkdirs() operation might need to\n         // create multiple inodes.\n         fsn.checkFsObjectLimit();\n \n         // Ensure that the user can traversal the path by adding implicit\n         // u+wx permission to all ancestor directories.\n         INodesInPath existing \u003d\n             createParentDirectories(fsd, iip, permissions, false);\n         if (existing !\u003d null) {\n           existing \u003d createSingleDirectory(\n               fsd, existing, iip.getLastLocalName(), permissions);\n         }\n         if (existing \u003d\u003d null) {\n           throw new IOException(\"Failed to create directory: \" + src);\n         }\n         iip \u003d existing;\n       }\n       return fsd.getAuditFileInfo(iip);\n     } finally {\n       fsd.writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static FileStatus mkdirs(FSNamesystem fsn, String src,\n      PermissionStatus permissions, boolean createParent) throws IOException {\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n    }\n    FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n    fsd.writeLock();\n    try {\n      INodesInPath iip \u003d fsd.resolvePath(pc, src, DirOp.CREATE);\n\n      final INode lastINode \u003d iip.getLastINode();\n      if (lastINode !\u003d null \u0026\u0026 lastINode.isFile()) {\n        throw new FileAlreadyExistsException(\"Path is not a directory: \" + src);\n      }\n\n      if (lastINode \u003d\u003d null) {\n        if (fsd.isPermissionEnabled()) {\n          fsd.checkAncestorAccess(pc, iip, FsAction.WRITE);\n        }\n\n        if (!createParent) {\n          fsd.verifyParentDir(iip);\n        }\n\n        // validate that we have enough inodes. This is, at best, a\n        // heuristic because the mkdirs() operation might need to\n        // create multiple inodes.\n        fsn.checkFsObjectLimit();\n\n        // Ensure that the user can traversal the path by adding implicit\n        // u+wx permission to all ancestor directories.\n        INodesInPath existing \u003d\n            createParentDirectories(fsd, iip, permissions, false);\n        if (existing !\u003d null) {\n          existing \u003d createSingleDirectory(\n              fsd, existing, iip.getLastLocalName(), permissions);\n        }\n        if (existing \u003d\u003d null) {\n          throw new IOException(\"Failed to create directory: \" + src);\n        }\n        iip \u003d existing;\n      }\n      return fsd.getAuditFileInfo(iip);\n    } finally {\n      fsd.writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirMkdirOp.java",
      "extendedDetails": {
        "oldValue": "HdfsFileStatus",
        "newValue": "FileStatus"
      }
    },
    "9d175853b0170683ad5f21d9bcdeaac49fe89e04": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10997. Reduce number of path resolving methods. Contributed by Daryn Sharp.\n",
      "commitDate": "24/10/16 3:14 PM",
      "commitName": "9d175853b0170683ad5f21d9bcdeaac49fe89e04",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "07/10/16 3:20 PM",
      "commitNameOld": "e57fa81d9559a93d77fd724f7792326c31a490be",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 17.0,
      "commitsBetweenForRepo": 108,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,55 +1,48 @@\n   static HdfsFileStatus mkdirs(FSNamesystem fsn, String src,\n       PermissionStatus permissions, boolean createParent) throws IOException {\n     FSDirectory fsd \u003d fsn.getFSDirectory();\n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n     }\n-    if (!DFSUtil.isValidName(src)) {\n-      throw new InvalidPathException(src);\n-    }\n     FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n     fsd.writeLock();\n     try {\n-      INodesInPath iip \u003d fsd.resolvePathForWrite(pc, src);\n-      src \u003d iip.getPath();\n-      if (fsd.isPermissionEnabled()) {\n-        fsd.checkTraverse(pc, iip);\n-      }\n+      INodesInPath iip \u003d fsd.resolvePath(pc, src, DirOp.CREATE);\n \n       final INode lastINode \u003d iip.getLastINode();\n       if (lastINode !\u003d null \u0026\u0026 lastINode.isFile()) {\n         throw new FileAlreadyExistsException(\"Path is not a directory: \" + src);\n       }\n \n       if (lastINode \u003d\u003d null) {\n         if (fsd.isPermissionEnabled()) {\n           fsd.checkAncestorAccess(pc, iip, FsAction.WRITE);\n         }\n \n         if (!createParent) {\n           fsd.verifyParentDir(iip);\n         }\n \n         // validate that we have enough inodes. This is, at best, a\n         // heuristic because the mkdirs() operation might need to\n         // create multiple inodes.\n         fsn.checkFsObjectLimit();\n \n         // Ensure that the user can traversal the path by adding implicit\n         // u+wx permission to all ancestor directories.\n         INodesInPath existing \u003d\n             createParentDirectories(fsd, iip, permissions, false);\n         if (existing !\u003d null) {\n           existing \u003d createSingleDirectory(\n               fsd, existing, iip.getLastLocalName(), permissions);\n         }\n         if (existing \u003d\u003d null) {\n           throw new IOException(\"Failed to create directory: \" + src);\n         }\n         iip \u003d existing;\n       }\n       return fsd.getAuditFileInfo(iip);\n     } finally {\n       fsd.writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static HdfsFileStatus mkdirs(FSNamesystem fsn, String src,\n      PermissionStatus permissions, boolean createParent) throws IOException {\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n    }\n    FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n    fsd.writeLock();\n    try {\n      INodesInPath iip \u003d fsd.resolvePath(pc, src, DirOp.CREATE);\n\n      final INode lastINode \u003d iip.getLastINode();\n      if (lastINode !\u003d null \u0026\u0026 lastINode.isFile()) {\n        throw new FileAlreadyExistsException(\"Path is not a directory: \" + src);\n      }\n\n      if (lastINode \u003d\u003d null) {\n        if (fsd.isPermissionEnabled()) {\n          fsd.checkAncestorAccess(pc, iip, FsAction.WRITE);\n        }\n\n        if (!createParent) {\n          fsd.verifyParentDir(iip);\n        }\n\n        // validate that we have enough inodes. This is, at best, a\n        // heuristic because the mkdirs() operation might need to\n        // create multiple inodes.\n        fsn.checkFsObjectLimit();\n\n        // Ensure that the user can traversal the path by adding implicit\n        // u+wx permission to all ancestor directories.\n        INodesInPath existing \u003d\n            createParentDirectories(fsd, iip, permissions, false);\n        if (existing !\u003d null) {\n          existing \u003d createSingleDirectory(\n              fsd, existing, iip.getLastLocalName(), permissions);\n        }\n        if (existing \u003d\u003d null) {\n          throw new IOException(\"Failed to create directory: \" + src);\n        }\n        iip \u003d existing;\n      }\n      return fsd.getAuditFileInfo(iip);\n    } finally {\n      fsd.writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirMkdirOp.java",
      "extendedDetails": {}
    },
    "e57fa81d9559a93d77fd724f7792326c31a490be": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10980. Optimize check for existence of parent directory. Contributed by Daryn Sharp.\n",
      "commitDate": "07/10/16 3:20 PM",
      "commitName": "e57fa81d9559a93d77fd724f7792326c31a490be",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "06/09/16 11:02 AM",
      "commitNameOld": "f0d5382ff3e31a47d13e4cb6c3a244cca82b17ce",
      "commitAuthorOld": "Chris Nauroth",
      "daysBetweenCommits": 31.18,
      "commitsBetweenForRepo": 201,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,55 +1,55 @@\n   static HdfsFileStatus mkdirs(FSNamesystem fsn, String src,\n       PermissionStatus permissions, boolean createParent) throws IOException {\n     FSDirectory fsd \u003d fsn.getFSDirectory();\n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n     }\n     if (!DFSUtil.isValidName(src)) {\n       throw new InvalidPathException(src);\n     }\n     FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n     fsd.writeLock();\n     try {\n       INodesInPath iip \u003d fsd.resolvePathForWrite(pc, src);\n       src \u003d iip.getPath();\n       if (fsd.isPermissionEnabled()) {\n         fsd.checkTraverse(pc, iip);\n       }\n \n       final INode lastINode \u003d iip.getLastINode();\n       if (lastINode !\u003d null \u0026\u0026 lastINode.isFile()) {\n         throw new FileAlreadyExistsException(\"Path is not a directory: \" + src);\n       }\n \n       if (lastINode \u003d\u003d null) {\n         if (fsd.isPermissionEnabled()) {\n           fsd.checkAncestorAccess(pc, iip, FsAction.WRITE);\n         }\n \n         if (!createParent) {\n-          fsd.verifyParentDir(iip, src);\n+          fsd.verifyParentDir(iip);\n         }\n \n         // validate that we have enough inodes. This is, at best, a\n         // heuristic because the mkdirs() operation might need to\n         // create multiple inodes.\n         fsn.checkFsObjectLimit();\n \n         // Ensure that the user can traversal the path by adding implicit\n         // u+wx permission to all ancestor directories.\n         INodesInPath existing \u003d\n             createParentDirectories(fsd, iip, permissions, false);\n         if (existing !\u003d null) {\n           existing \u003d createSingleDirectory(\n               fsd, existing, iip.getLastLocalName(), permissions);\n         }\n         if (existing \u003d\u003d null) {\n           throw new IOException(\"Failed to create directory: \" + src);\n         }\n         iip \u003d existing;\n       }\n       return fsd.getAuditFileInfo(iip);\n     } finally {\n       fsd.writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static HdfsFileStatus mkdirs(FSNamesystem fsn, String src,\n      PermissionStatus permissions, boolean createParent) throws IOException {\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n    }\n    if (!DFSUtil.isValidName(src)) {\n      throw new InvalidPathException(src);\n    }\n    FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n    fsd.writeLock();\n    try {\n      INodesInPath iip \u003d fsd.resolvePathForWrite(pc, src);\n      src \u003d iip.getPath();\n      if (fsd.isPermissionEnabled()) {\n        fsd.checkTraverse(pc, iip);\n      }\n\n      final INode lastINode \u003d iip.getLastINode();\n      if (lastINode !\u003d null \u0026\u0026 lastINode.isFile()) {\n        throw new FileAlreadyExistsException(\"Path is not a directory: \" + src);\n      }\n\n      if (lastINode \u003d\u003d null) {\n        if (fsd.isPermissionEnabled()) {\n          fsd.checkAncestorAccess(pc, iip, FsAction.WRITE);\n        }\n\n        if (!createParent) {\n          fsd.verifyParentDir(iip);\n        }\n\n        // validate that we have enough inodes. This is, at best, a\n        // heuristic because the mkdirs() operation might need to\n        // create multiple inodes.\n        fsn.checkFsObjectLimit();\n\n        // Ensure that the user can traversal the path by adding implicit\n        // u+wx permission to all ancestor directories.\n        INodesInPath existing \u003d\n            createParentDirectories(fsd, iip, permissions, false);\n        if (existing !\u003d null) {\n          existing \u003d createSingleDirectory(\n              fsd, existing, iip.getLastLocalName(), permissions);\n        }\n        if (existing \u003d\u003d null) {\n          throw new IOException(\"Failed to create directory: \" + src);\n        }\n        iip \u003d existing;\n      }\n      return fsd.getAuditFileInfo(iip);\n    } finally {\n      fsd.writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirMkdirOp.java",
      "extendedDetails": {}
    },
    "8b7adf4ddf420a93c586c4b2eac27dd0f649682e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10768. Optimize mkdir ops. Contributed by Daryn Sharp.\n",
      "commitDate": "26/08/16 1:39 PM",
      "commitName": "8b7adf4ddf420a93c586c4b2eac27dd0f649682e",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "17/08/16 1:53 PM",
      "commitNameOld": "869393643de23dcb010cc33091c8eb398de0fd6c",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 8.99,
      "commitsBetweenForRepo": 69,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,62 +1,55 @@\n   static HdfsFileStatus mkdirs(FSNamesystem fsn, String src,\n       PermissionStatus permissions, boolean createParent) throws IOException {\n     FSDirectory fsd \u003d fsn.getFSDirectory();\n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n     }\n     if (!DFSUtil.isValidName(src)) {\n       throw new InvalidPathException(src);\n     }\n     FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n     fsd.writeLock();\n     try {\n       INodesInPath iip \u003d fsd.resolvePathForWrite(pc, src);\n       src \u003d iip.getPath();\n       if (fsd.isPermissionEnabled()) {\n         fsd.checkTraverse(pc, iip);\n       }\n \n       final INode lastINode \u003d iip.getLastINode();\n       if (lastINode !\u003d null \u0026\u0026 lastINode.isFile()) {\n         throw new FileAlreadyExistsException(\"Path is not a directory: \" + src);\n       }\n \n-      INodesInPath existing \u003d lastINode !\u003d null ? iip : iip.getExistingINodes();\n       if (lastINode \u003d\u003d null) {\n         if (fsd.isPermissionEnabled()) {\n           fsd.checkAncestorAccess(pc, iip, FsAction.WRITE);\n         }\n \n         if (!createParent) {\n           fsd.verifyParentDir(iip, src);\n         }\n \n         // validate that we have enough inodes. This is, at best, a\n         // heuristic because the mkdirs() operation might need to\n         // create multiple inodes.\n         fsn.checkFsObjectLimit();\n \n-        List\u003cString\u003e nonExisting \u003d iip.getPath(existing.length(),\n-            iip.length() - existing.length());\n-        int length \u003d nonExisting.size();\n-        if (length \u003e 1) {\n-          List\u003cString\u003e ancestors \u003d nonExisting.subList(0, length - 1);\n-          // Ensure that the user can traversal the path by adding implicit\n-          // u+wx permission to all ancestor directories\n-          existing \u003d createChildrenDirectories(fsd, existing, ancestors,\n-              addImplicitUwx(permissions, permissions));\n-          if (existing \u003d\u003d null) {\n-            throw new IOException(\"Failed to create directory: \" + src);\n-          }\n+        // Ensure that the user can traversal the path by adding implicit\n+        // u+wx permission to all ancestor directories.\n+        INodesInPath existing \u003d\n+            createParentDirectories(fsd, iip, permissions, false);\n+        if (existing !\u003d null) {\n+          existing \u003d createSingleDirectory(\n+              fsd, existing, iip.getLastLocalName(), permissions);\n         }\n-\n-        if ((existing \u003d createChildrenDirectories(fsd, existing,\n-            nonExisting.subList(length - 1, length), permissions)) \u003d\u003d null) {\n+        if (existing \u003d\u003d null) {\n           throw new IOException(\"Failed to create directory: \" + src);\n         }\n+        iip \u003d existing;\n       }\n-      return fsd.getAuditFileInfo(existing);\n+      return fsd.getAuditFileInfo(iip);\n     } finally {\n       fsd.writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static HdfsFileStatus mkdirs(FSNamesystem fsn, String src,\n      PermissionStatus permissions, boolean createParent) throws IOException {\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n    }\n    if (!DFSUtil.isValidName(src)) {\n      throw new InvalidPathException(src);\n    }\n    FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n    fsd.writeLock();\n    try {\n      INodesInPath iip \u003d fsd.resolvePathForWrite(pc, src);\n      src \u003d iip.getPath();\n      if (fsd.isPermissionEnabled()) {\n        fsd.checkTraverse(pc, iip);\n      }\n\n      final INode lastINode \u003d iip.getLastINode();\n      if (lastINode !\u003d null \u0026\u0026 lastINode.isFile()) {\n        throw new FileAlreadyExistsException(\"Path is not a directory: \" + src);\n      }\n\n      if (lastINode \u003d\u003d null) {\n        if (fsd.isPermissionEnabled()) {\n          fsd.checkAncestorAccess(pc, iip, FsAction.WRITE);\n        }\n\n        if (!createParent) {\n          fsd.verifyParentDir(iip, src);\n        }\n\n        // validate that we have enough inodes. This is, at best, a\n        // heuristic because the mkdirs() operation might need to\n        // create multiple inodes.\n        fsn.checkFsObjectLimit();\n\n        // Ensure that the user can traversal the path by adding implicit\n        // u+wx permission to all ancestor directories.\n        INodesInPath existing \u003d\n            createParentDirectories(fsd, iip, permissions, false);\n        if (existing !\u003d null) {\n          existing \u003d createSingleDirectory(\n              fsd, existing, iip.getLastLocalName(), permissions);\n        }\n        if (existing \u003d\u003d null) {\n          throw new IOException(\"Failed to create directory: \" + src);\n        }\n        iip \u003d existing;\n      }\n      return fsd.getAuditFileInfo(iip);\n    } finally {\n      fsd.writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirMkdirOp.java",
      "extendedDetails": {}
    },
    "869393643de23dcb010cc33091c8eb398de0fd6c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10745. Directly resolve paths into INodesInPath. Contributed by Daryn Sharp.\n",
      "commitDate": "17/08/16 1:53 PM",
      "commitName": "869393643de23dcb010cc33091c8eb398de0fd6c",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "15/08/16 2:45 PM",
      "commitNameOld": "03dea65e0b17ca2f9460bb6110f6ab3a321b8bf2",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 1.96,
      "commitsBetweenForRepo": 23,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,62 +1,62 @@\n   static HdfsFileStatus mkdirs(FSNamesystem fsn, String src,\n       PermissionStatus permissions, boolean createParent) throws IOException {\n     FSDirectory fsd \u003d fsn.getFSDirectory();\n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n     }\n     if (!DFSUtil.isValidName(src)) {\n       throw new InvalidPathException(src);\n     }\n     FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n     fsd.writeLock();\n     try {\n-      src \u003d fsd.resolvePath(pc, src);\n-      INodesInPath iip \u003d fsd.getINodesInPath4Write(src);\n+      INodesInPath iip \u003d fsd.resolvePathForWrite(pc, src);\n+      src \u003d iip.getPath();\n       if (fsd.isPermissionEnabled()) {\n         fsd.checkTraverse(pc, iip);\n       }\n \n       final INode lastINode \u003d iip.getLastINode();\n       if (lastINode !\u003d null \u0026\u0026 lastINode.isFile()) {\n         throw new FileAlreadyExistsException(\"Path is not a directory: \" + src);\n       }\n \n       INodesInPath existing \u003d lastINode !\u003d null ? iip : iip.getExistingINodes();\n       if (lastINode \u003d\u003d null) {\n         if (fsd.isPermissionEnabled()) {\n           fsd.checkAncestorAccess(pc, iip, FsAction.WRITE);\n         }\n \n         if (!createParent) {\n           fsd.verifyParentDir(iip, src);\n         }\n \n         // validate that we have enough inodes. This is, at best, a\n         // heuristic because the mkdirs() operation might need to\n         // create multiple inodes.\n         fsn.checkFsObjectLimit();\n \n         List\u003cString\u003e nonExisting \u003d iip.getPath(existing.length(),\n             iip.length() - existing.length());\n         int length \u003d nonExisting.size();\n         if (length \u003e 1) {\n           List\u003cString\u003e ancestors \u003d nonExisting.subList(0, length - 1);\n           // Ensure that the user can traversal the path by adding implicit\n           // u+wx permission to all ancestor directories\n           existing \u003d createChildrenDirectories(fsd, existing, ancestors,\n               addImplicitUwx(permissions, permissions));\n           if (existing \u003d\u003d null) {\n             throw new IOException(\"Failed to create directory: \" + src);\n           }\n         }\n \n         if ((existing \u003d createChildrenDirectories(fsd, existing,\n             nonExisting.subList(length - 1, length), permissions)) \u003d\u003d null) {\n           throw new IOException(\"Failed to create directory: \" + src);\n         }\n       }\n       return fsd.getAuditFileInfo(existing);\n     } finally {\n       fsd.writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static HdfsFileStatus mkdirs(FSNamesystem fsn, String src,\n      PermissionStatus permissions, boolean createParent) throws IOException {\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n    }\n    if (!DFSUtil.isValidName(src)) {\n      throw new InvalidPathException(src);\n    }\n    FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n    fsd.writeLock();\n    try {\n      INodesInPath iip \u003d fsd.resolvePathForWrite(pc, src);\n      src \u003d iip.getPath();\n      if (fsd.isPermissionEnabled()) {\n        fsd.checkTraverse(pc, iip);\n      }\n\n      final INode lastINode \u003d iip.getLastINode();\n      if (lastINode !\u003d null \u0026\u0026 lastINode.isFile()) {\n        throw new FileAlreadyExistsException(\"Path is not a directory: \" + src);\n      }\n\n      INodesInPath existing \u003d lastINode !\u003d null ? iip : iip.getExistingINodes();\n      if (lastINode \u003d\u003d null) {\n        if (fsd.isPermissionEnabled()) {\n          fsd.checkAncestorAccess(pc, iip, FsAction.WRITE);\n        }\n\n        if (!createParent) {\n          fsd.verifyParentDir(iip, src);\n        }\n\n        // validate that we have enough inodes. This is, at best, a\n        // heuristic because the mkdirs() operation might need to\n        // create multiple inodes.\n        fsn.checkFsObjectLimit();\n\n        List\u003cString\u003e nonExisting \u003d iip.getPath(existing.length(),\n            iip.length() - existing.length());\n        int length \u003d nonExisting.size();\n        if (length \u003e 1) {\n          List\u003cString\u003e ancestors \u003d nonExisting.subList(0, length - 1);\n          // Ensure that the user can traversal the path by adding implicit\n          // u+wx permission to all ancestor directories\n          existing \u003d createChildrenDirectories(fsd, existing, ancestors,\n              addImplicitUwx(permissions, permissions));\n          if (existing \u003d\u003d null) {\n            throw new IOException(\"Failed to create directory: \" + src);\n          }\n        }\n\n        if ((existing \u003d createChildrenDirectories(fsd, existing,\n            nonExisting.subList(length - 1, length), permissions)) \u003d\u003d null) {\n          throw new IOException(\"Failed to create directory: \" + src);\n        }\n      }\n      return fsd.getAuditFileInfo(existing);\n    } finally {\n      fsd.writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirMkdirOp.java",
      "extendedDetails": {}
    },
    "03dea65e0b17ca2f9460bb6110f6ab3a321b8bf2": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10744. Internally optimize path component resolution. Contributed by Daryn Sharp.\n",
      "commitDate": "15/08/16 2:45 PM",
      "commitName": "03dea65e0b17ca2f9460bb6110f6ab3a321b8bf2",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "04/08/16 7:07 AM",
      "commitNameOld": "6ae39199dac6ac7be6802b31452552c76da16e24",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 11.32,
      "commitsBetweenForRepo": 73,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,63 +1,62 @@\n   static HdfsFileStatus mkdirs(FSNamesystem fsn, String src,\n       PermissionStatus permissions, boolean createParent) throws IOException {\n     FSDirectory fsd \u003d fsn.getFSDirectory();\n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n     }\n     if (!DFSUtil.isValidName(src)) {\n       throw new InvalidPathException(src);\n     }\n     FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n-    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     fsd.writeLock();\n     try {\n-      src \u003d fsd.resolvePath(pc, src, pathComponents);\n+      src \u003d fsd.resolvePath(pc, src);\n       INodesInPath iip \u003d fsd.getINodesInPath4Write(src);\n       if (fsd.isPermissionEnabled()) {\n         fsd.checkTraverse(pc, iip);\n       }\n \n       final INode lastINode \u003d iip.getLastINode();\n       if (lastINode !\u003d null \u0026\u0026 lastINode.isFile()) {\n         throw new FileAlreadyExistsException(\"Path is not a directory: \" + src);\n       }\n \n       INodesInPath existing \u003d lastINode !\u003d null ? iip : iip.getExistingINodes();\n       if (lastINode \u003d\u003d null) {\n         if (fsd.isPermissionEnabled()) {\n           fsd.checkAncestorAccess(pc, iip, FsAction.WRITE);\n         }\n \n         if (!createParent) {\n           fsd.verifyParentDir(iip, src);\n         }\n \n         // validate that we have enough inodes. This is, at best, a\n         // heuristic because the mkdirs() operation might need to\n         // create multiple inodes.\n         fsn.checkFsObjectLimit();\n \n         List\u003cString\u003e nonExisting \u003d iip.getPath(existing.length(),\n             iip.length() - existing.length());\n         int length \u003d nonExisting.size();\n         if (length \u003e 1) {\n           List\u003cString\u003e ancestors \u003d nonExisting.subList(0, length - 1);\n           // Ensure that the user can traversal the path by adding implicit\n           // u+wx permission to all ancestor directories\n           existing \u003d createChildrenDirectories(fsd, existing, ancestors,\n               addImplicitUwx(permissions, permissions));\n           if (existing \u003d\u003d null) {\n             throw new IOException(\"Failed to create directory: \" + src);\n           }\n         }\n \n         if ((existing \u003d createChildrenDirectories(fsd, existing,\n             nonExisting.subList(length - 1, length), permissions)) \u003d\u003d null) {\n           throw new IOException(\"Failed to create directory: \" + src);\n         }\n       }\n       return fsd.getAuditFileInfo(existing);\n     } finally {\n       fsd.writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static HdfsFileStatus mkdirs(FSNamesystem fsn, String src,\n      PermissionStatus permissions, boolean createParent) throws IOException {\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n    }\n    if (!DFSUtil.isValidName(src)) {\n      throw new InvalidPathException(src);\n    }\n    FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n    fsd.writeLock();\n    try {\n      src \u003d fsd.resolvePath(pc, src);\n      INodesInPath iip \u003d fsd.getINodesInPath4Write(src);\n      if (fsd.isPermissionEnabled()) {\n        fsd.checkTraverse(pc, iip);\n      }\n\n      final INode lastINode \u003d iip.getLastINode();\n      if (lastINode !\u003d null \u0026\u0026 lastINode.isFile()) {\n        throw new FileAlreadyExistsException(\"Path is not a directory: \" + src);\n      }\n\n      INodesInPath existing \u003d lastINode !\u003d null ? iip : iip.getExistingINodes();\n      if (lastINode \u003d\u003d null) {\n        if (fsd.isPermissionEnabled()) {\n          fsd.checkAncestorAccess(pc, iip, FsAction.WRITE);\n        }\n\n        if (!createParent) {\n          fsd.verifyParentDir(iip, src);\n        }\n\n        // validate that we have enough inodes. This is, at best, a\n        // heuristic because the mkdirs() operation might need to\n        // create multiple inodes.\n        fsn.checkFsObjectLimit();\n\n        List\u003cString\u003e nonExisting \u003d iip.getPath(existing.length(),\n            iip.length() - existing.length());\n        int length \u003d nonExisting.size();\n        if (length \u003e 1) {\n          List\u003cString\u003e ancestors \u003d nonExisting.subList(0, length - 1);\n          // Ensure that the user can traversal the path by adding implicit\n          // u+wx permission to all ancestor directories\n          existing \u003d createChildrenDirectories(fsd, existing, ancestors,\n              addImplicitUwx(permissions, permissions));\n          if (existing \u003d\u003d null) {\n            throw new IOException(\"Failed to create directory: \" + src);\n          }\n        }\n\n        if ((existing \u003d createChildrenDirectories(fsd, existing,\n            nonExisting.subList(length - 1, length), permissions)) \u003d\u003d null) {\n          throw new IOException(\"Failed to create directory: \" + src);\n        }\n      }\n      return fsd.getAuditFileInfo(existing);\n    } finally {\n      fsd.writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirMkdirOp.java",
      "extendedDetails": {}
    },
    "5caebbae8c2fc9ba2e32384657aee21641a1a6d0": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7484. Make FSDirectory#addINode take existing INodes as its parameter. Contributed by Jing Zhao.\n",
      "commitDate": "22/12/14 11:19 PM",
      "commitName": "5caebbae8c2fc9ba2e32384657aee21641a1a6d0",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "18/12/14 11:25 AM",
      "commitNameOld": "65f2a4ee600dfffa5203450261da3c1989de25a9",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 4.5,
      "commitsBetweenForRepo": 32,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,63 @@\n-  static HdfsFileStatus mkdirs(\n-      FSNamesystem fsn, String src, PermissionStatus permissions,\n-      boolean createParent) throws IOException {\n+  static HdfsFileStatus mkdirs(FSNamesystem fsn, String src,\n+      PermissionStatus permissions, boolean createParent) throws IOException {\n     FSDirectory fsd \u003d fsn.getFSDirectory();\n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n     }\n     if (!DFSUtil.isValidName(src)) {\n       throw new InvalidPathException(src);\n     }\n     FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n-    src \u003d fsd.resolvePath(pc, src, pathComponents);\n-    INodesInPath iip \u003d fsd.getINodesInPath4Write(src);\n-    if (fsd.isPermissionEnabled()) {\n-      fsd.checkTraverse(pc, iip);\n-    }\n-\n-    if (!isDirMutable(fsd, iip)) {\n+    fsd.writeLock();\n+    try {\n+      src \u003d fsd.resolvePath(pc, src, pathComponents);\n+      INodesInPath iip \u003d fsd.getINodesInPath4Write(src);\n       if (fsd.isPermissionEnabled()) {\n-        fsd.checkAncestorAccess(pc, iip, FsAction.WRITE);\n+        fsd.checkTraverse(pc, iip);\n       }\n \n-      if (!createParent) {\n-        fsd.verifyParentDir(iip, src);\n+      final INode lastINode \u003d iip.getLastINode();\n+      if (lastINode !\u003d null \u0026\u0026 lastINode.isFile()) {\n+        throw new FileAlreadyExistsException(\"Path is not a directory: \" + src);\n       }\n \n-      // validate that we have enough inodes. This is, at best, a\n-      // heuristic because the mkdirs() operation might need to\n-      // create multiple inodes.\n-      fsn.checkFsObjectLimit();\n-      iip \u003d mkdirsRecursively(fsd, iip, permissions, false, now());\n-      if (iip \u003d\u003d null) {\n-        throw new IOException(\"Failed to create directory: \" + src);\n+      INodesInPath existing \u003d lastINode !\u003d null ? iip : iip.getExistingINodes();\n+      if (lastINode \u003d\u003d null) {\n+        if (fsd.isPermissionEnabled()) {\n+          fsd.checkAncestorAccess(pc, iip, FsAction.WRITE);\n+        }\n+\n+        if (!createParent) {\n+          fsd.verifyParentDir(iip, src);\n+        }\n+\n+        // validate that we have enough inodes. This is, at best, a\n+        // heuristic because the mkdirs() operation might need to\n+        // create multiple inodes.\n+        fsn.checkFsObjectLimit();\n+\n+        List\u003cString\u003e nonExisting \u003d iip.getPath(existing.length(),\n+            iip.length() - existing.length());\n+        int length \u003d nonExisting.size();\n+        if (length \u003e 1) {\n+          List\u003cString\u003e ancestors \u003d nonExisting.subList(0, length - 1);\n+          // Ensure that the user can traversal the path by adding implicit\n+          // u+wx permission to all ancestor directories\n+          existing \u003d createChildrenDirectories(fsd, existing, ancestors,\n+              addImplicitUwx(permissions, permissions));\n+          if (existing \u003d\u003d null) {\n+            throw new IOException(\"Failed to create directory: \" + src);\n+          }\n+        }\n+\n+        if ((existing \u003d createChildrenDirectories(fsd, existing,\n+            nonExisting.subList(length - 1, length), permissions)) \u003d\u003d null) {\n+          throw new IOException(\"Failed to create directory: \" + src);\n+        }\n       }\n+      return fsd.getAuditFileInfo(existing);\n+    } finally {\n+      fsd.writeUnlock();\n     }\n-    return fsd.getAuditFileInfo(iip);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static HdfsFileStatus mkdirs(FSNamesystem fsn, String src,\n      PermissionStatus permissions, boolean createParent) throws IOException {\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n    }\n    if (!DFSUtil.isValidName(src)) {\n      throw new InvalidPathException(src);\n    }\n    FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    fsd.writeLock();\n    try {\n      src \u003d fsd.resolvePath(pc, src, pathComponents);\n      INodesInPath iip \u003d fsd.getINodesInPath4Write(src);\n      if (fsd.isPermissionEnabled()) {\n        fsd.checkTraverse(pc, iip);\n      }\n\n      final INode lastINode \u003d iip.getLastINode();\n      if (lastINode !\u003d null \u0026\u0026 lastINode.isFile()) {\n        throw new FileAlreadyExistsException(\"Path is not a directory: \" + src);\n      }\n\n      INodesInPath existing \u003d lastINode !\u003d null ? iip : iip.getExistingINodes();\n      if (lastINode \u003d\u003d null) {\n        if (fsd.isPermissionEnabled()) {\n          fsd.checkAncestorAccess(pc, iip, FsAction.WRITE);\n        }\n\n        if (!createParent) {\n          fsd.verifyParentDir(iip, src);\n        }\n\n        // validate that we have enough inodes. This is, at best, a\n        // heuristic because the mkdirs() operation might need to\n        // create multiple inodes.\n        fsn.checkFsObjectLimit();\n\n        List\u003cString\u003e nonExisting \u003d iip.getPath(existing.length(),\n            iip.length() - existing.length());\n        int length \u003d nonExisting.size();\n        if (length \u003e 1) {\n          List\u003cString\u003e ancestors \u003d nonExisting.subList(0, length - 1);\n          // Ensure that the user can traversal the path by adding implicit\n          // u+wx permission to all ancestor directories\n          existing \u003d createChildrenDirectories(fsd, existing, ancestors,\n              addImplicitUwx(permissions, permissions));\n          if (existing \u003d\u003d null) {\n            throw new IOException(\"Failed to create directory: \" + src);\n          }\n        }\n\n        if ((existing \u003d createChildrenDirectories(fsd, existing,\n            nonExisting.subList(length - 1, length), permissions)) \u003d\u003d null) {\n          throw new IOException(\"Failed to create directory: \" + src);\n        }\n      }\n      return fsd.getAuditFileInfo(existing);\n    } finally {\n      fsd.writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirMkdirOp.java",
      "extendedDetails": {}
    },
    "65f2a4ee600dfffa5203450261da3c1989de25a9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7543. Avoid path resolution when getting FileStatus for audit logs. Contributed by Haohui Mai.\n",
      "commitDate": "18/12/14 11:25 AM",
      "commitName": "65f2a4ee600dfffa5203450261da3c1989de25a9",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "12/12/14 3:13 PM",
      "commitNameOld": "c78e3a7cdd10c40454e9acb06986ba6d8573cb19",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 5.84,
      "commitsBetweenForRepo": 42,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,39 +1,38 @@\n   static HdfsFileStatus mkdirs(\n       FSNamesystem fsn, String src, PermissionStatus permissions,\n       boolean createParent) throws IOException {\n     FSDirectory fsd \u003d fsn.getFSDirectory();\n-    final String srcArg \u003d src;\n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n     }\n     if (!DFSUtil.isValidName(src)) {\n       throw new InvalidPathException(src);\n     }\n     FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     src \u003d fsd.resolvePath(pc, src, pathComponents);\n     INodesInPath iip \u003d fsd.getINodesInPath4Write(src);\n     if (fsd.isPermissionEnabled()) {\n       fsd.checkTraverse(pc, iip);\n     }\n \n     if (!isDirMutable(fsd, iip)) {\n       if (fsd.isPermissionEnabled()) {\n         fsd.checkAncestorAccess(pc, iip, FsAction.WRITE);\n       }\n \n       if (!createParent) {\n         fsd.verifyParentDir(iip, src);\n       }\n \n       // validate that we have enough inodes. This is, at best, a\n       // heuristic because the mkdirs() operation might need to\n       // create multiple inodes.\n       fsn.checkFsObjectLimit();\n-\n-      if (mkdirsRecursively(fsd, iip, permissions, false, now()) \u003d\u003d null) {\n+      iip \u003d mkdirsRecursively(fsd, iip, permissions, false, now());\n+      if (iip \u003d\u003d null) {\n         throw new IOException(\"Failed to create directory: \" + src);\n       }\n     }\n-    return fsd.getAuditFileInfo(srcArg, false);\n+    return fsd.getAuditFileInfo(iip);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static HdfsFileStatus mkdirs(\n      FSNamesystem fsn, String src, PermissionStatus permissions,\n      boolean createParent) throws IOException {\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n    }\n    if (!DFSUtil.isValidName(src)) {\n      throw new InvalidPathException(src);\n    }\n    FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    src \u003d fsd.resolvePath(pc, src, pathComponents);\n    INodesInPath iip \u003d fsd.getINodesInPath4Write(src);\n    if (fsd.isPermissionEnabled()) {\n      fsd.checkTraverse(pc, iip);\n    }\n\n    if (!isDirMutable(fsd, iip)) {\n      if (fsd.isPermissionEnabled()) {\n        fsd.checkAncestorAccess(pc, iip, FsAction.WRITE);\n      }\n\n      if (!createParent) {\n        fsd.verifyParentDir(iip, src);\n      }\n\n      // validate that we have enough inodes. This is, at best, a\n      // heuristic because the mkdirs() operation might need to\n      // create multiple inodes.\n      fsn.checkFsObjectLimit();\n      iip \u003d mkdirsRecursively(fsd, iip, permissions, false, now());\n      if (iip \u003d\u003d null) {\n        throw new IOException(\"Failed to create directory: \" + src);\n      }\n    }\n    return fsd.getAuditFileInfo(iip);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirMkdirOp.java",
      "extendedDetails": {}
    },
    "c78e3a7cdd10c40454e9acb06986ba6d8573cb19": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7059. Avoid resolving path multiple times. Contributed by Jing Zhao.\n",
      "commitDate": "12/12/14 3:13 PM",
      "commitName": "c78e3a7cdd10c40454e9acb06986ba6d8573cb19",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "09/12/14 11:37 AM",
      "commitNameOld": "5776a41da08af653206bb94d7c76c9c4dcce059a",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 3.15,
      "commitsBetweenForRepo": 33,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,40 +1,39 @@\n   static HdfsFileStatus mkdirs(\n       FSNamesystem fsn, String src, PermissionStatus permissions,\n       boolean createParent) throws IOException {\n     FSDirectory fsd \u003d fsn.getFSDirectory();\n     final String srcArg \u003d src;\n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n     }\n     if (!DFSUtil.isValidName(src)) {\n       throw new InvalidPathException(src);\n     }\n     FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n-    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath\n-        (src);\n+    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     src \u003d fsd.resolvePath(pc, src, pathComponents);\n     INodesInPath iip \u003d fsd.getINodesInPath4Write(src);\n     if (fsd.isPermissionEnabled()) {\n       fsd.checkTraverse(pc, iip);\n     }\n \n     if (!isDirMutable(fsd, iip)) {\n       if (fsd.isPermissionEnabled()) {\n         fsd.checkAncestorAccess(pc, iip, FsAction.WRITE);\n       }\n \n       if (!createParent) {\n         fsd.verifyParentDir(iip, src);\n       }\n \n       // validate that we have enough inodes. This is, at best, a\n       // heuristic because the mkdirs() operation might need to\n       // create multiple inodes.\n       fsn.checkFsObjectLimit();\n \n-      if (!mkdirsRecursively(fsd, src, permissions, false, now())) {\n+      if (mkdirsRecursively(fsd, iip, permissions, false, now()) \u003d\u003d null) {\n         throw new IOException(\"Failed to create directory: \" + src);\n       }\n     }\n     return fsd.getAuditFileInfo(srcArg, false);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static HdfsFileStatus mkdirs(\n      FSNamesystem fsn, String src, PermissionStatus permissions,\n      boolean createParent) throws IOException {\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    final String srcArg \u003d src;\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n    }\n    if (!DFSUtil.isValidName(src)) {\n      throw new InvalidPathException(src);\n    }\n    FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    src \u003d fsd.resolvePath(pc, src, pathComponents);\n    INodesInPath iip \u003d fsd.getINodesInPath4Write(src);\n    if (fsd.isPermissionEnabled()) {\n      fsd.checkTraverse(pc, iip);\n    }\n\n    if (!isDirMutable(fsd, iip)) {\n      if (fsd.isPermissionEnabled()) {\n        fsd.checkAncestorAccess(pc, iip, FsAction.WRITE);\n      }\n\n      if (!createParent) {\n        fsd.verifyParentDir(iip, src);\n      }\n\n      // validate that we have enough inodes. This is, at best, a\n      // heuristic because the mkdirs() operation might need to\n      // create multiple inodes.\n      fsn.checkFsObjectLimit();\n\n      if (mkdirsRecursively(fsd, iip, permissions, false, now()) \u003d\u003d null) {\n        throw new IOException(\"Failed to create directory: \" + src);\n      }\n    }\n    return fsd.getAuditFileInfo(srcArg, false);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirMkdirOp.java",
      "extendedDetails": {}
    },
    "475c6b4978045d55d1ebcea69cc9a2f24355aca2": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7474. Avoid resolving path in FSPermissionChecker. Contributed by Jing Zhao.\n",
      "commitDate": "05/12/14 2:17 PM",
      "commitName": "475c6b4978045d55d1ebcea69cc9a2f24355aca2",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "02/12/14 2:53 PM",
      "commitNameOld": "185e0c7b4c056b88f606362c71e4a22aae7076e0",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 2.97,
      "commitsBetweenForRepo": 27,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,39 +1,40 @@\n   static HdfsFileStatus mkdirs(\n       FSNamesystem fsn, String src, PermissionStatus permissions,\n       boolean createParent) throws IOException {\n     FSDirectory fsd \u003d fsn.getFSDirectory();\n     final String srcArg \u003d src;\n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n     }\n     if (!DFSUtil.isValidName(src)) {\n       throw new InvalidPathException(src);\n     }\n     FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath\n         (src);\n     src \u003d fsd.resolvePath(pc, src, pathComponents);\n+    INodesInPath iip \u003d fsd.getINodesInPath4Write(src);\n     if (fsd.isPermissionEnabled()) {\n-      fsd.checkTraverse(pc, src);\n+      fsd.checkTraverse(pc, iip);\n     }\n \n-    if (!isDirMutable(fsd, src)) {\n+    if (!isDirMutable(fsd, iip)) {\n       if (fsd.isPermissionEnabled()) {\n-        fsd.checkAncestorAccess(pc, src, FsAction.WRITE);\n+        fsd.checkAncestorAccess(pc, iip, FsAction.WRITE);\n       }\n \n       if (!createParent) {\n-        fsd.verifyParentDir(src);\n+        fsd.verifyParentDir(iip, src);\n       }\n \n       // validate that we have enough inodes. This is, at best, a\n       // heuristic because the mkdirs() operation might need to\n       // create multiple inodes.\n       fsn.checkFsObjectLimit();\n \n       if (!mkdirsRecursively(fsd, src, permissions, false, now())) {\n         throw new IOException(\"Failed to create directory: \" + src);\n       }\n     }\n     return fsd.getAuditFileInfo(srcArg, false);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static HdfsFileStatus mkdirs(\n      FSNamesystem fsn, String src, PermissionStatus permissions,\n      boolean createParent) throws IOException {\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    final String srcArg \u003d src;\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n    }\n    if (!DFSUtil.isValidName(src)) {\n      throw new InvalidPathException(src);\n    }\n    FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath\n        (src);\n    src \u003d fsd.resolvePath(pc, src, pathComponents);\n    INodesInPath iip \u003d fsd.getINodesInPath4Write(src);\n    if (fsd.isPermissionEnabled()) {\n      fsd.checkTraverse(pc, iip);\n    }\n\n    if (!isDirMutable(fsd, iip)) {\n      if (fsd.isPermissionEnabled()) {\n        fsd.checkAncestorAccess(pc, iip, FsAction.WRITE);\n      }\n\n      if (!createParent) {\n        fsd.verifyParentDir(iip, src);\n      }\n\n      // validate that we have enough inodes. This is, at best, a\n      // heuristic because the mkdirs() operation might need to\n      // create multiple inodes.\n      fsn.checkFsObjectLimit();\n\n      if (!mkdirsRecursively(fsd, src, permissions, false, now())) {\n        throw new IOException(\"Failed to create directory: \" + src);\n      }\n    }\n    return fsd.getAuditFileInfo(srcArg, false);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirMkdirOp.java",
      "extendedDetails": {}
    },
    "185e0c7b4c056b88f606362c71e4a22aae7076e0": {
      "type": "Ymultichange(Ymovefromfile,Yreturntypechange,Ymodifierchange,Yexceptionschange,Ybodychange,Yrename,Yparameterchange)",
      "commitMessage": "HDFS-7462. Consolidate implementation of mkdirs() into a single class. Contributed by Haohui Mai.\n",
      "commitDate": "02/12/14 2:53 PM",
      "commitName": "185e0c7b4c056b88f606362c71e4a22aae7076e0",
      "commitAuthor": "Haohui Mai",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-7462. Consolidate implementation of mkdirs() into a single class. Contributed by Haohui Mai.\n",
          "commitDate": "02/12/14 2:53 PM",
          "commitName": "185e0c7b4c056b88f606362c71e4a22aae7076e0",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "02/12/14 10:54 AM",
          "commitNameOld": "52bcefca8bb13d3757009f1f08203e7dca3b1e16",
          "commitAuthorOld": "Jian He",
          "daysBetweenCommits": 0.17,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,32 +1,39 @@\n-  private boolean mkdirsInt(final String srcArg, PermissionStatus permissions,\n-      boolean createParent) throws IOException, UnresolvedLinkException {\n-    String src \u003d srcArg;\n+  static HdfsFileStatus mkdirs(\n+      FSNamesystem fsn, String src, PermissionStatus permissions,\n+      boolean createParent) throws IOException {\n+    FSDirectory fsd \u003d fsn.getFSDirectory();\n+    final String srcArg \u003d src;\n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n     }\n     if (!DFSUtil.isValidName(src)) {\n       throw new InvalidPathException(src);\n     }\n-    FSPermissionChecker pc \u003d getPermissionChecker();\n-    checkOperation(OperationCategory.WRITE);\n-    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n-    HdfsFileStatus resultingStat \u003d null;\n-    boolean status \u003d false;\n-    writeLock();\n-    try {\n-      checkOperation(OperationCategory.WRITE);   \n-      checkNameNodeSafeMode(\"Cannot create directory \" + src);\n-      src \u003d dir.resolvePath(pc, src, pathComponents);\n-      status \u003d mkdirsInternal(pc, src, permissions, createParent);\n-      if (status) {\n-        resultingStat \u003d getAuditFileInfo(src, false);\n+    FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n+    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath\n+        (src);\n+    src \u003d fsd.resolvePath(pc, src, pathComponents);\n+    if (fsd.isPermissionEnabled()) {\n+      fsd.checkTraverse(pc, src);\n+    }\n+\n+    if (!isDirMutable(fsd, src)) {\n+      if (fsd.isPermissionEnabled()) {\n+        fsd.checkAncestorAccess(pc, src, FsAction.WRITE);\n       }\n-    } finally {\n-      writeUnlock();\n+\n+      if (!createParent) {\n+        fsd.verifyParentDir(src);\n+      }\n+\n+      // validate that we have enough inodes. This is, at best, a\n+      // heuristic because the mkdirs() operation might need to\n+      // create multiple inodes.\n+      fsn.checkFsObjectLimit();\n+\n+      if (!mkdirsRecursively(fsd, src, permissions, false, now())) {\n+        throw new IOException(\"Failed to create directory: \" + src);\n+      }\n     }\n-    getEditLog().logSync();\n-    if (status) {\n-      logAuditEvent(true, \"mkdirs\", srcArg, null, resultingStat);\n-    }\n-    return status;\n+    return fsd.getAuditFileInfo(srcArg, false);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static HdfsFileStatus mkdirs(\n      FSNamesystem fsn, String src, PermissionStatus permissions,\n      boolean createParent) throws IOException {\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    final String srcArg \u003d src;\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n    }\n    if (!DFSUtil.isValidName(src)) {\n      throw new InvalidPathException(src);\n    }\n    FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath\n        (src);\n    src \u003d fsd.resolvePath(pc, src, pathComponents);\n    if (fsd.isPermissionEnabled()) {\n      fsd.checkTraverse(pc, src);\n    }\n\n    if (!isDirMutable(fsd, src)) {\n      if (fsd.isPermissionEnabled()) {\n        fsd.checkAncestorAccess(pc, src, FsAction.WRITE);\n      }\n\n      if (!createParent) {\n        fsd.verifyParentDir(src);\n      }\n\n      // validate that we have enough inodes. This is, at best, a\n      // heuristic because the mkdirs() operation might need to\n      // create multiple inodes.\n      fsn.checkFsObjectLimit();\n\n      if (!mkdirsRecursively(fsd, src, permissions, false, now())) {\n        throw new IOException(\"Failed to create directory: \" + src);\n      }\n    }\n    return fsd.getAuditFileInfo(srcArg, false);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirMkdirOp.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirMkdirOp.java",
            "oldMethodName": "mkdirsInt",
            "newMethodName": "mkdirs"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-7462. Consolidate implementation of mkdirs() into a single class. Contributed by Haohui Mai.\n",
          "commitDate": "02/12/14 2:53 PM",
          "commitName": "185e0c7b4c056b88f606362c71e4a22aae7076e0",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "02/12/14 10:54 AM",
          "commitNameOld": "52bcefca8bb13d3757009f1f08203e7dca3b1e16",
          "commitAuthorOld": "Jian He",
          "daysBetweenCommits": 0.17,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,32 +1,39 @@\n-  private boolean mkdirsInt(final String srcArg, PermissionStatus permissions,\n-      boolean createParent) throws IOException, UnresolvedLinkException {\n-    String src \u003d srcArg;\n+  static HdfsFileStatus mkdirs(\n+      FSNamesystem fsn, String src, PermissionStatus permissions,\n+      boolean createParent) throws IOException {\n+    FSDirectory fsd \u003d fsn.getFSDirectory();\n+    final String srcArg \u003d src;\n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n     }\n     if (!DFSUtil.isValidName(src)) {\n       throw new InvalidPathException(src);\n     }\n-    FSPermissionChecker pc \u003d getPermissionChecker();\n-    checkOperation(OperationCategory.WRITE);\n-    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n-    HdfsFileStatus resultingStat \u003d null;\n-    boolean status \u003d false;\n-    writeLock();\n-    try {\n-      checkOperation(OperationCategory.WRITE);   \n-      checkNameNodeSafeMode(\"Cannot create directory \" + src);\n-      src \u003d dir.resolvePath(pc, src, pathComponents);\n-      status \u003d mkdirsInternal(pc, src, permissions, createParent);\n-      if (status) {\n-        resultingStat \u003d getAuditFileInfo(src, false);\n+    FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n+    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath\n+        (src);\n+    src \u003d fsd.resolvePath(pc, src, pathComponents);\n+    if (fsd.isPermissionEnabled()) {\n+      fsd.checkTraverse(pc, src);\n+    }\n+\n+    if (!isDirMutable(fsd, src)) {\n+      if (fsd.isPermissionEnabled()) {\n+        fsd.checkAncestorAccess(pc, src, FsAction.WRITE);\n       }\n-    } finally {\n-      writeUnlock();\n+\n+      if (!createParent) {\n+        fsd.verifyParentDir(src);\n+      }\n+\n+      // validate that we have enough inodes. This is, at best, a\n+      // heuristic because the mkdirs() operation might need to\n+      // create multiple inodes.\n+      fsn.checkFsObjectLimit();\n+\n+      if (!mkdirsRecursively(fsd, src, permissions, false, now())) {\n+        throw new IOException(\"Failed to create directory: \" + src);\n+      }\n     }\n-    getEditLog().logSync();\n-    if (status) {\n-      logAuditEvent(true, \"mkdirs\", srcArg, null, resultingStat);\n-    }\n-    return status;\n+    return fsd.getAuditFileInfo(srcArg, false);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static HdfsFileStatus mkdirs(\n      FSNamesystem fsn, String src, PermissionStatus permissions,\n      boolean createParent) throws IOException {\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    final String srcArg \u003d src;\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n    }\n    if (!DFSUtil.isValidName(src)) {\n      throw new InvalidPathException(src);\n    }\n    FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath\n        (src);\n    src \u003d fsd.resolvePath(pc, src, pathComponents);\n    if (fsd.isPermissionEnabled()) {\n      fsd.checkTraverse(pc, src);\n    }\n\n    if (!isDirMutable(fsd, src)) {\n      if (fsd.isPermissionEnabled()) {\n        fsd.checkAncestorAccess(pc, src, FsAction.WRITE);\n      }\n\n      if (!createParent) {\n        fsd.verifyParentDir(src);\n      }\n\n      // validate that we have enough inodes. This is, at best, a\n      // heuristic because the mkdirs() operation might need to\n      // create multiple inodes.\n      fsn.checkFsObjectLimit();\n\n      if (!mkdirsRecursively(fsd, src, permissions, false, now())) {\n        throw new IOException(\"Failed to create directory: \" + src);\n      }\n    }\n    return fsd.getAuditFileInfo(srcArg, false);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirMkdirOp.java",
          "extendedDetails": {
            "oldValue": "boolean",
            "newValue": "HdfsFileStatus"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-7462. Consolidate implementation of mkdirs() into a single class. Contributed by Haohui Mai.\n",
          "commitDate": "02/12/14 2:53 PM",
          "commitName": "185e0c7b4c056b88f606362c71e4a22aae7076e0",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "02/12/14 10:54 AM",
          "commitNameOld": "52bcefca8bb13d3757009f1f08203e7dca3b1e16",
          "commitAuthorOld": "Jian He",
          "daysBetweenCommits": 0.17,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,32 +1,39 @@\n-  private boolean mkdirsInt(final String srcArg, PermissionStatus permissions,\n-      boolean createParent) throws IOException, UnresolvedLinkException {\n-    String src \u003d srcArg;\n+  static HdfsFileStatus mkdirs(\n+      FSNamesystem fsn, String src, PermissionStatus permissions,\n+      boolean createParent) throws IOException {\n+    FSDirectory fsd \u003d fsn.getFSDirectory();\n+    final String srcArg \u003d src;\n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n     }\n     if (!DFSUtil.isValidName(src)) {\n       throw new InvalidPathException(src);\n     }\n-    FSPermissionChecker pc \u003d getPermissionChecker();\n-    checkOperation(OperationCategory.WRITE);\n-    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n-    HdfsFileStatus resultingStat \u003d null;\n-    boolean status \u003d false;\n-    writeLock();\n-    try {\n-      checkOperation(OperationCategory.WRITE);   \n-      checkNameNodeSafeMode(\"Cannot create directory \" + src);\n-      src \u003d dir.resolvePath(pc, src, pathComponents);\n-      status \u003d mkdirsInternal(pc, src, permissions, createParent);\n-      if (status) {\n-        resultingStat \u003d getAuditFileInfo(src, false);\n+    FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n+    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath\n+        (src);\n+    src \u003d fsd.resolvePath(pc, src, pathComponents);\n+    if (fsd.isPermissionEnabled()) {\n+      fsd.checkTraverse(pc, src);\n+    }\n+\n+    if (!isDirMutable(fsd, src)) {\n+      if (fsd.isPermissionEnabled()) {\n+        fsd.checkAncestorAccess(pc, src, FsAction.WRITE);\n       }\n-    } finally {\n-      writeUnlock();\n+\n+      if (!createParent) {\n+        fsd.verifyParentDir(src);\n+      }\n+\n+      // validate that we have enough inodes. This is, at best, a\n+      // heuristic because the mkdirs() operation might need to\n+      // create multiple inodes.\n+      fsn.checkFsObjectLimit();\n+\n+      if (!mkdirsRecursively(fsd, src, permissions, false, now())) {\n+        throw new IOException(\"Failed to create directory: \" + src);\n+      }\n     }\n-    getEditLog().logSync();\n-    if (status) {\n-      logAuditEvent(true, \"mkdirs\", srcArg, null, resultingStat);\n-    }\n-    return status;\n+    return fsd.getAuditFileInfo(srcArg, false);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static HdfsFileStatus mkdirs(\n      FSNamesystem fsn, String src, PermissionStatus permissions,\n      boolean createParent) throws IOException {\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    final String srcArg \u003d src;\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n    }\n    if (!DFSUtil.isValidName(src)) {\n      throw new InvalidPathException(src);\n    }\n    FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath\n        (src);\n    src \u003d fsd.resolvePath(pc, src, pathComponents);\n    if (fsd.isPermissionEnabled()) {\n      fsd.checkTraverse(pc, src);\n    }\n\n    if (!isDirMutable(fsd, src)) {\n      if (fsd.isPermissionEnabled()) {\n        fsd.checkAncestorAccess(pc, src, FsAction.WRITE);\n      }\n\n      if (!createParent) {\n        fsd.verifyParentDir(src);\n      }\n\n      // validate that we have enough inodes. This is, at best, a\n      // heuristic because the mkdirs() operation might need to\n      // create multiple inodes.\n      fsn.checkFsObjectLimit();\n\n      if (!mkdirsRecursively(fsd, src, permissions, false, now())) {\n        throw new IOException(\"Failed to create directory: \" + src);\n      }\n    }\n    return fsd.getAuditFileInfo(srcArg, false);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirMkdirOp.java",
          "extendedDetails": {
            "oldValue": "[private]",
            "newValue": "[static]"
          }
        },
        {
          "type": "Yexceptionschange",
          "commitMessage": "HDFS-7462. Consolidate implementation of mkdirs() into a single class. Contributed by Haohui Mai.\n",
          "commitDate": "02/12/14 2:53 PM",
          "commitName": "185e0c7b4c056b88f606362c71e4a22aae7076e0",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "02/12/14 10:54 AM",
          "commitNameOld": "52bcefca8bb13d3757009f1f08203e7dca3b1e16",
          "commitAuthorOld": "Jian He",
          "daysBetweenCommits": 0.17,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,32 +1,39 @@\n-  private boolean mkdirsInt(final String srcArg, PermissionStatus permissions,\n-      boolean createParent) throws IOException, UnresolvedLinkException {\n-    String src \u003d srcArg;\n+  static HdfsFileStatus mkdirs(\n+      FSNamesystem fsn, String src, PermissionStatus permissions,\n+      boolean createParent) throws IOException {\n+    FSDirectory fsd \u003d fsn.getFSDirectory();\n+    final String srcArg \u003d src;\n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n     }\n     if (!DFSUtil.isValidName(src)) {\n       throw new InvalidPathException(src);\n     }\n-    FSPermissionChecker pc \u003d getPermissionChecker();\n-    checkOperation(OperationCategory.WRITE);\n-    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n-    HdfsFileStatus resultingStat \u003d null;\n-    boolean status \u003d false;\n-    writeLock();\n-    try {\n-      checkOperation(OperationCategory.WRITE);   \n-      checkNameNodeSafeMode(\"Cannot create directory \" + src);\n-      src \u003d dir.resolvePath(pc, src, pathComponents);\n-      status \u003d mkdirsInternal(pc, src, permissions, createParent);\n-      if (status) {\n-        resultingStat \u003d getAuditFileInfo(src, false);\n+    FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n+    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath\n+        (src);\n+    src \u003d fsd.resolvePath(pc, src, pathComponents);\n+    if (fsd.isPermissionEnabled()) {\n+      fsd.checkTraverse(pc, src);\n+    }\n+\n+    if (!isDirMutable(fsd, src)) {\n+      if (fsd.isPermissionEnabled()) {\n+        fsd.checkAncestorAccess(pc, src, FsAction.WRITE);\n       }\n-    } finally {\n-      writeUnlock();\n+\n+      if (!createParent) {\n+        fsd.verifyParentDir(src);\n+      }\n+\n+      // validate that we have enough inodes. This is, at best, a\n+      // heuristic because the mkdirs() operation might need to\n+      // create multiple inodes.\n+      fsn.checkFsObjectLimit();\n+\n+      if (!mkdirsRecursively(fsd, src, permissions, false, now())) {\n+        throw new IOException(\"Failed to create directory: \" + src);\n+      }\n     }\n-    getEditLog().logSync();\n-    if (status) {\n-      logAuditEvent(true, \"mkdirs\", srcArg, null, resultingStat);\n-    }\n-    return status;\n+    return fsd.getAuditFileInfo(srcArg, false);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static HdfsFileStatus mkdirs(\n      FSNamesystem fsn, String src, PermissionStatus permissions,\n      boolean createParent) throws IOException {\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    final String srcArg \u003d src;\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n    }\n    if (!DFSUtil.isValidName(src)) {\n      throw new InvalidPathException(src);\n    }\n    FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath\n        (src);\n    src \u003d fsd.resolvePath(pc, src, pathComponents);\n    if (fsd.isPermissionEnabled()) {\n      fsd.checkTraverse(pc, src);\n    }\n\n    if (!isDirMutable(fsd, src)) {\n      if (fsd.isPermissionEnabled()) {\n        fsd.checkAncestorAccess(pc, src, FsAction.WRITE);\n      }\n\n      if (!createParent) {\n        fsd.verifyParentDir(src);\n      }\n\n      // validate that we have enough inodes. This is, at best, a\n      // heuristic because the mkdirs() operation might need to\n      // create multiple inodes.\n      fsn.checkFsObjectLimit();\n\n      if (!mkdirsRecursively(fsd, src, permissions, false, now())) {\n        throw new IOException(\"Failed to create directory: \" + src);\n      }\n    }\n    return fsd.getAuditFileInfo(srcArg, false);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirMkdirOp.java",
          "extendedDetails": {
            "oldValue": "[IOException, UnresolvedLinkException]",
            "newValue": "[IOException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7462. Consolidate implementation of mkdirs() into a single class. Contributed by Haohui Mai.\n",
          "commitDate": "02/12/14 2:53 PM",
          "commitName": "185e0c7b4c056b88f606362c71e4a22aae7076e0",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "02/12/14 10:54 AM",
          "commitNameOld": "52bcefca8bb13d3757009f1f08203e7dca3b1e16",
          "commitAuthorOld": "Jian He",
          "daysBetweenCommits": 0.17,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,32 +1,39 @@\n-  private boolean mkdirsInt(final String srcArg, PermissionStatus permissions,\n-      boolean createParent) throws IOException, UnresolvedLinkException {\n-    String src \u003d srcArg;\n+  static HdfsFileStatus mkdirs(\n+      FSNamesystem fsn, String src, PermissionStatus permissions,\n+      boolean createParent) throws IOException {\n+    FSDirectory fsd \u003d fsn.getFSDirectory();\n+    final String srcArg \u003d src;\n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n     }\n     if (!DFSUtil.isValidName(src)) {\n       throw new InvalidPathException(src);\n     }\n-    FSPermissionChecker pc \u003d getPermissionChecker();\n-    checkOperation(OperationCategory.WRITE);\n-    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n-    HdfsFileStatus resultingStat \u003d null;\n-    boolean status \u003d false;\n-    writeLock();\n-    try {\n-      checkOperation(OperationCategory.WRITE);   \n-      checkNameNodeSafeMode(\"Cannot create directory \" + src);\n-      src \u003d dir.resolvePath(pc, src, pathComponents);\n-      status \u003d mkdirsInternal(pc, src, permissions, createParent);\n-      if (status) {\n-        resultingStat \u003d getAuditFileInfo(src, false);\n+    FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n+    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath\n+        (src);\n+    src \u003d fsd.resolvePath(pc, src, pathComponents);\n+    if (fsd.isPermissionEnabled()) {\n+      fsd.checkTraverse(pc, src);\n+    }\n+\n+    if (!isDirMutable(fsd, src)) {\n+      if (fsd.isPermissionEnabled()) {\n+        fsd.checkAncestorAccess(pc, src, FsAction.WRITE);\n       }\n-    } finally {\n-      writeUnlock();\n+\n+      if (!createParent) {\n+        fsd.verifyParentDir(src);\n+      }\n+\n+      // validate that we have enough inodes. This is, at best, a\n+      // heuristic because the mkdirs() operation might need to\n+      // create multiple inodes.\n+      fsn.checkFsObjectLimit();\n+\n+      if (!mkdirsRecursively(fsd, src, permissions, false, now())) {\n+        throw new IOException(\"Failed to create directory: \" + src);\n+      }\n     }\n-    getEditLog().logSync();\n-    if (status) {\n-      logAuditEvent(true, \"mkdirs\", srcArg, null, resultingStat);\n-    }\n-    return status;\n+    return fsd.getAuditFileInfo(srcArg, false);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static HdfsFileStatus mkdirs(\n      FSNamesystem fsn, String src, PermissionStatus permissions,\n      boolean createParent) throws IOException {\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    final String srcArg \u003d src;\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n    }\n    if (!DFSUtil.isValidName(src)) {\n      throw new InvalidPathException(src);\n    }\n    FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath\n        (src);\n    src \u003d fsd.resolvePath(pc, src, pathComponents);\n    if (fsd.isPermissionEnabled()) {\n      fsd.checkTraverse(pc, src);\n    }\n\n    if (!isDirMutable(fsd, src)) {\n      if (fsd.isPermissionEnabled()) {\n        fsd.checkAncestorAccess(pc, src, FsAction.WRITE);\n      }\n\n      if (!createParent) {\n        fsd.verifyParentDir(src);\n      }\n\n      // validate that we have enough inodes. This is, at best, a\n      // heuristic because the mkdirs() operation might need to\n      // create multiple inodes.\n      fsn.checkFsObjectLimit();\n\n      if (!mkdirsRecursively(fsd, src, permissions, false, now())) {\n        throw new IOException(\"Failed to create directory: \" + src);\n      }\n    }\n    return fsd.getAuditFileInfo(srcArg, false);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirMkdirOp.java",
          "extendedDetails": {}
        },
        {
          "type": "Yrename",
          "commitMessage": "HDFS-7462. Consolidate implementation of mkdirs() into a single class. Contributed by Haohui Mai.\n",
          "commitDate": "02/12/14 2:53 PM",
          "commitName": "185e0c7b4c056b88f606362c71e4a22aae7076e0",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "02/12/14 10:54 AM",
          "commitNameOld": "52bcefca8bb13d3757009f1f08203e7dca3b1e16",
          "commitAuthorOld": "Jian He",
          "daysBetweenCommits": 0.17,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,32 +1,39 @@\n-  private boolean mkdirsInt(final String srcArg, PermissionStatus permissions,\n-      boolean createParent) throws IOException, UnresolvedLinkException {\n-    String src \u003d srcArg;\n+  static HdfsFileStatus mkdirs(\n+      FSNamesystem fsn, String src, PermissionStatus permissions,\n+      boolean createParent) throws IOException {\n+    FSDirectory fsd \u003d fsn.getFSDirectory();\n+    final String srcArg \u003d src;\n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n     }\n     if (!DFSUtil.isValidName(src)) {\n       throw new InvalidPathException(src);\n     }\n-    FSPermissionChecker pc \u003d getPermissionChecker();\n-    checkOperation(OperationCategory.WRITE);\n-    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n-    HdfsFileStatus resultingStat \u003d null;\n-    boolean status \u003d false;\n-    writeLock();\n-    try {\n-      checkOperation(OperationCategory.WRITE);   \n-      checkNameNodeSafeMode(\"Cannot create directory \" + src);\n-      src \u003d dir.resolvePath(pc, src, pathComponents);\n-      status \u003d mkdirsInternal(pc, src, permissions, createParent);\n-      if (status) {\n-        resultingStat \u003d getAuditFileInfo(src, false);\n+    FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n+    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath\n+        (src);\n+    src \u003d fsd.resolvePath(pc, src, pathComponents);\n+    if (fsd.isPermissionEnabled()) {\n+      fsd.checkTraverse(pc, src);\n+    }\n+\n+    if (!isDirMutable(fsd, src)) {\n+      if (fsd.isPermissionEnabled()) {\n+        fsd.checkAncestorAccess(pc, src, FsAction.WRITE);\n       }\n-    } finally {\n-      writeUnlock();\n+\n+      if (!createParent) {\n+        fsd.verifyParentDir(src);\n+      }\n+\n+      // validate that we have enough inodes. This is, at best, a\n+      // heuristic because the mkdirs() operation might need to\n+      // create multiple inodes.\n+      fsn.checkFsObjectLimit();\n+\n+      if (!mkdirsRecursively(fsd, src, permissions, false, now())) {\n+        throw new IOException(\"Failed to create directory: \" + src);\n+      }\n     }\n-    getEditLog().logSync();\n-    if (status) {\n-      logAuditEvent(true, \"mkdirs\", srcArg, null, resultingStat);\n-    }\n-    return status;\n+    return fsd.getAuditFileInfo(srcArg, false);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static HdfsFileStatus mkdirs(\n      FSNamesystem fsn, String src, PermissionStatus permissions,\n      boolean createParent) throws IOException {\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    final String srcArg \u003d src;\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n    }\n    if (!DFSUtil.isValidName(src)) {\n      throw new InvalidPathException(src);\n    }\n    FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath\n        (src);\n    src \u003d fsd.resolvePath(pc, src, pathComponents);\n    if (fsd.isPermissionEnabled()) {\n      fsd.checkTraverse(pc, src);\n    }\n\n    if (!isDirMutable(fsd, src)) {\n      if (fsd.isPermissionEnabled()) {\n        fsd.checkAncestorAccess(pc, src, FsAction.WRITE);\n      }\n\n      if (!createParent) {\n        fsd.verifyParentDir(src);\n      }\n\n      // validate that we have enough inodes. This is, at best, a\n      // heuristic because the mkdirs() operation might need to\n      // create multiple inodes.\n      fsn.checkFsObjectLimit();\n\n      if (!mkdirsRecursively(fsd, src, permissions, false, now())) {\n        throw new IOException(\"Failed to create directory: \" + src);\n      }\n    }\n    return fsd.getAuditFileInfo(srcArg, false);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirMkdirOp.java",
          "extendedDetails": {
            "oldValue": "mkdirsInt",
            "newValue": "mkdirs"
          }
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-7462. Consolidate implementation of mkdirs() into a single class. Contributed by Haohui Mai.\n",
          "commitDate": "02/12/14 2:53 PM",
          "commitName": "185e0c7b4c056b88f606362c71e4a22aae7076e0",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "02/12/14 10:54 AM",
          "commitNameOld": "52bcefca8bb13d3757009f1f08203e7dca3b1e16",
          "commitAuthorOld": "Jian He",
          "daysBetweenCommits": 0.17,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,32 +1,39 @@\n-  private boolean mkdirsInt(final String srcArg, PermissionStatus permissions,\n-      boolean createParent) throws IOException, UnresolvedLinkException {\n-    String src \u003d srcArg;\n+  static HdfsFileStatus mkdirs(\n+      FSNamesystem fsn, String src, PermissionStatus permissions,\n+      boolean createParent) throws IOException {\n+    FSDirectory fsd \u003d fsn.getFSDirectory();\n+    final String srcArg \u003d src;\n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n     }\n     if (!DFSUtil.isValidName(src)) {\n       throw new InvalidPathException(src);\n     }\n-    FSPermissionChecker pc \u003d getPermissionChecker();\n-    checkOperation(OperationCategory.WRITE);\n-    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n-    HdfsFileStatus resultingStat \u003d null;\n-    boolean status \u003d false;\n-    writeLock();\n-    try {\n-      checkOperation(OperationCategory.WRITE);   \n-      checkNameNodeSafeMode(\"Cannot create directory \" + src);\n-      src \u003d dir.resolvePath(pc, src, pathComponents);\n-      status \u003d mkdirsInternal(pc, src, permissions, createParent);\n-      if (status) {\n-        resultingStat \u003d getAuditFileInfo(src, false);\n+    FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n+    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath\n+        (src);\n+    src \u003d fsd.resolvePath(pc, src, pathComponents);\n+    if (fsd.isPermissionEnabled()) {\n+      fsd.checkTraverse(pc, src);\n+    }\n+\n+    if (!isDirMutable(fsd, src)) {\n+      if (fsd.isPermissionEnabled()) {\n+        fsd.checkAncestorAccess(pc, src, FsAction.WRITE);\n       }\n-    } finally {\n-      writeUnlock();\n+\n+      if (!createParent) {\n+        fsd.verifyParentDir(src);\n+      }\n+\n+      // validate that we have enough inodes. This is, at best, a\n+      // heuristic because the mkdirs() operation might need to\n+      // create multiple inodes.\n+      fsn.checkFsObjectLimit();\n+\n+      if (!mkdirsRecursively(fsd, src, permissions, false, now())) {\n+        throw new IOException(\"Failed to create directory: \" + src);\n+      }\n     }\n-    getEditLog().logSync();\n-    if (status) {\n-      logAuditEvent(true, \"mkdirs\", srcArg, null, resultingStat);\n-    }\n-    return status;\n+    return fsd.getAuditFileInfo(srcArg, false);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static HdfsFileStatus mkdirs(\n      FSNamesystem fsn, String src, PermissionStatus permissions,\n      boolean createParent) throws IOException {\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    final String srcArg \u003d src;\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n    }\n    if (!DFSUtil.isValidName(src)) {\n      throw new InvalidPathException(src);\n    }\n    FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath\n        (src);\n    src \u003d fsd.resolvePath(pc, src, pathComponents);\n    if (fsd.isPermissionEnabled()) {\n      fsd.checkTraverse(pc, src);\n    }\n\n    if (!isDirMutable(fsd, src)) {\n      if (fsd.isPermissionEnabled()) {\n        fsd.checkAncestorAccess(pc, src, FsAction.WRITE);\n      }\n\n      if (!createParent) {\n        fsd.verifyParentDir(src);\n      }\n\n      // validate that we have enough inodes. This is, at best, a\n      // heuristic because the mkdirs() operation might need to\n      // create multiple inodes.\n      fsn.checkFsObjectLimit();\n\n      if (!mkdirsRecursively(fsd, src, permissions, false, now())) {\n        throw new IOException(\"Failed to create directory: \" + src);\n      }\n    }\n    return fsd.getAuditFileInfo(srcArg, false);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirMkdirOp.java",
          "extendedDetails": {
            "oldValue": "[srcArg-String(modifiers-final), permissions-PermissionStatus, createParent-boolean]",
            "newValue": "[fsn-FSNamesystem, src-String, permissions-PermissionStatus, createParent-boolean]"
          }
        }
      ]
    },
    "c95b878abf313507666ea018f9e6033c4c166e10": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7415. Move FSNameSystem.resolvePath() to FSDirectory. Contributed by Haohui Mai.\n",
      "commitDate": "20/11/14 7:23 PM",
      "commitName": "c95b878abf313507666ea018f9e6033c4c166e10",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "17/11/14 5:33 PM",
      "commitNameOld": "dcb8e24427b02e2f3ff9a12d2eb1eb878e3443bb",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 3.08,
      "commitsBetweenForRepo": 22,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,32 +1,32 @@\n   private boolean mkdirsInt(final String srcArg, PermissionStatus permissions,\n       boolean createParent) throws IOException, UnresolvedLinkException {\n     String src \u003d srcArg;\n     if(NameNode.stateChangeLog.isDebugEnabled()) {\n       NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n     }\n     if (!DFSUtil.isValidName(src)) {\n       throw new InvalidPathException(src);\n     }\n     FSPermissionChecker pc \u003d getPermissionChecker();\n     checkOperation(OperationCategory.WRITE);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     HdfsFileStatus resultingStat \u003d null;\n     boolean status \u003d false;\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);   \n       checkNameNodeSafeMode(\"Cannot create directory \" + src);\n-      src \u003d resolvePath(src, pathComponents);\n+      src \u003d dir.resolvePath(pc, src, pathComponents);\n       status \u003d mkdirsInternal(pc, src, permissions, createParent);\n       if (status) {\n         resultingStat \u003d getAuditFileInfo(src, false);\n       }\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n     if (status) {\n       logAuditEvent(true, \"mkdirs\", srcArg, null, resultingStat);\n     }\n     return status;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean mkdirsInt(final String srcArg, PermissionStatus permissions,\n      boolean createParent) throws IOException, UnresolvedLinkException {\n    String src \u003d srcArg;\n    if(NameNode.stateChangeLog.isDebugEnabled()) {\n      NameNode.stateChangeLog.debug(\"DIR* NameSystem.mkdirs: \" + src);\n    }\n    if (!DFSUtil.isValidName(src)) {\n      throw new InvalidPathException(src);\n    }\n    FSPermissionChecker pc \u003d getPermissionChecker();\n    checkOperation(OperationCategory.WRITE);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    HdfsFileStatus resultingStat \u003d null;\n    boolean status \u003d false;\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);   \n      checkNameNodeSafeMode(\"Cannot create directory \" + src);\n      src \u003d dir.resolvePath(pc, src, pathComponents);\n      status \u003d mkdirsInternal(pc, src, permissions, createParent);\n      if (status) {\n        resultingStat \u003d getAuditFileInfo(src, false);\n      }\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n    if (status) {\n      logAuditEvent(true, \"mkdirs\", srcArg, null, resultingStat);\n    }\n    return status;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    }
  }
}