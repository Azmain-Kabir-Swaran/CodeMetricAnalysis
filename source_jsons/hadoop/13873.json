{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockManager.java",
  "functionName": "processMisReplicatedBlocks",
  "functionId": "processMisReplicatedBlocks___blocks-List__BlockInfo__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
  "functionStartLine": 3758,
  "functionEndLine": 3787,
  "numCommitsSeen": 477,
  "timeTaken": 3729,
  "changeHistory": [
    "f77d54c24343e6ca7c438d9db431cef14c3ae77b",
    "ffc9c50e074aeca804674c6e1e6b0f1eb629e230"
  ],
  "changeHistoryShort": {
    "f77d54c24343e6ca7c438d9db431cef14c3ae77b": "Ybodychange",
    "ffc9c50e074aeca804674c6e1e6b0f1eb629e230": "Yintroduced"
  },
  "changeHistoryDetails": {
    "f77d54c24343e6ca7c438d9db431cef14c3ae77b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14642. processMisReplicatedBlocks does not return correct processed count. Contributed by Stephen O\u0027Donnell.\n",
      "commitDate": "15/07/19 7:44 PM",
      "commitName": "f77d54c24343e6ca7c438d9db431cef14c3ae77b",
      "commitAuthor": "Ayush Saxena",
      "commitDateOld": "11/07/19 1:23 PM",
      "commitNameOld": "8fb5ca3f405550828a17e689b9c60ddf7fb95ec1",
      "commitAuthorOld": "Chen Liang",
      "daysBetweenCommits": 4.26,
      "commitsBetweenForRepo": 31,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,29 +1,30 @@\n   public int processMisReplicatedBlocks(List\u003cBlockInfo\u003e blocks) {\n     int processed \u003d 0;\n     Iterator\u003cBlockInfo\u003e iter \u003d blocks.iterator();\n \n     try {\n       while (isPopulatingReplQueues() \u0026\u0026 namesystem.isRunning()\n               \u0026\u0026 !Thread.currentThread().isInterrupted()\n               \u0026\u0026 iter.hasNext()) {\n         int limit \u003d processed + numBlocksPerIteration;\n         namesystem.writeLockInterruptibly();\n         try {\n           while (iter.hasNext() \u0026\u0026 processed \u003c limit) {\n             BlockInfo blk \u003d iter.next();\n             MisReplicationResult r \u003d processMisReplicatedBlock(blk);\n+            processed++;\n             LOG.debug(\"BLOCK* processMisReplicatedBlocks: \" +\n                     \"Re-scanned block {}, result is {}\", blk, r);\n           }\n         } finally {\n           namesystem.writeUnlock();\n         }\n       }\n     } catch (InterruptedException ex) {\n       LOG.info(\"Caught InterruptedException while scheduling replication work\" +\n               \" for mis-replicated blocks\");\n       Thread.currentThread().interrupt();\n     }\n \n     return processed;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int processMisReplicatedBlocks(List\u003cBlockInfo\u003e blocks) {\n    int processed \u003d 0;\n    Iterator\u003cBlockInfo\u003e iter \u003d blocks.iterator();\n\n    try {\n      while (isPopulatingReplQueues() \u0026\u0026 namesystem.isRunning()\n              \u0026\u0026 !Thread.currentThread().isInterrupted()\n              \u0026\u0026 iter.hasNext()) {\n        int limit \u003d processed + numBlocksPerIteration;\n        namesystem.writeLockInterruptibly();\n        try {\n          while (iter.hasNext() \u0026\u0026 processed \u003c limit) {\n            BlockInfo blk \u003d iter.next();\n            MisReplicationResult r \u003d processMisReplicatedBlock(blk);\n            processed++;\n            LOG.debug(\"BLOCK* processMisReplicatedBlocks: \" +\n                    \"Re-scanned block {}, result is {}\", blk, r);\n          }\n        } finally {\n          namesystem.writeUnlock();\n        }\n      }\n    } catch (InterruptedException ex) {\n      LOG.info(\"Caught InterruptedException while scheduling replication work\" +\n              \" for mis-replicated blocks\");\n      Thread.currentThread().interrupt();\n    }\n\n    return processed;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "ffc9c50e074aeca804674c6e1e6b0f1eb629e230": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-14053. Provide ability for NN to re-replicate based on topology changes. Contributed by Hrishikesh Gadre.\n",
      "commitDate": "05/11/18 9:38 PM",
      "commitName": "ffc9c50e074aeca804674c6e1e6b0f1eb629e230",
      "commitAuthor": "Xiao Chen",
      "diff": "@@ -0,0 +1,29 @@\n+  public int processMisReplicatedBlocks(List\u003cBlockInfo\u003e blocks) {\n+    int processed \u003d 0;\n+    Iterator\u003cBlockInfo\u003e iter \u003d blocks.iterator();\n+\n+    try {\n+      while (isPopulatingReplQueues() \u0026\u0026 namesystem.isRunning()\n+              \u0026\u0026 !Thread.currentThread().isInterrupted()\n+              \u0026\u0026 iter.hasNext()) {\n+        int limit \u003d processed + numBlocksPerIteration;\n+        namesystem.writeLockInterruptibly();\n+        try {\n+          while (iter.hasNext() \u0026\u0026 processed \u003c limit) {\n+            BlockInfo blk \u003d iter.next();\n+            MisReplicationResult r \u003d processMisReplicatedBlock(blk);\n+            LOG.debug(\"BLOCK* processMisReplicatedBlocks: \" +\n+                    \"Re-scanned block {}, result is {}\", blk, r);\n+          }\n+        } finally {\n+          namesystem.writeUnlock();\n+        }\n+      }\n+    } catch (InterruptedException ex) {\n+      LOG.info(\"Caught InterruptedException while scheduling replication work\" +\n+              \" for mis-replicated blocks\");\n+      Thread.currentThread().interrupt();\n+    }\n+\n+    return processed;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public int processMisReplicatedBlocks(List\u003cBlockInfo\u003e blocks) {\n    int processed \u003d 0;\n    Iterator\u003cBlockInfo\u003e iter \u003d blocks.iterator();\n\n    try {\n      while (isPopulatingReplQueues() \u0026\u0026 namesystem.isRunning()\n              \u0026\u0026 !Thread.currentThread().isInterrupted()\n              \u0026\u0026 iter.hasNext()) {\n        int limit \u003d processed + numBlocksPerIteration;\n        namesystem.writeLockInterruptibly();\n        try {\n          while (iter.hasNext() \u0026\u0026 processed \u003c limit) {\n            BlockInfo blk \u003d iter.next();\n            MisReplicationResult r \u003d processMisReplicatedBlock(blk);\n            LOG.debug(\"BLOCK* processMisReplicatedBlocks: \" +\n                    \"Re-scanned block {}, result is {}\", blk, r);\n          }\n        } finally {\n          namesystem.writeUnlock();\n        }\n      }\n    } catch (InterruptedException ex) {\n      LOG.info(\"Caught InterruptedException while scheduling replication work\" +\n              \" for mis-replicated blocks\");\n      Thread.currentThread().interrupt();\n    }\n\n    return processed;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java"
    }
  }
}