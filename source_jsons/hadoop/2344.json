{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "PBHelperClient.java",
  "functionName": "convert",
  "functionId": "convert___tok-Token__?__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
  "functionStartLine": 327,
  "functionEndLine": 329,
  "numCommitsSeen": 230,
  "timeTaken": 8848,
  "changeHistory": [
    "edbbc03ce7d479f1b84d9209021e9d2822909cfe",
    "8fb5ca3f405550828a17e689b9c60ddf7fb95ec1",
    "024c87291cb4cc67282fe5645fb827427cc581c6",
    "1d2640b6132e8308c07476badd2d1482be68a298",
    "c470c8953d4927043b6383fad8e792289c634c09",
    "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42",
    "251b485af5599d2cd8ba241388b5bc2713cb6645",
    "48da033901d3471ef176a94104158546152353e9",
    "7a59150bff64fc81f838de586eacd6d062172605",
    "0a713035f2fb1a222291cfdb2cbde906814c2fd9"
  ],
  "changeHistoryShort": {
    "edbbc03ce7d479f1b84d9209021e9d2822909cfe": "Ybodychange",
    "8fb5ca3f405550828a17e689b9c60ddf7fb95ec1": "Ybodychange",
    "024c87291cb4cc67282fe5645fb827427cc581c6": "Ybodychange",
    "1d2640b6132e8308c07476badd2d1482be68a298": "Ybodychange",
    "c470c8953d4927043b6383fad8e792289c634c09": "Ybodychange",
    "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42": "Ymovefromfile",
    "251b485af5599d2cd8ba241388b5bc2713cb6645": "Ymultichange(Yreturntypechange,Ybodychange)",
    "48da033901d3471ef176a94104158546152353e9": "Ymultichange(Yparameterchange,Ybodychange)",
    "7a59150bff64fc81f838de586eacd6d062172605": "Ymultichange(Yparameterchange,Yreturntypechange,Ybodychange)",
    "0a713035f2fb1a222291cfdb2cbde906814c2fd9": "Yintroduced"
  },
  "changeHistoryDetails": {
    "edbbc03ce7d479f1b84d9209021e9d2822909cfe": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16621. [pb-upgrade] Remove Protobuf classes from signatures of Public APIs. Contributed by Vinayakumar B. (#1803)\n\n",
      "commitDate": "16/01/20 9:57 AM",
      "commitName": "edbbc03ce7d479f1b84d9209021e9d2822909cfe",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "15/01/20 5:22 PM",
      "commitNameOld": "d7c4f8ab21c56a52afcfbd0a56d9120e61376d0c",
      "commitAuthorOld": "Chao Sun",
      "daysBetweenCommits": 0.69,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,8 +1,3 @@\n   public static TokenProto convert(Token\u003c?\u003e tok) {\n-    TokenProto.Builder builder \u003d TokenProto.newBuilder().\n-        setIdentifier(getByteString(tok.getIdentifier())).\n-        setPassword(getByteString(tok.getPassword())).\n-        setKindBytes(getFixedByteString(tok.getKind())).\n-        setServiceBytes(getFixedByteString(tok.getService()));\n-    return builder.build();\n+    return ProtobufHelper.protoFromToken(tok);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static TokenProto convert(Token\u003c?\u003e tok) {\n    return ProtobufHelper.protoFromToken(tok);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
      "extendedDetails": {}
    },
    "8fb5ca3f405550828a17e689b9c60ddf7fb95ec1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14611. Move handshake secret field from Token to BlockAccessToken. Contributed by Chen Liang.\n",
      "commitDate": "11/07/19 1:23 PM",
      "commitName": "8fb5ca3f405550828a17e689b9c60ddf7fb95ec1",
      "commitAuthor": "Chen Liang",
      "commitDateOld": "24/06/19 5:52 PM",
      "commitNameOld": "b76b843c8bd3906aaa5ad633d8a939aebc671907",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 16.81,
      "commitsBetweenForRepo": 83,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,8 @@\n   public static TokenProto convert(Token\u003c?\u003e tok) {\n     TokenProto.Builder builder \u003d TokenProto.newBuilder().\n         setIdentifier(getByteString(tok.getIdentifier())).\n         setPassword(getByteString(tok.getPassword())).\n         setKindBytes(getFixedByteString(tok.getKind())).\n         setServiceBytes(getFixedByteString(tok.getService()));\n-    if (tok.getDnHandshakeSecret() !\u003d null) {\n-      builder.setHandshakeSecret(\n-          ByteString.copyFrom(tok.getDnHandshakeSecret()));\n-    }\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static TokenProto convert(Token\u003c?\u003e tok) {\n    TokenProto.Builder builder \u003d TokenProto.newBuilder().\n        setIdentifier(getByteString(tok.getIdentifier())).\n        setPassword(getByteString(tok.getPassword())).\n        setKindBytes(getFixedByteString(tok.getKind())).\n        setServiceBytes(getFixedByteString(tok.getService()));\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
      "extendedDetails": {}
    },
    "024c87291cb4cc67282fe5645fb827427cc581c6": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13617. Allow wrapping NN QOP into token in encrypted message. Contributed by Chen Liang\n",
      "commitDate": "13/02/19 12:40 PM",
      "commitName": "024c87291cb4cc67282fe5645fb827427cc581c6",
      "commitAuthor": "Chen Liang",
      "commitDateOld": "10/10/18 10:23 AM",
      "commitNameOld": "bf3d591f0cb0fedeab5d89cc8d2270d3b9a70313",
      "commitAuthorOld": "Hrishikesh Gadre",
      "daysBetweenCommits": 126.14,
      "commitsBetweenForRepo": 920,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,7 +1,12 @@\n   public static TokenProto convert(Token\u003c?\u003e tok) {\n-    return TokenProto.newBuilder().\n+    TokenProto.Builder builder \u003d TokenProto.newBuilder().\n         setIdentifier(getByteString(tok.getIdentifier())).\n         setPassword(getByteString(tok.getPassword())).\n         setKindBytes(getFixedByteString(tok.getKind())).\n-        setServiceBytes(getFixedByteString(tok.getService())).build();\n+        setServiceBytes(getFixedByteString(tok.getService()));\n+    if (tok.getDnHandshakeSecret() !\u003d null) {\n+      builder.setHandshakeSecret(\n+          ByteString.copyFrom(tok.getDnHandshakeSecret()));\n+    }\n+    return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static TokenProto convert(Token\u003c?\u003e tok) {\n    TokenProto.Builder builder \u003d TokenProto.newBuilder().\n        setIdentifier(getByteString(tok.getIdentifier())).\n        setPassword(getByteString(tok.getPassword())).\n        setKindBytes(getFixedByteString(tok.getKind())).\n        setServiceBytes(getFixedByteString(tok.getService()));\n    if (tok.getDnHandshakeSecret() !\u003d null) {\n      builder.setHandshakeSecret(\n          ByteString.copyFrom(tok.getDnHandshakeSecret()));\n    }\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
      "extendedDetails": {}
    },
    "1d2640b6132e8308c07476badd2d1482be68a298": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13601. Optimize ByteString conversions in PBHelper.\n",
      "commitDate": "22/05/18 11:55 PM",
      "commitName": "1d2640b6132e8308c07476badd2d1482be68a298",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "26/04/18 5:36 AM",
      "commitNameOld": "0ec88ea42be7178d5fbc832ac393ded6c2aca8c8",
      "commitAuthorOld": "Nanda kumar",
      "daysBetweenCommits": 26.76,
      "commitsBetweenForRepo": 232,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,7 +1,7 @@\n   public static TokenProto convert(Token\u003c?\u003e tok) {\n     return TokenProto.newBuilder().\n         setIdentifier(getByteString(tok.getIdentifier())).\n         setPassword(getByteString(tok.getPassword())).\n-        setKind(tok.getKind().toString()).\n-        setService(tok.getService().toString()).build();\n+        setKindBytes(getFixedByteString(tok.getKind())).\n+        setServiceBytes(getFixedByteString(tok.getService())).build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static TokenProto convert(Token\u003c?\u003e tok) {\n    return TokenProto.newBuilder().\n        setIdentifier(getByteString(tok.getIdentifier())).\n        setPassword(getByteString(tok.getPassword())).\n        setKindBytes(getFixedByteString(tok.getKind())).\n        setServiceBytes(getFixedByteString(tok.getService())).build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
      "extendedDetails": {}
    },
    "c470c8953d4927043b6383fad8e792289c634c09": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9557. Reduce object allocation in PB conversion. Contributed by Daryn Sharp.\n",
      "commitDate": "16/12/15 11:10 AM",
      "commitName": "c470c8953d4927043b6383fad8e792289c634c09",
      "commitAuthor": "cnauroth",
      "commitDateOld": "23/11/15 10:50 AM",
      "commitNameOld": "298a8cb096906b5d688842f6520e90dc9779f0b3",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 23.01,
      "commitsBetweenForRepo": 138,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,7 +1,7 @@\n   public static TokenProto convert(Token\u003c?\u003e tok) {\n     return TokenProto.newBuilder().\n-        setIdentifier(ByteString.copyFrom(tok.getIdentifier())).\n-        setPassword(ByteString.copyFrom(tok.getPassword())).\n+        setIdentifier(getByteString(tok.getIdentifier())).\n+        setPassword(getByteString(tok.getPassword())).\n         setKind(tok.getKind().toString()).\n         setService(tok.getService().toString()).build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static TokenProto convert(Token\u003c?\u003e tok) {\n    return TokenProto.newBuilder().\n        setIdentifier(getByteString(tok.getIdentifier())).\n        setPassword(getByteString(tok.getPassword())).\n        setKind(tok.getKind().toString()).\n        setService(tok.getService().toString()).build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
      "extendedDetails": {}
    },
    "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42": {
      "type": "Ymovefromfile",
      "commitMessage": "HDFS-8934. Move ShortCircuitShm to hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "22/08/15 1:31 PM",
      "commitName": "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "22/08/15 12:39 AM",
      "commitNameOld": "61bf9cae6f3882c6e9a9222f59457b9be91e3018",
      "commitAuthorOld": "Karthik Kambatla",
      "daysBetweenCommits": 0.54,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,7 +1,7 @@\n   public static TokenProto convert(Token\u003c?\u003e tok) {\n     return TokenProto.newBuilder().\n-              setIdentifier(ByteString.copyFrom(tok.getIdentifier())).\n-              setPassword(ByteString.copyFrom(tok.getPassword())).\n-              setKind(tok.getKind().toString()).\n-              setService(tok.getService().toString()).build(); \n+      setIdentifier(ByteString.copyFrom(tok.getIdentifier())).\n+      setPassword(ByteString.copyFrom(tok.getPassword())).\n+      setKind(tok.getKind().toString()).\n+      setService(tok.getService().toString()).build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static TokenProto convert(Token\u003c?\u003e tok) {\n    return TokenProto.newBuilder().\n      setIdentifier(ByteString.copyFrom(tok.getIdentifier())).\n      setPassword(ByteString.copyFrom(tok.getPassword())).\n      setKind(tok.getKind().toString()).\n      setService(tok.getService().toString()).build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
        "oldMethodName": "convert",
        "newMethodName": "convert"
      }
    },
    "251b485af5599d2cd8ba241388b5bc2713cb6645": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HADOOP-9173. Add security token protobuf definition to common and use it in hdfs. Contributed by Suresh Srinivas.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1428972 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/01/13 8:49 AM",
      "commitName": "251b485af5599d2cd8ba241388b5bc2713cb6645",
      "commitAuthor": "Suresh Srinivas",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HADOOP-9173. Add security token protobuf definition to common and use it in hdfs. Contributed by Suresh Srinivas.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1428972 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "04/01/13 8:49 AM",
          "commitName": "251b485af5599d2cd8ba241388b5bc2713cb6645",
          "commitAuthor": "Suresh Srinivas",
          "commitDateOld": "05/12/12 11:20 PM",
          "commitNameOld": "8bb0dc34e4f14698bea104be6294acb4954358ca",
          "commitAuthorOld": "Konstantin Shvachko",
          "daysBetweenCommits": 29.4,
          "commitsBetweenForRepo": 102,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,7 +1,7 @@\n-  public static BlockTokenIdentifierProto convert(Token\u003c?\u003e tok) {\n-    return BlockTokenIdentifierProto.newBuilder().\n+  public static TokenProto convert(Token\u003c?\u003e tok) {\n+    return TokenProto.newBuilder().\n               setIdentifier(ByteString.copyFrom(tok.getIdentifier())).\n               setPassword(ByteString.copyFrom(tok.getPassword())).\n               setKind(tok.getKind().toString()).\n               setService(tok.getService().toString()).build(); \n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static TokenProto convert(Token\u003c?\u003e tok) {\n    return TokenProto.newBuilder().\n              setIdentifier(ByteString.copyFrom(tok.getIdentifier())).\n              setPassword(ByteString.copyFrom(tok.getPassword())).\n              setKind(tok.getKind().toString()).\n              setService(tok.getService().toString()).build(); \n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
          "extendedDetails": {
            "oldValue": "BlockTokenIdentifierProto",
            "newValue": "TokenProto"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-9173. Add security token protobuf definition to common and use it in hdfs. Contributed by Suresh Srinivas.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1428972 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "04/01/13 8:49 AM",
          "commitName": "251b485af5599d2cd8ba241388b5bc2713cb6645",
          "commitAuthor": "Suresh Srinivas",
          "commitDateOld": "05/12/12 11:20 PM",
          "commitNameOld": "8bb0dc34e4f14698bea104be6294acb4954358ca",
          "commitAuthorOld": "Konstantin Shvachko",
          "daysBetweenCommits": 29.4,
          "commitsBetweenForRepo": 102,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,7 +1,7 @@\n-  public static BlockTokenIdentifierProto convert(Token\u003c?\u003e tok) {\n-    return BlockTokenIdentifierProto.newBuilder().\n+  public static TokenProto convert(Token\u003c?\u003e tok) {\n+    return TokenProto.newBuilder().\n               setIdentifier(ByteString.copyFrom(tok.getIdentifier())).\n               setPassword(ByteString.copyFrom(tok.getPassword())).\n               setKind(tok.getKind().toString()).\n               setService(tok.getService().toString()).build(); \n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static TokenProto convert(Token\u003c?\u003e tok) {\n    return TokenProto.newBuilder().\n              setIdentifier(ByteString.copyFrom(tok.getIdentifier())).\n              setPassword(ByteString.copyFrom(tok.getPassword())).\n              setKind(tok.getKind().toString()).\n              setService(tok.getService().toString()).build(); \n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
          "extendedDetails": {}
        }
      ]
    },
    "48da033901d3471ef176a94104158546152353e9": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "    HDFS-2651 ClientNameNodeProtocol Translators for Protocol Buffers (sanjay)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1213143 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/12/11 9:36 PM",
      "commitName": "48da033901d3471ef176a94104158546152353e9",
      "commitAuthor": "Sanjay Radia",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "    HDFS-2651 ClientNameNodeProtocol Translators for Protocol Buffers (sanjay)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1213143 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "11/12/11 9:36 PM",
          "commitName": "48da033901d3471ef176a94104158546152353e9",
          "commitAuthor": "Sanjay Radia",
          "commitDateOld": "11/12/11 10:53 AM",
          "commitNameOld": "2740112bb64e1cc8132a1dc450d9e461c2e4729e",
          "commitAuthorOld": "Suresh Srinivas",
          "daysBetweenCommits": 0.45,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,8 +1,7 @@\n-  public static BlockTokenIdentifierProto convert(\n-      Token\u003cBlockTokenIdentifier\u003e token) {\n-    ByteString tokenId \u003d ByteString.copyFrom(token.getIdentifier());\n-    ByteString password \u003d ByteString.copyFrom(token.getPassword());\n-    return BlockTokenIdentifierProto.newBuilder().setIdentifier(tokenId)\n-        .setKind(token.getKind().toString()).setPassword(password)\n-        .setService(token.getService().toString()).build();\n+  public static BlockTokenIdentifierProto convert(Token\u003c?\u003e tok) {\n+    return BlockTokenIdentifierProto.newBuilder().\n+              setIdentifier(ByteString.copyFrom(tok.getIdentifier())).\n+              setPassword(ByteString.copyFrom(tok.getPassword())).\n+              setKind(tok.getKind().toString()).\n+              setService(tok.getService().toString()).build(); \n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static BlockTokenIdentifierProto convert(Token\u003c?\u003e tok) {\n    return BlockTokenIdentifierProto.newBuilder().\n              setIdentifier(ByteString.copyFrom(tok.getIdentifier())).\n              setPassword(ByteString.copyFrom(tok.getPassword())).\n              setKind(tok.getKind().toString()).\n              setService(tok.getService().toString()).build(); \n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
          "extendedDetails": {
            "oldValue": "[token-Token\u003cBlockTokenIdentifier\u003e]",
            "newValue": "[tok-Token\u003c?\u003e]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "    HDFS-2651 ClientNameNodeProtocol Translators for Protocol Buffers (sanjay)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1213143 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "11/12/11 9:36 PM",
          "commitName": "48da033901d3471ef176a94104158546152353e9",
          "commitAuthor": "Sanjay Radia",
          "commitDateOld": "11/12/11 10:53 AM",
          "commitNameOld": "2740112bb64e1cc8132a1dc450d9e461c2e4729e",
          "commitAuthorOld": "Suresh Srinivas",
          "daysBetweenCommits": 0.45,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,8 +1,7 @@\n-  public static BlockTokenIdentifierProto convert(\n-      Token\u003cBlockTokenIdentifier\u003e token) {\n-    ByteString tokenId \u003d ByteString.copyFrom(token.getIdentifier());\n-    ByteString password \u003d ByteString.copyFrom(token.getPassword());\n-    return BlockTokenIdentifierProto.newBuilder().setIdentifier(tokenId)\n-        .setKind(token.getKind().toString()).setPassword(password)\n-        .setService(token.getService().toString()).build();\n+  public static BlockTokenIdentifierProto convert(Token\u003c?\u003e tok) {\n+    return BlockTokenIdentifierProto.newBuilder().\n+              setIdentifier(ByteString.copyFrom(tok.getIdentifier())).\n+              setPassword(ByteString.copyFrom(tok.getPassword())).\n+              setKind(tok.getKind().toString()).\n+              setService(tok.getService().toString()).build(); \n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static BlockTokenIdentifierProto convert(Token\u003c?\u003e tok) {\n    return BlockTokenIdentifierProto.newBuilder().\n              setIdentifier(ByteString.copyFrom(tok.getIdentifier())).\n              setPassword(ByteString.copyFrom(tok.getPassword())).\n              setKind(tok.getKind().toString()).\n              setService(tok.getService().toString()).build(); \n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
          "extendedDetails": {}
        }
      ]
    },
    "7a59150bff64fc81f838de586eacd6d062172605": {
      "type": "Ymultichange(Yparameterchange,Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-2629. Implement protobuf service for InterDatanodeProtocol. Contributed by Suresh Srinivas.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1211206 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/12/11 2:19 PM",
      "commitName": "7a59150bff64fc81f838de586eacd6d062172605",
      "commitAuthor": "Suresh Srinivas",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-2629. Implement protobuf service for InterDatanodeProtocol. Contributed by Suresh Srinivas.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1211206 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "06/12/11 2:19 PM",
          "commitName": "7a59150bff64fc81f838de586eacd6d062172605",
          "commitAuthor": "Suresh Srinivas",
          "commitDateOld": "05/12/11 4:25 PM",
          "commitNameOld": "0a713035f2fb1a222291cfdb2cbde906814c2fd9",
          "commitAuthorOld": "Suresh Srinivas",
          "daysBetweenCommits": 0.91,
          "commitsBetweenForRepo": 5,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,8 +1,8 @@\n-  public static BlockWithLocations[] convert(List\u003cBlockWithLocationsProto\u003e b) {\n-    BlockWithLocations[] ret \u003d new BlockWithLocations[b.size()];\n-    int i \u003d 0;\n-    for (BlockWithLocationsProto entry : b) {\n-      ret[i++] \u003d convert(entry);\n-    }\n-    return ret;\n+  public static BlockTokenIdentifierProto convert(\n+      Token\u003cBlockTokenIdentifier\u003e token) {\n+    ByteString tokenId \u003d ByteString.copyFrom(token.getIdentifier());\n+    ByteString password \u003d ByteString.copyFrom(token.getPassword());\n+    return BlockTokenIdentifierProto.newBuilder().setIdentifier(tokenId)\n+        .setKind(token.getKind().toString()).setPassword(password)\n+        .setService(token.getService().toString()).build();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static BlockTokenIdentifierProto convert(\n      Token\u003cBlockTokenIdentifier\u003e token) {\n    ByteString tokenId \u003d ByteString.copyFrom(token.getIdentifier());\n    ByteString password \u003d ByteString.copyFrom(token.getPassword());\n    return BlockTokenIdentifierProto.newBuilder().setIdentifier(tokenId)\n        .setKind(token.getKind().toString()).setPassword(password)\n        .setService(token.getService().toString()).build();\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
          "extendedDetails": {
            "oldValue": "[b-List\u003cBlockWithLocationsProto\u003e]",
            "newValue": "[token-Token\u003cBlockTokenIdentifier\u003e]"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-2629. Implement protobuf service for InterDatanodeProtocol. Contributed by Suresh Srinivas.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1211206 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "06/12/11 2:19 PM",
          "commitName": "7a59150bff64fc81f838de586eacd6d062172605",
          "commitAuthor": "Suresh Srinivas",
          "commitDateOld": "05/12/11 4:25 PM",
          "commitNameOld": "0a713035f2fb1a222291cfdb2cbde906814c2fd9",
          "commitAuthorOld": "Suresh Srinivas",
          "daysBetweenCommits": 0.91,
          "commitsBetweenForRepo": 5,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,8 +1,8 @@\n-  public static BlockWithLocations[] convert(List\u003cBlockWithLocationsProto\u003e b) {\n-    BlockWithLocations[] ret \u003d new BlockWithLocations[b.size()];\n-    int i \u003d 0;\n-    for (BlockWithLocationsProto entry : b) {\n-      ret[i++] \u003d convert(entry);\n-    }\n-    return ret;\n+  public static BlockTokenIdentifierProto convert(\n+      Token\u003cBlockTokenIdentifier\u003e token) {\n+    ByteString tokenId \u003d ByteString.copyFrom(token.getIdentifier());\n+    ByteString password \u003d ByteString.copyFrom(token.getPassword());\n+    return BlockTokenIdentifierProto.newBuilder().setIdentifier(tokenId)\n+        .setKind(token.getKind().toString()).setPassword(password)\n+        .setService(token.getService().toString()).build();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static BlockTokenIdentifierProto convert(\n      Token\u003cBlockTokenIdentifier\u003e token) {\n    ByteString tokenId \u003d ByteString.copyFrom(token.getIdentifier());\n    ByteString password \u003d ByteString.copyFrom(token.getPassword());\n    return BlockTokenIdentifierProto.newBuilder().setIdentifier(tokenId)\n        .setKind(token.getKind().toString()).setPassword(password)\n        .setService(token.getService().toString()).build();\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
          "extendedDetails": {
            "oldValue": "BlockWithLocations[]",
            "newValue": "BlockTokenIdentifierProto"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-2629. Implement protobuf service for InterDatanodeProtocol. Contributed by Suresh Srinivas.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1211206 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "06/12/11 2:19 PM",
          "commitName": "7a59150bff64fc81f838de586eacd6d062172605",
          "commitAuthor": "Suresh Srinivas",
          "commitDateOld": "05/12/11 4:25 PM",
          "commitNameOld": "0a713035f2fb1a222291cfdb2cbde906814c2fd9",
          "commitAuthorOld": "Suresh Srinivas",
          "daysBetweenCommits": 0.91,
          "commitsBetweenForRepo": 5,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,8 +1,8 @@\n-  public static BlockWithLocations[] convert(List\u003cBlockWithLocationsProto\u003e b) {\n-    BlockWithLocations[] ret \u003d new BlockWithLocations[b.size()];\n-    int i \u003d 0;\n-    for (BlockWithLocationsProto entry : b) {\n-      ret[i++] \u003d convert(entry);\n-    }\n-    return ret;\n+  public static BlockTokenIdentifierProto convert(\n+      Token\u003cBlockTokenIdentifier\u003e token) {\n+    ByteString tokenId \u003d ByteString.copyFrom(token.getIdentifier());\n+    ByteString password \u003d ByteString.copyFrom(token.getPassword());\n+    return BlockTokenIdentifierProto.newBuilder().setIdentifier(tokenId)\n+        .setKind(token.getKind().toString()).setPassword(password)\n+        .setService(token.getService().toString()).build();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static BlockTokenIdentifierProto convert(\n      Token\u003cBlockTokenIdentifier\u003e token) {\n    ByteString tokenId \u003d ByteString.copyFrom(token.getIdentifier());\n    ByteString password \u003d ByteString.copyFrom(token.getPassword());\n    return BlockTokenIdentifierProto.newBuilder().setIdentifier(tokenId)\n        .setKind(token.getKind().toString()).setPassword(password)\n        .setService(token.getService().toString()).build();\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
          "extendedDetails": {}
        }
      ]
    },
    "0a713035f2fb1a222291cfdb2cbde906814c2fd9": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-2618. Implement protobuf service for NamenodeProtocol. Contributed by Suresh Srinivas.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1210719 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "05/12/11 4:25 PM",
      "commitName": "0a713035f2fb1a222291cfdb2cbde906814c2fd9",
      "commitAuthor": "Suresh Srinivas",
      "diff": "@@ -0,0 +1,8 @@\n+  public static BlockWithLocations[] convert(List\u003cBlockWithLocationsProto\u003e b) {\n+    BlockWithLocations[] ret \u003d new BlockWithLocations[b.size()];\n+    int i \u003d 0;\n+    for (BlockWithLocationsProto entry : b) {\n+      ret[i++] \u003d convert(entry);\n+    }\n+    return ret;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public static BlockWithLocations[] convert(List\u003cBlockWithLocationsProto\u003e b) {\n    BlockWithLocations[] ret \u003d new BlockWithLocations[b.size()];\n    int i \u003d 0;\n    for (BlockWithLocationsProto entry : b) {\n      ret[i++] \u003d convert(entry);\n    }\n    return ret;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java"
    }
  }
}