{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "JobHistory.java",
  "functionName": "serviceStart",
  "functionId": "serviceStart",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
  "functionStartLine": 125,
  "functionEndLine": 141,
  "numCommitsSeen": 54,
  "timeTaken": 8541,
  "changeHistory": [
    "2440671a117f165dcda5056404bc898df3c50803",
    "8fa3ebd13451a243510eed5c2f3dd43cdf605a77",
    "0928502029ef141759008997335ea2cd836a7154",
    "7d04a96027ad75877b41b7cd8f67455dd13159d7",
    "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f",
    "68328ae92632afc9cdd6e75b7a8d832723ddbe3b",
    "fafe8cd28e726566509c679e19d7da622f29f90d",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517"
  ],
  "changeHistoryShort": {
    "2440671a117f165dcda5056404bc898df3c50803": "Ybodychange",
    "8fa3ebd13451a243510eed5c2f3dd43cdf605a77": "Ybodychange",
    "0928502029ef141759008997335ea2cd836a7154": "Ymultichange(Yrename,Ymodifierchange,Yexceptionschange,Ybodychange)",
    "7d04a96027ad75877b41b7cd8f67455dd13159d7": "Ybodychange",
    "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f": "Ybodychange",
    "68328ae92632afc9cdd6e75b7a8d832723ddbe3b": "Ybodychange",
    "fafe8cd28e726566509c679e19d7da622f29f90d": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yintroduced"
  },
  "changeHistoryDetails": {
    "2440671a117f165dcda5056404bc898df3c50803": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6634. Log uncaught exceptions/errors in various thread pools in mapreduce. Contributed by Sidharta Seethana.\n",
      "commitDate": "18/02/16 12:48 AM",
      "commitName": "2440671a117f165dcda5056404bc898df3c50803",
      "commitAuthor": "Varun Vasudev",
      "commitDateOld": "11/05/15 3:37 PM",
      "commitNameOld": "444836b3dcd3ee28238af7b5e753d644e8095788",
      "commitAuthorOld": "Jason Lowe",
      "daysBetweenCommits": 282.42,
      "commitsBetweenForRepo": 2094,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n   protected void serviceStart() throws Exception {\n     hsManager.start();\n     if (storage instanceof Service) {\n       ((Service) storage).start();\n     }\n \n-    scheduledExecutor \u003d new ScheduledThreadPoolExecutor(2,\n+    scheduledExecutor \u003d new HadoopScheduledThreadPoolExecutor(2,\n         new ThreadFactoryBuilder().setNameFormat(\"Log Scanner/Cleaner #%d\")\n             .build());\n \n     scheduledExecutor.scheduleAtFixedRate(new MoveIntermediateToDoneRunnable(),\n         moveThreadInterval, moveThreadInterval, TimeUnit.MILLISECONDS);\n \n     // Start historyCleaner\n     scheduleHistoryCleaner();\n     super.serviceStart();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void serviceStart() throws Exception {\n    hsManager.start();\n    if (storage instanceof Service) {\n      ((Service) storage).start();\n    }\n\n    scheduledExecutor \u003d new HadoopScheduledThreadPoolExecutor(2,\n        new ThreadFactoryBuilder().setNameFormat(\"Log Scanner/Cleaner #%d\")\n            .build());\n\n    scheduledExecutor.scheduleAtFixedRate(new MoveIntermediateToDoneRunnable(),\n        moveThreadInterval, moveThreadInterval, TimeUnit.MILLISECONDS);\n\n    // Start historyCleaner\n    scheduleHistoryCleaner();\n    super.serviceStart();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
      "extendedDetails": {}
    },
    "8fa3ebd13451a243510eed5c2f3dd43cdf605a77": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5386. Ability to refresh history server job retention and job cleaner settings. Contributed by Ashwin Shankar\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1507135 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/07/13 2:27 PM",
      "commitName": "8fa3ebd13451a243510eed5c2f3dd43cdf605a77",
      "commitAuthor": "Jason Darrell Lowe",
      "commitDateOld": "20/06/13 5:08 PM",
      "commitNameOld": "1a06175440eec7994d6b63b0e5ac8b6532870fb3",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 34.89,
      "commitsBetweenForRepo": 172,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,17 @@\n   protected void serviceStart() throws Exception {\n     hsManager.start();\n     if (storage instanceof Service) {\n       ((Service) storage).start();\n     }\n \n     scheduledExecutor \u003d new ScheduledThreadPoolExecutor(2,\n         new ThreadFactoryBuilder().setNameFormat(\"Log Scanner/Cleaner #%d\")\n             .build());\n \n     scheduledExecutor.scheduleAtFixedRate(new MoveIntermediateToDoneRunnable(),\n         moveThreadInterval, moveThreadInterval, TimeUnit.MILLISECONDS);\n \n     // Start historyCleaner\n-    boolean startCleanerService \u003d conf.getBoolean(\n-        JHAdminConfig.MR_HISTORY_CLEANER_ENABLE, true);\n-    if (startCleanerService) {\n-      long runInterval \u003d conf.getLong(\n-          JHAdminConfig.MR_HISTORY_CLEANER_INTERVAL_MS,\n-          JHAdminConfig.DEFAULT_MR_HISTORY_CLEANER_INTERVAL_MS);\n-      scheduledExecutor\n-          .scheduleAtFixedRate(new HistoryCleaner(),\n-              30 * 1000l, runInterval, TimeUnit.MILLISECONDS);\n-    }\n+    scheduleHistoryCleaner();\n     super.serviceStart();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void serviceStart() throws Exception {\n    hsManager.start();\n    if (storage instanceof Service) {\n      ((Service) storage).start();\n    }\n\n    scheduledExecutor \u003d new ScheduledThreadPoolExecutor(2,\n        new ThreadFactoryBuilder().setNameFormat(\"Log Scanner/Cleaner #%d\")\n            .build());\n\n    scheduledExecutor.scheduleAtFixedRate(new MoveIntermediateToDoneRunnable(),\n        moveThreadInterval, moveThreadInterval, TimeUnit.MILLISECONDS);\n\n    // Start historyCleaner\n    scheduleHistoryCleaner();\n    super.serviceStart();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
      "extendedDetails": {}
    },
    "0928502029ef141759008997335ea2cd836a7154": {
      "type": "Ymultichange(Yrename,Ymodifierchange,Yexceptionschange,Ybodychange)",
      "commitMessage": "YARN-530. Defined Service model strictly, implemented AbstractService for robust subclassing and migrated yarn-common services. Contributed by Steve Loughran.\nYARN-117. Migrated rest of YARN to the new service model. Contributed by Steve Louhran.\nMAPREDUCE-5298. Moved MapReduce services to YARN-530 stricter lifecycle. Contributed by Steve Loughran.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1492718 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/06/13 8:54 AM",
      "commitName": "0928502029ef141759008997335ea2cd836a7154",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "YARN-530. Defined Service model strictly, implemented AbstractService for robust subclassing and migrated yarn-common services. Contributed by Steve Loughran.\nYARN-117. Migrated rest of YARN to the new service model. Contributed by Steve Louhran.\nMAPREDUCE-5298. Moved MapReduce services to YARN-530 stricter lifecycle. Contributed by Steve Loughran.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1492718 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/06/13 8:54 AM",
          "commitName": "0928502029ef141759008997335ea2cd836a7154",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "03/06/13 9:05 PM",
          "commitNameOld": "a83fb61ac07c0468cbc7a38526e92683883dd932",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 9.49,
          "commitsBetweenForRepo": 61,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,26 +1,26 @@\n-  public void start() {\n+  protected void serviceStart() throws Exception {\n     hsManager.start();\n     if (storage instanceof Service) {\n       ((Service) storage).start();\n     }\n \n     scheduledExecutor \u003d new ScheduledThreadPoolExecutor(2,\n         new ThreadFactoryBuilder().setNameFormat(\"Log Scanner/Cleaner #%d\")\n             .build());\n \n     scheduledExecutor.scheduleAtFixedRate(new MoveIntermediateToDoneRunnable(),\n         moveThreadInterval, moveThreadInterval, TimeUnit.MILLISECONDS);\n \n     // Start historyCleaner\n     boolean startCleanerService \u003d conf.getBoolean(\n         JHAdminConfig.MR_HISTORY_CLEANER_ENABLE, true);\n     if (startCleanerService) {\n       long runInterval \u003d conf.getLong(\n           JHAdminConfig.MR_HISTORY_CLEANER_INTERVAL_MS,\n           JHAdminConfig.DEFAULT_MR_HISTORY_CLEANER_INTERVAL_MS);\n       scheduledExecutor\n           .scheduleAtFixedRate(new HistoryCleaner(),\n               30 * 1000l, runInterval, TimeUnit.MILLISECONDS);\n     }\n-    super.start();\n+    super.serviceStart();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void serviceStart() throws Exception {\n    hsManager.start();\n    if (storage instanceof Service) {\n      ((Service) storage).start();\n    }\n\n    scheduledExecutor \u003d new ScheduledThreadPoolExecutor(2,\n        new ThreadFactoryBuilder().setNameFormat(\"Log Scanner/Cleaner #%d\")\n            .build());\n\n    scheduledExecutor.scheduleAtFixedRate(new MoveIntermediateToDoneRunnable(),\n        moveThreadInterval, moveThreadInterval, TimeUnit.MILLISECONDS);\n\n    // Start historyCleaner\n    boolean startCleanerService \u003d conf.getBoolean(\n        JHAdminConfig.MR_HISTORY_CLEANER_ENABLE, true);\n    if (startCleanerService) {\n      long runInterval \u003d conf.getLong(\n          JHAdminConfig.MR_HISTORY_CLEANER_INTERVAL_MS,\n          JHAdminConfig.DEFAULT_MR_HISTORY_CLEANER_INTERVAL_MS);\n      scheduledExecutor\n          .scheduleAtFixedRate(new HistoryCleaner(),\n              30 * 1000l, runInterval, TimeUnit.MILLISECONDS);\n    }\n    super.serviceStart();\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
          "extendedDetails": {
            "oldValue": "start",
            "newValue": "serviceStart"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "YARN-530. Defined Service model strictly, implemented AbstractService for robust subclassing and migrated yarn-common services. Contributed by Steve Loughran.\nYARN-117. Migrated rest of YARN to the new service model. Contributed by Steve Louhran.\nMAPREDUCE-5298. Moved MapReduce services to YARN-530 stricter lifecycle. Contributed by Steve Loughran.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1492718 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/06/13 8:54 AM",
          "commitName": "0928502029ef141759008997335ea2cd836a7154",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "03/06/13 9:05 PM",
          "commitNameOld": "a83fb61ac07c0468cbc7a38526e92683883dd932",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 9.49,
          "commitsBetweenForRepo": 61,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,26 +1,26 @@\n-  public void start() {\n+  protected void serviceStart() throws Exception {\n     hsManager.start();\n     if (storage instanceof Service) {\n       ((Service) storage).start();\n     }\n \n     scheduledExecutor \u003d new ScheduledThreadPoolExecutor(2,\n         new ThreadFactoryBuilder().setNameFormat(\"Log Scanner/Cleaner #%d\")\n             .build());\n \n     scheduledExecutor.scheduleAtFixedRate(new MoveIntermediateToDoneRunnable(),\n         moveThreadInterval, moveThreadInterval, TimeUnit.MILLISECONDS);\n \n     // Start historyCleaner\n     boolean startCleanerService \u003d conf.getBoolean(\n         JHAdminConfig.MR_HISTORY_CLEANER_ENABLE, true);\n     if (startCleanerService) {\n       long runInterval \u003d conf.getLong(\n           JHAdminConfig.MR_HISTORY_CLEANER_INTERVAL_MS,\n           JHAdminConfig.DEFAULT_MR_HISTORY_CLEANER_INTERVAL_MS);\n       scheduledExecutor\n           .scheduleAtFixedRate(new HistoryCleaner(),\n               30 * 1000l, runInterval, TimeUnit.MILLISECONDS);\n     }\n-    super.start();\n+    super.serviceStart();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void serviceStart() throws Exception {\n    hsManager.start();\n    if (storage instanceof Service) {\n      ((Service) storage).start();\n    }\n\n    scheduledExecutor \u003d new ScheduledThreadPoolExecutor(2,\n        new ThreadFactoryBuilder().setNameFormat(\"Log Scanner/Cleaner #%d\")\n            .build());\n\n    scheduledExecutor.scheduleAtFixedRate(new MoveIntermediateToDoneRunnable(),\n        moveThreadInterval, moveThreadInterval, TimeUnit.MILLISECONDS);\n\n    // Start historyCleaner\n    boolean startCleanerService \u003d conf.getBoolean(\n        JHAdminConfig.MR_HISTORY_CLEANER_ENABLE, true);\n    if (startCleanerService) {\n      long runInterval \u003d conf.getLong(\n          JHAdminConfig.MR_HISTORY_CLEANER_INTERVAL_MS,\n          JHAdminConfig.DEFAULT_MR_HISTORY_CLEANER_INTERVAL_MS);\n      scheduledExecutor\n          .scheduleAtFixedRate(new HistoryCleaner(),\n              30 * 1000l, runInterval, TimeUnit.MILLISECONDS);\n    }\n    super.serviceStart();\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
          "extendedDetails": {
            "oldValue": "[public]",
            "newValue": "[protected]"
          }
        },
        {
          "type": "Yexceptionschange",
          "commitMessage": "YARN-530. Defined Service model strictly, implemented AbstractService for robust subclassing and migrated yarn-common services. Contributed by Steve Loughran.\nYARN-117. Migrated rest of YARN to the new service model. Contributed by Steve Louhran.\nMAPREDUCE-5298. Moved MapReduce services to YARN-530 stricter lifecycle. Contributed by Steve Loughran.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1492718 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/06/13 8:54 AM",
          "commitName": "0928502029ef141759008997335ea2cd836a7154",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "03/06/13 9:05 PM",
          "commitNameOld": "a83fb61ac07c0468cbc7a38526e92683883dd932",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 9.49,
          "commitsBetweenForRepo": 61,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,26 +1,26 @@\n-  public void start() {\n+  protected void serviceStart() throws Exception {\n     hsManager.start();\n     if (storage instanceof Service) {\n       ((Service) storage).start();\n     }\n \n     scheduledExecutor \u003d new ScheduledThreadPoolExecutor(2,\n         new ThreadFactoryBuilder().setNameFormat(\"Log Scanner/Cleaner #%d\")\n             .build());\n \n     scheduledExecutor.scheduleAtFixedRate(new MoveIntermediateToDoneRunnable(),\n         moveThreadInterval, moveThreadInterval, TimeUnit.MILLISECONDS);\n \n     // Start historyCleaner\n     boolean startCleanerService \u003d conf.getBoolean(\n         JHAdminConfig.MR_HISTORY_CLEANER_ENABLE, true);\n     if (startCleanerService) {\n       long runInterval \u003d conf.getLong(\n           JHAdminConfig.MR_HISTORY_CLEANER_INTERVAL_MS,\n           JHAdminConfig.DEFAULT_MR_HISTORY_CLEANER_INTERVAL_MS);\n       scheduledExecutor\n           .scheduleAtFixedRate(new HistoryCleaner(),\n               30 * 1000l, runInterval, TimeUnit.MILLISECONDS);\n     }\n-    super.start();\n+    super.serviceStart();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void serviceStart() throws Exception {\n    hsManager.start();\n    if (storage instanceof Service) {\n      ((Service) storage).start();\n    }\n\n    scheduledExecutor \u003d new ScheduledThreadPoolExecutor(2,\n        new ThreadFactoryBuilder().setNameFormat(\"Log Scanner/Cleaner #%d\")\n            .build());\n\n    scheduledExecutor.scheduleAtFixedRate(new MoveIntermediateToDoneRunnable(),\n        moveThreadInterval, moveThreadInterval, TimeUnit.MILLISECONDS);\n\n    // Start historyCleaner\n    boolean startCleanerService \u003d conf.getBoolean(\n        JHAdminConfig.MR_HISTORY_CLEANER_ENABLE, true);\n    if (startCleanerService) {\n      long runInterval \u003d conf.getLong(\n          JHAdminConfig.MR_HISTORY_CLEANER_INTERVAL_MS,\n          JHAdminConfig.DEFAULT_MR_HISTORY_CLEANER_INTERVAL_MS);\n      scheduledExecutor\n          .scheduleAtFixedRate(new HistoryCleaner(),\n              30 * 1000l, runInterval, TimeUnit.MILLISECONDS);\n    }\n    super.serviceStart();\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[Exception]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-530. Defined Service model strictly, implemented AbstractService for robust subclassing and migrated yarn-common services. Contributed by Steve Loughran.\nYARN-117. Migrated rest of YARN to the new service model. Contributed by Steve Louhran.\nMAPREDUCE-5298. Moved MapReduce services to YARN-530 stricter lifecycle. Contributed by Steve Loughran.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1492718 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/06/13 8:54 AM",
          "commitName": "0928502029ef141759008997335ea2cd836a7154",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "03/06/13 9:05 PM",
          "commitNameOld": "a83fb61ac07c0468cbc7a38526e92683883dd932",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 9.49,
          "commitsBetweenForRepo": 61,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,26 +1,26 @@\n-  public void start() {\n+  protected void serviceStart() throws Exception {\n     hsManager.start();\n     if (storage instanceof Service) {\n       ((Service) storage).start();\n     }\n \n     scheduledExecutor \u003d new ScheduledThreadPoolExecutor(2,\n         new ThreadFactoryBuilder().setNameFormat(\"Log Scanner/Cleaner #%d\")\n             .build());\n \n     scheduledExecutor.scheduleAtFixedRate(new MoveIntermediateToDoneRunnable(),\n         moveThreadInterval, moveThreadInterval, TimeUnit.MILLISECONDS);\n \n     // Start historyCleaner\n     boolean startCleanerService \u003d conf.getBoolean(\n         JHAdminConfig.MR_HISTORY_CLEANER_ENABLE, true);\n     if (startCleanerService) {\n       long runInterval \u003d conf.getLong(\n           JHAdminConfig.MR_HISTORY_CLEANER_INTERVAL_MS,\n           JHAdminConfig.DEFAULT_MR_HISTORY_CLEANER_INTERVAL_MS);\n       scheduledExecutor\n           .scheduleAtFixedRate(new HistoryCleaner(),\n               30 * 1000l, runInterval, TimeUnit.MILLISECONDS);\n     }\n-    super.start();\n+    super.serviceStart();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void serviceStart() throws Exception {\n    hsManager.start();\n    if (storage instanceof Service) {\n      ((Service) storage).start();\n    }\n\n    scheduledExecutor \u003d new ScheduledThreadPoolExecutor(2,\n        new ThreadFactoryBuilder().setNameFormat(\"Log Scanner/Cleaner #%d\")\n            .build());\n\n    scheduledExecutor.scheduleAtFixedRate(new MoveIntermediateToDoneRunnable(),\n        moveThreadInterval, moveThreadInterval, TimeUnit.MILLISECONDS);\n\n    // Start historyCleaner\n    boolean startCleanerService \u003d conf.getBoolean(\n        JHAdminConfig.MR_HISTORY_CLEANER_ENABLE, true);\n    if (startCleanerService) {\n      long runInterval \u003d conf.getLong(\n          JHAdminConfig.MR_HISTORY_CLEANER_INTERVAL_MS,\n          JHAdminConfig.DEFAULT_MR_HISTORY_CLEANER_INTERVAL_MS);\n      scheduledExecutor\n          .scheduleAtFixedRate(new HistoryCleaner(),\n              30 * 1000l, runInterval, TimeUnit.MILLISECONDS);\n    }\n    super.serviceStart();\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
          "extendedDetails": {}
        }
      ]
    },
    "7d04a96027ad75877b41b7cd8f67455dd13159d7": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3972. Fix locking and exception issues in JobHistory server. (Contributed by Robert Joseph Evans)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1327354 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/04/12 6:59 PM",
      "commitName": "7d04a96027ad75877b41b7cd8f67455dd13159d7",
      "commitAuthor": "Siddharth Seth",
      "commitDateOld": "10/04/12 11:11 AM",
      "commitNameOld": "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f",
      "commitAuthorOld": "Thomas Graves",
      "daysBetweenCommits": 7.32,
      "commitsBetweenForRepo": 59,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,26 @@\n   public void start() {\n     hsManager.start();\n     if (storage instanceof Service) {\n       ((Service) storage).start();\n     }\n \n-    // Start moveIntermediatToDoneThread\n-    moveIntermediateToDoneRunnable \u003d new MoveIntermediateToDoneRunnable(\n-        moveThreadInterval, numMoveThreads);\n-    moveIntermediateToDoneThread \u003d new Thread(moveIntermediateToDoneRunnable);\n-    moveIntermediateToDoneThread.setName(\"MoveIntermediateToDoneScanner\");\n-    moveIntermediateToDoneThread.start();\n+    scheduledExecutor \u003d new ScheduledThreadPoolExecutor(2,\n+        new ThreadFactoryBuilder().setNameFormat(\"Log Scanner/Cleaner #%d\")\n+            .build());\n+\n+    scheduledExecutor.scheduleAtFixedRate(new MoveIntermediateToDoneRunnable(),\n+        moveThreadInterval, moveThreadInterval, TimeUnit.MILLISECONDS);\n \n     // Start historyCleaner\n     boolean startCleanerService \u003d conf.getBoolean(\n         JHAdminConfig.MR_HISTORY_CLEANER_ENABLE, true);\n     if (startCleanerService) {\n-      long maxAgeOfHistoryFiles \u003d conf.getLong(\n-          JHAdminConfig.MR_HISTORY_MAX_AGE_MS,\n-          JHAdminConfig.DEFAULT_MR_HISTORY_MAX_AGE);\n-      cleanerScheduledExecutor \u003d new ScheduledThreadPoolExecutor(1,\n-          new ThreadFactoryBuilder().setNameFormat(\"LogCleaner\").build());\n       long runInterval \u003d conf.getLong(\n           JHAdminConfig.MR_HISTORY_CLEANER_INTERVAL_MS,\n           JHAdminConfig.DEFAULT_MR_HISTORY_CLEANER_INTERVAL_MS);\n-      cleanerScheduledExecutor\n-          .scheduleAtFixedRate(new HistoryCleaner(maxAgeOfHistoryFiles),\n+      scheduledExecutor\n+          .scheduleAtFixedRate(new HistoryCleaner(),\n               30 * 1000l, runInterval, TimeUnit.MILLISECONDS);\n     }\n     super.start();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void start() {\n    hsManager.start();\n    if (storage instanceof Service) {\n      ((Service) storage).start();\n    }\n\n    scheduledExecutor \u003d new ScheduledThreadPoolExecutor(2,\n        new ThreadFactoryBuilder().setNameFormat(\"Log Scanner/Cleaner #%d\")\n            .build());\n\n    scheduledExecutor.scheduleAtFixedRate(new MoveIntermediateToDoneRunnable(),\n        moveThreadInterval, moveThreadInterval, TimeUnit.MILLISECONDS);\n\n    // Start historyCleaner\n    boolean startCleanerService \u003d conf.getBoolean(\n        JHAdminConfig.MR_HISTORY_CLEANER_ENABLE, true);\n    if (startCleanerService) {\n      long runInterval \u003d conf.getLong(\n          JHAdminConfig.MR_HISTORY_CLEANER_INTERVAL_MS,\n          JHAdminConfig.DEFAULT_MR_HISTORY_CLEANER_INTERVAL_MS);\n      scheduledExecutor\n          .scheduleAtFixedRate(new HistoryCleaner(),\n              30 * 1000l, runInterval, TimeUnit.MILLISECONDS);\n    }\n    super.start();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
      "extendedDetails": {}
    },
    "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4059. The history server should have a separate pluggable storage/query interface. (Robert Evans via tgraves).\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1311896 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/04/12 11:11 AM",
      "commitName": "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f",
      "commitAuthor": "Thomas Graves",
      "commitDateOld": "06/03/12 3:21 PM",
      "commitNameOld": "c3a4de0ec0389064f5468180d1b9024f64b00f40",
      "commitAuthorOld": "Robert Joseph Evans",
      "daysBetweenCommits": 34.78,
      "commitsBetweenForRepo": 243,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,25 +1,31 @@\n   public void start() {\n-    //Start moveIntermediatToDoneThread\n-    moveIntermediateToDoneRunnable \u003d \n-      new MoveIntermediateToDoneRunnable(moveThreadInterval, numMoveThreads);\n+    hsManager.start();\n+    if (storage instanceof Service) {\n+      ((Service) storage).start();\n+    }\n+\n+    // Start moveIntermediatToDoneThread\n+    moveIntermediateToDoneRunnable \u003d new MoveIntermediateToDoneRunnable(\n+        moveThreadInterval, numMoveThreads);\n     moveIntermediateToDoneThread \u003d new Thread(moveIntermediateToDoneRunnable);\n     moveIntermediateToDoneThread.setName(\"MoveIntermediateToDoneScanner\");\n     moveIntermediateToDoneThread.start();\n-    \n-    //Start historyCleaner\n+\n+    // Start historyCleaner\n     boolean startCleanerService \u003d conf.getBoolean(\n         JHAdminConfig.MR_HISTORY_CLEANER_ENABLE, true);\n     if (startCleanerService) {\n       long maxAgeOfHistoryFiles \u003d conf.getLong(\n-          JHAdminConfig.MR_HISTORY_MAX_AGE_MS, DEFAULT_HISTORY_MAX_AGE);\n+          JHAdminConfig.MR_HISTORY_MAX_AGE_MS,\n+          JHAdminConfig.DEFAULT_MR_HISTORY_MAX_AGE);\n       cleanerScheduledExecutor \u003d new ScheduledThreadPoolExecutor(1,\n-          new ThreadFactoryBuilder().setNameFormat(\"LogCleaner\").build()\n-      );\n+          new ThreadFactoryBuilder().setNameFormat(\"LogCleaner\").build());\n       long runInterval \u003d conf.getLong(\n-          JHAdminConfig.MR_HISTORY_CLEANER_INTERVAL_MS, DEFAULT_RUN_INTERVAL);\n+          JHAdminConfig.MR_HISTORY_CLEANER_INTERVAL_MS,\n+          JHAdminConfig.DEFAULT_MR_HISTORY_CLEANER_INTERVAL_MS);\n       cleanerScheduledExecutor\n           .scheduleAtFixedRate(new HistoryCleaner(maxAgeOfHistoryFiles),\n               30 * 1000l, runInterval, TimeUnit.MILLISECONDS);\n     }\n     super.start();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void start() {\n    hsManager.start();\n    if (storage instanceof Service) {\n      ((Service) storage).start();\n    }\n\n    // Start moveIntermediatToDoneThread\n    moveIntermediateToDoneRunnable \u003d new MoveIntermediateToDoneRunnable(\n        moveThreadInterval, numMoveThreads);\n    moveIntermediateToDoneThread \u003d new Thread(moveIntermediateToDoneRunnable);\n    moveIntermediateToDoneThread.setName(\"MoveIntermediateToDoneScanner\");\n    moveIntermediateToDoneThread.start();\n\n    // Start historyCleaner\n    boolean startCleanerService \u003d conf.getBoolean(\n        JHAdminConfig.MR_HISTORY_CLEANER_ENABLE, true);\n    if (startCleanerService) {\n      long maxAgeOfHistoryFiles \u003d conf.getLong(\n          JHAdminConfig.MR_HISTORY_MAX_AGE_MS,\n          JHAdminConfig.DEFAULT_MR_HISTORY_MAX_AGE);\n      cleanerScheduledExecutor \u003d new ScheduledThreadPoolExecutor(1,\n          new ThreadFactoryBuilder().setNameFormat(\"LogCleaner\").build());\n      long runInterval \u003d conf.getLong(\n          JHAdminConfig.MR_HISTORY_CLEANER_INTERVAL_MS,\n          JHAdminConfig.DEFAULT_MR_HISTORY_CLEANER_INTERVAL_MS);\n      cleanerScheduledExecutor\n          .scheduleAtFixedRate(new HistoryCleaner(maxAgeOfHistoryFiles),\n              30 * 1000l, runInterval, TimeUnit.MILLISECONDS);\n    }\n    super.start();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
      "extendedDetails": {}
    },
    "68328ae92632afc9cdd6e75b7a8d832723ddbe3b": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3187. Add names for various unnamed threads in MR2. (Todd Lipcon and Siddharth Seth via mahadev)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1184904 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/10/11 12:27 PM",
      "commitName": "68328ae92632afc9cdd6e75b7a8d832723ddbe3b",
      "commitAuthor": "Mahadev Konar",
      "commitDateOld": "14/10/11 3:49 PM",
      "commitNameOld": "b5e21e7e633a06b9ebb3cbe181cdb4837db99c9c",
      "commitAuthorOld": "Mahadev Konar",
      "daysBetweenCommits": 1.86,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,25 @@\n   public void start() {\n     //Start moveIntermediatToDoneThread\n     moveIntermediateToDoneRunnable \u003d \n       new MoveIntermediateToDoneRunnable(moveThreadInterval, numMoveThreads);\n     moveIntermediateToDoneThread \u003d new Thread(moveIntermediateToDoneRunnable);\n     moveIntermediateToDoneThread.setName(\"MoveIntermediateToDoneScanner\");\n     moveIntermediateToDoneThread.start();\n     \n     //Start historyCleaner\n     boolean startCleanerService \u003d conf.getBoolean(\n         JHAdminConfig.MR_HISTORY_CLEANER_ENABLE, true);\n     if (startCleanerService) {\n       long maxAgeOfHistoryFiles \u003d conf.getLong(\n           JHAdminConfig.MR_HISTORY_MAX_AGE_MS, DEFAULT_HISTORY_MAX_AGE);\n-    cleanerScheduledExecutor \u003d new ScheduledThreadPoolExecutor(1);\n+      cleanerScheduledExecutor \u003d new ScheduledThreadPoolExecutor(1,\n+          new ThreadFactoryBuilder().setNameFormat(\"LogCleaner\").build()\n+      );\n       long runInterval \u003d conf.getLong(\n           JHAdminConfig.MR_HISTORY_CLEANER_INTERVAL_MS, DEFAULT_RUN_INTERVAL);\n       cleanerScheduledExecutor\n           .scheduleAtFixedRate(new HistoryCleaner(maxAgeOfHistoryFiles),\n               30 * 1000l, runInterval, TimeUnit.MILLISECONDS);\n     }\n     super.start();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void start() {\n    //Start moveIntermediatToDoneThread\n    moveIntermediateToDoneRunnable \u003d \n      new MoveIntermediateToDoneRunnable(moveThreadInterval, numMoveThreads);\n    moveIntermediateToDoneThread \u003d new Thread(moveIntermediateToDoneRunnable);\n    moveIntermediateToDoneThread.setName(\"MoveIntermediateToDoneScanner\");\n    moveIntermediateToDoneThread.start();\n    \n    //Start historyCleaner\n    boolean startCleanerService \u003d conf.getBoolean(\n        JHAdminConfig.MR_HISTORY_CLEANER_ENABLE, true);\n    if (startCleanerService) {\n      long maxAgeOfHistoryFiles \u003d conf.getLong(\n          JHAdminConfig.MR_HISTORY_MAX_AGE_MS, DEFAULT_HISTORY_MAX_AGE);\n      cleanerScheduledExecutor \u003d new ScheduledThreadPoolExecutor(1,\n          new ThreadFactoryBuilder().setNameFormat(\"LogCleaner\").build()\n      );\n      long runInterval \u003d conf.getLong(\n          JHAdminConfig.MR_HISTORY_CLEANER_INTERVAL_MS, DEFAULT_RUN_INTERVAL);\n      cleanerScheduledExecutor\n          .scheduleAtFixedRate(new HistoryCleaner(maxAgeOfHistoryFiles),\n              30 * 1000l, runInterval, TimeUnit.MILLISECONDS);\n    }\n    super.start();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
      "extendedDetails": {}
    },
    "fafe8cd28e726566509c679e19d7da622f29f90d": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2864. Normalize configuration variable names for YARN. Contributed by Robert Evans.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1166955 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/09/11 6:44 PM",
      "commitName": "fafe8cd28e726566509c679e19d7da622f29f90d",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:14 PM",
      "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 15.06,
      "commitsBetweenForRepo": 86,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,21 @@\n   public void start() {\n     //Start moveIntermediatToDoneThread\n     moveIntermediateToDoneRunnable \u003d new MoveIntermediateToDoneRunnable(moveThreadInterval, numMoveThreads);\n     moveIntermediateToDoneThread \u003d new Thread(moveIntermediateToDoneRunnable);\n     moveIntermediateToDoneThread.setName(\"MoveIntermediateToDoneScanner\");\n     moveIntermediateToDoneThread.start();\n     \n     //Start historyCleaner\n-    boolean startCleanerService \u003d conf.getBoolean(JHConfig.RUN_HISTORY_CLEANER_KEY, true);\n+    boolean startCleanerService \u003d conf.getBoolean(JHAdminConfig.MR_HISTORY_CLEANER_ENABLE, true);\n     if (startCleanerService) {\n-      long maxAgeOfHistoryFiles \u003d conf.getLong(JHConfig.HISTORY_MAXAGE,\n+      long maxAgeOfHistoryFiles \u003d conf.getLong(JHAdminConfig.MR_HISTORY_MAX_AGE_MS,\n           DEFAULT_HISTORY_MAX_AGE);\n     cleanerScheduledExecutor \u003d new ScheduledThreadPoolExecutor(1);\n-      long runInterval \u003d conf.getLong(JHConfig.HISTORY_CLEANER_RUN_INTERVAL,\n+      long runInterval \u003d conf.getLong(JHAdminConfig.MR_HISTORY_CLEANER_INTERVAL_MS,\n           DEFAULT_RUN_INTERVAL);\n       cleanerScheduledExecutor\n           .scheduleAtFixedRate(new HistoryCleaner(maxAgeOfHistoryFiles),\n               30 * 1000l, runInterval, TimeUnit.MILLISECONDS);\n     }\n     super.start();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void start() {\n    //Start moveIntermediatToDoneThread\n    moveIntermediateToDoneRunnable \u003d new MoveIntermediateToDoneRunnable(moveThreadInterval, numMoveThreads);\n    moveIntermediateToDoneThread \u003d new Thread(moveIntermediateToDoneRunnable);\n    moveIntermediateToDoneThread.setName(\"MoveIntermediateToDoneScanner\");\n    moveIntermediateToDoneThread.start();\n    \n    //Start historyCleaner\n    boolean startCleanerService \u003d conf.getBoolean(JHAdminConfig.MR_HISTORY_CLEANER_ENABLE, true);\n    if (startCleanerService) {\n      long maxAgeOfHistoryFiles \u003d conf.getLong(JHAdminConfig.MR_HISTORY_MAX_AGE_MS,\n          DEFAULT_HISTORY_MAX_AGE);\n    cleanerScheduledExecutor \u003d new ScheduledThreadPoolExecutor(1);\n      long runInterval \u003d conf.getLong(JHAdminConfig.MR_HISTORY_CLEANER_INTERVAL_MS,\n          DEFAULT_RUN_INTERVAL);\n      cleanerScheduledExecutor\n          .scheduleAtFixedRate(new HistoryCleaner(maxAgeOfHistoryFiles),\n              30 * 1000l, runInterval, TimeUnit.MILLISECONDS);\n    }\n    super.start();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void start() {\n    //Start moveIntermediatToDoneThread\n    moveIntermediateToDoneRunnable \u003d new MoveIntermediateToDoneRunnable(moveThreadInterval, numMoveThreads);\n    moveIntermediateToDoneThread \u003d new Thread(moveIntermediateToDoneRunnable);\n    moveIntermediateToDoneThread.setName(\"MoveIntermediateToDoneScanner\");\n    moveIntermediateToDoneThread.start();\n    \n    //Start historyCleaner\n    boolean startCleanerService \u003d conf.getBoolean(JHConfig.RUN_HISTORY_CLEANER_KEY, true);\n    if (startCleanerService) {\n      long maxAgeOfHistoryFiles \u003d conf.getLong(JHConfig.HISTORY_MAXAGE,\n          DEFAULT_HISTORY_MAX_AGE);\n    cleanerScheduledExecutor \u003d new ScheduledThreadPoolExecutor(1);\n      long runInterval \u003d conf.getLong(JHConfig.HISTORY_CLEANER_RUN_INTERVAL,\n          DEFAULT_RUN_INTERVAL);\n      cleanerScheduledExecutor\n          .scheduleAtFixedRate(new HistoryCleaner(maxAgeOfHistoryFiles),\n              30 * 1000l, runInterval, TimeUnit.MILLISECONDS);\n    }\n    super.start();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "diff": "@@ -0,0 +1,21 @@\n+  public void start() {\n+    //Start moveIntermediatToDoneThread\n+    moveIntermediateToDoneRunnable \u003d new MoveIntermediateToDoneRunnable(moveThreadInterval, numMoveThreads);\n+    moveIntermediateToDoneThread \u003d new Thread(moveIntermediateToDoneRunnable);\n+    moveIntermediateToDoneThread.setName(\"MoveIntermediateToDoneScanner\");\n+    moveIntermediateToDoneThread.start();\n+    \n+    //Start historyCleaner\n+    boolean startCleanerService \u003d conf.getBoolean(JHConfig.RUN_HISTORY_CLEANER_KEY, true);\n+    if (startCleanerService) {\n+      long maxAgeOfHistoryFiles \u003d conf.getLong(JHConfig.HISTORY_MAXAGE,\n+          DEFAULT_HISTORY_MAX_AGE);\n+    cleanerScheduledExecutor \u003d new ScheduledThreadPoolExecutor(1);\n+      long runInterval \u003d conf.getLong(JHConfig.HISTORY_CLEANER_RUN_INTERVAL,\n+          DEFAULT_RUN_INTERVAL);\n+      cleanerScheduledExecutor\n+          .scheduleAtFixedRate(new HistoryCleaner(maxAgeOfHistoryFiles),\n+              30 * 1000l, runInterval, TimeUnit.MILLISECONDS);\n+    }\n+    super.start();\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void start() {\n    //Start moveIntermediatToDoneThread\n    moveIntermediateToDoneRunnable \u003d new MoveIntermediateToDoneRunnable(moveThreadInterval, numMoveThreads);\n    moveIntermediateToDoneThread \u003d new Thread(moveIntermediateToDoneRunnable);\n    moveIntermediateToDoneThread.setName(\"MoveIntermediateToDoneScanner\");\n    moveIntermediateToDoneThread.start();\n    \n    //Start historyCleaner\n    boolean startCleanerService \u003d conf.getBoolean(JHConfig.RUN_HISTORY_CLEANER_KEY, true);\n    if (startCleanerService) {\n      long maxAgeOfHistoryFiles \u003d conf.getLong(JHConfig.HISTORY_MAXAGE,\n          DEFAULT_HISTORY_MAX_AGE);\n    cleanerScheduledExecutor \u003d new ScheduledThreadPoolExecutor(1);\n      long runInterval \u003d conf.getLong(JHConfig.HISTORY_CLEANER_RUN_INTERVAL,\n          DEFAULT_RUN_INTERVAL);\n      cleanerScheduledExecutor\n          .scheduleAtFixedRate(new HistoryCleaner(maxAgeOfHistoryFiles),\n              30 * 1000l, runInterval, TimeUnit.MILLISECONDS);\n    }\n    super.start();\n  }",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java"
    }
  }
}