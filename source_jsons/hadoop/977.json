{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DFSStripedOutputStream.java",
  "functionName": "closeImpl",
  "functionId": "closeImpl",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSStripedOutputStream.java",
  "functionStartLine": 1196,
  "functionEndLine": 1275,
  "numCommitsSeen": 38,
  "timeTaken": 2734,
  "changeHistory": [
    "1d772dc5429bfffa015a1209e6f4a864505c871a",
    "df622cf4a32ee172ded6c4b3b97a1e49befc4f10",
    "f27a4ad0324aa0b4080a1c4c6bf4cd560c927e20",
    "84d787b9d51196010495d51dc5ebf66c01c340ab",
    "f3c91a41a5bf16542eca7f09787eb1727fd18e08",
    "e30ce01ddce1cfd1e9d49c4784eb4a6bc87e36ca",
    "5104077e1f431ad3675d0b1c5c3cf53936902d8e",
    "e8bd1ba74b2fc7a6a1b71d068ef01a0fb0bbe294",
    "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93"
  ],
  "changeHistoryShort": {
    "1d772dc5429bfffa015a1209e6f4a864505c871a": "Ybodychange",
    "df622cf4a32ee172ded6c4b3b97a1e49befc4f10": "Ybodychange",
    "f27a4ad0324aa0b4080a1c4c6bf4cd560c927e20": "Ybodychange",
    "84d787b9d51196010495d51dc5ebf66c01c340ab": "Ybodychange",
    "f3c91a41a5bf16542eca7f09787eb1727fd18e08": "Ybodychange",
    "e30ce01ddce1cfd1e9d49c4784eb4a6bc87e36ca": "Ybodychange",
    "5104077e1f431ad3675d0b1c5c3cf53936902d8e": "Ybodychange",
    "e8bd1ba74b2fc7a6a1b71d068ef01a0fb0bbe294": "Ybodychange",
    "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93": "Ybodychange"
  },
  "changeHistoryDetails": {
    "1d772dc5429bfffa015a1209e6f4a864505c871a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-15211. EC: File write hangs during close in case of Exception during updatePipeline. Contributed by Ayush Saxena.\n",
      "commitDate": "15/03/20 8:14 AM",
      "commitName": "1d772dc5429bfffa015a1209e6f4a864505c871a",
      "commitAuthor": "Surendra Singh Lilhore",
      "commitDateOld": "24/12/19 9:37 PM",
      "commitNameOld": "df622cf4a32ee172ded6c4b3b97a1e49befc4f10",
      "commitAuthorOld": "Ayush Saxena",
      "daysBetweenCommits": 81.4,
      "commitsBetweenForRepo": 272,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,80 +1,80 @@\n   protected synchronized void closeImpl() throws IOException {\n-    if (isClosed()) {\n-      exceptionLastSeen.check(true);\n-\n-      // Writing to at least {dataUnits} replicas can be considered as success,\n-      // and the rest of data can be recovered.\n-      final int minReplication \u003d ecPolicy.getNumDataUnits();\n-      int goodStreamers \u003d 0;\n-      final MultipleIOException.Builder b \u003d new MultipleIOException.Builder();\n-      for (final StripedDataStreamer si : streamers) {\n-        try {\n-          si.getLastException().check(true);\n-          goodStreamers++;\n-        } catch (IOException e) {\n-          b.add(e);\n-        }\n-      }\n-      if (goodStreamers \u003c minReplication) {\n-        final IOException ioe \u003d b.build();\n-        if (ioe !\u003d null) {\n-          throw ioe;\n-        }\n-      }\n-      return;\n-    }\n-\n     try {\n+      if (isClosed()) {\n+        exceptionLastSeen.check(true);\n+\n+        // Writing to at least {dataUnits} replicas can be considered as\n+        //  success, and the rest of data can be recovered.\n+        final int minReplication \u003d ecPolicy.getNumDataUnits();\n+        int goodStreamers \u003d 0;\n+        final MultipleIOException.Builder b \u003d new MultipleIOException.Builder();\n+        for (final StripedDataStreamer si : streamers) {\n+          try {\n+            si.getLastException().check(true);\n+            goodStreamers++;\n+          } catch (IOException e) {\n+            b.add(e);\n+          }\n+        }\n+        if (goodStreamers \u003c minReplication) {\n+          final IOException ioe \u003d b.build();\n+          if (ioe !\u003d null) {\n+            throw ioe;\n+          }\n+        }\n+        return;\n+      }\n+\n       try {\n         // flush from all upper layers\n         flushBuffer();\n         // if the last stripe is incomplete, generate and write parity cells\n         if (generateParityCellsForLastStripe()) {\n           writeParityCells();\n         }\n         enqueueAllCurrentPackets();\n \n         // flush all the data packets\n         flushAllInternals();\n         // check failures\n         checkStreamerFailures(false);\n \n         for (int i \u003d 0; i \u003c numAllBlocks; i++) {\n           final StripedDataStreamer s \u003d setCurrentStreamer(i);\n           if (s.isHealthy()) {\n             try {\n               if (s.getBytesCurBlock() \u003e 0) {\n                 setCurrentPacketToEmpty();\n               }\n               // flush the last \"close\" packet to Datanode\n               flushInternal();\n             } catch (Exception e) {\n               // TODO for both close and endBlock, we currently do not handle\n               // failures when sending the last packet. We actually do not need to\n               // bump GS for this kind of failure. Thus counting the total number\n               // of failures may be good enough.\n             }\n           }\n         }\n       } finally {\n         // Failures may happen when flushing data/parity data out. Exceptions\n         // may be thrown if the number of failed streamers is more than the\n         // number of parity blocks, or updatePipeline RPC fails. Streamers may\n         // keep waiting for the new block/GS information. Thus need to force\n         // closing these threads.\n         closeThreads(true);\n       }\n \n       try (TraceScope ignored \u003d\n                dfsClient.getTracer().newScope(\"completeFile\")) {\n         completeFile(currentBlockGroup);\n       }\n       logCorruptBlocks();\n     } catch (ClosedChannelException ignored) {\n     } finally {\n       setClosed();\n       // shutdown executor of flushAll tasks\n       flushAllExecutor.shutdownNow();\n       encoder.release();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected synchronized void closeImpl() throws IOException {\n    try {\n      if (isClosed()) {\n        exceptionLastSeen.check(true);\n\n        // Writing to at least {dataUnits} replicas can be considered as\n        //  success, and the rest of data can be recovered.\n        final int minReplication \u003d ecPolicy.getNumDataUnits();\n        int goodStreamers \u003d 0;\n        final MultipleIOException.Builder b \u003d new MultipleIOException.Builder();\n        for (final StripedDataStreamer si : streamers) {\n          try {\n            si.getLastException().check(true);\n            goodStreamers++;\n          } catch (IOException e) {\n            b.add(e);\n          }\n        }\n        if (goodStreamers \u003c minReplication) {\n          final IOException ioe \u003d b.build();\n          if (ioe !\u003d null) {\n            throw ioe;\n          }\n        }\n        return;\n      }\n\n      try {\n        // flush from all upper layers\n        flushBuffer();\n        // if the last stripe is incomplete, generate and write parity cells\n        if (generateParityCellsForLastStripe()) {\n          writeParityCells();\n        }\n        enqueueAllCurrentPackets();\n\n        // flush all the data packets\n        flushAllInternals();\n        // check failures\n        checkStreamerFailures(false);\n\n        for (int i \u003d 0; i \u003c numAllBlocks; i++) {\n          final StripedDataStreamer s \u003d setCurrentStreamer(i);\n          if (s.isHealthy()) {\n            try {\n              if (s.getBytesCurBlock() \u003e 0) {\n                setCurrentPacketToEmpty();\n              }\n              // flush the last \"close\" packet to Datanode\n              flushInternal();\n            } catch (Exception e) {\n              // TODO for both close and endBlock, we currently do not handle\n              // failures when sending the last packet. We actually do not need to\n              // bump GS for this kind of failure. Thus counting the total number\n              // of failures may be good enough.\n            }\n          }\n        }\n      } finally {\n        // Failures may happen when flushing data/parity data out. Exceptions\n        // may be thrown if the number of failed streamers is more than the\n        // number of parity blocks, or updatePipeline RPC fails. Streamers may\n        // keep waiting for the new block/GS information. Thus need to force\n        // closing these threads.\n        closeThreads(true);\n      }\n\n      try (TraceScope ignored \u003d\n               dfsClient.getTracer().newScope(\"completeFile\")) {\n        completeFile(currentBlockGroup);\n      }\n      logCorruptBlocks();\n    } catch (ClosedChannelException ignored) {\n    } finally {\n      setClosed();\n      // shutdown executor of flushAll tasks\n      flushAllExecutor.shutdownNow();\n      encoder.release();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSStripedOutputStream.java",
      "extendedDetails": {}
    },
    "df622cf4a32ee172ded6c4b3b97a1e49befc4f10": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12999. When reach the end of the block group, it may not need to flush all the data packets(flushAllInternals) twice. Contributed by lufei and Fei Hui.\n",
      "commitDate": "24/12/19 9:37 PM",
      "commitName": "df622cf4a32ee172ded6c4b3b97a1e49befc4f10",
      "commitAuthor": "Ayush Saxena",
      "commitDateOld": "05/03/19 5:56 AM",
      "commitNameOld": "f940ab242da80a22bae95509d5c282d7e2f7ecdb",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 294.65,
      "commitsBetweenForRepo": 1993,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,80 +1,80 @@\n   protected synchronized void closeImpl() throws IOException {\n     if (isClosed()) {\n       exceptionLastSeen.check(true);\n \n       // Writing to at least {dataUnits} replicas can be considered as success,\n       // and the rest of data can be recovered.\n       final int minReplication \u003d ecPolicy.getNumDataUnits();\n       int goodStreamers \u003d 0;\n       final MultipleIOException.Builder b \u003d new MultipleIOException.Builder();\n       for (final StripedDataStreamer si : streamers) {\n         try {\n           si.getLastException().check(true);\n           goodStreamers++;\n         } catch (IOException e) {\n           b.add(e);\n         }\n       }\n       if (goodStreamers \u003c minReplication) {\n         final IOException ioe \u003d b.build();\n         if (ioe !\u003d null) {\n           throw ioe;\n         }\n       }\n       return;\n     }\n \n     try {\n       try {\n         // flush from all upper layers\n         flushBuffer();\n         // if the last stripe is incomplete, generate and write parity cells\n         if (generateParityCellsForLastStripe()) {\n           writeParityCells();\n         }\n         enqueueAllCurrentPackets();\n \n         // flush all the data packets\n         flushAllInternals();\n         // check failures\n-        checkStreamerFailures();\n+        checkStreamerFailures(false);\n \n         for (int i \u003d 0; i \u003c numAllBlocks; i++) {\n           final StripedDataStreamer s \u003d setCurrentStreamer(i);\n           if (s.isHealthy()) {\n             try {\n               if (s.getBytesCurBlock() \u003e 0) {\n                 setCurrentPacketToEmpty();\n               }\n               // flush the last \"close\" packet to Datanode\n               flushInternal();\n             } catch (Exception e) {\n               // TODO for both close and endBlock, we currently do not handle\n               // failures when sending the last packet. We actually do not need to\n               // bump GS for this kind of failure. Thus counting the total number\n               // of failures may be good enough.\n             }\n           }\n         }\n       } finally {\n         // Failures may happen when flushing data/parity data out. Exceptions\n         // may be thrown if the number of failed streamers is more than the\n         // number of parity blocks, or updatePipeline RPC fails. Streamers may\n         // keep waiting for the new block/GS information. Thus need to force\n         // closing these threads.\n         closeThreads(true);\n       }\n \n       try (TraceScope ignored \u003d\n                dfsClient.getTracer().newScope(\"completeFile\")) {\n         completeFile(currentBlockGroup);\n       }\n       logCorruptBlocks();\n     } catch (ClosedChannelException ignored) {\n     } finally {\n       setClosed();\n       // shutdown executor of flushAll tasks\n       flushAllExecutor.shutdownNow();\n       encoder.release();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected synchronized void closeImpl() throws IOException {\n    if (isClosed()) {\n      exceptionLastSeen.check(true);\n\n      // Writing to at least {dataUnits} replicas can be considered as success,\n      // and the rest of data can be recovered.\n      final int minReplication \u003d ecPolicy.getNumDataUnits();\n      int goodStreamers \u003d 0;\n      final MultipleIOException.Builder b \u003d new MultipleIOException.Builder();\n      for (final StripedDataStreamer si : streamers) {\n        try {\n          si.getLastException().check(true);\n          goodStreamers++;\n        } catch (IOException e) {\n          b.add(e);\n        }\n      }\n      if (goodStreamers \u003c minReplication) {\n        final IOException ioe \u003d b.build();\n        if (ioe !\u003d null) {\n          throw ioe;\n        }\n      }\n      return;\n    }\n\n    try {\n      try {\n        // flush from all upper layers\n        flushBuffer();\n        // if the last stripe is incomplete, generate and write parity cells\n        if (generateParityCellsForLastStripe()) {\n          writeParityCells();\n        }\n        enqueueAllCurrentPackets();\n\n        // flush all the data packets\n        flushAllInternals();\n        // check failures\n        checkStreamerFailures(false);\n\n        for (int i \u003d 0; i \u003c numAllBlocks; i++) {\n          final StripedDataStreamer s \u003d setCurrentStreamer(i);\n          if (s.isHealthy()) {\n            try {\n              if (s.getBytesCurBlock() \u003e 0) {\n                setCurrentPacketToEmpty();\n              }\n              // flush the last \"close\" packet to Datanode\n              flushInternal();\n            } catch (Exception e) {\n              // TODO for both close and endBlock, we currently do not handle\n              // failures when sending the last packet. We actually do not need to\n              // bump GS for this kind of failure. Thus counting the total number\n              // of failures may be good enough.\n            }\n          }\n        }\n      } finally {\n        // Failures may happen when flushing data/parity data out. Exceptions\n        // may be thrown if the number of failed streamers is more than the\n        // number of parity blocks, or updatePipeline RPC fails. Streamers may\n        // keep waiting for the new block/GS information. Thus need to force\n        // closing these threads.\n        closeThreads(true);\n      }\n\n      try (TraceScope ignored \u003d\n               dfsClient.getTracer().newScope(\"completeFile\")) {\n        completeFile(currentBlockGroup);\n      }\n      logCorruptBlocks();\n    } catch (ClosedChannelException ignored) {\n    } finally {\n      setClosed();\n      // shutdown executor of flushAll tasks\n      flushAllExecutor.shutdownNow();\n      encoder.release();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSStripedOutputStream.java",
      "extendedDetails": {}
    },
    "f27a4ad0324aa0b4080a1c4c6bf4cd560c927e20": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12612. DFSStripedOutputStream.close will throw if called a second time with a failed streamer. (Lei (Eddy) Xu)\n",
      "commitDate": "17/10/17 3:52 PM",
      "commitName": "f27a4ad0324aa0b4080a1c4c6bf4cd560c927e20",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "16/10/17 7:44 PM",
      "commitNameOld": "31ebccc96238136560f4210bdf6766fe18e0650c",
      "commitAuthorOld": "Lei Xu",
      "daysBetweenCommits": 0.84,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,71 +1,80 @@\n   protected synchronized void closeImpl() throws IOException {\n     if (isClosed()) {\n+      exceptionLastSeen.check(true);\n+\n+      // Writing to at least {dataUnits} replicas can be considered as success,\n+      // and the rest of data can be recovered.\n+      final int minReplication \u003d ecPolicy.getNumDataUnits();\n+      int goodStreamers \u003d 0;\n       final MultipleIOException.Builder b \u003d new MultipleIOException.Builder();\n-      for(int i \u003d 0; i \u003c streamers.size(); i++) {\n-        final StripedDataStreamer si \u003d getStripedDataStreamer(i);\n+      for (final StripedDataStreamer si : streamers) {\n         try {\n           si.getLastException().check(true);\n+          goodStreamers++;\n         } catch (IOException e) {\n           b.add(e);\n         }\n       }\n-      final IOException ioe \u003d b.build();\n-      if (ioe !\u003d null) {\n-        throw ioe;\n+      if (goodStreamers \u003c minReplication) {\n+        final IOException ioe \u003d b.build();\n+        if (ioe !\u003d null) {\n+          throw ioe;\n+        }\n       }\n       return;\n     }\n \n     try {\n       try {\n         // flush from all upper layers\n         flushBuffer();\n         // if the last stripe is incomplete, generate and write parity cells\n         if (generateParityCellsForLastStripe()) {\n           writeParityCells();\n         }\n         enqueueAllCurrentPackets();\n \n         // flush all the data packets\n         flushAllInternals();\n         // check failures\n         checkStreamerFailures();\n \n         for (int i \u003d 0; i \u003c numAllBlocks; i++) {\n           final StripedDataStreamer s \u003d setCurrentStreamer(i);\n           if (s.isHealthy()) {\n             try {\n               if (s.getBytesCurBlock() \u003e 0) {\n                 setCurrentPacketToEmpty();\n               }\n               // flush the last \"close\" packet to Datanode\n               flushInternal();\n             } catch (Exception e) {\n               // TODO for both close and endBlock, we currently do not handle\n               // failures when sending the last packet. We actually do not need to\n               // bump GS for this kind of failure. Thus counting the total number\n               // of failures may be good enough.\n             }\n           }\n         }\n       } finally {\n         // Failures may happen when flushing data/parity data out. Exceptions\n-        // may be thrown if more than 3 streamers fail, or updatePipeline RPC\n-        // fails. Streamers may keep waiting for the new block/GS information.\n-        // Thus need to force closing these threads.\n+        // may be thrown if the number of failed streamers is more than the\n+        // number of parity blocks, or updatePipeline RPC fails. Streamers may\n+        // keep waiting for the new block/GS information. Thus need to force\n+        // closing these threads.\n         closeThreads(true);\n       }\n \n       try (TraceScope ignored \u003d\n                dfsClient.getTracer().newScope(\"completeFile\")) {\n         completeFile(currentBlockGroup);\n       }\n       logCorruptBlocks();\n     } catch (ClosedChannelException ignored) {\n     } finally {\n       setClosed();\n       // shutdown executor of flushAll tasks\n       flushAllExecutor.shutdownNow();\n       encoder.release();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected synchronized void closeImpl() throws IOException {\n    if (isClosed()) {\n      exceptionLastSeen.check(true);\n\n      // Writing to at least {dataUnits} replicas can be considered as success,\n      // and the rest of data can be recovered.\n      final int minReplication \u003d ecPolicy.getNumDataUnits();\n      int goodStreamers \u003d 0;\n      final MultipleIOException.Builder b \u003d new MultipleIOException.Builder();\n      for (final StripedDataStreamer si : streamers) {\n        try {\n          si.getLastException().check(true);\n          goodStreamers++;\n        } catch (IOException e) {\n          b.add(e);\n        }\n      }\n      if (goodStreamers \u003c minReplication) {\n        final IOException ioe \u003d b.build();\n        if (ioe !\u003d null) {\n          throw ioe;\n        }\n      }\n      return;\n    }\n\n    try {\n      try {\n        // flush from all upper layers\n        flushBuffer();\n        // if the last stripe is incomplete, generate and write parity cells\n        if (generateParityCellsForLastStripe()) {\n          writeParityCells();\n        }\n        enqueueAllCurrentPackets();\n\n        // flush all the data packets\n        flushAllInternals();\n        // check failures\n        checkStreamerFailures();\n\n        for (int i \u003d 0; i \u003c numAllBlocks; i++) {\n          final StripedDataStreamer s \u003d setCurrentStreamer(i);\n          if (s.isHealthy()) {\n            try {\n              if (s.getBytesCurBlock() \u003e 0) {\n                setCurrentPacketToEmpty();\n              }\n              // flush the last \"close\" packet to Datanode\n              flushInternal();\n            } catch (Exception e) {\n              // TODO for both close and endBlock, we currently do not handle\n              // failures when sending the last packet. We actually do not need to\n              // bump GS for this kind of failure. Thus counting the total number\n              // of failures may be good enough.\n            }\n          }\n        }\n      } finally {\n        // Failures may happen when flushing data/parity data out. Exceptions\n        // may be thrown if the number of failed streamers is more than the\n        // number of parity blocks, or updatePipeline RPC fails. Streamers may\n        // keep waiting for the new block/GS information. Thus need to force\n        // closing these threads.\n        closeThreads(true);\n      }\n\n      try (TraceScope ignored \u003d\n               dfsClient.getTracer().newScope(\"completeFile\")) {\n        completeFile(currentBlockGroup);\n      }\n      logCorruptBlocks();\n    } catch (ClosedChannelException ignored) {\n    } finally {\n      setClosed();\n      // shutdown executor of flushAll tasks\n      flushAllExecutor.shutdownNow();\n      encoder.release();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSStripedOutputStream.java",
      "extendedDetails": {}
    },
    "84d787b9d51196010495d51dc5ebf66c01c340ab": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11541. Call RawErasureEncoder and RawErasureDecoder release() methods. Contributed by SammiChen.\n",
      "commitDate": "28/03/17 11:11 PM",
      "commitName": "84d787b9d51196010495d51dc5ebf66c01c340ab",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "08/11/16 6:17 PM",
      "commitNameOld": "ed0bebabaaf27cd730f7f8eb002d92c9c7db327d",
      "commitAuthorOld": "Brahma Reddy Battula",
      "daysBetweenCommits": 140.16,
      "commitsBetweenForRepo": 758,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,70 +1,71 @@\n   protected synchronized void closeImpl() throws IOException {\n     if (isClosed()) {\n       final MultipleIOException.Builder b \u003d new MultipleIOException.Builder();\n       for(int i \u003d 0; i \u003c streamers.size(); i++) {\n         final StripedDataStreamer si \u003d getStripedDataStreamer(i);\n         try {\n           si.getLastException().check(true);\n         } catch (IOException e) {\n           b.add(e);\n         }\n       }\n       final IOException ioe \u003d b.build();\n       if (ioe !\u003d null) {\n         throw ioe;\n       }\n       return;\n     }\n \n     try {\n       try {\n         // flush from all upper layers\n         flushBuffer();\n         // if the last stripe is incomplete, generate and write parity cells\n         if (generateParityCellsForLastStripe()) {\n           writeParityCells();\n         }\n         enqueueAllCurrentPackets();\n \n         // flush all the data packets\n         flushAllInternals();\n         // check failures\n         checkStreamerFailures();\n \n         for (int i \u003d 0; i \u003c numAllBlocks; i++) {\n           final StripedDataStreamer s \u003d setCurrentStreamer(i);\n           if (s.isHealthy()) {\n             try {\n               if (s.getBytesCurBlock() \u003e 0) {\n                 setCurrentPacketToEmpty();\n               }\n               // flush the last \"close\" packet to Datanode\n               flushInternal();\n             } catch (Exception e) {\n               // TODO for both close and endBlock, we currently do not handle\n               // failures when sending the last packet. We actually do not need to\n               // bump GS for this kind of failure. Thus counting the total number\n               // of failures may be good enough.\n             }\n           }\n         }\n       } finally {\n         // Failures may happen when flushing data/parity data out. Exceptions\n         // may be thrown if more than 3 streamers fail, or updatePipeline RPC\n         // fails. Streamers may keep waiting for the new block/GS information.\n         // Thus need to force closing these threads.\n         closeThreads(true);\n       }\n \n       try (TraceScope ignored \u003d\n                dfsClient.getTracer().newScope(\"completeFile\")) {\n         completeFile(currentBlockGroup);\n       }\n       logCorruptBlocks();\n     } catch (ClosedChannelException ignored) {\n     } finally {\n       setClosed();\n       // shutdown executor of flushAll tasks\n       flushAllExecutor.shutdownNow();\n+      encoder.release();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected synchronized void closeImpl() throws IOException {\n    if (isClosed()) {\n      final MultipleIOException.Builder b \u003d new MultipleIOException.Builder();\n      for(int i \u003d 0; i \u003c streamers.size(); i++) {\n        final StripedDataStreamer si \u003d getStripedDataStreamer(i);\n        try {\n          si.getLastException().check(true);\n        } catch (IOException e) {\n          b.add(e);\n        }\n      }\n      final IOException ioe \u003d b.build();\n      if (ioe !\u003d null) {\n        throw ioe;\n      }\n      return;\n    }\n\n    try {\n      try {\n        // flush from all upper layers\n        flushBuffer();\n        // if the last stripe is incomplete, generate and write parity cells\n        if (generateParityCellsForLastStripe()) {\n          writeParityCells();\n        }\n        enqueueAllCurrentPackets();\n\n        // flush all the data packets\n        flushAllInternals();\n        // check failures\n        checkStreamerFailures();\n\n        for (int i \u003d 0; i \u003c numAllBlocks; i++) {\n          final StripedDataStreamer s \u003d setCurrentStreamer(i);\n          if (s.isHealthy()) {\n            try {\n              if (s.getBytesCurBlock() \u003e 0) {\n                setCurrentPacketToEmpty();\n              }\n              // flush the last \"close\" packet to Datanode\n              flushInternal();\n            } catch (Exception e) {\n              // TODO for both close and endBlock, we currently do not handle\n              // failures when sending the last packet. We actually do not need to\n              // bump GS for this kind of failure. Thus counting the total number\n              // of failures may be good enough.\n            }\n          }\n        }\n      } finally {\n        // Failures may happen when flushing data/parity data out. Exceptions\n        // may be thrown if more than 3 streamers fail, or updatePipeline RPC\n        // fails. Streamers may keep waiting for the new block/GS information.\n        // Thus need to force closing these threads.\n        closeThreads(true);\n      }\n\n      try (TraceScope ignored \u003d\n               dfsClient.getTracer().newScope(\"completeFile\")) {\n        completeFile(currentBlockGroup);\n      }\n      logCorruptBlocks();\n    } catch (ClosedChannelException ignored) {\n    } finally {\n      setClosed();\n      // shutdown executor of flushAll tasks\n      flushAllExecutor.shutdownNow();\n      encoder.release();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSStripedOutputStream.java",
      "extendedDetails": {}
    },
    "f3c91a41a5bf16542eca7f09787eb1727fd18e08": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9794. Streamer threads may leak if failure happens when closing the striped outputstream. Contributed by Jing Zhao.\n",
      "commitDate": "12/02/16 10:59 AM",
      "commitName": "f3c91a41a5bf16542eca7f09787eb1727fd18e08",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "01/02/16 1:02 PM",
      "commitNameOld": "e30ce01ddce1cfd1e9d49c4784eb4a6bc87e36ca",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 10.91,
      "commitsBetweenForRepo": 93,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,63 +1,70 @@\n   protected synchronized void closeImpl() throws IOException {\n     if (isClosed()) {\n       final MultipleIOException.Builder b \u003d new MultipleIOException.Builder();\n       for(int i \u003d 0; i \u003c streamers.size(); i++) {\n         final StripedDataStreamer si \u003d getStripedDataStreamer(i);\n         try {\n           si.getLastException().check(true);\n         } catch (IOException e) {\n           b.add(e);\n         }\n       }\n       final IOException ioe \u003d b.build();\n       if (ioe !\u003d null) {\n         throw ioe;\n       }\n       return;\n     }\n \n     try {\n-      // flush from all upper layers\n-      flushBuffer();\n-      // if the last stripe is incomplete, generate and write parity cells\n-      if (generateParityCellsForLastStripe()) {\n-        writeParityCells();\n-      }\n-      enqueueAllCurrentPackets();\n+      try {\n+        // flush from all upper layers\n+        flushBuffer();\n+        // if the last stripe is incomplete, generate and write parity cells\n+        if (generateParityCellsForLastStripe()) {\n+          writeParityCells();\n+        }\n+        enqueueAllCurrentPackets();\n \n-      // flush all the data packets\n-      flushAllInternals();\n-      // check failures\n-      checkStreamerFailures();\n+        // flush all the data packets\n+        flushAllInternals();\n+        // check failures\n+        checkStreamerFailures();\n \n-      for (int i \u003d 0; i \u003c numAllBlocks; i++) {\n-        final StripedDataStreamer s \u003d setCurrentStreamer(i);\n-        if (s.isHealthy()) {\n-          try {\n-            if (s.getBytesCurBlock() \u003e 0) {\n-              setCurrentPacketToEmpty();\n+        for (int i \u003d 0; i \u003c numAllBlocks; i++) {\n+          final StripedDataStreamer s \u003d setCurrentStreamer(i);\n+          if (s.isHealthy()) {\n+            try {\n+              if (s.getBytesCurBlock() \u003e 0) {\n+                setCurrentPacketToEmpty();\n+              }\n+              // flush the last \"close\" packet to Datanode\n+              flushInternal();\n+            } catch (Exception e) {\n+              // TODO for both close and endBlock, we currently do not handle\n+              // failures when sending the last packet. We actually do not need to\n+              // bump GS for this kind of failure. Thus counting the total number\n+              // of failures may be good enough.\n             }\n-            // flush the last \"close\" packet to Datanode\n-            flushInternal();\n-          } catch(Exception e) {\n-            // TODO for both close and endBlock, we currently do not handle\n-            // failures when sending the last packet. We actually do not need to\n-            // bump GS for this kind of failure. Thus counting the total number\n-            // of failures may be good enough.\n           }\n         }\n+      } finally {\n+        // Failures may happen when flushing data/parity data out. Exceptions\n+        // may be thrown if more than 3 streamers fail, or updatePipeline RPC\n+        // fails. Streamers may keep waiting for the new block/GS information.\n+        // Thus need to force closing these threads.\n+        closeThreads(true);\n       }\n \n-      closeThreads(false);\n       try (TraceScope ignored \u003d\n                dfsClient.getTracer().newScope(\"completeFile\")) {\n         completeFile(currentBlockGroup);\n       }\n       logCorruptBlocks();\n     } catch (ClosedChannelException ignored) {\n     } finally {\n       setClosed();\n       // shutdown executor of flushAll tasks\n       flushAllExecutor.shutdownNow();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected synchronized void closeImpl() throws IOException {\n    if (isClosed()) {\n      final MultipleIOException.Builder b \u003d new MultipleIOException.Builder();\n      for(int i \u003d 0; i \u003c streamers.size(); i++) {\n        final StripedDataStreamer si \u003d getStripedDataStreamer(i);\n        try {\n          si.getLastException().check(true);\n        } catch (IOException e) {\n          b.add(e);\n        }\n      }\n      final IOException ioe \u003d b.build();\n      if (ioe !\u003d null) {\n        throw ioe;\n      }\n      return;\n    }\n\n    try {\n      try {\n        // flush from all upper layers\n        flushBuffer();\n        // if the last stripe is incomplete, generate and write parity cells\n        if (generateParityCellsForLastStripe()) {\n          writeParityCells();\n        }\n        enqueueAllCurrentPackets();\n\n        // flush all the data packets\n        flushAllInternals();\n        // check failures\n        checkStreamerFailures();\n\n        for (int i \u003d 0; i \u003c numAllBlocks; i++) {\n          final StripedDataStreamer s \u003d setCurrentStreamer(i);\n          if (s.isHealthy()) {\n            try {\n              if (s.getBytesCurBlock() \u003e 0) {\n                setCurrentPacketToEmpty();\n              }\n              // flush the last \"close\" packet to Datanode\n              flushInternal();\n            } catch (Exception e) {\n              // TODO for both close and endBlock, we currently do not handle\n              // failures when sending the last packet. We actually do not need to\n              // bump GS for this kind of failure. Thus counting the total number\n              // of failures may be good enough.\n            }\n          }\n        }\n      } finally {\n        // Failures may happen when flushing data/parity data out. Exceptions\n        // may be thrown if more than 3 streamers fail, or updatePipeline RPC\n        // fails. Streamers may keep waiting for the new block/GS information.\n        // Thus need to force closing these threads.\n        closeThreads(true);\n      }\n\n      try (TraceScope ignored \u003d\n               dfsClient.getTracer().newScope(\"completeFile\")) {\n        completeFile(currentBlockGroup);\n      }\n      logCorruptBlocks();\n    } catch (ClosedChannelException ignored) {\n    } finally {\n      setClosed();\n      // shutdown executor of flushAll tasks\n      flushAllExecutor.shutdownNow();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSStripedOutputStream.java",
      "extendedDetails": {}
    },
    "e30ce01ddce1cfd1e9d49c4784eb4a6bc87e36ca": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9494. Parallel optimization of DFSStripedOutputStream#flushAllInternals. Contributed by Gao Rui.\n",
      "commitDate": "01/02/16 1:02 PM",
      "commitName": "e30ce01ddce1cfd1e9d49c4784eb4a6bc87e36ca",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "18/12/15 3:57 PM",
      "commitNameOld": "61ab0440f7eaff0f631cbae0378403912f88d7ad",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 44.88,
      "commitsBetweenForRepo": 252,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,61 +1,63 @@\n   protected synchronized void closeImpl() throws IOException {\n     if (isClosed()) {\n       final MultipleIOException.Builder b \u003d new MultipleIOException.Builder();\n       for(int i \u003d 0; i \u003c streamers.size(); i++) {\n         final StripedDataStreamer si \u003d getStripedDataStreamer(i);\n         try {\n           si.getLastException().check(true);\n         } catch (IOException e) {\n           b.add(e);\n         }\n       }\n       final IOException ioe \u003d b.build();\n       if (ioe !\u003d null) {\n         throw ioe;\n       }\n       return;\n     }\n \n     try {\n       // flush from all upper layers\n       flushBuffer();\n       // if the last stripe is incomplete, generate and write parity cells\n       if (generateParityCellsForLastStripe()) {\n         writeParityCells();\n       }\n       enqueueAllCurrentPackets();\n \n       // flush all the data packets\n       flushAllInternals();\n       // check failures\n       checkStreamerFailures();\n \n       for (int i \u003d 0; i \u003c numAllBlocks; i++) {\n         final StripedDataStreamer s \u003d setCurrentStreamer(i);\n         if (s.isHealthy()) {\n           try {\n             if (s.getBytesCurBlock() \u003e 0) {\n               setCurrentPacketToEmpty();\n             }\n             // flush the last \"close\" packet to Datanode\n             flushInternal();\n           } catch(Exception e) {\n             // TODO for both close and endBlock, we currently do not handle\n             // failures when sending the last packet. We actually do not need to\n             // bump GS for this kind of failure. Thus counting the total number\n             // of failures may be good enough.\n           }\n         }\n       }\n \n       closeThreads(false);\n       try (TraceScope ignored \u003d\n                dfsClient.getTracer().newScope(\"completeFile\")) {\n         completeFile(currentBlockGroup);\n       }\n       logCorruptBlocks();\n     } catch (ClosedChannelException ignored) {\n     } finally {\n       setClosed();\n+      // shutdown executor of flushAll tasks\n+      flushAllExecutor.shutdownNow();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected synchronized void closeImpl() throws IOException {\n    if (isClosed()) {\n      final MultipleIOException.Builder b \u003d new MultipleIOException.Builder();\n      for(int i \u003d 0; i \u003c streamers.size(); i++) {\n        final StripedDataStreamer si \u003d getStripedDataStreamer(i);\n        try {\n          si.getLastException().check(true);\n        } catch (IOException e) {\n          b.add(e);\n        }\n      }\n      final IOException ioe \u003d b.build();\n      if (ioe !\u003d null) {\n        throw ioe;\n      }\n      return;\n    }\n\n    try {\n      // flush from all upper layers\n      flushBuffer();\n      // if the last stripe is incomplete, generate and write parity cells\n      if (generateParityCellsForLastStripe()) {\n        writeParityCells();\n      }\n      enqueueAllCurrentPackets();\n\n      // flush all the data packets\n      flushAllInternals();\n      // check failures\n      checkStreamerFailures();\n\n      for (int i \u003d 0; i \u003c numAllBlocks; i++) {\n        final StripedDataStreamer s \u003d setCurrentStreamer(i);\n        if (s.isHealthy()) {\n          try {\n            if (s.getBytesCurBlock() \u003e 0) {\n              setCurrentPacketToEmpty();\n            }\n            // flush the last \"close\" packet to Datanode\n            flushInternal();\n          } catch(Exception e) {\n            // TODO for both close and endBlock, we currently do not handle\n            // failures when sending the last packet. We actually do not need to\n            // bump GS for this kind of failure. Thus counting the total number\n            // of failures may be good enough.\n          }\n        }\n      }\n\n      closeThreads(false);\n      try (TraceScope ignored \u003d\n               dfsClient.getTracer().newScope(\"completeFile\")) {\n        completeFile(currentBlockGroup);\n      }\n      logCorruptBlocks();\n    } catch (ClosedChannelException ignored) {\n    } finally {\n      setClosed();\n      // shutdown executor of flushAll tasks\n      flushAllExecutor.shutdownNow();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSStripedOutputStream.java",
      "extendedDetails": {}
    },
    "5104077e1f431ad3675d0b1c5c3cf53936902d8e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9373. Erasure coding: friendly log information for write operations with some failed streamers. Contributed by Li Bo.\n\nChange-Id: Ie8ab4ae00e9ee0eb03c32a54bea26a3524308038\n",
      "commitDate": "17/12/15 1:05 PM",
      "commitName": "5104077e1f431ad3675d0b1c5c3cf53936902d8e",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "02/12/15 5:39 PM",
      "commitNameOld": "e8bd1ba74b2fc7a6a1b71d068ef01a0fb0bbe294",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 14.81,
      "commitsBetweenForRepo": 93,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,60 +1,61 @@\n   protected synchronized void closeImpl() throws IOException {\n     if (isClosed()) {\n       final MultipleIOException.Builder b \u003d new MultipleIOException.Builder();\n       for(int i \u003d 0; i \u003c streamers.size(); i++) {\n         final StripedDataStreamer si \u003d getStripedDataStreamer(i);\n         try {\n           si.getLastException().check(true);\n         } catch (IOException e) {\n           b.add(e);\n         }\n       }\n       final IOException ioe \u003d b.build();\n       if (ioe !\u003d null) {\n         throw ioe;\n       }\n       return;\n     }\n \n     try {\n       // flush from all upper layers\n       flushBuffer();\n       // if the last stripe is incomplete, generate and write parity cells\n       if (generateParityCellsForLastStripe()) {\n         writeParityCells();\n       }\n       enqueueAllCurrentPackets();\n \n       // flush all the data packets\n       flushAllInternals();\n       // check failures\n       checkStreamerFailures();\n \n       for (int i \u003d 0; i \u003c numAllBlocks; i++) {\n         final StripedDataStreamer s \u003d setCurrentStreamer(i);\n         if (s.isHealthy()) {\n           try {\n             if (s.getBytesCurBlock() \u003e 0) {\n               setCurrentPacketToEmpty();\n             }\n             // flush the last \"close\" packet to Datanode\n             flushInternal();\n           } catch(Exception e) {\n             // TODO for both close and endBlock, we currently do not handle\n             // failures when sending the last packet. We actually do not need to\n             // bump GS for this kind of failure. Thus counting the total number\n             // of failures may be good enough.\n           }\n         }\n       }\n \n       closeThreads(false);\n       try (TraceScope ignored \u003d\n                dfsClient.getTracer().newScope(\"completeFile\")) {\n         completeFile(currentBlockGroup);\n       }\n+      logCorruptBlocks();\n     } catch (ClosedChannelException ignored) {\n     } finally {\n       setClosed();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected synchronized void closeImpl() throws IOException {\n    if (isClosed()) {\n      final MultipleIOException.Builder b \u003d new MultipleIOException.Builder();\n      for(int i \u003d 0; i \u003c streamers.size(); i++) {\n        final StripedDataStreamer si \u003d getStripedDataStreamer(i);\n        try {\n          si.getLastException().check(true);\n        } catch (IOException e) {\n          b.add(e);\n        }\n      }\n      final IOException ioe \u003d b.build();\n      if (ioe !\u003d null) {\n        throw ioe;\n      }\n      return;\n    }\n\n    try {\n      // flush from all upper layers\n      flushBuffer();\n      // if the last stripe is incomplete, generate and write parity cells\n      if (generateParityCellsForLastStripe()) {\n        writeParityCells();\n      }\n      enqueueAllCurrentPackets();\n\n      // flush all the data packets\n      flushAllInternals();\n      // check failures\n      checkStreamerFailures();\n\n      for (int i \u003d 0; i \u003c numAllBlocks; i++) {\n        final StripedDataStreamer s \u003d setCurrentStreamer(i);\n        if (s.isHealthy()) {\n          try {\n            if (s.getBytesCurBlock() \u003e 0) {\n              setCurrentPacketToEmpty();\n            }\n            // flush the last \"close\" packet to Datanode\n            flushInternal();\n          } catch(Exception e) {\n            // TODO for both close and endBlock, we currently do not handle\n            // failures when sending the last packet. We actually do not need to\n            // bump GS for this kind of failure. Thus counting the total number\n            // of failures may be good enough.\n          }\n        }\n      }\n\n      closeThreads(false);\n      try (TraceScope ignored \u003d\n               dfsClient.getTracer().newScope(\"completeFile\")) {\n        completeFile(currentBlockGroup);\n      }\n      logCorruptBlocks();\n    } catch (ClosedChannelException ignored) {\n    } finally {\n      setClosed();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSStripedOutputStream.java",
      "extendedDetails": {}
    },
    "e8bd1ba74b2fc7a6a1b71d068ef01a0fb0bbe294": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9294. DFSClient deadlock when close file and failed to renew lease.  Contributed by Brahma Reddy Battula\n",
      "commitDate": "02/12/15 5:39 PM",
      "commitName": "e8bd1ba74b2fc7a6a1b71d068ef01a0fb0bbe294",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "29/10/15 12:04 AM",
      "commitNameOld": "5eca6dece67620f990f3306b6caaf09f317b38f6",
      "commitAuthorOld": "Walter Su",
      "daysBetweenCommits": 34.77,
      "commitsBetweenForRepo": 235,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,61 +1,60 @@\n   protected synchronized void closeImpl() throws IOException {\n     if (isClosed()) {\n       final MultipleIOException.Builder b \u003d new MultipleIOException.Builder();\n       for(int i \u003d 0; i \u003c streamers.size(); i++) {\n         final StripedDataStreamer si \u003d getStripedDataStreamer(i);\n         try {\n           si.getLastException().check(true);\n         } catch (IOException e) {\n           b.add(e);\n         }\n       }\n       final IOException ioe \u003d b.build();\n       if (ioe !\u003d null) {\n         throw ioe;\n       }\n       return;\n     }\n \n     try {\n       // flush from all upper layers\n       flushBuffer();\n       // if the last stripe is incomplete, generate and write parity cells\n       if (generateParityCellsForLastStripe()) {\n         writeParityCells();\n       }\n       enqueueAllCurrentPackets();\n \n       // flush all the data packets\n       flushAllInternals();\n       // check failures\n       checkStreamerFailures();\n \n       for (int i \u003d 0; i \u003c numAllBlocks; i++) {\n         final StripedDataStreamer s \u003d setCurrentStreamer(i);\n         if (s.isHealthy()) {\n           try {\n             if (s.getBytesCurBlock() \u003e 0) {\n               setCurrentPacketToEmpty();\n             }\n             // flush the last \"close\" packet to Datanode\n             flushInternal();\n           } catch(Exception e) {\n             // TODO for both close and endBlock, we currently do not handle\n             // failures when sending the last packet. We actually do not need to\n             // bump GS for this kind of failure. Thus counting the total number\n             // of failures may be good enough.\n           }\n         }\n       }\n \n       closeThreads(false);\n       try (TraceScope ignored \u003d\n                dfsClient.getTracer().newScope(\"completeFile\")) {\n         completeFile(currentBlockGroup);\n       }\n-      dfsClient.endFileLease(fileId);\n     } catch (ClosedChannelException ignored) {\n     } finally {\n       setClosed();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected synchronized void closeImpl() throws IOException {\n    if (isClosed()) {\n      final MultipleIOException.Builder b \u003d new MultipleIOException.Builder();\n      for(int i \u003d 0; i \u003c streamers.size(); i++) {\n        final StripedDataStreamer si \u003d getStripedDataStreamer(i);\n        try {\n          si.getLastException().check(true);\n        } catch (IOException e) {\n          b.add(e);\n        }\n      }\n      final IOException ioe \u003d b.build();\n      if (ioe !\u003d null) {\n        throw ioe;\n      }\n      return;\n    }\n\n    try {\n      // flush from all upper layers\n      flushBuffer();\n      // if the last stripe is incomplete, generate and write parity cells\n      if (generateParityCellsForLastStripe()) {\n        writeParityCells();\n      }\n      enqueueAllCurrentPackets();\n\n      // flush all the data packets\n      flushAllInternals();\n      // check failures\n      checkStreamerFailures();\n\n      for (int i \u003d 0; i \u003c numAllBlocks; i++) {\n        final StripedDataStreamer s \u003d setCurrentStreamer(i);\n        if (s.isHealthy()) {\n          try {\n            if (s.getBytesCurBlock() \u003e 0) {\n              setCurrentPacketToEmpty();\n            }\n            // flush the last \"close\" packet to Datanode\n            flushInternal();\n          } catch(Exception e) {\n            // TODO for both close and endBlock, we currently do not handle\n            // failures when sending the last packet. We actually do not need to\n            // bump GS for this kind of failure. Thus counting the total number\n            // of failures may be good enough.\n          }\n        }\n      }\n\n      closeThreads(false);\n      try (TraceScope ignored \u003d\n               dfsClient.getTracer().newScope(\"completeFile\")) {\n        completeFile(currentBlockGroup);\n      }\n    } catch (ClosedChannelException ignored) {\n    } finally {\n      setClosed();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSStripedOutputStream.java",
      "extendedDetails": {}
    },
    "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8979. Clean up checkstyle warnings in hadoop-hdfs-client module. Contributed by Mingliang Liu.\n",
      "commitDate": "03/10/15 11:38 AM",
      "commitName": "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "29/09/15 1:39 AM",
      "commitNameOld": "8fd55202468b28422b0df888641c9b08906fe4a7",
      "commitAuthorOld": "",
      "daysBetweenCommits": 4.42,
      "commitsBetweenForRepo": 29,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,63 +1,61 @@\n   protected synchronized void closeImpl() throws IOException {\n     if (isClosed()) {\n       final MultipleIOException.Builder b \u003d new MultipleIOException.Builder();\n       for(int i \u003d 0; i \u003c streamers.size(); i++) {\n         final StripedDataStreamer si \u003d getStripedDataStreamer(i);\n         try {\n           si.getLastException().check(true);\n         } catch (IOException e) {\n           b.add(e);\n         }\n       }\n       final IOException ioe \u003d b.build();\n       if (ioe !\u003d null) {\n         throw ioe;\n       }\n       return;\n     }\n \n     try {\n       // flush from all upper layers\n       flushBuffer();\n       // if the last stripe is incomplete, generate and write parity cells\n       if (generateParityCellsForLastStripe()) {\n         writeParityCells();\n       }\n       enqueueAllCurrentPackets();\n \n       // flush all the data packets\n       flushAllInternals();\n       // check failures\n       checkStreamerFailures();\n \n       for (int i \u003d 0; i \u003c numAllBlocks; i++) {\n         final StripedDataStreamer s \u003d setCurrentStreamer(i);\n         if (s.isHealthy()) {\n           try {\n             if (s.getBytesCurBlock() \u003e 0) {\n               setCurrentPacketToEmpty();\n             }\n             // flush the last \"close\" packet to Datanode\n             flushInternal();\n           } catch(Exception e) {\n             // TODO for both close and endBlock, we currently do not handle\n             // failures when sending the last packet. We actually do not need to\n             // bump GS for this kind of failure. Thus counting the total number\n             // of failures may be good enough.\n           }\n         }\n       }\n \n       closeThreads(false);\n-      TraceScope scope \u003d dfsClient.getTracer().newScope(\"completeFile\");\n-      try {\n+      try (TraceScope ignored \u003d\n+               dfsClient.getTracer().newScope(\"completeFile\")) {\n         completeFile(currentBlockGroup);\n-      } finally {\n-        scope.close();\n       }\n       dfsClient.endFileLease(fileId);\n     } catch (ClosedChannelException ignored) {\n     } finally {\n       setClosed();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected synchronized void closeImpl() throws IOException {\n    if (isClosed()) {\n      final MultipleIOException.Builder b \u003d new MultipleIOException.Builder();\n      for(int i \u003d 0; i \u003c streamers.size(); i++) {\n        final StripedDataStreamer si \u003d getStripedDataStreamer(i);\n        try {\n          si.getLastException().check(true);\n        } catch (IOException e) {\n          b.add(e);\n        }\n      }\n      final IOException ioe \u003d b.build();\n      if (ioe !\u003d null) {\n        throw ioe;\n      }\n      return;\n    }\n\n    try {\n      // flush from all upper layers\n      flushBuffer();\n      // if the last stripe is incomplete, generate and write parity cells\n      if (generateParityCellsForLastStripe()) {\n        writeParityCells();\n      }\n      enqueueAllCurrentPackets();\n\n      // flush all the data packets\n      flushAllInternals();\n      // check failures\n      checkStreamerFailures();\n\n      for (int i \u003d 0; i \u003c numAllBlocks; i++) {\n        final StripedDataStreamer s \u003d setCurrentStreamer(i);\n        if (s.isHealthy()) {\n          try {\n            if (s.getBytesCurBlock() \u003e 0) {\n              setCurrentPacketToEmpty();\n            }\n            // flush the last \"close\" packet to Datanode\n            flushInternal();\n          } catch(Exception e) {\n            // TODO for both close and endBlock, we currently do not handle\n            // failures when sending the last packet. We actually do not need to\n            // bump GS for this kind of failure. Thus counting the total number\n            // of failures may be good enough.\n          }\n        }\n      }\n\n      closeThreads(false);\n      try (TraceScope ignored \u003d\n               dfsClient.getTracer().newScope(\"completeFile\")) {\n        completeFile(currentBlockGroup);\n      }\n      dfsClient.endFileLease(fileId);\n    } catch (ClosedChannelException ignored) {\n    } finally {\n      setClosed();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSStripedOutputStream.java",
      "extendedDetails": {}
    }
  }
}