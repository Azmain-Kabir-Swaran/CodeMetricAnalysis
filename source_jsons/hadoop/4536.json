{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "PBHelper.java",
  "functionName": "convert",
  "functionId": "convert___blkCmd-BlockCommandProto",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
  "functionStartLine": 633,
  "functionEndLine": 682,
  "numCommitsSeen": 195,
  "timeTaken": 7282,
  "changeHistory": [
    "06022b8fdc40e50eaac63758246353058e8cfa6d",
    "3e2a0b5446bce51871ab3e1262a0ac6bd365e94f",
    "552b4fb9f9a76b18605322c0b0e8072613d67773",
    "25b0e8471ed744578b2d8e3f0debe5477b268e54",
    "15d08c4778350a86d7bae0174aeb48f8d8f61cce",
    "eb9f1b670726e1af03f2e940ce2696b880964972",
    "abf09f090f77a7e54e331b7a07354e7926b60dc9",
    "40eb94ade3161d93e7a762a839004748f6d0ae89",
    "8134b1c8702d7d6b3994c73b34afc7f8ee33ac6e",
    "3cffe34177c72ea67194c3b0aaf0ddbf67ff3a0c",
    "38a19bc293dec6221ae96e304fc6ab660d94e706"
  ],
  "changeHistoryShort": {
    "06022b8fdc40e50eaac63758246353058e8cfa6d": "Ybodychange",
    "3e2a0b5446bce51871ab3e1262a0ac6bd365e94f": "Ybodychange",
    "552b4fb9f9a76b18605322c0b0e8072613d67773": "Ybodychange",
    "25b0e8471ed744578b2d8e3f0debe5477b268e54": "Ybodychange",
    "15d08c4778350a86d7bae0174aeb48f8d8f61cce": "Ybodychange",
    "eb9f1b670726e1af03f2e940ce2696b880964972": "Ybodychange",
    "abf09f090f77a7e54e331b7a07354e7926b60dc9": "Ybodychange",
    "40eb94ade3161d93e7a762a839004748f6d0ae89": "Ybodychange",
    "8134b1c8702d7d6b3994c73b34afc7f8ee33ac6e": "Ybodychange",
    "3cffe34177c72ea67194c3b0aaf0ddbf67ff3a0c": "Ybodychange",
    "38a19bc293dec6221ae96e304fc6ab660d94e706": "Yintroduced"
  },
  "changeHistoryDetails": {
    "06022b8fdc40e50eaac63758246353058e8cfa6d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9111. Move hdfs-client protobuf convert methods from PBHelper to PBHelperClient. Contributed by Mingliang Liu.\n",
      "commitDate": "21/09/15 6:53 PM",
      "commitName": "06022b8fdc40e50eaac63758246353058e8cfa6d",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "19/09/15 6:08 PM",
      "commitNameOld": "3a9c7076e81c1cc47c0ecf30c60abd9a65d8a501",
      "commitAuthorOld": "Lei Xu",
      "daysBetweenCommits": 2.03,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,50 +1,50 @@\n   public static BlockCommand convert(BlockCommandProto blkCmd) {\n     List\u003cBlockProto\u003e blockProtoList \u003d blkCmd.getBlocksList();\n     Block[] blocks \u003d new Block[blockProtoList.size()];\n     for (int i \u003d 0; i \u003c blockProtoList.size(); i++) {\n-      blocks[i] \u003d PBHelper.convert(blockProtoList.get(i));\n+      blocks[i] \u003d PBHelperClient.convert(blockProtoList.get(i));\n     }\n     List\u003cDatanodeInfosProto\u003e targetList \u003d blkCmd.getTargetsList();\n     DatanodeInfo[][] targets \u003d new DatanodeInfo[targetList.size()][];\n     for (int i \u003d 0; i \u003c targetList.size(); i++) {\n-      targets[i] \u003d PBHelper.convert(targetList.get(i));\n+      targets[i] \u003d PBHelperClient.convert(targetList.get(i));\n     }\n \n     StorageType[][] targetStorageTypes \u003d new StorageType[targetList.size()][];\n     List\u003cStorageTypesProto\u003e targetStorageTypesList \u003d blkCmd.getTargetStorageTypesList();\n     if (targetStorageTypesList.isEmpty()) { // missing storage types\n       for(int i \u003d 0; i \u003c targetStorageTypes.length; i++) {\n         targetStorageTypes[i] \u003d new StorageType[targets[i].length];\n         Arrays.fill(targetStorageTypes[i], StorageType.DEFAULT);\n       }\n     } else {\n       for(int i \u003d 0; i \u003c targetStorageTypes.length; i++) {\n         List\u003cStorageTypeProto\u003e p \u003d targetStorageTypesList.get(i).getStorageTypesList();\n-        targetStorageTypes[i] \u003d convertStorageTypes(p, targets[i].length);\n+        targetStorageTypes[i] \u003d PBHelperClient.convertStorageTypes(p, targets[i].length);\n       }\n     }\n \n     List\u003cStorageUuidsProto\u003e targetStorageUuidsList \u003d blkCmd.getTargetStorageUuidsList();\n     String[][] targetStorageIDs \u003d new String[targetStorageUuidsList.size()][];\n     for(int i \u003d 0; i \u003c targetStorageIDs.length; i++) {\n       List\u003cString\u003e storageIDs \u003d targetStorageUuidsList.get(i).getStorageUuidsList();\n       targetStorageIDs[i] \u003d storageIDs.toArray(new String[storageIDs.size()]);\n     }\n \n     int action \u003d DatanodeProtocol.DNA_UNKNOWN;\n     switch (blkCmd.getAction()) {\n     case TRANSFER:\n       action \u003d DatanodeProtocol.DNA_TRANSFER;\n       break;\n     case INVALIDATE:\n       action \u003d DatanodeProtocol.DNA_INVALIDATE;\n       break;\n     case SHUTDOWN:\n       action \u003d DatanodeProtocol.DNA_SHUTDOWN;\n       break;\n     default:\n       throw new AssertionError(\"Unknown action type: \" + blkCmd.getAction());\n     }\n     return new BlockCommand(action, blkCmd.getBlockPoolId(), blocks, targets,\n         targetStorageTypes, targetStorageIDs);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static BlockCommand convert(BlockCommandProto blkCmd) {\n    List\u003cBlockProto\u003e blockProtoList \u003d blkCmd.getBlocksList();\n    Block[] blocks \u003d new Block[blockProtoList.size()];\n    for (int i \u003d 0; i \u003c blockProtoList.size(); i++) {\n      blocks[i] \u003d PBHelperClient.convert(blockProtoList.get(i));\n    }\n    List\u003cDatanodeInfosProto\u003e targetList \u003d blkCmd.getTargetsList();\n    DatanodeInfo[][] targets \u003d new DatanodeInfo[targetList.size()][];\n    for (int i \u003d 0; i \u003c targetList.size(); i++) {\n      targets[i] \u003d PBHelperClient.convert(targetList.get(i));\n    }\n\n    StorageType[][] targetStorageTypes \u003d new StorageType[targetList.size()][];\n    List\u003cStorageTypesProto\u003e targetStorageTypesList \u003d blkCmd.getTargetStorageTypesList();\n    if (targetStorageTypesList.isEmpty()) { // missing storage types\n      for(int i \u003d 0; i \u003c targetStorageTypes.length; i++) {\n        targetStorageTypes[i] \u003d new StorageType[targets[i].length];\n        Arrays.fill(targetStorageTypes[i], StorageType.DEFAULT);\n      }\n    } else {\n      for(int i \u003d 0; i \u003c targetStorageTypes.length; i++) {\n        List\u003cStorageTypeProto\u003e p \u003d targetStorageTypesList.get(i).getStorageTypesList();\n        targetStorageTypes[i] \u003d PBHelperClient.convertStorageTypes(p, targets[i].length);\n      }\n    }\n\n    List\u003cStorageUuidsProto\u003e targetStorageUuidsList \u003d blkCmd.getTargetStorageUuidsList();\n    String[][] targetStorageIDs \u003d new String[targetStorageUuidsList.size()][];\n    for(int i \u003d 0; i \u003c targetStorageIDs.length; i++) {\n      List\u003cString\u003e storageIDs \u003d targetStorageUuidsList.get(i).getStorageUuidsList();\n      targetStorageIDs[i] \u003d storageIDs.toArray(new String[storageIDs.size()]);\n    }\n\n    int action \u003d DatanodeProtocol.DNA_UNKNOWN;\n    switch (blkCmd.getAction()) {\n    case TRANSFER:\n      action \u003d DatanodeProtocol.DNA_TRANSFER;\n      break;\n    case INVALIDATE:\n      action \u003d DatanodeProtocol.DNA_INVALIDATE;\n      break;\n    case SHUTDOWN:\n      action \u003d DatanodeProtocol.DNA_SHUTDOWN;\n      break;\n    default:\n      throw new AssertionError(\"Unknown action type: \" + blkCmd.getAction());\n    }\n    return new BlockCommand(action, blkCmd.getBlockPoolId(), blocks, targets,\n        targetStorageTypes, targetStorageIDs);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
      "extendedDetails": {}
    },
    "3e2a0b5446bce51871ab3e1262a0ac6bd365e94f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6969. Archival Storage: INode#getStoragePolicyID should always return the latest storage policy. Contributed by Jing Zhao.\n",
      "commitDate": "01/09/14 5:56 PM",
      "commitName": "3e2a0b5446bce51871ab3e1262a0ac6bd365e94f",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "20/08/14 10:22 PM",
      "commitNameOld": "c92d869d02af4d7870649317474134ba94b1dd0c",
      "commitAuthorOld": "",
      "daysBetweenCommits": 11.82,
      "commitsBetweenForRepo": 34,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,50 +1,50 @@\n   public static BlockCommand convert(BlockCommandProto blkCmd) {\n     List\u003cBlockProto\u003e blockProtoList \u003d blkCmd.getBlocksList();\n     Block[] blocks \u003d new Block[blockProtoList.size()];\n     for (int i \u003d 0; i \u003c blockProtoList.size(); i++) {\n       blocks[i] \u003d PBHelper.convert(blockProtoList.get(i));\n     }\n     List\u003cDatanodeInfosProto\u003e targetList \u003d blkCmd.getTargetsList();\n     DatanodeInfo[][] targets \u003d new DatanodeInfo[targetList.size()][];\n     for (int i \u003d 0; i \u003c targetList.size(); i++) {\n       targets[i] \u003d PBHelper.convert(targetList.get(i));\n     }\n \n     StorageType[][] targetStorageTypes \u003d new StorageType[targetList.size()][];\n     List\u003cStorageTypesProto\u003e targetStorageTypesList \u003d blkCmd.getTargetStorageTypesList();\n     if (targetStorageTypesList.isEmpty()) { // missing storage types\n       for(int i \u003d 0; i \u003c targetStorageTypes.length; i++) {\n         targetStorageTypes[i] \u003d new StorageType[targets[i].length];\n         Arrays.fill(targetStorageTypes[i], StorageType.DEFAULT);\n       }\n     } else {\n       for(int i \u003d 0; i \u003c targetStorageTypes.length; i++) {\n         List\u003cStorageTypeProto\u003e p \u003d targetStorageTypesList.get(i).getStorageTypesList();\n-        targetStorageTypes[i] \u003d p.toArray(new StorageType[p.size()]);\n+        targetStorageTypes[i] \u003d convertStorageTypes(p, targets[i].length);\n       }\n     }\n \n     List\u003cStorageUuidsProto\u003e targetStorageUuidsList \u003d blkCmd.getTargetStorageUuidsList();\n     String[][] targetStorageIDs \u003d new String[targetStorageUuidsList.size()][];\n     for(int i \u003d 0; i \u003c targetStorageIDs.length; i++) {\n       List\u003cString\u003e storageIDs \u003d targetStorageUuidsList.get(i).getStorageUuidsList();\n       targetStorageIDs[i] \u003d storageIDs.toArray(new String[storageIDs.size()]);\n     }\n \n     int action \u003d DatanodeProtocol.DNA_UNKNOWN;\n     switch (blkCmd.getAction()) {\n     case TRANSFER:\n       action \u003d DatanodeProtocol.DNA_TRANSFER;\n       break;\n     case INVALIDATE:\n       action \u003d DatanodeProtocol.DNA_INVALIDATE;\n       break;\n     case SHUTDOWN:\n       action \u003d DatanodeProtocol.DNA_SHUTDOWN;\n       break;\n     default:\n       throw new AssertionError(\"Unknown action type: \" + blkCmd.getAction());\n     }\n     return new BlockCommand(action, blkCmd.getBlockPoolId(), blocks, targets,\n         targetStorageTypes, targetStorageIDs);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static BlockCommand convert(BlockCommandProto blkCmd) {\n    List\u003cBlockProto\u003e blockProtoList \u003d blkCmd.getBlocksList();\n    Block[] blocks \u003d new Block[blockProtoList.size()];\n    for (int i \u003d 0; i \u003c blockProtoList.size(); i++) {\n      blocks[i] \u003d PBHelper.convert(blockProtoList.get(i));\n    }\n    List\u003cDatanodeInfosProto\u003e targetList \u003d blkCmd.getTargetsList();\n    DatanodeInfo[][] targets \u003d new DatanodeInfo[targetList.size()][];\n    for (int i \u003d 0; i \u003c targetList.size(); i++) {\n      targets[i] \u003d PBHelper.convert(targetList.get(i));\n    }\n\n    StorageType[][] targetStorageTypes \u003d new StorageType[targetList.size()][];\n    List\u003cStorageTypesProto\u003e targetStorageTypesList \u003d blkCmd.getTargetStorageTypesList();\n    if (targetStorageTypesList.isEmpty()) { // missing storage types\n      for(int i \u003d 0; i \u003c targetStorageTypes.length; i++) {\n        targetStorageTypes[i] \u003d new StorageType[targets[i].length];\n        Arrays.fill(targetStorageTypes[i], StorageType.DEFAULT);\n      }\n    } else {\n      for(int i \u003d 0; i \u003c targetStorageTypes.length; i++) {\n        List\u003cStorageTypeProto\u003e p \u003d targetStorageTypesList.get(i).getStorageTypesList();\n        targetStorageTypes[i] \u003d convertStorageTypes(p, targets[i].length);\n      }\n    }\n\n    List\u003cStorageUuidsProto\u003e targetStorageUuidsList \u003d blkCmd.getTargetStorageUuidsList();\n    String[][] targetStorageIDs \u003d new String[targetStorageUuidsList.size()][];\n    for(int i \u003d 0; i \u003c targetStorageIDs.length; i++) {\n      List\u003cString\u003e storageIDs \u003d targetStorageUuidsList.get(i).getStorageUuidsList();\n      targetStorageIDs[i] \u003d storageIDs.toArray(new String[storageIDs.size()]);\n    }\n\n    int action \u003d DatanodeProtocol.DNA_UNKNOWN;\n    switch (blkCmd.getAction()) {\n    case TRANSFER:\n      action \u003d DatanodeProtocol.DNA_TRANSFER;\n      break;\n    case INVALIDATE:\n      action \u003d DatanodeProtocol.DNA_INVALIDATE;\n      break;\n    case SHUTDOWN:\n      action \u003d DatanodeProtocol.DNA_SHUTDOWN;\n      break;\n    default:\n      throw new AssertionError(\"Unknown action type: \" + blkCmd.getAction());\n    }\n    return new BlockCommand(action, blkCmd.getBlockPoolId(), blocks, targets,\n        targetStorageTypes, targetStorageIDs);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
      "extendedDetails": {}
    },
    "552b4fb9f9a76b18605322c0b0e8072613d67773": {
      "type": "Ybodychange",
      "commitMessage": "Merge from trunk to branch\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/fs-encryption@1612928 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/07/14 12:26 PM",
      "commitName": "552b4fb9f9a76b18605322c0b0e8072613d67773",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "22/07/14 10:57 AM",
      "commitNameOld": "69b75fca7aec5f5cbf79bc7db3915119cef69e65",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 1.06,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,36 +1,50 @@\n   public static BlockCommand convert(BlockCommandProto blkCmd) {\n     List\u003cBlockProto\u003e blockProtoList \u003d blkCmd.getBlocksList();\n     Block[] blocks \u003d new Block[blockProtoList.size()];\n     for (int i \u003d 0; i \u003c blockProtoList.size(); i++) {\n       blocks[i] \u003d PBHelper.convert(blockProtoList.get(i));\n     }\n     List\u003cDatanodeInfosProto\u003e targetList \u003d blkCmd.getTargetsList();\n     DatanodeInfo[][] targets \u003d new DatanodeInfo[targetList.size()][];\n     for (int i \u003d 0; i \u003c targetList.size(); i++) {\n       targets[i] \u003d PBHelper.convert(targetList.get(i));\n     }\n \n+    StorageType[][] targetStorageTypes \u003d new StorageType[targetList.size()][];\n+    List\u003cStorageTypesProto\u003e targetStorageTypesList \u003d blkCmd.getTargetStorageTypesList();\n+    if (targetStorageTypesList.isEmpty()) { // missing storage types\n+      for(int i \u003d 0; i \u003c targetStorageTypes.length; i++) {\n+        targetStorageTypes[i] \u003d new StorageType[targets[i].length];\n+        Arrays.fill(targetStorageTypes[i], StorageType.DEFAULT);\n+      }\n+    } else {\n+      for(int i \u003d 0; i \u003c targetStorageTypes.length; i++) {\n+        List\u003cStorageTypeProto\u003e p \u003d targetStorageTypesList.get(i).getStorageTypesList();\n+        targetStorageTypes[i] \u003d p.toArray(new StorageType[p.size()]);\n+      }\n+    }\n+\n     List\u003cStorageUuidsProto\u003e targetStorageUuidsList \u003d blkCmd.getTargetStorageUuidsList();\n     String[][] targetStorageIDs \u003d new String[targetStorageUuidsList.size()][];\n     for(int i \u003d 0; i \u003c targetStorageIDs.length; i++) {\n       List\u003cString\u003e storageIDs \u003d targetStorageUuidsList.get(i).getStorageUuidsList();\n       targetStorageIDs[i] \u003d storageIDs.toArray(new String[storageIDs.size()]);\n     }\n \n     int action \u003d DatanodeProtocol.DNA_UNKNOWN;\n     switch (blkCmd.getAction()) {\n     case TRANSFER:\n       action \u003d DatanodeProtocol.DNA_TRANSFER;\n       break;\n     case INVALIDATE:\n       action \u003d DatanodeProtocol.DNA_INVALIDATE;\n       break;\n     case SHUTDOWN:\n       action \u003d DatanodeProtocol.DNA_SHUTDOWN;\n       break;\n     default:\n       throw new AssertionError(\"Unknown action type: \" + blkCmd.getAction());\n     }\n     return new BlockCommand(action, blkCmd.getBlockPoolId(), blocks, targets,\n-        targetStorageIDs);\n+        targetStorageTypes, targetStorageIDs);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static BlockCommand convert(BlockCommandProto blkCmd) {\n    List\u003cBlockProto\u003e blockProtoList \u003d blkCmd.getBlocksList();\n    Block[] blocks \u003d new Block[blockProtoList.size()];\n    for (int i \u003d 0; i \u003c blockProtoList.size(); i++) {\n      blocks[i] \u003d PBHelper.convert(blockProtoList.get(i));\n    }\n    List\u003cDatanodeInfosProto\u003e targetList \u003d blkCmd.getTargetsList();\n    DatanodeInfo[][] targets \u003d new DatanodeInfo[targetList.size()][];\n    for (int i \u003d 0; i \u003c targetList.size(); i++) {\n      targets[i] \u003d PBHelper.convert(targetList.get(i));\n    }\n\n    StorageType[][] targetStorageTypes \u003d new StorageType[targetList.size()][];\n    List\u003cStorageTypesProto\u003e targetStorageTypesList \u003d blkCmd.getTargetStorageTypesList();\n    if (targetStorageTypesList.isEmpty()) { // missing storage types\n      for(int i \u003d 0; i \u003c targetStorageTypes.length; i++) {\n        targetStorageTypes[i] \u003d new StorageType[targets[i].length];\n        Arrays.fill(targetStorageTypes[i], StorageType.DEFAULT);\n      }\n    } else {\n      for(int i \u003d 0; i \u003c targetStorageTypes.length; i++) {\n        List\u003cStorageTypeProto\u003e p \u003d targetStorageTypesList.get(i).getStorageTypesList();\n        targetStorageTypes[i] \u003d p.toArray(new StorageType[p.size()]);\n      }\n    }\n\n    List\u003cStorageUuidsProto\u003e targetStorageUuidsList \u003d blkCmd.getTargetStorageUuidsList();\n    String[][] targetStorageIDs \u003d new String[targetStorageUuidsList.size()][];\n    for(int i \u003d 0; i \u003c targetStorageIDs.length; i++) {\n      List\u003cString\u003e storageIDs \u003d targetStorageUuidsList.get(i).getStorageUuidsList();\n      targetStorageIDs[i] \u003d storageIDs.toArray(new String[storageIDs.size()]);\n    }\n\n    int action \u003d DatanodeProtocol.DNA_UNKNOWN;\n    switch (blkCmd.getAction()) {\n    case TRANSFER:\n      action \u003d DatanodeProtocol.DNA_TRANSFER;\n      break;\n    case INVALIDATE:\n      action \u003d DatanodeProtocol.DNA_INVALIDATE;\n      break;\n    case SHUTDOWN:\n      action \u003d DatanodeProtocol.DNA_SHUTDOWN;\n      break;\n    default:\n      throw new AssertionError(\"Unknown action type: \" + blkCmd.getAction());\n    }\n    return new BlockCommand(action, blkCmd.getBlockPoolId(), blocks, targets,\n        targetStorageTypes, targetStorageIDs);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
      "extendedDetails": {}
    },
    "25b0e8471ed744578b2d8e3f0debe5477b268e54": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6702. Change DFSClient to pass the StorageType from the namenode to datanodes and change datanode to write block replicas using the specified storage type.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1612493 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/07/14 12:41 AM",
      "commitName": "25b0e8471ed744578b2d8e3f0debe5477b268e54",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "21/06/14 3:59 PM",
      "commitNameOld": "8a83bb7ad6177f473c20c4cc9c0f46746224332c",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 30.36,
      "commitsBetweenForRepo": 203,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,36 +1,50 @@\n   public static BlockCommand convert(BlockCommandProto blkCmd) {\n     List\u003cBlockProto\u003e blockProtoList \u003d blkCmd.getBlocksList();\n     Block[] blocks \u003d new Block[blockProtoList.size()];\n     for (int i \u003d 0; i \u003c blockProtoList.size(); i++) {\n       blocks[i] \u003d PBHelper.convert(blockProtoList.get(i));\n     }\n     List\u003cDatanodeInfosProto\u003e targetList \u003d blkCmd.getTargetsList();\n     DatanodeInfo[][] targets \u003d new DatanodeInfo[targetList.size()][];\n     for (int i \u003d 0; i \u003c targetList.size(); i++) {\n       targets[i] \u003d PBHelper.convert(targetList.get(i));\n     }\n \n+    StorageType[][] targetStorageTypes \u003d new StorageType[targetList.size()][];\n+    List\u003cStorageTypesProto\u003e targetStorageTypesList \u003d blkCmd.getTargetStorageTypesList();\n+    if (targetStorageTypesList.isEmpty()) { // missing storage types\n+      for(int i \u003d 0; i \u003c targetStorageTypes.length; i++) {\n+        targetStorageTypes[i] \u003d new StorageType[targets[i].length];\n+        Arrays.fill(targetStorageTypes[i], StorageType.DEFAULT);\n+      }\n+    } else {\n+      for(int i \u003d 0; i \u003c targetStorageTypes.length; i++) {\n+        List\u003cStorageTypeProto\u003e p \u003d targetStorageTypesList.get(i).getStorageTypesList();\n+        targetStorageTypes[i] \u003d p.toArray(new StorageType[p.size()]);\n+      }\n+    }\n+\n     List\u003cStorageUuidsProto\u003e targetStorageUuidsList \u003d blkCmd.getTargetStorageUuidsList();\n     String[][] targetStorageIDs \u003d new String[targetStorageUuidsList.size()][];\n     for(int i \u003d 0; i \u003c targetStorageIDs.length; i++) {\n       List\u003cString\u003e storageIDs \u003d targetStorageUuidsList.get(i).getStorageUuidsList();\n       targetStorageIDs[i] \u003d storageIDs.toArray(new String[storageIDs.size()]);\n     }\n \n     int action \u003d DatanodeProtocol.DNA_UNKNOWN;\n     switch (blkCmd.getAction()) {\n     case TRANSFER:\n       action \u003d DatanodeProtocol.DNA_TRANSFER;\n       break;\n     case INVALIDATE:\n       action \u003d DatanodeProtocol.DNA_INVALIDATE;\n       break;\n     case SHUTDOWN:\n       action \u003d DatanodeProtocol.DNA_SHUTDOWN;\n       break;\n     default:\n       throw new AssertionError(\"Unknown action type: \" + blkCmd.getAction());\n     }\n     return new BlockCommand(action, blkCmd.getBlockPoolId(), blocks, targets,\n-        targetStorageIDs);\n+        targetStorageTypes, targetStorageIDs);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static BlockCommand convert(BlockCommandProto blkCmd) {\n    List\u003cBlockProto\u003e blockProtoList \u003d blkCmd.getBlocksList();\n    Block[] blocks \u003d new Block[blockProtoList.size()];\n    for (int i \u003d 0; i \u003c blockProtoList.size(); i++) {\n      blocks[i] \u003d PBHelper.convert(blockProtoList.get(i));\n    }\n    List\u003cDatanodeInfosProto\u003e targetList \u003d blkCmd.getTargetsList();\n    DatanodeInfo[][] targets \u003d new DatanodeInfo[targetList.size()][];\n    for (int i \u003d 0; i \u003c targetList.size(); i++) {\n      targets[i] \u003d PBHelper.convert(targetList.get(i));\n    }\n\n    StorageType[][] targetStorageTypes \u003d new StorageType[targetList.size()][];\n    List\u003cStorageTypesProto\u003e targetStorageTypesList \u003d blkCmd.getTargetStorageTypesList();\n    if (targetStorageTypesList.isEmpty()) { // missing storage types\n      for(int i \u003d 0; i \u003c targetStorageTypes.length; i++) {\n        targetStorageTypes[i] \u003d new StorageType[targets[i].length];\n        Arrays.fill(targetStorageTypes[i], StorageType.DEFAULT);\n      }\n    } else {\n      for(int i \u003d 0; i \u003c targetStorageTypes.length; i++) {\n        List\u003cStorageTypeProto\u003e p \u003d targetStorageTypesList.get(i).getStorageTypesList();\n        targetStorageTypes[i] \u003d p.toArray(new StorageType[p.size()]);\n      }\n    }\n\n    List\u003cStorageUuidsProto\u003e targetStorageUuidsList \u003d blkCmd.getTargetStorageUuidsList();\n    String[][] targetStorageIDs \u003d new String[targetStorageUuidsList.size()][];\n    for(int i \u003d 0; i \u003c targetStorageIDs.length; i++) {\n      List\u003cString\u003e storageIDs \u003d targetStorageUuidsList.get(i).getStorageUuidsList();\n      targetStorageIDs[i] \u003d storageIDs.toArray(new String[storageIDs.size()]);\n    }\n\n    int action \u003d DatanodeProtocol.DNA_UNKNOWN;\n    switch (blkCmd.getAction()) {\n    case TRANSFER:\n      action \u003d DatanodeProtocol.DNA_TRANSFER;\n      break;\n    case INVALIDATE:\n      action \u003d DatanodeProtocol.DNA_INVALIDATE;\n      break;\n    case SHUTDOWN:\n      action \u003d DatanodeProtocol.DNA_SHUTDOWN;\n      break;\n    default:\n      throw new AssertionError(\"Unknown action type: \" + blkCmd.getAction());\n    }\n    return new BlockCommand(action, blkCmd.getBlockPoolId(), blocks, targets,\n        targetStorageTypes, targetStorageIDs);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
      "extendedDetails": {}
    },
    "15d08c4778350a86d7bae0174aeb48f8d8f61cce": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5349. DNA_CACHE and DNA_UNCACHE should be by blockId only (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1532116 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/10/13 3:19 PM",
      "commitName": "15d08c4778350a86d7bae0174aeb48f8d8f61cce",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "09/10/13 2:30 PM",
      "commitNameOld": "3fc8792b5c75fca9fc4f6cf4b95fb2927c62e624",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 5.03,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,33 +1,27 @@\n   public static BlockCommand convert(BlockCommandProto blkCmd) {\n     List\u003cBlockProto\u003e blockProtoList \u003d blkCmd.getBlocksList();\n     Block[] blocks \u003d new Block[blockProtoList.size()];\n     for (int i \u003d 0; i \u003c blockProtoList.size(); i++) {\n       blocks[i] \u003d PBHelper.convert(blockProtoList.get(i));\n     }\n     List\u003cDatanodeInfosProto\u003e targetList \u003d blkCmd.getTargetsList();\n     DatanodeInfo[][] targets \u003d new DatanodeInfo[targetList.size()][];\n     for (int i \u003d 0; i \u003c targetList.size(); i++) {\n       targets[i] \u003d PBHelper.convert(targetList.get(i));\n     }\n     int action \u003d DatanodeProtocol.DNA_UNKNOWN;\n     switch (blkCmd.getAction()) {\n     case TRANSFER:\n       action \u003d DatanodeProtocol.DNA_TRANSFER;\n       break;\n     case INVALIDATE:\n       action \u003d DatanodeProtocol.DNA_INVALIDATE;\n       break;\n     case SHUTDOWN:\n       action \u003d DatanodeProtocol.DNA_SHUTDOWN;\n       break;\n-    case CACHE:\n-      action \u003d DatanodeProtocol.DNA_CACHE;\n-      break;\n-    case UNCACHE:\n-      action \u003d DatanodeProtocol.DNA_UNCACHE;\n-      break;\n     default:\n       throw new AssertionError(\"Unknown action type: \" + blkCmd.getAction());\n     }\n     return new BlockCommand(action, blkCmd.getBlockPoolId(), blocks, targets);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static BlockCommand convert(BlockCommandProto blkCmd) {\n    List\u003cBlockProto\u003e blockProtoList \u003d blkCmd.getBlocksList();\n    Block[] blocks \u003d new Block[blockProtoList.size()];\n    for (int i \u003d 0; i \u003c blockProtoList.size(); i++) {\n      blocks[i] \u003d PBHelper.convert(blockProtoList.get(i));\n    }\n    List\u003cDatanodeInfosProto\u003e targetList \u003d blkCmd.getTargetsList();\n    DatanodeInfo[][] targets \u003d new DatanodeInfo[targetList.size()][];\n    for (int i \u003d 0; i \u003c targetList.size(); i++) {\n      targets[i] \u003d PBHelper.convert(targetList.get(i));\n    }\n    int action \u003d DatanodeProtocol.DNA_UNKNOWN;\n    switch (blkCmd.getAction()) {\n    case TRANSFER:\n      action \u003d DatanodeProtocol.DNA_TRANSFER;\n      break;\n    case INVALIDATE:\n      action \u003d DatanodeProtocol.DNA_INVALIDATE;\n      break;\n    case SHUTDOWN:\n      action \u003d DatanodeProtocol.DNA_SHUTDOWN;\n      break;\n    default:\n      throw new AssertionError(\"Unknown action type: \" + blkCmd.getAction());\n    }\n    return new BlockCommand(action, blkCmd.getBlockPoolId(), blocks, targets);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
      "extendedDetails": {}
    },
    "eb9f1b670726e1af03f2e940ce2696b880964972": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5232. Protocol changes to transmit StorageUuid.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2832@1525153 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/09/13 3:06 PM",
      "commitName": "eb9f1b670726e1af03f2e940ce2696b880964972",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "18/09/13 8:12 AM",
      "commitNameOld": "abf09f090f77a7e54e331b7a07354e7926b60dc9",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 2.29,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,34 @@\n   public static BlockCommand convert(BlockCommandProto blkCmd) {\n     List\u003cBlockProto\u003e blockProtoList \u003d blkCmd.getBlocksList();\n     Block[] blocks \u003d new Block[blockProtoList.size()];\n     for (int i \u003d 0; i \u003c blockProtoList.size(); i++) {\n       blocks[i] \u003d PBHelper.convert(blockProtoList.get(i));\n     }\n     List\u003cDatanodeInfosProto\u003e targetList \u003d blkCmd.getTargetsList();\n     DatanodeInfo[][] targets \u003d new DatanodeInfo[targetList.size()][];\n     for (int i \u003d 0; i \u003c targetList.size(); i++) {\n       targets[i] \u003d PBHelper.convert(targetList.get(i));\n     }\n \n-    List\u003cStorageIDsProto\u003e targetStorageIDsList \u003d blkCmd.getTargetStorageIDsList();\n-    String[][] targetStorageIDs \u003d new String[targetStorageIDsList.size()][];\n+    List\u003cStorageUuidsProto\u003e targetStorageUuidsList \u003d blkCmd.getTargetStorageUuidsList();\n+    String[][] targetStorageIDs \u003d new String[targetStorageUuidsList.size()][];\n     for(int i \u003d 0; i \u003c targetStorageIDs.length; i++) {\n-      List\u003cString\u003e storageIDs \u003d targetStorageIDsList.get(i).getStorageIDsList();\n+      List\u003cString\u003e storageIDs \u003d targetStorageUuidsList.get(i).getStorageUuidsList();\n       targetStorageIDs[i] \u003d storageIDs.toArray(new String[storageIDs.size()]);\n     }\n \n     int action \u003d DatanodeProtocol.DNA_UNKNOWN;\n     switch (blkCmd.getAction()) {\n     case TRANSFER:\n       action \u003d DatanodeProtocol.DNA_TRANSFER;\n       break;\n     case INVALIDATE:\n       action \u003d DatanodeProtocol.DNA_INVALIDATE;\n       break;\n     case SHUTDOWN:\n       action \u003d DatanodeProtocol.DNA_SHUTDOWN;\n       break;\n     }\n     return new BlockCommand(action, blkCmd.getBlockPoolId(), blocks, targets,\n         targetStorageIDs);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static BlockCommand convert(BlockCommandProto blkCmd) {\n    List\u003cBlockProto\u003e blockProtoList \u003d blkCmd.getBlocksList();\n    Block[] blocks \u003d new Block[blockProtoList.size()];\n    for (int i \u003d 0; i \u003c blockProtoList.size(); i++) {\n      blocks[i] \u003d PBHelper.convert(blockProtoList.get(i));\n    }\n    List\u003cDatanodeInfosProto\u003e targetList \u003d blkCmd.getTargetsList();\n    DatanodeInfo[][] targets \u003d new DatanodeInfo[targetList.size()][];\n    for (int i \u003d 0; i \u003c targetList.size(); i++) {\n      targets[i] \u003d PBHelper.convert(targetList.get(i));\n    }\n\n    List\u003cStorageUuidsProto\u003e targetStorageUuidsList \u003d blkCmd.getTargetStorageUuidsList();\n    String[][] targetStorageIDs \u003d new String[targetStorageUuidsList.size()][];\n    for(int i \u003d 0; i \u003c targetStorageIDs.length; i++) {\n      List\u003cString\u003e storageIDs \u003d targetStorageUuidsList.get(i).getStorageUuidsList();\n      targetStorageIDs[i] \u003d storageIDs.toArray(new String[storageIDs.size()]);\n    }\n\n    int action \u003d DatanodeProtocol.DNA_UNKNOWN;\n    switch (blkCmd.getAction()) {\n    case TRANSFER:\n      action \u003d DatanodeProtocol.DNA_TRANSFER;\n      break;\n    case INVALIDATE:\n      action \u003d DatanodeProtocol.DNA_INVALIDATE;\n      break;\n    case SHUTDOWN:\n      action \u003d DatanodeProtocol.DNA_SHUTDOWN;\n      break;\n    }\n    return new BlockCommand(action, blkCmd.getBlockPoolId(), blocks, targets,\n        targetStorageIDs);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
      "extendedDetails": {}
    },
    "abf09f090f77a7e54e331b7a07354e7926b60dc9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4990. Change BlockPlacementPolicy to choose storages instead of datanodes.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2832@1524444 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/09/13 8:12 AM",
      "commitName": "abf09f090f77a7e54e331b7a07354e7926b60dc9",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "03/09/13 7:03 AM",
      "commitNameOld": "3f070e83b1f4e0211ece8c0ab508a61188ad352a",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 15.05,
      "commitsBetweenForRepo": 72,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,25 +1,34 @@\n   public static BlockCommand convert(BlockCommandProto blkCmd) {\n     List\u003cBlockProto\u003e blockProtoList \u003d blkCmd.getBlocksList();\n     Block[] blocks \u003d new Block[blockProtoList.size()];\n     for (int i \u003d 0; i \u003c blockProtoList.size(); i++) {\n       blocks[i] \u003d PBHelper.convert(blockProtoList.get(i));\n     }\n     List\u003cDatanodeInfosProto\u003e targetList \u003d blkCmd.getTargetsList();\n     DatanodeInfo[][] targets \u003d new DatanodeInfo[targetList.size()][];\n     for (int i \u003d 0; i \u003c targetList.size(); i++) {\n       targets[i] \u003d PBHelper.convert(targetList.get(i));\n     }\n+\n+    List\u003cStorageIDsProto\u003e targetStorageIDsList \u003d blkCmd.getTargetStorageIDsList();\n+    String[][] targetStorageIDs \u003d new String[targetStorageIDsList.size()][];\n+    for(int i \u003d 0; i \u003c targetStorageIDs.length; i++) {\n+      List\u003cString\u003e storageIDs \u003d targetStorageIDsList.get(i).getStorageIDsList();\n+      targetStorageIDs[i] \u003d storageIDs.toArray(new String[storageIDs.size()]);\n+    }\n+\n     int action \u003d DatanodeProtocol.DNA_UNKNOWN;\n     switch (blkCmd.getAction()) {\n     case TRANSFER:\n       action \u003d DatanodeProtocol.DNA_TRANSFER;\n       break;\n     case INVALIDATE:\n       action \u003d DatanodeProtocol.DNA_INVALIDATE;\n       break;\n     case SHUTDOWN:\n       action \u003d DatanodeProtocol.DNA_SHUTDOWN;\n       break;\n     }\n-    return new BlockCommand(action, blkCmd.getBlockPoolId(), blocks, targets);\n+    return new BlockCommand(action, blkCmd.getBlockPoolId(), blocks, targets,\n+        targetStorageIDs);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static BlockCommand convert(BlockCommandProto blkCmd) {\n    List\u003cBlockProto\u003e blockProtoList \u003d blkCmd.getBlocksList();\n    Block[] blocks \u003d new Block[blockProtoList.size()];\n    for (int i \u003d 0; i \u003c blockProtoList.size(); i++) {\n      blocks[i] \u003d PBHelper.convert(blockProtoList.get(i));\n    }\n    List\u003cDatanodeInfosProto\u003e targetList \u003d blkCmd.getTargetsList();\n    DatanodeInfo[][] targets \u003d new DatanodeInfo[targetList.size()][];\n    for (int i \u003d 0; i \u003c targetList.size(); i++) {\n      targets[i] \u003d PBHelper.convert(targetList.get(i));\n    }\n\n    List\u003cStorageIDsProto\u003e targetStorageIDsList \u003d blkCmd.getTargetStorageIDsList();\n    String[][] targetStorageIDs \u003d new String[targetStorageIDsList.size()][];\n    for(int i \u003d 0; i \u003c targetStorageIDs.length; i++) {\n      List\u003cString\u003e storageIDs \u003d targetStorageIDsList.get(i).getStorageIDsList();\n      targetStorageIDs[i] \u003d storageIDs.toArray(new String[storageIDs.size()]);\n    }\n\n    int action \u003d DatanodeProtocol.DNA_UNKNOWN;\n    switch (blkCmd.getAction()) {\n    case TRANSFER:\n      action \u003d DatanodeProtocol.DNA_TRANSFER;\n      break;\n    case INVALIDATE:\n      action \u003d DatanodeProtocol.DNA_INVALIDATE;\n      break;\n    case SHUTDOWN:\n      action \u003d DatanodeProtocol.DNA_SHUTDOWN;\n      break;\n    }\n    return new BlockCommand(action, blkCmd.getBlockPoolId(), blocks, targets,\n        targetStorageIDs);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
      "extendedDetails": {}
    },
    "40eb94ade3161d93e7a762a839004748f6d0ae89": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5053. NameNode should invoke DataNode APIs to coordinate caching. (Andrew Wang)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1523145 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/09/13 4:27 PM",
      "commitName": "40eb94ade3161d93e7a762a839004748f6d0ae89",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "06/09/13 11:52 AM",
      "commitNameOld": "f41f8b8842c3f26d19f7fa928070c7c07f760e4c",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 7.19,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,25 +1,33 @@\n   public static BlockCommand convert(BlockCommandProto blkCmd) {\n     List\u003cBlockProto\u003e blockProtoList \u003d blkCmd.getBlocksList();\n     Block[] blocks \u003d new Block[blockProtoList.size()];\n     for (int i \u003d 0; i \u003c blockProtoList.size(); i++) {\n       blocks[i] \u003d PBHelper.convert(blockProtoList.get(i));\n     }\n     List\u003cDatanodeInfosProto\u003e targetList \u003d blkCmd.getTargetsList();\n     DatanodeInfo[][] targets \u003d new DatanodeInfo[targetList.size()][];\n     for (int i \u003d 0; i \u003c targetList.size(); i++) {\n       targets[i] \u003d PBHelper.convert(targetList.get(i));\n     }\n     int action \u003d DatanodeProtocol.DNA_UNKNOWN;\n     switch (blkCmd.getAction()) {\n     case TRANSFER:\n       action \u003d DatanodeProtocol.DNA_TRANSFER;\n       break;\n     case INVALIDATE:\n       action \u003d DatanodeProtocol.DNA_INVALIDATE;\n       break;\n     case SHUTDOWN:\n       action \u003d DatanodeProtocol.DNA_SHUTDOWN;\n       break;\n+    case CACHE:\n+      action \u003d DatanodeProtocol.DNA_CACHE;\n+      break;\n+    case UNCACHE:\n+      action \u003d DatanodeProtocol.DNA_UNCACHE;\n+      break;\n+    default:\n+      throw new AssertionError(\"Unknown action type: \" + blkCmd.getAction());\n     }\n     return new BlockCommand(action, blkCmd.getBlockPoolId(), blocks, targets);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static BlockCommand convert(BlockCommandProto blkCmd) {\n    List\u003cBlockProto\u003e blockProtoList \u003d blkCmd.getBlocksList();\n    Block[] blocks \u003d new Block[blockProtoList.size()];\n    for (int i \u003d 0; i \u003c blockProtoList.size(); i++) {\n      blocks[i] \u003d PBHelper.convert(blockProtoList.get(i));\n    }\n    List\u003cDatanodeInfosProto\u003e targetList \u003d blkCmd.getTargetsList();\n    DatanodeInfo[][] targets \u003d new DatanodeInfo[targetList.size()][];\n    for (int i \u003d 0; i \u003c targetList.size(); i++) {\n      targets[i] \u003d PBHelper.convert(targetList.get(i));\n    }\n    int action \u003d DatanodeProtocol.DNA_UNKNOWN;\n    switch (blkCmd.getAction()) {\n    case TRANSFER:\n      action \u003d DatanodeProtocol.DNA_TRANSFER;\n      break;\n    case INVALIDATE:\n      action \u003d DatanodeProtocol.DNA_INVALIDATE;\n      break;\n    case SHUTDOWN:\n      action \u003d DatanodeProtocol.DNA_SHUTDOWN;\n      break;\n    case CACHE:\n      action \u003d DatanodeProtocol.DNA_CACHE;\n      break;\n    case UNCACHE:\n      action \u003d DatanodeProtocol.DNA_UNCACHE;\n      break;\n    default:\n      throw new AssertionError(\"Unknown action type: \" + blkCmd.getAction());\n    }\n    return new BlockCommand(action, blkCmd.getBlockPoolId(), blocks, targets);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
      "extendedDetails": {}
    },
    "8134b1c8702d7d6b3994c73b34afc7f8ee33ac6e": {
      "type": "Ybodychange",
      "commitMessage": "Merge trunk into HA branch.\n\nSeveral conflicts around introduction of protobuf translator for DatanodeProtocol - mostly trivial resolutions.\n\nNB: this does not successfully pass any tests since the HAStatus field needs\nto be integrated into the HeartbeatResponse Protobuf implementation.\nThat will be a separate commit for clearer history.\n\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1214518 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/12/11 2:47 PM",
      "commitName": "8134b1c8702d7d6b3994c73b34afc7f8ee33ac6e",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "13/12/11 11:02 AM",
      "commitNameOld": "a0fe4f476ae907c9c070af48a250739a4fb33362",
      "commitAuthorOld": "",
      "daysBetweenCommits": 1.16,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,25 @@\n   public static BlockCommand convert(BlockCommandProto blkCmd) {\n     List\u003cBlockProto\u003e blockProtoList \u003d blkCmd.getBlocksList();\n-    List\u003cDatanodeInfosProto\u003e targetList \u003d blkCmd.getTargetsList();\n-    DatanodeInfo[][] targets \u003d new DatanodeInfo[blockProtoList.size()][];\n     Block[] blocks \u003d new Block[blockProtoList.size()];\n     for (int i \u003d 0; i \u003c blockProtoList.size(); i++) {\n-      targets[i] \u003d PBHelper.convert(targetList.get(i));\n       blocks[i] \u003d PBHelper.convert(blockProtoList.get(i));\n     }\n+    List\u003cDatanodeInfosProto\u003e targetList \u003d blkCmd.getTargetsList();\n+    DatanodeInfo[][] targets \u003d new DatanodeInfo[targetList.size()][];\n+    for (int i \u003d 0; i \u003c targetList.size(); i++) {\n+      targets[i] \u003d PBHelper.convert(targetList.get(i));\n+    }\n     int action \u003d DatanodeProtocol.DNA_UNKNOWN;\n     switch (blkCmd.getAction()) {\n     case TRANSFER:\n       action \u003d DatanodeProtocol.DNA_TRANSFER;\n       break;\n     case INVALIDATE:\n       action \u003d DatanodeProtocol.DNA_INVALIDATE;\n       break;\n+    case SHUTDOWN:\n+      action \u003d DatanodeProtocol.DNA_SHUTDOWN;\n+      break;\n     }\n     return new BlockCommand(action, blkCmd.getBlockPoolId(), blocks, targets);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static BlockCommand convert(BlockCommandProto blkCmd) {\n    List\u003cBlockProto\u003e blockProtoList \u003d blkCmd.getBlocksList();\n    Block[] blocks \u003d new Block[blockProtoList.size()];\n    for (int i \u003d 0; i \u003c blockProtoList.size(); i++) {\n      blocks[i] \u003d PBHelper.convert(blockProtoList.get(i));\n    }\n    List\u003cDatanodeInfosProto\u003e targetList \u003d blkCmd.getTargetsList();\n    DatanodeInfo[][] targets \u003d new DatanodeInfo[targetList.size()][];\n    for (int i \u003d 0; i \u003c targetList.size(); i++) {\n      targets[i] \u003d PBHelper.convert(targetList.get(i));\n    }\n    int action \u003d DatanodeProtocol.DNA_UNKNOWN;\n    switch (blkCmd.getAction()) {\n    case TRANSFER:\n      action \u003d DatanodeProtocol.DNA_TRANSFER;\n      break;\n    case INVALIDATE:\n      action \u003d DatanodeProtocol.DNA_INVALIDATE;\n      break;\n    case SHUTDOWN:\n      action \u003d DatanodeProtocol.DNA_SHUTDOWN;\n      break;\n    }\n    return new BlockCommand(action, blkCmd.getBlockPoolId(), blocks, targets);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
      "extendedDetails": {}
    },
    "3cffe34177c72ea67194c3b0aaf0ddbf67ff3a0c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2661. Enable protobuf RPC for DatanodeProtocol.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1214033 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/12/11 6:15 PM",
      "commitName": "3cffe34177c72ea67194c3b0aaf0ddbf67ff3a0c",
      "commitAuthor": "Jitendra Nath Pandey",
      "commitDateOld": "13/12/11 3:31 PM",
      "commitNameOld": "3954a2fb1cbc7a8a0d1ad5859e7f5c9415530f4c",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 0.11,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,25 @@\n   public static BlockCommand convert(BlockCommandProto blkCmd) {\n     List\u003cBlockProto\u003e blockProtoList \u003d blkCmd.getBlocksList();\n-    List\u003cDatanodeInfosProto\u003e targetList \u003d blkCmd.getTargetsList();\n-    DatanodeInfo[][] targets \u003d new DatanodeInfo[blockProtoList.size()][];\n     Block[] blocks \u003d new Block[blockProtoList.size()];\n     for (int i \u003d 0; i \u003c blockProtoList.size(); i++) {\n-      targets[i] \u003d PBHelper.convert(targetList.get(i));\n       blocks[i] \u003d PBHelper.convert(blockProtoList.get(i));\n     }\n+    List\u003cDatanodeInfosProto\u003e targetList \u003d blkCmd.getTargetsList();\n+    DatanodeInfo[][] targets \u003d new DatanodeInfo[targetList.size()][];\n+    for (int i \u003d 0; i \u003c targetList.size(); i++) {\n+      targets[i] \u003d PBHelper.convert(targetList.get(i));\n+    }\n     int action \u003d DatanodeProtocol.DNA_UNKNOWN;\n     switch (blkCmd.getAction()) {\n     case TRANSFER:\n       action \u003d DatanodeProtocol.DNA_TRANSFER;\n       break;\n     case INVALIDATE:\n       action \u003d DatanodeProtocol.DNA_INVALIDATE;\n       break;\n+    case SHUTDOWN:\n+      action \u003d DatanodeProtocol.DNA_SHUTDOWN;\n+      break;\n     }\n     return new BlockCommand(action, blkCmd.getBlockPoolId(), blocks, targets);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static BlockCommand convert(BlockCommandProto blkCmd) {\n    List\u003cBlockProto\u003e blockProtoList \u003d blkCmd.getBlocksList();\n    Block[] blocks \u003d new Block[blockProtoList.size()];\n    for (int i \u003d 0; i \u003c blockProtoList.size(); i++) {\n      blocks[i] \u003d PBHelper.convert(blockProtoList.get(i));\n    }\n    List\u003cDatanodeInfosProto\u003e targetList \u003d blkCmd.getTargetsList();\n    DatanodeInfo[][] targets \u003d new DatanodeInfo[targetList.size()][];\n    for (int i \u003d 0; i \u003c targetList.size(); i++) {\n      targets[i] \u003d PBHelper.convert(targetList.get(i));\n    }\n    int action \u003d DatanodeProtocol.DNA_UNKNOWN;\n    switch (blkCmd.getAction()) {\n    case TRANSFER:\n      action \u003d DatanodeProtocol.DNA_TRANSFER;\n      break;\n    case INVALIDATE:\n      action \u003d DatanodeProtocol.DNA_INVALIDATE;\n      break;\n    case SHUTDOWN:\n      action \u003d DatanodeProtocol.DNA_SHUTDOWN;\n      break;\n    }\n    return new BlockCommand(action, blkCmd.getBlockPoolId(), blocks, targets);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
      "extendedDetails": {}
    },
    "38a19bc293dec6221ae96e304fc6ab660d94e706": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-2642. Protobuf translators for DatanodeProtocol.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1212606 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/12/11 12:02 PM",
      "commitName": "38a19bc293dec6221ae96e304fc6ab660d94e706",
      "commitAuthor": "Jitendra Nath Pandey",
      "diff": "@@ -0,0 +1,20 @@\n+  public static BlockCommand convert(BlockCommandProto blkCmd) {\n+    List\u003cBlockProto\u003e blockProtoList \u003d blkCmd.getBlocksList();\n+    List\u003cDatanodeInfosProto\u003e targetList \u003d blkCmd.getTargetsList();\n+    DatanodeInfo[][] targets \u003d new DatanodeInfo[blockProtoList.size()][];\n+    Block[] blocks \u003d new Block[blockProtoList.size()];\n+    for (int i \u003d 0; i \u003c blockProtoList.size(); i++) {\n+      targets[i] \u003d PBHelper.convert(targetList.get(i));\n+      blocks[i] \u003d PBHelper.convert(blockProtoList.get(i));\n+    }\n+    int action \u003d DatanodeProtocol.DNA_UNKNOWN;\n+    switch (blkCmd.getAction()) {\n+    case TRANSFER:\n+      action \u003d DatanodeProtocol.DNA_TRANSFER;\n+      break;\n+    case INVALIDATE:\n+      action \u003d DatanodeProtocol.DNA_INVALIDATE;\n+      break;\n+    }\n+    return new BlockCommand(action, blkCmd.getBlockPoolId(), blocks, targets);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public static BlockCommand convert(BlockCommandProto blkCmd) {\n    List\u003cBlockProto\u003e blockProtoList \u003d blkCmd.getBlocksList();\n    List\u003cDatanodeInfosProto\u003e targetList \u003d blkCmd.getTargetsList();\n    DatanodeInfo[][] targets \u003d new DatanodeInfo[blockProtoList.size()][];\n    Block[] blocks \u003d new Block[blockProtoList.size()];\n    for (int i \u003d 0; i \u003c blockProtoList.size(); i++) {\n      targets[i] \u003d PBHelper.convert(targetList.get(i));\n      blocks[i] \u003d PBHelper.convert(blockProtoList.get(i));\n    }\n    int action \u003d DatanodeProtocol.DNA_UNKNOWN;\n    switch (blkCmd.getAction()) {\n    case TRANSFER:\n      action \u003d DatanodeProtocol.DNA_TRANSFER;\n      break;\n    case INVALIDATE:\n      action \u003d DatanodeProtocol.DNA_INVALIDATE;\n      break;\n    }\n    return new BlockCommand(action, blkCmd.getBlockPoolId(), blocks, targets);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java"
    }
  }
}