{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockManager.java",
  "functionName": "getMissingReplOneBlocksCount",
  "functionId": "getMissingReplOneBlocksCount",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
  "functionStartLine": 4816,
  "functionEndLine": 4819,
  "numCommitsSeen": 477,
  "timeTaken": 12637,
  "changeHistory": [
    "999c8fcbefc876d9c26c23c5b87a64a81e4f113e",
    "32d043d9c5f4615058ea4f65a58ba271ba47fcb5",
    "8c5b23b5473e447384f818d69d907d5c35ed6d6a"
  ],
  "changeHistoryShort": {
    "999c8fcbefc876d9c26c23c5b87a64a81e4f113e": "Ybodychange",
    "32d043d9c5f4615058ea4f65a58ba271ba47fcb5": "Ybodychange",
    "8c5b23b5473e447384f818d69d907d5c35ed6d6a": "Yintroduced"
  },
  "changeHistoryDetails": {
    "999c8fcbefc876d9c26c23c5b87a64a81e4f113e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10999. Introduce separate stats for Replicated and Erasure Coded Blocks apart from the current Aggregated stats. (Manoj Govindassamy via lei)\n",
      "commitDate": "14/06/17 10:44 AM",
      "commitName": "999c8fcbefc876d9c26c23c5b87a64a81e4f113e",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "29/05/17 1:30 AM",
      "commitNameOld": "a7f085d6bf499edf23e650a4f7211c53a442da0e",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 16.38,
      "commitsBetweenForRepo": 71,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,4 +1,4 @@\n   public long getMissingReplOneBlocksCount() {\n     // not locking\n-    return this.neededReconstruction.getCorruptReplOneBlockSize();\n+    return this.neededReconstruction.getCorruptReplicationOneBlockSize();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public long getMissingReplOneBlocksCount() {\n    // not locking\n    return this.neededReconstruction.getCorruptReplicationOneBlockSize();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "32d043d9c5f4615058ea4f65a58ba271ba47fcb5": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9857. Erasure Coding: Rename replication-based names in BlockManager to more generic [part-1]. Contributed by Rakesh R.\n",
      "commitDate": "16/03/16 4:53 PM",
      "commitName": "32d043d9c5f4615058ea4f65a58ba271ba47fcb5",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "10/03/16 7:03 PM",
      "commitNameOld": "e01c6ea688e62f25c4310e771a0cd85b53a5fb87",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 5.87,
      "commitsBetweenForRepo": 26,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,4 +1,4 @@\n   public long getMissingReplOneBlocksCount() {\n     // not locking\n-    return this.neededReplications.getCorruptReplOneBlockSize();\n+    return this.neededReconstruction.getCorruptReplOneBlockSize();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public long getMissingReplOneBlocksCount() {\n    // not locking\n    return this.neededReconstruction.getCorruptReplOneBlockSize();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "8c5b23b5473e447384f818d69d907d5c35ed6d6a": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-7165. Separate block metrics for files with replication count 1. (Zhe Zhang via wang)\n",
      "commitDate": "23/10/14 12:28 PM",
      "commitName": "8c5b23b5473e447384f818d69d907d5c35ed6d6a",
      "commitAuthor": "Andrew Wang",
      "diff": "@@ -0,0 +1,4 @@\n+  public long getMissingReplOneBlocksCount() {\n+    // not locking\n+    return this.neededReplications.getCorruptReplOneBlockSize();\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public long getMissingReplOneBlocksCount() {\n    // not locking\n    return this.neededReplications.getCorruptReplOneBlockSize();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java"
    }
  }
}