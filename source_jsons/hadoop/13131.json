{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "CacheReplicationMonitor.java",
  "functionName": "addNewPendingUncached",
  "functionId": "addNewPendingUncached___neededUncached-int__cachedBlock-CachedBlock__cached-List__DatanodeDescriptor____pendingUncached-List__DatanodeDescriptor__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/CacheReplicationMonitor.java",
  "functionStartLine": 618,
  "functionEndLine": 642,
  "numCommitsSeen": 28,
  "timeTaken": 2133,
  "changeHistory": [
    "d85c017d0488930d806f267141057fc73e68c728",
    "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a"
  ],
  "changeHistoryShort": {
    "d85c017d0488930d806f267141057fc73e68c728": "Ybodychange",
    "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a": "Yintroduced"
  },
  "changeHistoryDetails": {
    "d85c017d0488930d806f267141057fc73e68c728": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5651. Remove dfs.namenode.caching.enabled and improve CRM locking. Contributed by Colin Patrick McCabe.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1555002 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/01/14 6:45 PM",
      "commitName": "d85c017d0488930d806f267141057fc73e68c728",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "31/12/13 4:01 PM",
      "commitNameOld": "07e4fb1455abc33584fc666ef745abe256ebd7d1",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 2.11,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,25 @@\n   private void addNewPendingUncached(int neededUncached,\n       CachedBlock cachedBlock, List\u003cDatanodeDescriptor\u003e cached,\n       List\u003cDatanodeDescriptor\u003e pendingUncached) {\n-    if (!cacheManager.isActive()) {\n-      return;\n-    }\n     // Figure out which replicas can be uncached.\n     LinkedList\u003cDatanodeDescriptor\u003e possibilities \u003d\n         new LinkedList\u003cDatanodeDescriptor\u003e();\n     for (DatanodeDescriptor datanode : cached) {\n       if (!pendingUncached.contains(datanode)) {\n         possibilities.add(datanode);\n       }\n     }\n     while (neededUncached \u003e 0) {\n       if (possibilities.isEmpty()) {\n         LOG.warn(\"Logic error: we\u0027re trying to uncache more replicas than \" +\n             \"actually exist for \" + cachedBlock);\n         return;\n       }\n       DatanodeDescriptor datanode \u003d\n         possibilities.remove(random.nextInt(possibilities.size()));\n       pendingUncached.add(datanode);\n       boolean added \u003d datanode.getPendingUncached().add(cachedBlock);\n       assert added;\n       neededUncached--;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void addNewPendingUncached(int neededUncached,\n      CachedBlock cachedBlock, List\u003cDatanodeDescriptor\u003e cached,\n      List\u003cDatanodeDescriptor\u003e pendingUncached) {\n    // Figure out which replicas can be uncached.\n    LinkedList\u003cDatanodeDescriptor\u003e possibilities \u003d\n        new LinkedList\u003cDatanodeDescriptor\u003e();\n    for (DatanodeDescriptor datanode : cached) {\n      if (!pendingUncached.contains(datanode)) {\n        possibilities.add(datanode);\n      }\n    }\n    while (neededUncached \u003e 0) {\n      if (possibilities.isEmpty()) {\n        LOG.warn(\"Logic error: we\u0027re trying to uncache more replicas than \" +\n            \"actually exist for \" + cachedBlock);\n        return;\n      }\n      DatanodeDescriptor datanode \u003d\n        possibilities.remove(random.nextInt(possibilities.size()));\n      pendingUncached.add(datanode);\n      boolean added \u003d datanode.getPendingUncached().add(cachedBlock);\n      assert added;\n      neededUncached--;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/CacheReplicationMonitor.java",
      "extendedDetails": {}
    },
    "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5096. Automatically cache new data added to a cached path (contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1532924 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/10/13 3:15 PM",
      "commitName": "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
      "commitAuthor": "Colin McCabe",
      "diff": "@@ -0,0 +1,28 @@\n+  private void addNewPendingUncached(int neededUncached,\n+      CachedBlock cachedBlock, List\u003cDatanodeDescriptor\u003e cached,\n+      List\u003cDatanodeDescriptor\u003e pendingUncached) {\n+    if (!cacheManager.isActive()) {\n+      return;\n+    }\n+    // Figure out which replicas can be uncached.\n+    LinkedList\u003cDatanodeDescriptor\u003e possibilities \u003d\n+        new LinkedList\u003cDatanodeDescriptor\u003e();\n+    for (DatanodeDescriptor datanode : cached) {\n+      if (!pendingUncached.contains(datanode)) {\n+        possibilities.add(datanode);\n+      }\n+    }\n+    while (neededUncached \u003e 0) {\n+      if (possibilities.isEmpty()) {\n+        LOG.warn(\"Logic error: we\u0027re trying to uncache more replicas than \" +\n+            \"actually exist for \" + cachedBlock);\n+        return;\n+      }\n+      DatanodeDescriptor datanode \u003d\n+        possibilities.remove(random.nextInt(possibilities.size()));\n+      pendingUncached.add(datanode);\n+      boolean added \u003d datanode.getPendingUncached().add(cachedBlock);\n+      assert added;\n+      neededUncached--;\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void addNewPendingUncached(int neededUncached,\n      CachedBlock cachedBlock, List\u003cDatanodeDescriptor\u003e cached,\n      List\u003cDatanodeDescriptor\u003e pendingUncached) {\n    if (!cacheManager.isActive()) {\n      return;\n    }\n    // Figure out which replicas can be uncached.\n    LinkedList\u003cDatanodeDescriptor\u003e possibilities \u003d\n        new LinkedList\u003cDatanodeDescriptor\u003e();\n    for (DatanodeDescriptor datanode : cached) {\n      if (!pendingUncached.contains(datanode)) {\n        possibilities.add(datanode);\n      }\n    }\n    while (neededUncached \u003e 0) {\n      if (possibilities.isEmpty()) {\n        LOG.warn(\"Logic error: we\u0027re trying to uncache more replicas than \" +\n            \"actually exist for \" + cachedBlock);\n        return;\n      }\n      DatanodeDescriptor datanode \u003d\n        possibilities.remove(random.nextInt(possibilities.size()));\n      pendingUncached.add(datanode);\n      boolean added \u003d datanode.getPendingUncached().add(cachedBlock);\n      assert added;\n      neededUncached--;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/CacheReplicationMonitor.java"
    }
  }
}