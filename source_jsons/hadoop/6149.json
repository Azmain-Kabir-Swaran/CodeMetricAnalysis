{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSImageFormat.java",
  "functionName": "loadDirectory",
  "functionId": "loadDirectory___in-DataInput__counter-Counter",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
  "functionStartLine": 598,
  "functionEndLine": 605,
  "numCommitsSeen": 180,
  "timeTaken": 3729,
  "changeHistory": [
    "9d175853b0170683ad5f21d9bcdeaac49fe89e04",
    "c78e3a7cdd10c40454e9acb06986ba6d8573cb19",
    "0689363343a281a6f7f6f395227668bddc2663eb",
    "d6bd920bba0d7cb77ca76c3a79d1ba1e039da9e5",
    "da8e962e39bd41b73b53966826c82e741b08010b"
  ],
  "changeHistoryShort": {
    "9d175853b0170683ad5f21d9bcdeaac49fe89e04": "Ybodychange",
    "c78e3a7cdd10c40454e9acb06986ba6d8573cb19": "Ybodychange",
    "0689363343a281a6f7f6f395227668bddc2663eb": "Ybodychange",
    "d6bd920bba0d7cb77ca76c3a79d1ba1e039da9e5": "Ybodychange",
    "da8e962e39bd41b73b53966826c82e741b08010b": "Ymultichange(Yparameterchange,Ybodychange)"
  },
  "changeHistoryDetails": {
    "9d175853b0170683ad5f21d9bcdeaac49fe89e04": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10997. Reduce number of path resolving methods. Contributed by Daryn Sharp.\n",
      "commitDate": "24/10/16 3:14 PM",
      "commitName": "9d175853b0170683ad5f21d9bcdeaac49fe89e04",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "27/01/16 4:34 PM",
      "commitNameOld": "ec25c7f9c7e60c077d8c4143253c20445fcdaecf",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 270.9,
      "commitsBetweenForRepo": 1893,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,8 +1,8 @@\n    private int loadDirectory(DataInput in, Counter counter) throws IOException {\n      String parentPath \u003d FSImageSerialization.readString(in);\n      // Rename .snapshot paths if we\u0027re doing an upgrade\n      parentPath \u003d renameReservedPathsOnUpgrade(parentPath, getLayoutVersion());\n      final INodeDirectory parent \u003d INodeDirectory.valueOf(\n-         namesystem.dir.getINode(parentPath, true), parentPath);\n+         namesystem.dir.getINode(parentPath, DirOp.READ), parentPath);\n      return loadChildren(parent, in, counter);\n    }\n\\ No newline at end of file\n",
      "actualSource": "   private int loadDirectory(DataInput in, Counter counter) throws IOException {\n     String parentPath \u003d FSImageSerialization.readString(in);\n     // Rename .snapshot paths if we\u0027re doing an upgrade\n     parentPath \u003d renameReservedPathsOnUpgrade(parentPath, getLayoutVersion());\n     final INodeDirectory parent \u003d INodeDirectory.valueOf(\n         namesystem.dir.getINode(parentPath, DirOp.READ), parentPath);\n     return loadChildren(parent, in, counter);\n   }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "c78e3a7cdd10c40454e9acb06986ba6d8573cb19": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7059. Avoid resolving path multiple times. Contributed by Jing Zhao.\n",
      "commitDate": "12/12/14 3:13 PM",
      "commitName": "c78e3a7cdd10c40454e9acb06986ba6d8573cb19",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "02/12/14 2:53 PM",
      "commitNameOld": "185e0c7b4c056b88f606362c71e4a22aae7076e0",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 10.01,
      "commitsBetweenForRepo": 86,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,8 +1,8 @@\n    private int loadDirectory(DataInput in, Counter counter) throws IOException {\n      String parentPath \u003d FSImageSerialization.readString(in);\n      // Rename .snapshot paths if we\u0027re doing an upgrade\n      parentPath \u003d renameReservedPathsOnUpgrade(parentPath, getLayoutVersion());\n      final INodeDirectory parent \u003d INodeDirectory.valueOf(\n-         namesystem.dir.getNode(parentPath, true), parentPath);\n+         namesystem.dir.getINode(parentPath, true), parentPath);\n      return loadChildren(parent, in, counter);\n    }\n\\ No newline at end of file\n",
      "actualSource": "   private int loadDirectory(DataInput in, Counter counter) throws IOException {\n     String parentPath \u003d FSImageSerialization.readString(in);\n     // Rename .snapshot paths if we\u0027re doing an upgrade\n     parentPath \u003d renameReservedPathsOnUpgrade(parentPath, getLayoutVersion());\n     final INodeDirectory parent \u003d INodeDirectory.valueOf(\n         namesystem.dir.getINode(parentPath, true), parentPath);\n     return loadChildren(parent, in, counter);\n   }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "0689363343a281a6f7f6f395227668bddc2663eb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6304. Consolidate the logic of path resolution in FSDirectory. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1591411 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/04/14 10:44 AM",
      "commitName": "0689363343a281a6f7f6f395227668bddc2663eb",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "23/04/14 10:05 PM",
      "commitNameOld": "f36f0dde8866e2233dad26b38a8d432d2302a51a",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 6.53,
      "commitsBetweenForRepo": 38,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,8 +1,8 @@\n    private int loadDirectory(DataInput in, Counter counter) throws IOException {\n      String parentPath \u003d FSImageSerialization.readString(in);\n      // Rename .snapshot paths if we\u0027re doing an upgrade\n      parentPath \u003d renameReservedPathsOnUpgrade(parentPath, getLayoutVersion());\n      final INodeDirectory parent \u003d INodeDirectory.valueOf(\n-         namesystem.dir.rootDir.getNode(parentPath, true), parentPath);\n+         namesystem.dir.getNode(parentPath, true), parentPath);\n      return loadChildren(parent, in, counter);\n    }\n\\ No newline at end of file\n",
      "actualSource": "   private int loadDirectory(DataInput in, Counter counter) throws IOException {\n     String parentPath \u003d FSImageSerialization.readString(in);\n     // Rename .snapshot paths if we\u0027re doing an upgrade\n     parentPath \u003d renameReservedPathsOnUpgrade(parentPath, getLayoutVersion());\n     final INodeDirectory parent \u003d INodeDirectory.valueOf(\n         namesystem.dir.getNode(parentPath, true), parentPath);\n     return loadChildren(parent, in, counter);\n   }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "d6bd920bba0d7cb77ca76c3a79d1ba1e039da9e5": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5709. Improve NameNode upgrade with existing reserved paths and path components. Contributed by Andrew Wang.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1564645 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/02/14 10:48 PM",
      "commitName": "d6bd920bba0d7cb77ca76c3a79d1ba1e039da9e5",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "16/01/14 5:32 PM",
      "commitNameOld": "a7ec44d41b0ad1fa133408a10caaae32a27ea569",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 19.22,
      "commitsBetweenForRepo": 121,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,6 +1,8 @@\n    private int loadDirectory(DataInput in, Counter counter) throws IOException {\n      String parentPath \u003d FSImageSerialization.readString(in);\n+     // Rename .snapshot paths if we\u0027re doing an upgrade\n+     parentPath \u003d renameReservedPathsOnUpgrade(parentPath, getLayoutVersion());\n      final INodeDirectory parent \u003d INodeDirectory.valueOf(\n          namesystem.dir.rootDir.getNode(parentPath, true), parentPath);\n      return loadChildren(parent, in, counter);\n    }\n\\ No newline at end of file\n",
      "actualSource": "   private int loadDirectory(DataInput in, Counter counter) throws IOException {\n     String parentPath \u003d FSImageSerialization.readString(in);\n     // Rename .snapshot paths if we\u0027re doing an upgrade\n     parentPath \u003d renameReservedPathsOnUpgrade(parentPath, getLayoutVersion());\n     final INodeDirectory parent \u003d INodeDirectory.valueOf(\n         namesystem.dir.rootDir.getNode(parentPath, true), parentPath);\n     return loadChildren(parent, in, counter);\n   }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "da8e962e39bd41b73b53966826c82e741b08010b": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-4372. Track NameNode startup progress. Contributed by Chris Nauroth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1502120 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/07/13 10:35 PM",
      "commitName": "da8e962e39bd41b73b53966826c82e741b08010b",
      "commitAuthor": "Chris Nauroth",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-4372. Track NameNode startup progress. Contributed by Chris Nauroth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1502120 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "10/07/13 10:35 PM",
          "commitName": "da8e962e39bd41b73b53966826c82e741b08010b",
          "commitAuthor": "Chris Nauroth",
          "commitDateOld": "07/07/13 10:29 PM",
          "commitNameOld": "6770de7ec4f73e16740f1723f4e35d2fef2c22c8",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 3.0,
          "commitsBetweenForRepo": 22,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,6 +1,6 @@\n-   private int loadDirectory(DataInput in) throws IOException {\n+   private int loadDirectory(DataInput in, Counter counter) throws IOException {\n      String parentPath \u003d FSImageSerialization.readString(in);\n      final INodeDirectory parent \u003d INodeDirectory.valueOf(\n          namesystem.dir.rootDir.getNode(parentPath, true), parentPath);\n-     return loadChildren(parent, in);\n+     return loadChildren(parent, in, counter);\n    }\n\\ No newline at end of file\n",
          "actualSource": "   private int loadDirectory(DataInput in, Counter counter) throws IOException {\n     String parentPath \u003d FSImageSerialization.readString(in);\n     final INodeDirectory parent \u003d INodeDirectory.valueOf(\n         namesystem.dir.rootDir.getNode(parentPath, true), parentPath);\n     return loadChildren(parent, in, counter);\n   }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
          "extendedDetails": {
            "oldValue": "[in-DataInput]",
            "newValue": "[in-DataInput, counter-Counter]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-4372. Track NameNode startup progress. Contributed by Chris Nauroth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1502120 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "10/07/13 10:35 PM",
          "commitName": "da8e962e39bd41b73b53966826c82e741b08010b",
          "commitAuthor": "Chris Nauroth",
          "commitDateOld": "07/07/13 10:29 PM",
          "commitNameOld": "6770de7ec4f73e16740f1723f4e35d2fef2c22c8",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 3.0,
          "commitsBetweenForRepo": 22,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,6 +1,6 @@\n-   private int loadDirectory(DataInput in) throws IOException {\n+   private int loadDirectory(DataInput in, Counter counter) throws IOException {\n      String parentPath \u003d FSImageSerialization.readString(in);\n      final INodeDirectory parent \u003d INodeDirectory.valueOf(\n          namesystem.dir.rootDir.getNode(parentPath, true), parentPath);\n-     return loadChildren(parent, in);\n+     return loadChildren(parent, in, counter);\n    }\n\\ No newline at end of file\n",
          "actualSource": "   private int loadDirectory(DataInput in, Counter counter) throws IOException {\n     String parentPath \u003d FSImageSerialization.readString(in);\n     final INodeDirectory parent \u003d INodeDirectory.valueOf(\n         namesystem.dir.rootDir.getNode(parentPath, true), parentPath);\n     return loadChildren(parent, in, counter);\n   }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
          "extendedDetails": {}
        }
      ]
    }
  }
}