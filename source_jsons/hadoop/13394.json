{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ErasureCodingWork.java",
  "functionName": "chooseTargets",
  "functionId": "chooseTargets___blockplacement-BlockPlacementPolicy__storagePolicySuite-BlockStoragePolicySuite__excludedNodes-Set__Node__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ErasureCodingWork.java",
  "functionStartLine": 58,
  "functionEndLine": 67,
  "numCommitsSeen": 13,
  "timeTaken": 1299,
  "changeHistory": [
    "96bb6a51ec4a470e9b287c94e377444a9f97c410",
    "d331762f24b3f22f609366740c9c4f449edc61ac",
    "0a152103f19a3e8e1b7f33aeb9dd115ba231d7b7",
    "e54cc2931262bf49682a8323da9811976218c03b"
  ],
  "changeHistoryShort": {
    "96bb6a51ec4a470e9b287c94e377444a9f97c410": "Ybodychange",
    "d331762f24b3f22f609366740c9c4f449edc61ac": "Ybodychange",
    "0a152103f19a3e8e1b7f33aeb9dd115ba231d7b7": "Ybodychange",
    "e54cc2931262bf49682a8323da9811976218c03b": "Ybodychange"
  },
  "changeHistoryDetails": {
    "96bb6a51ec4a470e9b287c94e377444a9f97c410": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10453. ReplicationMonitor thread could stuck for long time due to the race between replication and delete of same file in a large cluster.. Contributed by He Xiaoqiao.\n",
      "commitDate": "12/02/18 7:17 AM",
      "commitName": "96bb6a51ec4a470e9b287c94e377444a9f97c410",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "28/11/17 5:14 PM",
      "commitNameOld": "d331762f24b3f22f609366740c9c4f449edc61ac",
      "commitAuthorOld": "Konstantin V Shvachko",
      "daysBetweenCommits": 75.59,
      "commitsBetweenForRepo": 449,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,10 @@\n   void chooseTargets(BlockPlacementPolicy blockplacement,\n       BlockStoragePolicySuite storagePolicySuite,\n       Set\u003cNode\u003e excludedNodes) {\n     // TODO: new placement policy for EC considering multiple writers\n     DatanodeStorageInfo[] chosenTargets \u003d blockplacement.chooseTarget(\n         getSrcPath(), getAdditionalReplRequired(), getSrcNodes()[0],\n-        getLiveReplicaStorages(), false, excludedNodes,\n-        getBlock().getNumBytes(),\n+        getLiveReplicaStorages(), false, excludedNodes, getBlockSize(),\n         storagePolicySuite.getPolicy(getStoragePolicyID()), null);\n     setTargets(chosenTargets);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void chooseTargets(BlockPlacementPolicy blockplacement,\n      BlockStoragePolicySuite storagePolicySuite,\n      Set\u003cNode\u003e excludedNodes) {\n    // TODO: new placement policy for EC considering multiple writers\n    DatanodeStorageInfo[] chosenTargets \u003d blockplacement.chooseTarget(\n        getSrcPath(), getAdditionalReplRequired(), getSrcNodes()[0],\n        getLiveReplicaStorages(), false, excludedNodes, getBlockSize(),\n        storagePolicySuite.getPolicy(getStoragePolicyID()), null);\n    setTargets(chosenTargets);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ErasureCodingWork.java",
      "extendedDetails": {}
    },
    "d331762f24b3f22f609366740c9c4f449edc61ac": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12832. INode.getFullPathName may throw ArrayIndexOutOfBoundsException lead to NameNode exit. Contribuited by Konstantin Shvachko.",
      "commitDate": "28/11/17 5:14 PM",
      "commitName": "d331762f24b3f22f609366740c9c4f449edc61ac",
      "commitAuthor": "Konstantin V Shvachko",
      "commitDateOld": "17/10/16 5:45 PM",
      "commitNameOld": "b61fb267b92b2736920b4bd0c673d31e7632ebb9",
      "commitAuthorOld": "Ming Ma",
      "daysBetweenCommits": 407.02,
      "commitsBetweenForRepo": 2682,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,11 @@\n   void chooseTargets(BlockPlacementPolicy blockplacement,\n       BlockStoragePolicySuite storagePolicySuite,\n       Set\u003cNode\u003e excludedNodes) {\n     // TODO: new placement policy for EC considering multiple writers\n     DatanodeStorageInfo[] chosenTargets \u003d blockplacement.chooseTarget(\n-        getBc().getName(), getAdditionalReplRequired(), getSrcNodes()[0],\n+        getSrcPath(), getAdditionalReplRequired(), getSrcNodes()[0],\n         getLiveReplicaStorages(), false, excludedNodes,\n         getBlock().getNumBytes(),\n-        storagePolicySuite.getPolicy(getBc().getStoragePolicyID()), null);\n+        storagePolicySuite.getPolicy(getStoragePolicyID()), null);\n     setTargets(chosenTargets);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void chooseTargets(BlockPlacementPolicy blockplacement,\n      BlockStoragePolicySuite storagePolicySuite,\n      Set\u003cNode\u003e excludedNodes) {\n    // TODO: new placement policy for EC considering multiple writers\n    DatanodeStorageInfo[] chosenTargets \u003d blockplacement.chooseTarget(\n        getSrcPath(), getAdditionalReplRequired(), getSrcNodes()[0],\n        getLiveReplicaStorages(), false, excludedNodes,\n        getBlock().getNumBytes(),\n        storagePolicySuite.getPolicy(getStoragePolicyID()), null);\n    setTargets(chosenTargets);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ErasureCodingWork.java",
      "extendedDetails": {}
    },
    "0a152103f19a3e8e1b7f33aeb9dd115ba231d7b7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3702. Add an option for NOT writing the blocks locally if there is a datanode on the same box as the client. (Contributed by Lei (Eddy) Xu)\n",
      "commitDate": "27/04/16 2:22 PM",
      "commitName": "0a152103f19a3e8e1b7f33aeb9dd115ba231d7b7",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "08/03/16 10:24 AM",
      "commitNameOld": "743a99f2dbc9a27e19f92ff3551937d90dba2e89",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 50.12,
      "commitsBetweenForRepo": 300,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,11 @@\n   void chooseTargets(BlockPlacementPolicy blockplacement,\n       BlockStoragePolicySuite storagePolicySuite,\n       Set\u003cNode\u003e excludedNodes) {\n     // TODO: new placement policy for EC considering multiple writers\n     DatanodeStorageInfo[] chosenTargets \u003d blockplacement.chooseTarget(\n         getBc().getName(), getAdditionalReplRequired(), getSrcNodes()[0],\n         getLiveReplicaStorages(), false, excludedNodes,\n         getBlock().getNumBytes(),\n-        storagePolicySuite.getPolicy(getBc().getStoragePolicyID()));\n+        storagePolicySuite.getPolicy(getBc().getStoragePolicyID()), null);\n     setTargets(chosenTargets);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void chooseTargets(BlockPlacementPolicy blockplacement,\n      BlockStoragePolicySuite storagePolicySuite,\n      Set\u003cNode\u003e excludedNodes) {\n    // TODO: new placement policy for EC considering multiple writers\n    DatanodeStorageInfo[] chosenTargets \u003d blockplacement.chooseTarget(\n        getBc().getName(), getAdditionalReplRequired(), getSrcNodes()[0],\n        getLiveReplicaStorages(), false, excludedNodes,\n        getBlock().getNumBytes(),\n        storagePolicySuite.getPolicy(getBc().getStoragePolicyID()), null);\n    setTargets(chosenTargets);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ErasureCodingWork.java",
      "extendedDetails": {}
    },
    "e54cc2931262bf49682a8323da9811976218c03b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9818. Correctly handle EC reconstruction work caused by not enough racks. Contributed by Jing Zhao.\n",
      "commitDate": "19/02/16 7:02 PM",
      "commitName": "e54cc2931262bf49682a8323da9811976218c03b",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "09/02/16 2:43 PM",
      "commitNameOld": "a0fb2eff9b71e2e2c0e53262773b34bed82585d4",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 10.18,
      "commitsBetweenForRepo": 77,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,11 @@\n   void chooseTargets(BlockPlacementPolicy blockplacement,\n       BlockStoragePolicySuite storagePolicySuite,\n       Set\u003cNode\u003e excludedNodes) {\n-    try {\n-      // TODO: new placement policy for EC considering multiple writers\n-      DatanodeStorageInfo[] chosenTargets \u003d blockplacement.chooseTarget(\n-          getBc().getName(), getAdditionalReplRequired(), getSrcNodes()[0],\n-          getLiveReplicaStorages(), false, excludedNodes,\n-          getBlock().getNumBytes(),\n-          storagePolicySuite.getPolicy(getBc().getStoragePolicyID()));\n-      setTargets(chosenTargets);\n-    } finally {\n-    }\n+    // TODO: new placement policy for EC considering multiple writers\n+    DatanodeStorageInfo[] chosenTargets \u003d blockplacement.chooseTarget(\n+        getBc().getName(), getAdditionalReplRequired(), getSrcNodes()[0],\n+        getLiveReplicaStorages(), false, excludedNodes,\n+        getBlock().getNumBytes(),\n+        storagePolicySuite.getPolicy(getBc().getStoragePolicyID()));\n+    setTargets(chosenTargets);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void chooseTargets(BlockPlacementPolicy blockplacement,\n      BlockStoragePolicySuite storagePolicySuite,\n      Set\u003cNode\u003e excludedNodes) {\n    // TODO: new placement policy for EC considering multiple writers\n    DatanodeStorageInfo[] chosenTargets \u003d blockplacement.chooseTarget(\n        getBc().getName(), getAdditionalReplRequired(), getSrcNodes()[0],\n        getLiveReplicaStorages(), false, excludedNodes,\n        getBlock().getNumBytes(),\n        storagePolicySuite.getPolicy(getBc().getStoragePolicyID()));\n    setTargets(chosenTargets);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ErasureCodingWork.java",
      "extendedDetails": {}
    }
  }
}