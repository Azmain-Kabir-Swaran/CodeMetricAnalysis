{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FileDistributionVisitor.java",
  "functionName": "output",
  "functionId": "output",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/FileDistributionVisitor.java",
  "functionStartLine": 117,
  "functionEndLine": 140,
  "numCommitsSeen": 8,
  "timeTaken": 2316,
  "changeHistory": [
    "63f594892ecd4687e37a99790288e36eb278849f",
    "97f58955a6045b373ab73653bf26ab5922b00cf3"
  ],
  "changeHistoryShort": {
    "63f594892ecd4687e37a99790288e36eb278849f": "Ybodychange",
    "97f58955a6045b373ab73653bf26ab5922b00cf3": "Yintroduced"
  },
  "changeHistoryDetails": {
    "63f594892ecd4687e37a99790288e36eb278849f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10778. Add -format option to make the output of FileDistribution processor human-readable in OfflineImageViewer.\n",
      "commitDate": "07/09/16 11:13 PM",
      "commitName": "63f594892ecd4687e37a99790288e36eb278849f",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "28/07/16 11:39 PM",
      "commitNameOld": "204a2055b1b9270ae13ea03b7aeac62b65166efd",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 40.98,
      "commitsBetweenForRepo": 264,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,24 @@\n   private void output() throws IOException {\n     // write the distribution into the output file\n-    write(\"Size\\tNumFiles\\n\");\n-    for(int i \u003d 0; i \u003c distribution.length; i++)\n-      write(((long)i * step) + \"\\t\" + distribution[i] + \"\\n\");\n+    write((formatOutput ? \"Size Range\" : \"Size\") + \"\\tNumFiles\\n\");\n+    for (int i \u003d 0; i \u003c distribution.length; i++) {\n+      if (distribution[i] \u003e 0) {\n+        if (formatOutput) {\n+          write((i \u003d\u003d 0 ? \"[\" : \"(\")\n+              + StringUtils.byteDesc(((long) (i \u003d\u003d 0 ? 0 : i - 1) * step))\n+              + \", \"\n+              + StringUtils.byteDesc((long)\n+                  (i \u003d\u003d distribution.length - 1 ? maxFileSize : i * step))\n+                  + \"]\\t\"\n+              + distribution[i] + \"\\n\");\n+        } else {\n+          write(((long) i * step) + \"\\t\" + distribution[i] + \"\\n\");\n+        }\n+      }\n+    }\n     System.out.println(\"totalFiles \u003d \" + totalFiles);\n     System.out.println(\"totalDirectories \u003d \" + totalDirectories);\n     System.out.println(\"totalBlocks \u003d \" + totalBlocks);\n     System.out.println(\"totalSpace \u003d \" + totalSpace);\n     System.out.println(\"maxFileSize \u003d \" + maxFileSize);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void output() throws IOException {\n    // write the distribution into the output file\n    write((formatOutput ? \"Size Range\" : \"Size\") + \"\\tNumFiles\\n\");\n    for (int i \u003d 0; i \u003c distribution.length; i++) {\n      if (distribution[i] \u003e 0) {\n        if (formatOutput) {\n          write((i \u003d\u003d 0 ? \"[\" : \"(\")\n              + StringUtils.byteDesc(((long) (i \u003d\u003d 0 ? 0 : i - 1) * step))\n              + \", \"\n              + StringUtils.byteDesc((long)\n                  (i \u003d\u003d distribution.length - 1 ? maxFileSize : i * step))\n                  + \"]\\t\"\n              + distribution[i] + \"\\n\");\n        } else {\n          write(((long) i * step) + \"\\t\" + distribution[i] + \"\\n\");\n        }\n      }\n    }\n    System.out.println(\"totalFiles \u003d \" + totalFiles);\n    System.out.println(\"totalDirectories \u003d \" + totalDirectories);\n    System.out.println(\"totalBlocks \u003d \" + totalBlocks);\n    System.out.println(\"totalSpace \u003d \" + totalSpace);\n    System.out.println(\"maxFileSize \u003d \" + maxFileSize);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/FileDistributionVisitor.java",
      "extendedDetails": {}
    },
    "97f58955a6045b373ab73653bf26ab5922b00cf3": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-6293. Issues with OIV processing PB-based fsimages. Contributed by Kihwal Lee.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1594439 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/05/14 6:15 PM",
      "commitName": "97f58955a6045b373ab73653bf26ab5922b00cf3",
      "commitAuthor": "Kihwal Lee",
      "diff": "@@ -0,0 +1,11 @@\n+  private void output() throws IOException {\n+    // write the distribution into the output file\n+    write(\"Size\\tNumFiles\\n\");\n+    for(int i \u003d 0; i \u003c distribution.length; i++)\n+      write(((long)i * step) + \"\\t\" + distribution[i] + \"\\n\");\n+    System.out.println(\"totalFiles \u003d \" + totalFiles);\n+    System.out.println(\"totalDirectories \u003d \" + totalDirectories);\n+    System.out.println(\"totalBlocks \u003d \" + totalBlocks);\n+    System.out.println(\"totalSpace \u003d \" + totalSpace);\n+    System.out.println(\"maxFileSize \u003d \" + maxFileSize);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void output() throws IOException {\n    // write the distribution into the output file\n    write(\"Size\\tNumFiles\\n\");\n    for(int i \u003d 0; i \u003c distribution.length; i++)\n      write(((long)i * step) + \"\\t\" + distribution[i] + \"\\n\");\n    System.out.println(\"totalFiles \u003d \" + totalFiles);\n    System.out.println(\"totalDirectories \u003d \" + totalDirectories);\n    System.out.println(\"totalBlocks \u003d \" + totalBlocks);\n    System.out.println(\"totalSpace \u003d \" + totalSpace);\n    System.out.println(\"maxFileSize \u003d \" + maxFileSize);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/FileDistributionVisitor.java"
    }
  }
}