{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "HttpFSUtils.java",
  "functionName": "createURL",
  "functionId": "createURL___path-Path__params-Map__String,String__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-httpfs/src/main/java/org/apache/hadoop/fs/http/client/HttpFSUtils.java",
  "functionStartLine": 64,
  "functionEndLine": 67,
  "numCommitsSeen": 11,
  "timeTaken": 1382,
  "changeHistory": [
    "46162a213f60f915df76c60b0412f45a021e1e7e",
    "5e09ae1633fb7fcf293ea10e663064e566c70909",
    "4d4560189adccb941a3dc5eee7add134adbf6519"
  ],
  "changeHistoryShort": {
    "46162a213f60f915df76c60b0412f45a021e1e7e": "Ybodychange",
    "5e09ae1633fb7fcf293ea10e663064e566c70909": "Ymultichange(Yrename,Ybodychange)",
    "4d4560189adccb941a3dc5eee7add134adbf6519": "Yintroduced"
  },
  "changeHistoryDetails": {
    "46162a213f60f915df76c60b0412f45a021e1e7e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6430. HTTPFS - Implement XAttr support. (Yi Liu via tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1605118 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/06/14 8:59 AM",
      "commitName": "46162a213f60f915df76c60b0412f45a021e1e7e",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "22/01/14 12:38 PM",
      "commitNameOld": "5e09ae1633fb7fcf293ea10e663064e566c70909",
      "commitAuthorOld": "Alejandro Abdelnur",
      "daysBetweenCommits": 152.81,
      "commitsBetweenForRepo": 1097,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,4 @@\n   static URL createURL(Path path, Map\u003cString, String\u003e params)\n     throws IOException {\n-    URI uri \u003d path.toUri();\n-    String realScheme;\n-    if (uri.getScheme().equalsIgnoreCase(HttpFSFileSystem.SCHEME)) {\n-      realScheme \u003d \"http\";\n-    } else if (uri.getScheme().equalsIgnoreCase(HttpsFSFileSystem.SCHEME)) {\n-      realScheme \u003d \"https\";\n-\n-    } else {\n-      throw new IllegalArgumentException(MessageFormat.format(\n-        \"Invalid scheme [{0}] it should be \u0027\" + HttpFSFileSystem.SCHEME + \"\u0027 \" +\n-            \"or \u0027\" + HttpsFSFileSystem.SCHEME + \"\u0027\", uri));\n-    }\n-    StringBuilder sb \u003d new StringBuilder();\n-    sb.append(realScheme).append(\"://\").append(uri.getAuthority()).\n-      append(SERVICE_PATH).append(uri.getPath());\n-\n-    String separator \u003d \"?\";\n-    for (Map.Entry\u003cString, String\u003e entry : params.entrySet()) {\n-      sb.append(separator).append(entry.getKey()).append(\"\u003d\").\n-        append(URLEncoder.encode(entry.getValue(), \"UTF8\"));\n-      separator \u003d \"\u0026\";\n-    }\n-    return new URL(sb.toString());\n+    return createURL(path, params, null);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static URL createURL(Path path, Map\u003cString, String\u003e params)\n    throws IOException {\n    return createURL(path, params, null);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-httpfs/src/main/java/org/apache/hadoop/fs/http/client/HttpFSUtils.java",
      "extendedDetails": {}
    },
    "5e09ae1633fb7fcf293ea10e663064e566c70909": {
      "type": "Ymultichange(Yrename,Ybodychange)",
      "commitMessage": "HDFS-5703. Add support for HTTPS and swebhdfs to HttpFS. (tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1560504 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/01/14 12:38 PM",
      "commitName": "5e09ae1633fb7fcf293ea10e663064e566c70909",
      "commitAuthor": "Alejandro Abdelnur",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "HDFS-5703. Add support for HTTPS and swebhdfs to HttpFS. (tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1560504 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "22/01/14 12:38 PM",
          "commitName": "5e09ae1633fb7fcf293ea10e663064e566c70909",
          "commitAuthor": "Alejandro Abdelnur",
          "commitDateOld": "01/08/12 4:14 PM",
          "commitNameOld": "08e89662170010dd619c0df859c670cb37b630dd",
          "commitAuthorOld": "Alejandro Abdelnur",
          "daysBetweenCommits": 538.89,
          "commitsBetweenForRepo": 3159,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,22 +1,26 @@\n-  static URL createHttpURL(Path path, Map\u003cString, String\u003e params)\n+  static URL createURL(Path path, Map\u003cString, String\u003e params)\n     throws IOException {\n     URI uri \u003d path.toUri();\n     String realScheme;\n     if (uri.getScheme().equalsIgnoreCase(HttpFSFileSystem.SCHEME)) {\n       realScheme \u003d \"http\";\n+    } else if (uri.getScheme().equalsIgnoreCase(HttpsFSFileSystem.SCHEME)) {\n+      realScheme \u003d \"https\";\n+\n     } else {\n       throw new IllegalArgumentException(MessageFormat.format(\n-        \"Invalid scheme [{0}] it should be \u0027webhdfs\u0027\", uri));\n+        \"Invalid scheme [{0}] it should be \u0027\" + HttpFSFileSystem.SCHEME + \"\u0027 \" +\n+            \"or \u0027\" + HttpsFSFileSystem.SCHEME + \"\u0027\", uri));\n     }\n     StringBuilder sb \u003d new StringBuilder();\n     sb.append(realScheme).append(\"://\").append(uri.getAuthority()).\n       append(SERVICE_PATH).append(uri.getPath());\n \n     String separator \u003d \"?\";\n     for (Map.Entry\u003cString, String\u003e entry : params.entrySet()) {\n       sb.append(separator).append(entry.getKey()).append(\"\u003d\").\n         append(URLEncoder.encode(entry.getValue(), \"UTF8\"));\n       separator \u003d \"\u0026\";\n     }\n     return new URL(sb.toString());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static URL createURL(Path path, Map\u003cString, String\u003e params)\n    throws IOException {\n    URI uri \u003d path.toUri();\n    String realScheme;\n    if (uri.getScheme().equalsIgnoreCase(HttpFSFileSystem.SCHEME)) {\n      realScheme \u003d \"http\";\n    } else if (uri.getScheme().equalsIgnoreCase(HttpsFSFileSystem.SCHEME)) {\n      realScheme \u003d \"https\";\n\n    } else {\n      throw new IllegalArgumentException(MessageFormat.format(\n        \"Invalid scheme [{0}] it should be \u0027\" + HttpFSFileSystem.SCHEME + \"\u0027 \" +\n            \"or \u0027\" + HttpsFSFileSystem.SCHEME + \"\u0027\", uri));\n    }\n    StringBuilder sb \u003d new StringBuilder();\n    sb.append(realScheme).append(\"://\").append(uri.getAuthority()).\n      append(SERVICE_PATH).append(uri.getPath());\n\n    String separator \u003d \"?\";\n    for (Map.Entry\u003cString, String\u003e entry : params.entrySet()) {\n      sb.append(separator).append(entry.getKey()).append(\"\u003d\").\n        append(URLEncoder.encode(entry.getValue(), \"UTF8\"));\n      separator \u003d \"\u0026\";\n    }\n    return new URL(sb.toString());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-httpfs/src/main/java/org/apache/hadoop/fs/http/client/HttpFSUtils.java",
          "extendedDetails": {
            "oldValue": "createHttpURL",
            "newValue": "createURL"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5703. Add support for HTTPS and swebhdfs to HttpFS. (tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1560504 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "22/01/14 12:38 PM",
          "commitName": "5e09ae1633fb7fcf293ea10e663064e566c70909",
          "commitAuthor": "Alejandro Abdelnur",
          "commitDateOld": "01/08/12 4:14 PM",
          "commitNameOld": "08e89662170010dd619c0df859c670cb37b630dd",
          "commitAuthorOld": "Alejandro Abdelnur",
          "daysBetweenCommits": 538.89,
          "commitsBetweenForRepo": 3159,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,22 +1,26 @@\n-  static URL createHttpURL(Path path, Map\u003cString, String\u003e params)\n+  static URL createURL(Path path, Map\u003cString, String\u003e params)\n     throws IOException {\n     URI uri \u003d path.toUri();\n     String realScheme;\n     if (uri.getScheme().equalsIgnoreCase(HttpFSFileSystem.SCHEME)) {\n       realScheme \u003d \"http\";\n+    } else if (uri.getScheme().equalsIgnoreCase(HttpsFSFileSystem.SCHEME)) {\n+      realScheme \u003d \"https\";\n+\n     } else {\n       throw new IllegalArgumentException(MessageFormat.format(\n-        \"Invalid scheme [{0}] it should be \u0027webhdfs\u0027\", uri));\n+        \"Invalid scheme [{0}] it should be \u0027\" + HttpFSFileSystem.SCHEME + \"\u0027 \" +\n+            \"or \u0027\" + HttpsFSFileSystem.SCHEME + \"\u0027\", uri));\n     }\n     StringBuilder sb \u003d new StringBuilder();\n     sb.append(realScheme).append(\"://\").append(uri.getAuthority()).\n       append(SERVICE_PATH).append(uri.getPath());\n \n     String separator \u003d \"?\";\n     for (Map.Entry\u003cString, String\u003e entry : params.entrySet()) {\n       sb.append(separator).append(entry.getKey()).append(\"\u003d\").\n         append(URLEncoder.encode(entry.getValue(), \"UTF8\"));\n       separator \u003d \"\u0026\";\n     }\n     return new URL(sb.toString());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static URL createURL(Path path, Map\u003cString, String\u003e params)\n    throws IOException {\n    URI uri \u003d path.toUri();\n    String realScheme;\n    if (uri.getScheme().equalsIgnoreCase(HttpFSFileSystem.SCHEME)) {\n      realScheme \u003d \"http\";\n    } else if (uri.getScheme().equalsIgnoreCase(HttpsFSFileSystem.SCHEME)) {\n      realScheme \u003d \"https\";\n\n    } else {\n      throw new IllegalArgumentException(MessageFormat.format(\n        \"Invalid scheme [{0}] it should be \u0027\" + HttpFSFileSystem.SCHEME + \"\u0027 \" +\n            \"or \u0027\" + HttpsFSFileSystem.SCHEME + \"\u0027\", uri));\n    }\n    StringBuilder sb \u003d new StringBuilder();\n    sb.append(realScheme).append(\"://\").append(uri.getAuthority()).\n      append(SERVICE_PATH).append(uri.getPath());\n\n    String separator \u003d \"?\";\n    for (Map.Entry\u003cString, String\u003e entry : params.entrySet()) {\n      sb.append(separator).append(entry.getKey()).append(\"\u003d\").\n        append(URLEncoder.encode(entry.getValue(), \"UTF8\"));\n      separator \u003d \"\u0026\";\n    }\n    return new URL(sb.toString());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-httpfs/src/main/java/org/apache/hadoop/fs/http/client/HttpFSUtils.java",
          "extendedDetails": {}
        }
      ]
    },
    "4d4560189adccb941a3dc5eee7add134adbf6519": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-3113. httpfs does not support delegation tokens. (tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1365988 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/07/12 6:39 AM",
      "commitName": "4d4560189adccb941a3dc5eee7add134adbf6519",
      "commitAuthor": "Alejandro Abdelnur",
      "diff": "@@ -0,0 +1,22 @@\n+  static URL createHttpURL(Path path, Map\u003cString, String\u003e params)\n+    throws IOException {\n+    URI uri \u003d path.toUri();\n+    String realScheme;\n+    if (uri.getScheme().equalsIgnoreCase(HttpFSFileSystem.SCHEME)) {\n+      realScheme \u003d \"http\";\n+    } else {\n+      throw new IllegalArgumentException(MessageFormat.format(\n+        \"Invalid scheme [{0}] it should be \u0027webhdfs\u0027\", uri));\n+    }\n+    StringBuilder sb \u003d new StringBuilder();\n+    sb.append(realScheme).append(\"://\").append(uri.getAuthority()).\n+      append(SERVICE_PATH).append(uri.getPath());\n+\n+    String separator \u003d \"?\";\n+    for (Map.Entry\u003cString, String\u003e entry : params.entrySet()) {\n+      sb.append(separator).append(entry.getKey()).append(\"\u003d\").\n+        append(URLEncoder.encode(entry.getValue(), \"UTF8\"));\n+      separator \u003d \"\u0026\";\n+    }\n+    return new URL(sb.toString());\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  static URL createHttpURL(Path path, Map\u003cString, String\u003e params)\n    throws IOException {\n    URI uri \u003d path.toUri();\n    String realScheme;\n    if (uri.getScheme().equalsIgnoreCase(HttpFSFileSystem.SCHEME)) {\n      realScheme \u003d \"http\";\n    } else {\n      throw new IllegalArgumentException(MessageFormat.format(\n        \"Invalid scheme [{0}] it should be \u0027webhdfs\u0027\", uri));\n    }\n    StringBuilder sb \u003d new StringBuilder();\n    sb.append(realScheme).append(\"://\").append(uri.getAuthority()).\n      append(SERVICE_PATH).append(uri.getPath());\n\n    String separator \u003d \"?\";\n    for (Map.Entry\u003cString, String\u003e entry : params.entrySet()) {\n      sb.append(separator).append(entry.getKey()).append(\"\u003d\").\n        append(URLEncoder.encode(entry.getValue(), \"UTF8\"));\n      separator \u003d \"\u0026\";\n    }\n    return new URL(sb.toString());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-httpfs/src/main/java/org/apache/hadoop/fs/http/client/HttpFSUtils.java"
    }
  }
}